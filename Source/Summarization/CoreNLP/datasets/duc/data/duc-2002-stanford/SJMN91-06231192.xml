<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="SJMN91-06231192">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>NIXON, disco, LSD -- it&amp;apost;s no surprise, really, that those &amp;apost;70s rejects have staged comebacks But Yoko Ono?</content>
      <tokens>
        <token id="1" string="NIXON" lemma="NIXON" stem="nixon" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="disco" lemma="disco" stem="disco" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="LSD" lemma="LSD" stem="lsd" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="surprise" lemma="surprise" stem="surpris" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="'70s" lemma="'70" stem="'70" pos="NNS" type="Word" isStopWord="false" ner="SET" is_referenced="true" is_refers="false" />
        <token id="17" string="rejects" lemma="reject" stem="reject" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="staged" lemma="stage" stem="stage" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="comebacks" lemma="comeback" stem="comeback" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Yoko" lemma="Yoko" stem="yoko" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="23" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="24" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (NP (NP (NNP NIXON)) (, ,) (NP (NN disco)) (, ,) (NP (NNP LSD))) (: --) (SINV (S (NP (PRP it)) (VP (VBZ 's) (NP (DT no) (NN surprise)) (, ,) (ADVP (RB really)) (, ,) (SBAR (IN that) (S (NP (DT those) (NNS '70s)) (VP (VBZ rejects)))))) (VP (VBP have) (VP (VBN staged) (NP (NNS comebacks)) (ADVP (CC But)))) (NP (NNP Yoko) (NNP Ono))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="NIXON , disco , LSD" type="NP">
          <tokens>
            <token id="1" string="NIXON" />
            <token id="2" string="," />
            <token id="3" string="disco" />
            <token id="4" string="," />
            <token id="5" string="LSD" />
          </tokens>
        </chunking>
        <chunking id="2" string="that those '70s rejects" type="SBAR">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="those" />
            <token id="16" string="'70s" />
            <token id="17" string="rejects" />
          </tokens>
        </chunking>
        <chunking id="3" string="'s no surprise , really , that those '70s rejects" type="VP">
          <tokens>
            <token id="8" string="'s" />
            <token id="9" string="no" />
            <token id="10" string="surprise" />
            <token id="11" string="," />
            <token id="12" string="really" />
            <token id="13" string="," />
            <token id="14" string="that" />
            <token id="15" string="those" />
            <token id="16" string="'70s" />
            <token id="17" string="rejects" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="disco" type="NP">
          <tokens>
            <token id="3" string="disco" />
          </tokens>
        </chunking>
        <chunking id="6" string="comebacks" type="NP">
          <tokens>
            <token id="20" string="comebacks" />
          </tokens>
        </chunking>
        <chunking id="7" string="have staged comebacks But" type="VP">
          <tokens>
            <token id="18" string="have" />
            <token id="19" string="staged" />
            <token id="20" string="comebacks" />
            <token id="21" string="But" />
          </tokens>
        </chunking>
        <chunking id="8" string="no surprise" type="NP">
          <tokens>
            <token id="9" string="no" />
            <token id="10" string="surprise" />
          </tokens>
        </chunking>
        <chunking id="9" string="NIXON" type="NP">
          <tokens>
            <token id="1" string="NIXON" />
          </tokens>
        </chunking>
        <chunking id="10" string="rejects" type="VP">
          <tokens>
            <token id="17" string="rejects" />
          </tokens>
        </chunking>
        <chunking id="11" string="those '70s" type="NP">
          <tokens>
            <token id="15" string="those" />
            <token id="16" string="'70s" />
          </tokens>
        </chunking>
        <chunking id="12" string="Yoko Ono" type="NP">
          <tokens>
            <token id="22" string="Yoko" />
            <token id="23" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="13" string="staged comebacks But" type="VP">
          <tokens>
            <token id="19" string="staged" />
            <token id="20" string="comebacks" />
            <token id="21" string="But" />
          </tokens>
        </chunking>
        <chunking id="14" string="LSD" type="NP">
          <tokens>
            <token id="5" string="LSD" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">NIXON</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="1">NIXON</governor>
          <dependent id="3">disco</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="1">NIXON</governor>
          <dependent id="5">LSD</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">surprise</governor>
          <dependent id="7">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">surprise</governor>
          <dependent id="8">'s</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="10">surprise</governor>
          <dependent id="9">no</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="19">staged</governor>
          <dependent id="10">surprise</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">surprise</governor>
          <dependent id="12">really</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">rejects</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">'70s</governor>
          <dependent id="15">those</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">rejects</governor>
          <dependent id="16">'70s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">surprise</governor>
          <dependent id="17">rejects</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">staged</governor>
          <dependent id="18">have</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="1">NIXON</governor>
          <dependent id="19">staged</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">staged</governor>
          <dependent id="20">comebacks</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">staged</governor>
          <dependent id="21">But</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Ono</governor>
          <dependent id="22">Yoko</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">staged</governor>
          <dependent id="23">Ono</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="'70s" type="SET" score="0.0">
          <tokens>
            <token id="16" string="'70s" />
          </tokens>
        </entity>
        <entity id="2" string="NIXON" type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="NIXON" />
          </tokens>
        </entity>
        <entity id="3" string="Yoko Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Yoko" />
            <token id="23" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>The flaky avant-garde artist whose idea of music was to scream inside a plastic bag while John Lennon played guitar?</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="flaky" lemma="flaky" stem="flaki" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="avant-garde" lemma="avant-garde" stem="avant-gard" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="artist" lemma="artist" stem="artist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="whose" lemma="whose" stem="whose" pos="WP$" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="idea" lemma="idea" stem="idea" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="music" lemma="music" stem="music" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="scream" lemma="scream" stem="scream" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="inside" lemma="inside" stem="insid" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="plastic" lemma="plastic" stem="plastic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="bag" lemma="bag" stem="bag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="18" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="19" string="played" lemma="play" stem="plai" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="guitar" lemma="guitar" stem="guitar" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (NP (NP (DT The) (JJ flaky) (JJ avant-garde) (NN artist)) (SBAR (WHNP (WHNP (WP$ whose) (NN idea)) (PP (IN of) (NP (NN music)))) (S (VP (VBD was) (S (VP (TO to) (VP (VB scream) (PP (IN inside) (NP (DT a) (JJ plastic) (NN bag))) (SBAR (IN while) (S (NP (NNP John) (NNP Lennon)) (VP (VBD played) (NP (NN guitar)))))))))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="John Lennon" type="NP">
          <tokens>
            <token id="17" string="John" />
            <token id="18" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="2" string="to scream inside a plastic bag while John Lennon played guitar" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="scream" />
            <token id="12" string="inside" />
            <token id="13" string="a" />
            <token id="14" string="plastic" />
            <token id="15" string="bag" />
            <token id="16" string="while" />
            <token id="17" string="John" />
            <token id="18" string="Lennon" />
            <token id="19" string="played" />
            <token id="20" string="guitar" />
          </tokens>
        </chunking>
        <chunking id="3" string="music" type="NP">
          <tokens>
            <token id="8" string="music" />
          </tokens>
        </chunking>
        <chunking id="4" string="was to scream inside a plastic bag while John Lennon played guitar" type="VP">
          <tokens>
            <token id="9" string="was" />
            <token id="10" string="to" />
            <token id="11" string="scream" />
            <token id="12" string="inside" />
            <token id="13" string="a" />
            <token id="14" string="plastic" />
            <token id="15" string="bag" />
            <token id="16" string="while" />
            <token id="17" string="John" />
            <token id="18" string="Lennon" />
            <token id="19" string="played" />
            <token id="20" string="guitar" />
          </tokens>
        </chunking>
        <chunking id="5" string="played guitar" type="VP">
          <tokens>
            <token id="19" string="played" />
            <token id="20" string="guitar" />
          </tokens>
        </chunking>
        <chunking id="6" string="a plastic bag" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="plastic" />
            <token id="15" string="bag" />
          </tokens>
        </chunking>
        <chunking id="7" string="whose idea of music was to scream inside a plastic bag while John Lennon played guitar" type="SBAR">
          <tokens>
            <token id="5" string="whose" />
            <token id="6" string="idea" />
            <token id="7" string="of" />
            <token id="8" string="music" />
            <token id="9" string="was" />
            <token id="10" string="to" />
            <token id="11" string="scream" />
            <token id="12" string="inside" />
            <token id="13" string="a" />
            <token id="14" string="plastic" />
            <token id="15" string="bag" />
            <token id="16" string="while" />
            <token id="17" string="John" />
            <token id="18" string="Lennon" />
            <token id="19" string="played" />
            <token id="20" string="guitar" />
          </tokens>
        </chunking>
        <chunking id="8" string="The flaky avant-garde artist" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="flaky" />
            <token id="3" string="avant-garde" />
            <token id="4" string="artist" />
          </tokens>
        </chunking>
        <chunking id="9" string="The flaky avant-garde artist whose idea of music was to scream inside a plastic bag while John Lennon played guitar" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="flaky" />
            <token id="3" string="avant-garde" />
            <token id="4" string="artist" />
            <token id="5" string="whose" />
            <token id="6" string="idea" />
            <token id="7" string="of" />
            <token id="8" string="music" />
            <token id="9" string="was" />
            <token id="10" string="to" />
            <token id="11" string="scream" />
            <token id="12" string="inside" />
            <token id="13" string="a" />
            <token id="14" string="plastic" />
            <token id="15" string="bag" />
            <token id="16" string="while" />
            <token id="17" string="John" />
            <token id="18" string="Lennon" />
            <token id="19" string="played" />
            <token id="20" string="guitar" />
          </tokens>
        </chunking>
        <chunking id="10" string="scream inside a plastic bag while John Lennon played guitar" type="VP">
          <tokens>
            <token id="11" string="scream" />
            <token id="12" string="inside" />
            <token id="13" string="a" />
            <token id="14" string="plastic" />
            <token id="15" string="bag" />
            <token id="16" string="while" />
            <token id="17" string="John" />
            <token id="18" string="Lennon" />
            <token id="19" string="played" />
            <token id="20" string="guitar" />
          </tokens>
        </chunking>
        <chunking id="11" string="while John Lennon played guitar" type="SBAR">
          <tokens>
            <token id="16" string="while" />
            <token id="17" string="John" />
            <token id="18" string="Lennon" />
            <token id="19" string="played" />
            <token id="20" string="guitar" />
          </tokens>
        </chunking>
        <chunking id="12" string="guitar" type="NP">
          <tokens>
            <token id="20" string="guitar" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">artist</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">artist</governor>
          <dependent id="2">flaky</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">artist</governor>
          <dependent id="3">avant-garde</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">artist</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">idea</governor>
          <dependent id="5">whose</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">was</governor>
          <dependent id="6">idea</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">music</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">idea</governor>
          <dependent id="8">music</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">artist</governor>
          <dependent id="9">was</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">scream</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">was</governor>
          <dependent id="11">scream</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">bag</governor>
          <dependent id="12">inside</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">bag</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">bag</governor>
          <dependent id="14">plastic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">scream</governor>
          <dependent id="15">bag</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">played</governor>
          <dependent id="16">while</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Lennon</governor>
          <dependent id="17">John</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">played</governor>
          <dependent id="18">Lennon</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">scream</governor>
          <dependent id="19">played</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">played</governor>
          <dependent id="20">guitar</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="John" />
            <token id="18" string="Lennon" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>The Evil One who single-handedly killed the Beatles and destroyed her husband&amp;apost;s talent and ambition?</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Evil" lemma="Evil" stem="evil" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="3" string="One" lemma="one" stem="one" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="single-handedly" lemma="single-handedly" stem="single-handedli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="killed" lemma="kill" stem="kill" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="Beatles" lemma="Beatles" stem="beatl" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="destroyed" lemma="destroy" stem="destroi" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="husband" lemma="husband" stem="husband" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="talent" lemma="talent" stem="talent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="ambition" lemma="ambition" stem="ambit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (NP (NP (DT The) (NNP Evil) (CD One)) (SBAR (WHNP (WP who)) (S (VP (VP (ADVP (RB single-handedly)) (VBD killed) (NP (DT the) (NNPS Beatles))) (CC and) (VP (VBD destroyed) (NP (NP (PRP$ her) (NN husband) (POS 's)) (NN talent) (CC and) (NN ambition))))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The Evil One" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Evil" />
            <token id="3" string="One" />
          </tokens>
        </chunking>
        <chunking id="2" string="single-handedly killed the Beatles and destroyed her husband 's talent and ambition" type="VP">
          <tokens>
            <token id="5" string="single-handedly" />
            <token id="6" string="killed" />
            <token id="7" string="the" />
            <token id="8" string="Beatles" />
            <token id="9" string="and" />
            <token id="10" string="destroyed" />
            <token id="11" string="her" />
            <token id="12" string="husband" />
            <token id="13" string="'s" />
            <token id="14" string="talent" />
            <token id="15" string="and" />
            <token id="16" string="ambition" />
          </tokens>
        </chunking>
        <chunking id="3" string="single-handedly killed the Beatles" type="VP">
          <tokens>
            <token id="5" string="single-handedly" />
            <token id="6" string="killed" />
            <token id="7" string="the" />
            <token id="8" string="Beatles" />
          </tokens>
        </chunking>
        <chunking id="4" string="her husband 's talent and ambition" type="NP">
          <tokens>
            <token id="11" string="her" />
            <token id="12" string="husband" />
            <token id="13" string="'s" />
            <token id="14" string="talent" />
            <token id="15" string="and" />
            <token id="16" string="ambition" />
          </tokens>
        </chunking>
        <chunking id="5" string="The Evil One who single-handedly killed the Beatles and destroyed her husband 's talent and ambition" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Evil" />
            <token id="3" string="One" />
            <token id="4" string="who" />
            <token id="5" string="single-handedly" />
            <token id="6" string="killed" />
            <token id="7" string="the" />
            <token id="8" string="Beatles" />
            <token id="9" string="and" />
            <token id="10" string="destroyed" />
            <token id="11" string="her" />
            <token id="12" string="husband" />
            <token id="13" string="'s" />
            <token id="14" string="talent" />
            <token id="15" string="and" />
            <token id="16" string="ambition" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Beatles" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Beatles" />
          </tokens>
        </chunking>
        <chunking id="7" string="destroyed her husband 's talent and ambition" type="VP">
          <tokens>
            <token id="10" string="destroyed" />
            <token id="11" string="her" />
            <token id="12" string="husband" />
            <token id="13" string="'s" />
            <token id="14" string="talent" />
            <token id="15" string="and" />
            <token id="16" string="ambition" />
          </tokens>
        </chunking>
        <chunking id="8" string="who single-handedly killed the Beatles and destroyed her husband 's talent and ambition" type="SBAR">
          <tokens>
            <token id="4" string="who" />
            <token id="5" string="single-handedly" />
            <token id="6" string="killed" />
            <token id="7" string="the" />
            <token id="8" string="Beatles" />
            <token id="9" string="and" />
            <token id="10" string="destroyed" />
            <token id="11" string="her" />
            <token id="12" string="husband" />
            <token id="13" string="'s" />
            <token id="14" string="talent" />
            <token id="15" string="and" />
            <token id="16" string="ambition" />
          </tokens>
        </chunking>
        <chunking id="9" string="her husband 's" type="NP">
          <tokens>
            <token id="11" string="her" />
            <token id="12" string="husband" />
            <token id="13" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">Evil</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">Evil</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">Evil</governor>
          <dependent id="3">One</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">killed</governor>
          <dependent id="4">who</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">killed</governor>
          <dependent id="5">single-handedly</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">Evil</governor>
          <dependent id="6">killed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">Beatles</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">killed</governor>
          <dependent id="8">Beatles</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">killed</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">killed</governor>
          <dependent id="10">destroyed</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">husband</governor>
          <dependent id="11">her</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">talent</governor>
          <dependent id="12">husband</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">husband</governor>
          <dependent id="13">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">destroyed</governor>
          <dependent id="14">talent</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">talent</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">talent</governor>
          <dependent id="16">ambition</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Evil" type="MISC" score="0.0">
          <tokens>
            <token id="2" string="Evil" />
          </tokens>
        </entity>
        <entity id="2" string="One" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="One" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>Who could possibly regard her as anything other than a crackpot and a public menace?</content>
      <tokens>
        <token id="1" string="Who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="possibly" lemma="possibly" stem="possibli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="regard" lemma="regard" stem="regard" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="her" lemma="she" stem="her" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="anything" lemma="anything" stem="anyth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="crackpot" lemma="crackpot" stem="crackpot" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="menace" lemma="menace" stem="menac" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SBARQ (WHNP (WP Who)) (SQ (VP (MD could) (ADVP (RB possibly)) (VP (VB regard) (NP (PRP her)) (PP (IN as) (NP (NP (NN anything)) (PP (JJ other) (IN than) (NP (NP (DT a) (JJ crackpot)) (CC and) (NP (DT a) (JJ public) (NN menace))))))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="her" type="NP">
          <tokens>
            <token id="5" string="her" />
          </tokens>
        </chunking>
        <chunking id="2" string="could possibly regard her as anything other than a crackpot and a public menace" type="VP">
          <tokens>
            <token id="2" string="could" />
            <token id="3" string="possibly" />
            <token id="4" string="regard" />
            <token id="5" string="her" />
            <token id="6" string="as" />
            <token id="7" string="anything" />
            <token id="8" string="other" />
            <token id="9" string="than" />
            <token id="10" string="a" />
            <token id="11" string="crackpot" />
            <token id="12" string="and" />
            <token id="13" string="a" />
            <token id="14" string="public" />
            <token id="15" string="menace" />
          </tokens>
        </chunking>
        <chunking id="3" string="regard her as anything other than a crackpot and a public menace" type="VP">
          <tokens>
            <token id="4" string="regard" />
            <token id="5" string="her" />
            <token id="6" string="as" />
            <token id="7" string="anything" />
            <token id="8" string="other" />
            <token id="9" string="than" />
            <token id="10" string="a" />
            <token id="11" string="crackpot" />
            <token id="12" string="and" />
            <token id="13" string="a" />
            <token id="14" string="public" />
            <token id="15" string="menace" />
          </tokens>
        </chunking>
        <chunking id="4" string="anything" type="NP">
          <tokens>
            <token id="7" string="anything" />
          </tokens>
        </chunking>
        <chunking id="5" string="a public menace" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="public" />
            <token id="15" string="menace" />
          </tokens>
        </chunking>
        <chunking id="6" string="a crackpot and a public menace" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="crackpot" />
            <token id="12" string="and" />
            <token id="13" string="a" />
            <token id="14" string="public" />
            <token id="15" string="menace" />
          </tokens>
        </chunking>
        <chunking id="7" string="a crackpot" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="crackpot" />
          </tokens>
        </chunking>
        <chunking id="8" string="anything other than a crackpot and a public menace" type="NP">
          <tokens>
            <token id="7" string="anything" />
            <token id="8" string="other" />
            <token id="9" string="than" />
            <token id="10" string="a" />
            <token id="11" string="crackpot" />
            <token id="12" string="and" />
            <token id="13" string="a" />
            <token id="14" string="public" />
            <token id="15" string="menace" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">regard</governor>
          <dependent id="1">Who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">regard</governor>
          <dependent id="2">could</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">regard</governor>
          <dependent id="3">possibly</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">regard</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">regard</governor>
          <dependent id="5">her</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">anything</governor>
          <dependent id="6">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">regard</governor>
          <dependent id="7">anything</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">crackpot</governor>
          <dependent id="8">other</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">crackpot</governor>
          <dependent id="9">than</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">crackpot</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">anything</governor>
          <dependent id="11">crackpot</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">crackpot</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">menace</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">menace</governor>
          <dependent id="14">public</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">crackpot</governor>
          <dependent id="15">menace</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>; Well, let&amp;apost;s see: there&amp;apost;s party rockers the B52s and cult singer Lene Lovich -- successful, critically acclaimed musicians who credit Ono&amp;apost;s music as an influence.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Well" lemma="well" stem="well" pos="UH" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="let" lemma="let" stem="let" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="see" lemma="see" stem="see" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="party" lemma="party" stem="parti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="rockers" lemma="rocker" stem="rocker" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="B52s" lemma="b52" stem="b52" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="cult" lemma="cult" stem="cult" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="singer" lemma="singer" stem="singer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="Lene" lemma="Lene" stem="lene" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="18" string="Lovich" lemma="Lovich" stem="lovich" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="19" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="successful" lemma="successful" stem="success" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="critically" lemma="critically" stem="critic" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="acclaimed" lemma="acclaimed" stem="acclaim" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="musicians" lemma="musician" stem="musician" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="credit" lemma="credit" stem="credit" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="28" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="29" string="music" lemma="music" stem="music" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="32" string="influence" lemma="influence" stem="influenc" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (S (S (INTJ (UH Well)) (, ,) (VP (VP (VB let) (S (NP (POS 's)) (VP (VB see))) (PRN (: :) (S (NP (EX there)) (VP (VBZ 's) (NP (NN party) (NNS rockers))))) (NP (NP (DT the) (NNS B52s)) (CC and) (NP (NN cult) (NN singer) (NNP Lene) (NNP Lovich))) (: --) (FRAG (ADJP (JJ successful)))) (, ,) (NP (NP (RB critically) (JJ acclaimed) (NNS musicians)) (SBAR (WHNP (WP who)))))) (VP (VBP credit) (NP (NP (NP (NNP Ono) (POS 's)) (NN music)) (PP (IN as) (NP (DT an) (NN influence)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="let 's see : there 's party rockers the B52s and cult singer Lene Lovich -- successful" type="VP">
          <tokens>
            <token id="4" string="let" />
            <token id="5" string="'s" />
            <token id="6" string="see" />
            <token id="7" string=":" />
            <token id="8" string="there" />
            <token id="9" string="'s" />
            <token id="10" string="party" />
            <token id="11" string="rockers" />
            <token id="12" string="the" />
            <token id="13" string="B52s" />
            <token id="14" string="and" />
            <token id="15" string="cult" />
            <token id="16" string="singer" />
            <token id="17" string="Lene" />
            <token id="18" string="Lovich" />
            <token id="19" string="--" />
            <token id="20" string="successful" />
          </tokens>
        </chunking>
        <chunking id="2" string="'s party rockers" type="VP">
          <tokens>
            <token id="9" string="'s" />
            <token id="10" string="party" />
            <token id="11" string="rockers" />
          </tokens>
        </chunking>
        <chunking id="3" string="credit Ono 's music as an influence" type="VP">
          <tokens>
            <token id="26" string="credit" />
            <token id="27" string="Ono" />
            <token id="28" string="'s" />
            <token id="29" string="music" />
            <token id="30" string="as" />
            <token id="31" string="an" />
            <token id="32" string="influence" />
          </tokens>
        </chunking>
        <chunking id="4" string="the B52s" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="B52s" />
          </tokens>
        </chunking>
        <chunking id="5" string="Ono 's music" type="NP">
          <tokens>
            <token id="27" string="Ono" />
            <token id="28" string="'s" />
            <token id="29" string="music" />
          </tokens>
        </chunking>
        <chunking id="6" string="'s" type="NP">
          <tokens>
            <token id="5" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="Ono 's music as an influence" type="NP">
          <tokens>
            <token id="27" string="Ono" />
            <token id="28" string="'s" />
            <token id="29" string="music" />
            <token id="30" string="as" />
            <token id="31" string="an" />
            <token id="32" string="influence" />
          </tokens>
        </chunking>
        <chunking id="8" string="there" type="NP">
          <tokens>
            <token id="8" string="there" />
          </tokens>
        </chunking>
        <chunking id="9" string="critically acclaimed musicians who" type="NP">
          <tokens>
            <token id="22" string="critically" />
            <token id="23" string="acclaimed" />
            <token id="24" string="musicians" />
            <token id="25" string="who" />
          </tokens>
        </chunking>
        <chunking id="10" string="see" type="VP">
          <tokens>
            <token id="6" string="see" />
          </tokens>
        </chunking>
        <chunking id="11" string="party rockers" type="NP">
          <tokens>
            <token id="10" string="party" />
            <token id="11" string="rockers" />
          </tokens>
        </chunking>
        <chunking id="12" string="critically acclaimed musicians" type="NP">
          <tokens>
            <token id="22" string="critically" />
            <token id="23" string="acclaimed" />
            <token id="24" string="musicians" />
          </tokens>
        </chunking>
        <chunking id="13" string="Ono 's" type="NP">
          <tokens>
            <token id="27" string="Ono" />
            <token id="28" string="'s" />
          </tokens>
        </chunking>
        <chunking id="14" string="let 's see : there 's party rockers the B52s and cult singer Lene Lovich -- successful , critically acclaimed musicians who" type="VP">
          <tokens>
            <token id="4" string="let" />
            <token id="5" string="'s" />
            <token id="6" string="see" />
            <token id="7" string=":" />
            <token id="8" string="there" />
            <token id="9" string="'s" />
            <token id="10" string="party" />
            <token id="11" string="rockers" />
            <token id="12" string="the" />
            <token id="13" string="B52s" />
            <token id="14" string="and" />
            <token id="15" string="cult" />
            <token id="16" string="singer" />
            <token id="17" string="Lene" />
            <token id="18" string="Lovich" />
            <token id="19" string="--" />
            <token id="20" string="successful" />
            <token id="21" string="," />
            <token id="22" string="critically" />
            <token id="23" string="acclaimed" />
            <token id="24" string="musicians" />
            <token id="25" string="who" />
          </tokens>
        </chunking>
        <chunking id="15" string="the B52s and cult singer Lene Lovich" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="B52s" />
            <token id="14" string="and" />
            <token id="15" string="cult" />
            <token id="16" string="singer" />
            <token id="17" string="Lene" />
            <token id="18" string="Lovich" />
          </tokens>
        </chunking>
        <chunking id="16" string="cult singer Lene Lovich" type="NP">
          <tokens>
            <token id="15" string="cult" />
            <token id="16" string="singer" />
            <token id="17" string="Lene" />
            <token id="18" string="Lovich" />
          </tokens>
        </chunking>
        <chunking id="17" string="successful" type="ADJP">
          <tokens>
            <token id="20" string="successful" />
          </tokens>
        </chunking>
        <chunking id="18" string="who" type="SBAR">
          <tokens>
            <token id="25" string="who" />
          </tokens>
        </chunking>
        <chunking id="19" string="an influence" type="NP">
          <tokens>
            <token id="31" string="an" />
            <token id="32" string="influence" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="discourse">
          <governor id="4">let</governor>
          <dependent id="2">Well</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="26">credit</governor>
          <dependent id="4">let</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">see</governor>
          <dependent id="5">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">let</governor>
          <dependent id="6">see</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="9">'s</governor>
          <dependent id="8">there</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="4">let</governor>
          <dependent id="9">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">rockers</governor>
          <dependent id="10">party</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">'s</governor>
          <dependent id="11">rockers</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">B52s</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">let</governor>
          <dependent id="13">B52s</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">B52s</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Lovich</governor>
          <dependent id="15">cult</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Lovich</governor>
          <dependent id="16">singer</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Lovich</governor>
          <dependent id="17">Lene</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">B52s</governor>
          <dependent id="18">Lovich</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">let</governor>
          <dependent id="20">successful</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">musicians</governor>
          <dependent id="22">critically</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">musicians</governor>
          <dependent id="23">acclaimed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">let</governor>
          <dependent id="24">musicians</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="24">musicians</governor>
          <dependent id="25">who</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="26">credit</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="29">music</governor>
          <dependent id="27">Ono</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">Ono</governor>
          <dependent id="28">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">credit</governor>
          <dependent id="29">music</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">influence</governor>
          <dependent id="30">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">influence</governor>
          <dependent id="31">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">music</governor>
          <dependent id="32">influence</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lene Lovich" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Lene" />
            <token id="18" string="Lovich" />
          </tokens>
        </entity>
        <entity id="2" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="27" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>There&amp;apost;s the Whitney Museum of Art, which exhibited Ono&amp;apost;s artwork last year -- one of the 10 museum shows she has had around the world There&amp;apost;s also the American Film Institute, which Ono says is staging an international tour of her experimental films.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Whitney" lemma="Whitney" stem="whitnei" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="5" string="Museum" lemma="Museum" stem="museum" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="7" string="Art" lemma="Art" stem="art" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="exhibited" lemma="exhibit" stem="exhibit" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="artwork" lemma="artwork" stem="artwork" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="15" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="16" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="10" lemma="10" stem="10" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="21" string="museum" lemma="museum" stem="museum" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="shows" lemma="show" stem="show" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="had" lemma="have" stem="had" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="around" lemma="around" stem="around" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="American" lemma="american" stem="american" pos="JJ" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="34" string="Film" lemma="Film" stem="film" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="35" string="Institute" lemma="Institute" stem="institut" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="36" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="37" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="38" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="39" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="40" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="41" string="staging" lemma="stage" stem="stage" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="42" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="43" string="international" lemma="international" stem="intern" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="44" string="tour" lemma="tour" stem="tour" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="45" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="46" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="47" string="experimental" lemma="experimental" stem="experiment" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="48" string="films" lemma="film" stem="film" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="49" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (EX There)) (VP (VBZ 's) (NP (NP (DT the) (NNP Whitney) (NNP Museum)) (PP (IN of) (NP (NP (NNP Art)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBD exhibited) (NP (NP (NNP Ono) (POS 's)) (NN artwork)) (NP-TMP (JJ last) (NN year)))))))))) (: --) (S (NP (NP (CD one)) (PP (IN of) (NP (DT the) (CD 10) (NN museum)))) (VP (VBZ shows) (SBAR (S (NP (PRP she)) (VP (VBZ has) (VP (VBN had) (PP (IN around) (NP (NP (DT the) (NN world)) (SBAR (S (NP (EX There)) (VP (VBZ 's) (ADVP (RB also)) (NP (NP (DT the) (JJ American) (NNP Film) (NNP Institute)) (, ,) (SBAR (WHNP (WDT which)) (S (NP (NNP Ono)) (VP (VBZ says) (SBAR (S (VP (VBZ is) (VP (VBG staging) (NP (NP (DT an) (JJ international) (NN tour)) (PP (IN of) (NP (PRP$ her) (JJ experimental) (NNS films))))))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="says is staging an international tour of her experimental films" type="VP">
          <tokens>
            <token id="39" string="says" />
            <token id="40" string="is" />
            <token id="41" string="staging" />
            <token id="42" string="an" />
            <token id="43" string="international" />
            <token id="44" string="tour" />
            <token id="45" string="of" />
            <token id="46" string="her" />
            <token id="47" string="experimental" />
            <token id="48" string="films" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Whitney Museum" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="Whitney" />
            <token id="5" string="Museum" />
          </tokens>
        </chunking>
        <chunking id="3" string="one" type="NP">
          <tokens>
            <token id="17" string="one" />
          </tokens>
        </chunking>
        <chunking id="4" string="the American Film Institute , which Ono says is staging an international tour of her experimental films" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="American" />
            <token id="34" string="Film" />
            <token id="35" string="Institute" />
            <token id="36" string="," />
            <token id="37" string="which" />
            <token id="38" string="Ono" />
            <token id="39" string="says" />
            <token id="40" string="is" />
            <token id="41" string="staging" />
            <token id="42" string="an" />
            <token id="43" string="international" />
            <token id="44" string="tour" />
            <token id="45" string="of" />
            <token id="46" string="her" />
            <token id="47" string="experimental" />
            <token id="48" string="films" />
          </tokens>
        </chunking>
        <chunking id="5" string="the American Film Institute" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="American" />
            <token id="34" string="Film" />
            <token id="35" string="Institute" />
          </tokens>
        </chunking>
        <chunking id="6" string="an international tour" type="NP">
          <tokens>
            <token id="42" string="an" />
            <token id="43" string="international" />
            <token id="44" string="tour" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="23" string="she" />
          </tokens>
        </chunking>
        <chunking id="8" string="had around the world There 's also the American Film Institute , which Ono says is staging an international tour of her experimental films" type="VP">
          <tokens>
            <token id="25" string="had" />
            <token id="26" string="around" />
            <token id="27" string="the" />
            <token id="28" string="world" />
            <token id="29" string="There" />
            <token id="30" string="'s" />
            <token id="31" string="also" />
            <token id="32" string="the" />
            <token id="33" string="American" />
            <token id="34" string="Film" />
            <token id="35" string="Institute" />
            <token id="36" string="," />
            <token id="37" string="which" />
            <token id="38" string="Ono" />
            <token id="39" string="says" />
            <token id="40" string="is" />
            <token id="41" string="staging" />
            <token id="42" string="an" />
            <token id="43" string="international" />
            <token id="44" string="tour" />
            <token id="45" string="of" />
            <token id="46" string="her" />
            <token id="47" string="experimental" />
            <token id="48" string="films" />
          </tokens>
        </chunking>
        <chunking id="9" string="the 10 museum" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="10" />
            <token id="21" string="museum" />
          </tokens>
        </chunking>
        <chunking id="10" string="is staging an international tour of her experimental films" type="SBAR">
          <tokens>
            <token id="40" string="is" />
            <token id="41" string="staging" />
            <token id="42" string="an" />
            <token id="43" string="international" />
            <token id="44" string="tour" />
            <token id="45" string="of" />
            <token id="46" string="her" />
            <token id="47" string="experimental" />
            <token id="48" string="films" />
          </tokens>
        </chunking>
        <chunking id="11" string="an international tour of her experimental films" type="NP">
          <tokens>
            <token id="42" string="an" />
            <token id="43" string="international" />
            <token id="44" string="tour" />
            <token id="45" string="of" />
            <token id="46" string="her" />
            <token id="47" string="experimental" />
            <token id="48" string="films" />
          </tokens>
        </chunking>
        <chunking id="12" string="Ono 's" type="NP">
          <tokens>
            <token id="11" string="Ono" />
            <token id="12" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="staging an international tour of her experimental films" type="VP">
          <tokens>
            <token id="41" string="staging" />
            <token id="42" string="an" />
            <token id="43" string="international" />
            <token id="44" string="tour" />
            <token id="45" string="of" />
            <token id="46" string="her" />
            <token id="47" string="experimental" />
            <token id="48" string="films" />
          </tokens>
        </chunking>
        <chunking id="14" string="the Whitney Museum of Art , which exhibited Ono 's artwork last year" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="Whitney" />
            <token id="5" string="Museum" />
            <token id="6" string="of" />
            <token id="7" string="Art" />
            <token id="8" string="," />
            <token id="9" string="which" />
            <token id="10" string="exhibited" />
            <token id="11" string="Ono" />
            <token id="12" string="'s" />
            <token id="13" string="artwork" />
            <token id="14" string="last" />
            <token id="15" string="year" />
          </tokens>
        </chunking>
        <chunking id="15" string="one of the 10 museum" type="NP">
          <tokens>
            <token id="17" string="one" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="10" />
            <token id="21" string="museum" />
          </tokens>
        </chunking>
        <chunking id="16" string="shows she has had around the world There 's also the American Film Institute , which Ono says is staging an international tour of her experimental films" type="VP">
          <tokens>
            <token id="22" string="shows" />
            <token id="23" string="she" />
            <token id="24" string="has" />
            <token id="25" string="had" />
            <token id="26" string="around" />
            <token id="27" string="the" />
            <token id="28" string="world" />
            <token id="29" string="There" />
            <token id="30" string="'s" />
            <token id="31" string="also" />
            <token id="32" string="the" />
            <token id="33" string="American" />
            <token id="34" string="Film" />
            <token id="35" string="Institute" />
            <token id="36" string="," />
            <token id="37" string="which" />
            <token id="38" string="Ono" />
            <token id="39" string="says" />
            <token id="40" string="is" />
            <token id="41" string="staging" />
            <token id="42" string="an" />
            <token id="43" string="international" />
            <token id="44" string="tour" />
            <token id="45" string="of" />
            <token id="46" string="her" />
            <token id="47" string="experimental" />
            <token id="48" string="films" />
          </tokens>
        </chunking>
        <chunking id="17" string="'s also the American Film Institute , which Ono says is staging an international tour of her experimental films" type="VP">
          <tokens>
            <token id="30" string="'s" />
            <token id="31" string="also" />
            <token id="32" string="the" />
            <token id="33" string="American" />
            <token id="34" string="Film" />
            <token id="35" string="Institute" />
            <token id="36" string="," />
            <token id="37" string="which" />
            <token id="38" string="Ono" />
            <token id="39" string="says" />
            <token id="40" string="is" />
            <token id="41" string="staging" />
            <token id="42" string="an" />
            <token id="43" string="international" />
            <token id="44" string="tour" />
            <token id="45" string="of" />
            <token id="46" string="her" />
            <token id="47" string="experimental" />
            <token id="48" string="films" />
          </tokens>
        </chunking>
        <chunking id="18" string="exhibited Ono 's artwork last year" type="VP">
          <tokens>
            <token id="10" string="exhibited" />
            <token id="11" string="Ono" />
            <token id="12" string="'s" />
            <token id="13" string="artwork" />
            <token id="14" string="last" />
            <token id="15" string="year" />
          </tokens>
        </chunking>
        <chunking id="19" string="she has had around the world There 's also the American Film Institute , which Ono says is staging an international tour of her experimental films" type="SBAR">
          <tokens>
            <token id="23" string="she" />
            <token id="24" string="has" />
            <token id="25" string="had" />
            <token id="26" string="around" />
            <token id="27" string="the" />
            <token id="28" string="world" />
            <token id="29" string="There" />
            <token id="30" string="'s" />
            <token id="31" string="also" />
            <token id="32" string="the" />
            <token id="33" string="American" />
            <token id="34" string="Film" />
            <token id="35" string="Institute" />
            <token id="36" string="," />
            <token id="37" string="which" />
            <token id="38" string="Ono" />
            <token id="39" string="says" />
            <token id="40" string="is" />
            <token id="41" string="staging" />
            <token id="42" string="an" />
            <token id="43" string="international" />
            <token id="44" string="tour" />
            <token id="45" string="of" />
            <token id="46" string="her" />
            <token id="47" string="experimental" />
            <token id="48" string="films" />
          </tokens>
        </chunking>
        <chunking id="20" string="which exhibited Ono 's artwork last year" type="SBAR">
          <tokens>
            <token id="9" string="which" />
            <token id="10" string="exhibited" />
            <token id="11" string="Ono" />
            <token id="12" string="'s" />
            <token id="13" string="artwork" />
            <token id="14" string="last" />
            <token id="15" string="year" />
          </tokens>
        </chunking>
        <chunking id="21" string="Ono 's artwork" type="NP">
          <tokens>
            <token id="11" string="Ono" />
            <token id="12" string="'s" />
            <token id="13" string="artwork" />
          </tokens>
        </chunking>
        <chunking id="22" string="'s the Whitney Museum of Art , which exhibited Ono 's artwork last year" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="the" />
            <token id="4" string="Whitney" />
            <token id="5" string="Museum" />
            <token id="6" string="of" />
            <token id="7" string="Art" />
            <token id="8" string="," />
            <token id="9" string="which" />
            <token id="10" string="exhibited" />
            <token id="11" string="Ono" />
            <token id="12" string="'s" />
            <token id="13" string="artwork" />
            <token id="14" string="last" />
            <token id="15" string="year" />
          </tokens>
        </chunking>
        <chunking id="23" string="Art" type="NP">
          <tokens>
            <token id="7" string="Art" />
          </tokens>
        </chunking>
        <chunking id="24" string="There 's also the American Film Institute , which Ono says is staging an international tour of her experimental films" type="SBAR">
          <tokens>
            <token id="29" string="There" />
            <token id="30" string="'s" />
            <token id="31" string="also" />
            <token id="32" string="the" />
            <token id="33" string="American" />
            <token id="34" string="Film" />
            <token id="35" string="Institute" />
            <token id="36" string="," />
            <token id="37" string="which" />
            <token id="38" string="Ono" />
            <token id="39" string="says" />
            <token id="40" string="is" />
            <token id="41" string="staging" />
            <token id="42" string="an" />
            <token id="43" string="international" />
            <token id="44" string="tour" />
            <token id="45" string="of" />
            <token id="46" string="her" />
            <token id="47" string="experimental" />
            <token id="48" string="films" />
          </tokens>
        </chunking>
        <chunking id="25" string="her experimental films" type="NP">
          <tokens>
            <token id="46" string="her" />
            <token id="47" string="experimental" />
            <token id="48" string="films" />
          </tokens>
        </chunking>
        <chunking id="26" string="the world" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="world" />
          </tokens>
        </chunking>
        <chunking id="27" string="Ono" type="NP">
          <tokens>
            <token id="38" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="28" string="has had around the world There 's also the American Film Institute , which Ono says is staging an international tour of her experimental films" type="VP">
          <tokens>
            <token id="24" string="has" />
            <token id="25" string="had" />
            <token id="26" string="around" />
            <token id="27" string="the" />
            <token id="28" string="world" />
            <token id="29" string="There" />
            <token id="30" string="'s" />
            <token id="31" string="also" />
            <token id="32" string="the" />
            <token id="33" string="American" />
            <token id="34" string="Film" />
            <token id="35" string="Institute" />
            <token id="36" string="," />
            <token id="37" string="which" />
            <token id="38" string="Ono" />
            <token id="39" string="says" />
            <token id="40" string="is" />
            <token id="41" string="staging" />
            <token id="42" string="an" />
            <token id="43" string="international" />
            <token id="44" string="tour" />
            <token id="45" string="of" />
            <token id="46" string="her" />
            <token id="47" string="experimental" />
            <token id="48" string="films" />
          </tokens>
        </chunking>
        <chunking id="29" string="which Ono says is staging an international tour of her experimental films" type="SBAR">
          <tokens>
            <token id="37" string="which" />
            <token id="38" string="Ono" />
            <token id="39" string="says" />
            <token id="40" string="is" />
            <token id="41" string="staging" />
            <token id="42" string="an" />
            <token id="43" string="international" />
            <token id="44" string="tour" />
            <token id="45" string="of" />
            <token id="46" string="her" />
            <token id="47" string="experimental" />
            <token id="48" string="films" />
          </tokens>
        </chunking>
        <chunking id="30" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="31" string="the world There 's also the American Film Institute , which Ono says is staging an international tour of her experimental films" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="world" />
            <token id="29" string="There" />
            <token id="30" string="'s" />
            <token id="31" string="also" />
            <token id="32" string="the" />
            <token id="33" string="American" />
            <token id="34" string="Film" />
            <token id="35" string="Institute" />
            <token id="36" string="," />
            <token id="37" string="which" />
            <token id="38" string="Ono" />
            <token id="39" string="says" />
            <token id="40" string="is" />
            <token id="41" string="staging" />
            <token id="42" string="an" />
            <token id="43" string="international" />
            <token id="44" string="tour" />
            <token id="45" string="of" />
            <token id="46" string="her" />
            <token id="47" string="experimental" />
            <token id="48" string="films" />
          </tokens>
        </chunking>
        <chunking id="32" string="Art , which exhibited Ono 's artwork last year" type="NP">
          <tokens>
            <token id="7" string="Art" />
            <token id="8" string="," />
            <token id="9" string="which" />
            <token id="10" string="exhibited" />
            <token id="11" string="Ono" />
            <token id="12" string="'s" />
            <token id="13" string="artwork" />
            <token id="14" string="last" />
            <token id="15" string="year" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="2">'s</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">Museum</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Museum</governor>
          <dependent id="4">Whitney</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="2">'s</governor>
          <dependent id="5">Museum</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Art</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">Museum</governor>
          <dependent id="7">Art</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">exhibited</governor>
          <dependent id="9">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">Art</governor>
          <dependent id="10">exhibited</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">artwork</governor>
          <dependent id="11">Ono</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Ono</governor>
          <dependent id="12">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">exhibited</governor>
          <dependent id="13">artwork</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">year</governor>
          <dependent id="14">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="10">exhibited</governor>
          <dependent id="15">year</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">shows</governor>
          <dependent id="17">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">museum</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">museum</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="21">museum</governor>
          <dependent id="20">10</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">one</governor>
          <dependent id="21">museum</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="2">'s</governor>
          <dependent id="22">shows</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">had</governor>
          <dependent id="23">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="25">had</governor>
          <dependent id="24">has</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">shows</governor>
          <dependent id="25">had</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">world</governor>
          <dependent id="26">around</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">world</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">had</governor>
          <dependent id="28">world</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="30">'s</governor>
          <dependent id="29">There</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="28">world</governor>
          <dependent id="30">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="30">'s</governor>
          <dependent id="31">also</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">Institute</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">Institute</governor>
          <dependent id="33">American</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Institute</governor>
          <dependent id="34">Film</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">'s</governor>
          <dependent id="35">Institute</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="39">says</governor>
          <dependent id="37">which</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="39">says</governor>
          <dependent id="38">Ono</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="35">Institute</governor>
          <dependent id="39">says</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="41">staging</governor>
          <dependent id="40">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="39">says</governor>
          <dependent id="41">staging</dependent>
        </dependency>
        <dependency type="det">
          <governor id="44">tour</governor>
          <dependent id="42">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="44">tour</governor>
          <dependent id="43">international</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="41">staging</governor>
          <dependent id="44">tour</dependent>
        </dependency>
        <dependency type="case">
          <governor id="48">films</governor>
          <dependent id="45">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="48">films</governor>
          <dependent id="46">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="48">films</governor>
          <dependent id="47">experimental</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="44">tour</governor>
          <dependent id="48">films</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="American Film Institute" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="33" string="American" />
            <token id="34" string="Film" />
            <token id="35" string="Institute" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="17" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="last year" type="DATE" score="0.0">
          <tokens>
            <token id="14" string="last" />
            <token id="15" string="year" />
          </tokens>
        </entity>
        <entity id="4" string="Whitney Museum of Art" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="4" string="Whitney" />
            <token id="5" string="Museum" />
            <token id="6" string="of" />
            <token id="7" string="Art" />
          </tokens>
        </entity>
        <entity id="5" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Ono" />
          </tokens>
        </entity>
        <entity id="6" string="10" type="NUMBER" score="0.0">
          <tokens>
            <token id="20" string="10" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>And Ono&amp;apost;s record label -- &amp;quot;they want to put out all my songs in a kind of CD box or something,&amp;quot; Ono says Surprised?</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="record" lemma="record" stem="record" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="label" lemma="label" stem="label" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="want" lemma="want" stem="want" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="put" lemma="put" stem="put" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="songs" lemma="song" stem="song" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="kind" lemma="kind" stem="kind" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="CD" lemma="cd" stem="cd" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="box" lemma="box" stem="box" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="something" lemma="something" stem="someth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="27" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="Surprised" lemma="surprise" stem="surpris" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (CC And) (NP (NP (NP (NNP Ono) (POS 's)) (NN record) (NN label)) (: --) (S (`` ``) (NP (PRP they)) (VP (VBP want) (S (VP (TO to) (VP (VB put) (PRT (RP out)) (NP (DT all) (PRP$ my) (NNS songs)))))))) (SBAR (S (PP (IN in) (NP (NP (DT a) (NN kind)) (PP (IN of) (NP (NN CD) (NN box) (CC or) (NN something))))) (, ,) ('' '') (NP (NNP Ono)) (VP (VBZ says) (VP (VBN Surprised))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="want to put out all my songs" type="VP">
          <tokens>
            <token id="9" string="want" />
            <token id="10" string="to" />
            <token id="11" string="put" />
            <token id="12" string="out" />
            <token id="13" string="all" />
            <token id="14" string="my" />
            <token id="15" string="songs" />
          </tokens>
        </chunking>
        <chunking id="2" string="all my songs" type="NP">
          <tokens>
            <token id="13" string="all" />
            <token id="14" string="my" />
            <token id="15" string="songs" />
          </tokens>
        </chunking>
        <chunking id="3" string="Ono 's record label" type="NP">
          <tokens>
            <token id="2" string="Ono" />
            <token id="3" string="'s" />
            <token id="4" string="record" />
            <token id="5" string="label" />
          </tokens>
        </chunking>
        <chunking id="4" string="a kind" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="kind" />
          </tokens>
        </chunking>
        <chunking id="5" string="Surprised" type="VP">
          <tokens>
            <token id="28" string="Surprised" />
          </tokens>
        </chunking>
        <chunking id="6" string="Ono" type="NP">
          <tokens>
            <token id="26" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="7" string="they" type="NP">
          <tokens>
            <token id="8" string="they" />
          </tokens>
        </chunking>
        <chunking id="8" string="Ono 's" type="NP">
          <tokens>
            <token id="2" string="Ono" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="CD box or something" type="NP">
          <tokens>
            <token id="20" string="CD" />
            <token id="21" string="box" />
            <token id="22" string="or" />
            <token id="23" string="something" />
          </tokens>
        </chunking>
        <chunking id="10" string="to put out all my songs" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="put" />
            <token id="12" string="out" />
            <token id="13" string="all" />
            <token id="14" string="my" />
            <token id="15" string="songs" />
          </tokens>
        </chunking>
        <chunking id="11" string="in a kind of CD box or something , '' Ono says Surprised" type="SBAR">
          <tokens>
            <token id="16" string="in" />
            <token id="17" string="a" />
            <token id="18" string="kind" />
            <token id="19" string="of" />
            <token id="20" string="CD" />
            <token id="21" string="box" />
            <token id="22" string="or" />
            <token id="23" string="something" />
            <token id="24" string="," />
            <token id="25" string="&quot;" />
            <token id="26" string="Ono" />
            <token id="27" string="says" />
            <token id="28" string="Surprised" />
          </tokens>
        </chunking>
        <chunking id="12" string="Ono 's record label -- `` they want to put out all my songs" type="NP">
          <tokens>
            <token id="2" string="Ono" />
            <token id="3" string="'s" />
            <token id="4" string="record" />
            <token id="5" string="label" />
            <token id="6" string="--" />
            <token id="7" string="&quot;" />
            <token id="8" string="they" />
            <token id="9" string="want" />
            <token id="10" string="to" />
            <token id="11" string="put" />
            <token id="12" string="out" />
            <token id="13" string="all" />
            <token id="14" string="my" />
            <token id="15" string="songs" />
          </tokens>
        </chunking>
        <chunking id="13" string="a kind of CD box or something" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="kind" />
            <token id="19" string="of" />
            <token id="20" string="CD" />
            <token id="21" string="box" />
            <token id="22" string="or" />
            <token id="23" string="something" />
          </tokens>
        </chunking>
        <chunking id="14" string="says Surprised" type="VP">
          <tokens>
            <token id="27" string="says" />
            <token id="28" string="Surprised" />
          </tokens>
        </chunking>
        <chunking id="15" string="put out all my songs" type="VP">
          <tokens>
            <token id="11" string="put" />
            <token id="12" string="out" />
            <token id="13" string="all" />
            <token id="14" string="my" />
            <token id="15" string="songs" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="5">label</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">label</governor>
          <dependent id="2">Ono</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Ono</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">label</governor>
          <dependent id="4">record</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">label</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">want</governor>
          <dependent id="8">they</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="5">label</governor>
          <dependent id="9">want</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">put</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">want</governor>
          <dependent id="11">put</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="11">put</governor>
          <dependent id="12">out</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="15">songs</governor>
          <dependent id="13">all</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">songs</governor>
          <dependent id="14">my</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">put</governor>
          <dependent id="15">songs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">kind</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">kind</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">says</governor>
          <dependent id="18">kind</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">box</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">box</governor>
          <dependent id="20">CD</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">kind</governor>
          <dependent id="21">box</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">box</governor>
          <dependent id="22">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">box</governor>
          <dependent id="23">something</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">says</governor>
          <dependent id="26">Ono</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">label</governor>
          <dependent id="27">says</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="27">says</governor>
          <dependent id="28">Surprised</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>So&amp;apost;s Ono.</content>
      <tokens>
        <token id="1" string="So" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB So)) (NP (POS 's)) (VP (NNP Ono)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="'s" type="NP">
          <tokens>
            <token id="2" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="Ono" type="VP">
          <tokens>
            <token id="3" string="Ono" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">Ono</governor>
          <dependent id="1">So</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">Ono</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">Ono</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>She&amp;apost;s used to rougher treatment.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="used" lemma="use" stem="us" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="rougher" lemma="rougher" stem="rougher" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="treatment" lemma="treatment" stem="treatment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VBZ 's) (VP (VBN used) (PP (TO to) (NP (ADJP (JJR rougher)) (NN treatment))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="rougher" type="ADJP">
          <tokens>
            <token id="5" string="rougher" />
          </tokens>
        </chunking>
        <chunking id="2" string="used to rougher treatment" type="VP">
          <tokens>
            <token id="3" string="used" />
            <token id="4" string="to" />
            <token id="5" string="rougher" />
            <token id="6" string="treatment" />
          </tokens>
        </chunking>
        <chunking id="3" string="rougher treatment" type="NP">
          <tokens>
            <token id="5" string="rougher" />
            <token id="6" string="treatment" />
          </tokens>
        </chunking>
        <chunking id="4" string="'s used to rougher treatment" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="used" />
            <token id="4" string="to" />
            <token id="5" string="rougher" />
            <token id="6" string="treatment" />
          </tokens>
        </chunking>
        <chunking id="5" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="3">used</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="3">used</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">used</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">treatment</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">treatment</governor>
          <dependent id="5">rougher</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">used</governor>
          <dependent id="6">treatment</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Acceptance is a difficult concept for her &amp;quot;I&amp;apost;m used to sort of knocking the door rather than having the door opened and having to cope with entering it,&amp;quot; Ono says during a telephone interview She&amp;apost;s speaking from the New York office of Bag One Arts, the company Ono founded to promote Lennon&amp;apost;s art and image Marketing an icon; Since his death in 1980, Ono has steadily kept Lennon products coming out: the albums &amp;quot;Milk and Honey&amp;quot; and &amp;quot;Menlove Avenue&amp;quot; and the 4-CD boxed set &amp;quot;The John Lennon Collection&amp;quot;; the book &amp;quot;Skywriting by Word of Mouth,&amp;quot; a collection of Lennon&amp;apost;s unpublished writings; Lennon&amp;apost;s art, which Ono says was his main interest in his final years; and Lennon-inspired merchandise, such as a line of John Lennon eyeglasses &amp;quot;I told the fans that I&amp;apost;m going to do 10 years of it.</content>
      <tokens>
        <token id="1" string="Acceptance" lemma="Acceptance" stem="acceptanc" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="difficult" lemma="difficult" stem="difficult" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="concept" lemma="concept" stem="concept" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="used" lemma="use" stem="us" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="sort" lemma="sort" stem="sort" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="knocking" lemma="knock" stem="knock" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="17" string="door" lemma="door" stem="door" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="18" string="rather" lemma="rather" stem="rather" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="having" lemma="have" stem="have" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="door" lemma="door" stem="door" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="opened" lemma="open" stem="open" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="having" lemma="have" stem="have" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="cope" lemma="cope" stem="cope" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="entering" lemma="enter" stem="enter" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="30" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="34" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="35" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="37" string="telephone" lemma="telephone" stem="telephon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="38" string="interview" lemma="interview" stem="interview" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="39" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="40" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="41" string="speaking" lemma="speak" stem="speak" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="42" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="43" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="44" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="45" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="46" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="47" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="48" string="Bag" lemma="Bag" stem="bag" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="49" string="One" lemma="one" stem="one" pos="CD" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="50" string="Arts" lemma="art" stem="art" pos="NNS" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="51" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="52" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="53" string="company" lemma="company" stem="compani" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="54" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="55" string="founded" lemma="found" stem="found" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="56" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="57" string="promote" lemma="promote" stem="promot" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="58" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="59" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="60" string="art" lemma="art" stem="art" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="61" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="62" string="image" lemma="image" stem="imag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="63" string="Marketing" lemma="Marketing" stem="market" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="64" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="65" string="icon" lemma="icon" stem="icon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="66" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="67" string="Since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="68" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="69" string="death" lemma="death" stem="death" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="70" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="71" string="1980" lemma="1980" stem="1980" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="72" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="73" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="74" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="75" string="steadily" lemma="steadily" stem="steadili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="76" string="kept" lemma="keep" stem="kept" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="77" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="78" string="products" lemma="product" stem="product" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="79" string="coming" lemma="come" stem="come" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="80" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="81" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="82" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="83" string="albums" lemma="album" stem="album" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="84" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="85" string="Milk" lemma="milk" stem="milk" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="86" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="87" string="Honey" lemma="Honey" stem="honei" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="88" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="89" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="90" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="91" string="Menlove" lemma="Menlove" stem="menlov" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="92" string="Avenue" lemma="Avenue" stem="avenu" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="93" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="94" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="95" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="96" string="4-CD" lemma="4-cd" stem="4-cd" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="97" string="boxed" lemma="boxed" stem="box" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="98" string="set" lemma="set" stem="set" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="99" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="100" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="101" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="102" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="103" string="Collection" lemma="Collection" stem="collect" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="104" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="105" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="106" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="107" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="108" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="109" string="Skywriting" lemma="skywriting" stem="skywrit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="110" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="111" string="Word" lemma="word" stem="word" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="112" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="113" string="Mouth" lemma="Mouth" stem="mouth" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="114" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="115" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="116" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="117" string="collection" lemma="collection" stem="collect" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="118" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="119" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="120" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="121" string="unpublished" lemma="unpublished" stem="unpublish" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="122" string="writings" lemma="writings" stem="write" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="123" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="124" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="125" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="126" string="art" lemma="art" stem="art" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="127" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="128" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="129" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="130" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="131" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="132" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="133" string="main" lemma="main" stem="main" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="134" string="interest" lemma="interest" stem="interest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="135" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="136" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="137" string="final" lemma="final" stem="final" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="138" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="139" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="140" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="141" string="Lennon-inspired" lemma="lennon-inspired" stem="lennon-inspir" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="142" string="merchandise" lemma="merchandise" stem="merchandis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="143" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="144" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="145" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="146" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="147" string="line" lemma="line" stem="line" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="148" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="149" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="150" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="151" string="eyeglasses" lemma="eyeglass" stem="eyeglass" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="152" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="153" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="154" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="155" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="156" string="fans" lemma="fan" stem="fan" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="157" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="158" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="159" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="160" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="161" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="162" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="163" string="10" lemma="10" stem="10" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="164" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="165" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="166" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="167" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Acceptance)) (VP (VBZ is) (NP (NP (NP (DT a) (JJ difficult) (NN concept)) (PP (IN for) (NP (NP (PRP$ her)) (`` ``) (S (S (NP (PRP I)) (VP (VBP 'm) (VP (VBN used) (PP (TO to) (NP (NP (NN sort)) (PP (IN of) (S (VP (VP (VBG knocking) (NP (DT the) (NN door))) (CONJP (RB rather) (IN than)) (VP (VBG having) (S (S (NP (DT the) (NN door)) (VP (VBD opened))) (CC and) (S (S (VP (VBG having) (S (VP (TO to) (VP (VB cope) (PP (IN with) (S (VP (VBG entering) (NP (PRP it)))))))))) (PRN (, ,) ('' '') (S (NP (NNP Ono)) (VP (VBZ says) (PP (IN during) (NP (NP (DT a) (NN telephone) (NN interview)) (SBAR (S (NP (PRP She)) (VP (VBZ 's) (VP (VBG speaking) (PP (IN from) (NP (NP (DT the) (NNP New) (NNP York) (NN office)) (PP (IN of) (NP (NNP Bag) (CD One) (NNS Arts))))))))))))) (, ,)) (NP (DT the) (NN company) (NNP Ono)) (VP (VBD founded) (S (VP (TO to) (VP (VB promote) (NP (NP (NNP Lennon) (POS 's)) (NN art) (CC and) (NN image)) (NP-TMP (NP (NNP Marketing)) (NP (DT an) (NN icon)))))))))))))))))) (: ;) (S (PP (IN Since) (NP (NP (PRP$ his) (NN death)) (PP (IN in) (NP (CD 1980))))) (, ,) (NP (NNP Ono)) (VP (VBZ has) (ADVP (RB steadily)) (VP (VBN kept) (NP (NP (NP (NNP Lennon) (NNS products)) (VP (VBG coming) (PRT (RP out)))) (: :) (NP (NP (DT the) (NNS albums)) (SBAR (S (NP (`` ``) (NP (NP (NN Milk)) (CC and) (NP (NNP Honey))) ('' '') (CC and) (`` ``) (NP (NNP Menlove) (NNP Avenue)) ('' ''))))) (CC and) (NP (NP (DT the) (NN 4-CD) (JJ boxed) (NN set)) (`` ``) (NP (DT The) (NNP John) (NNP Lennon) (NNP Collection)))))))) ('' '')))) (: ;) (NP (NP (DT the) (NN book)) (SBAR (S (NP (`` ``) (NP (NP (NN Skywriting)) (PP (IN by) (NP (NP (NN Word)) (PP (IN of) (NP (NNP Mouth)))))) (, ,) ('' '') (NP (NP (NP (DT a) (NN collection)) (PP (IN of) (NP (NP (NNP Lennon) (POS 's)) (JJ unpublished) (NNS writings)))) (: ;) (NP (NP (NP (NNP Lennon) (POS 's)) (NN art)) (, ,) (SBAR (WHNP (WDT which)) (S (NP (NNP Ono)) (VP (VBZ says))))))) (VP (VBD was) (NP (NP (PRP$ his) (JJ main) (NN interest)) (PP (IN in) (NP (PRP$ his) (JJ final) (NNS years)))))))) (: ;) (CC and) (NP (NP (JJ Lennon-inspired) (NN merchandise)) (, ,) (PP (JJ such) (IN as) (NP (NP (DT a) (NN line)) (PP (IN of) (NP (NNP John) (NNP Lennon) (NNS eyeglasses))) (`` ``) (S (NP (PRP I)) (VP (VBD told) (NP (DT the) (NNS fans)) (SBAR (IN that) (S (NP (PRP I)) (VP (VBP 'm) (VP (VBG going) (S (VP (TO to) (VP (VB do) (NP (NP (CD 10) (NNS years)) (PP (IN of) (NP (PRP it)))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the albums `` Milk and Honey '' and `` Menlove Avenue ''" type="NP">
          <tokens>
            <token id="82" string="the" />
            <token id="83" string="albums" />
            <token id="84" string="&quot;" />
            <token id="85" string="Milk" />
            <token id="86" string="and" />
            <token id="87" string="Honey" />
            <token id="88" string="&quot;" />
            <token id="89" string="and" />
            <token id="90" string="&quot;" />
            <token id="91" string="Menlove" />
            <token id="92" string="Avenue" />
            <token id="93" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="2" string="Milk and Honey" type="NP">
          <tokens>
            <token id="85" string="Milk" />
            <token id="86" string="and" />
            <token id="87" string="Honey" />
          </tokens>
        </chunking>
        <chunking id="3" string="The John Lennon Collection" type="NP">
          <tokens>
            <token id="100" string="The" />
            <token id="101" string="John" />
            <token id="102" string="Lennon" />
            <token id="103" string="Collection" />
          </tokens>
        </chunking>
        <chunking id="4" string="Lennon 's art" type="NP">
          <tokens>
            <token id="124" string="Lennon" />
            <token id="125" string="'s" />
            <token id="126" string="art" />
          </tokens>
        </chunking>
        <chunking id="5" string="'m going to do 10 years of it" type="VP">
          <tokens>
            <token id="159" string="'m" />
            <token id="160" string="going" />
            <token id="161" string="to" />
            <token id="162" string="do" />
            <token id="163" string="10" />
            <token id="164" string="years" />
            <token id="165" string="of" />
            <token id="166" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="his final years" type="NP">
          <tokens>
            <token id="136" string="his" />
            <token id="137" string="final" />
            <token id="138" string="years" />
          </tokens>
        </chunking>
        <chunking id="7" string="told the fans that I 'm going to do 10 years of it" type="VP">
          <tokens>
            <token id="154" string="told" />
            <token id="155" string="the" />
            <token id="156" string="fans" />
            <token id="157" string="that" />
            <token id="158" string="I" />
            <token id="159" string="'m" />
            <token id="160" string="going" />
            <token id="161" string="to" />
            <token id="162" string="do" />
            <token id="163" string="10" />
            <token id="164" string="years" />
            <token id="165" string="of" />
            <token id="166" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="sort" type="NP">
          <tokens>
            <token id="13" string="sort" />
          </tokens>
        </chunking>
        <chunking id="9" string="says during a telephone interview She 's speaking from the New York office of Bag One Arts" type="VP">
          <tokens>
            <token id="34" string="says" />
            <token id="35" string="during" />
            <token id="36" string="a" />
            <token id="37" string="telephone" />
            <token id="38" string="interview" />
            <token id="39" string="She" />
            <token id="40" string="'s" />
            <token id="41" string="speaking" />
            <token id="42" string="from" />
            <token id="43" string="the" />
            <token id="44" string="New" />
            <token id="45" string="York" />
            <token id="46" string="office" />
            <token id="47" string="of" />
            <token id="48" string="Bag" />
            <token id="49" string="One" />
            <token id="50" string="Arts" />
          </tokens>
        </chunking>
        <chunking id="10" string="has steadily kept Lennon products coming out : the albums `` Milk and Honey '' and `` Menlove Avenue '' and the 4-CD boxed set `` The John Lennon Collection" type="VP">
          <tokens>
            <token id="74" string="has" />
            <token id="75" string="steadily" />
            <token id="76" string="kept" />
            <token id="77" string="Lennon" />
            <token id="78" string="products" />
            <token id="79" string="coming" />
            <token id="80" string="out" />
            <token id="81" string=":" />
            <token id="82" string="the" />
            <token id="83" string="albums" />
            <token id="84" string="&quot;" />
            <token id="85" string="Milk" />
            <token id="86" string="and" />
            <token id="87" string="Honey" />
            <token id="88" string="&quot;" />
            <token id="89" string="and" />
            <token id="90" string="&quot;" />
            <token id="91" string="Menlove" />
            <token id="92" string="Avenue" />
            <token id="93" string="&quot;" />
            <token id="94" string="and" />
            <token id="95" string="the" />
            <token id="96" string="4-CD" />
            <token id="97" string="boxed" />
            <token id="98" string="set" />
            <token id="99" string="&quot;" />
            <token id="100" string="The" />
            <token id="101" string="John" />
            <token id="102" string="Lennon" />
            <token id="103" string="Collection" />
          </tokens>
        </chunking>
        <chunking id="11" string="a line" type="NP">
          <tokens>
            <token id="146" string="a" />
            <token id="147" string="line" />
          </tokens>
        </chunking>
        <chunking id="12" string="the book" type="NP">
          <tokens>
            <token id="106" string="the" />
            <token id="107" string="book" />
          </tokens>
        </chunking>
        <chunking id="13" string="10 years" type="NP">
          <tokens>
            <token id="163" string="10" />
            <token id="164" string="years" />
          </tokens>
        </chunking>
        <chunking id="14" string="a telephone interview" type="NP">
          <tokens>
            <token id="36" string="a" />
            <token id="37" string="telephone" />
            <token id="38" string="interview" />
          </tokens>
        </chunking>
        <chunking id="15" string="to promote Lennon 's art and image Marketing an icon" type="VP">
          <tokens>
            <token id="56" string="to" />
            <token id="57" string="promote" />
            <token id="58" string="Lennon" />
            <token id="59" string="'s" />
            <token id="60" string="art" />
            <token id="61" string="and" />
            <token id="62" string="image" />
            <token id="63" string="Marketing" />
            <token id="64" string="an" />
            <token id="65" string="icon" />
          </tokens>
        </chunking>
        <chunking id="16" string="Honey" type="NP">
          <tokens>
            <token id="87" string="Honey" />
          </tokens>
        </chunking>
        <chunking id="17" string="going to do 10 years of it" type="VP">
          <tokens>
            <token id="160" string="going" />
            <token id="161" string="to" />
            <token id="162" string="do" />
            <token id="163" string="10" />
            <token id="164" string="years" />
            <token id="165" string="of" />
            <token id="166" string="it" />
          </tokens>
        </chunking>
        <chunking id="18" string="She 's speaking from the New York office of Bag One Arts" type="SBAR">
          <tokens>
            <token id="39" string="She" />
            <token id="40" string="'s" />
            <token id="41" string="speaking" />
            <token id="42" string="from" />
            <token id="43" string="the" />
            <token id="44" string="New" />
            <token id="45" string="York" />
            <token id="46" string="office" />
            <token id="47" string="of" />
            <token id="48" string="Bag" />
            <token id="49" string="One" />
            <token id="50" string="Arts" />
          </tokens>
        </chunking>
        <chunking id="19" string="having to cope with entering it" type="VP">
          <tokens>
            <token id="25" string="having" />
            <token id="26" string="to" />
            <token id="27" string="cope" />
            <token id="28" string="with" />
            <token id="29" string="entering" />
            <token id="30" string="it" />
          </tokens>
        </chunking>
        <chunking id="20" string="the company Ono" type="NP">
          <tokens>
            <token id="52" string="the" />
            <token id="53" string="company" />
            <token id="54" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="21" string="knocking the door" type="VP">
          <tokens>
            <token id="15" string="knocking" />
            <token id="16" string="the" />
            <token id="17" string="door" />
          </tokens>
        </chunking>
        <chunking id="22" string="that I 'm going to do 10 years of it" type="SBAR">
          <tokens>
            <token id="157" string="that" />
            <token id="158" string="I" />
            <token id="159" string="'m" />
            <token id="160" string="going" />
            <token id="161" string="to" />
            <token id="162" string="do" />
            <token id="163" string="10" />
            <token id="164" string="years" />
            <token id="165" string="of" />
            <token id="166" string="it" />
          </tokens>
        </chunking>
        <chunking id="23" string="Lennon products coming out" type="NP">
          <tokens>
            <token id="77" string="Lennon" />
            <token id="78" string="products" />
            <token id="79" string="coming" />
            <token id="80" string="out" />
          </tokens>
        </chunking>
        <chunking id="24" string="Lennon 's art , which Ono says" type="NP">
          <tokens>
            <token id="124" string="Lennon" />
            <token id="125" string="'s" />
            <token id="126" string="art" />
            <token id="127" string="," />
            <token id="128" string="which" />
            <token id="129" string="Ono" />
            <token id="130" string="says" />
          </tokens>
        </chunking>
        <chunking id="25" string="Acceptance" type="NP">
          <tokens>
            <token id="1" string="Acceptance" />
          </tokens>
        </chunking>
        <chunking id="26" string="to cope with entering it" type="VP">
          <tokens>
            <token id="26" string="to" />
            <token id="27" string="cope" />
            <token id="28" string="with" />
            <token id="29" string="entering" />
            <token id="30" string="it" />
          </tokens>
        </chunking>
        <chunking id="27" string="her `` I 'm used to sort of knocking the door rather than having the door opened and having to cope with entering it , '' Ono says during a telephone interview She 's speaking from the New York office of Bag One Arts , the company Ono founded to promote Lennon 's art and image Marketing an icon ; Since his death in 1980 , Ono has steadily kept Lennon products coming out : the albums `` Milk and Honey '' and `` Menlove Avenue '' and the 4-CD boxed set `` The John Lennon Collection ''" type="NP">
          <tokens>
            <token id="7" string="her" />
            <token id="8" string="&quot;" />
            <token id="9" string="I" />
            <token id="10" string="'m" />
            <token id="11" string="used" />
            <token id="12" string="to" />
            <token id="13" string="sort" />
            <token id="14" string="of" />
            <token id="15" string="knocking" />
            <token id="16" string="the" />
            <token id="17" string="door" />
            <token id="18" string="rather" />
            <token id="19" string="than" />
            <token id="20" string="having" />
            <token id="21" string="the" />
            <token id="22" string="door" />
            <token id="23" string="opened" />
            <token id="24" string="and" />
            <token id="25" string="having" />
            <token id="26" string="to" />
            <token id="27" string="cope" />
            <token id="28" string="with" />
            <token id="29" string="entering" />
            <token id="30" string="it" />
            <token id="31" string="," />
            <token id="32" string="&quot;" />
            <token id="33" string="Ono" />
            <token id="34" string="says" />
            <token id="35" string="during" />
            <token id="36" string="a" />
            <token id="37" string="telephone" />
            <token id="38" string="interview" />
            <token id="39" string="She" />
            <token id="40" string="'s" />
            <token id="41" string="speaking" />
            <token id="42" string="from" />
            <token id="43" string="the" />
            <token id="44" string="New" />
            <token id="45" string="York" />
            <token id="46" string="office" />
            <token id="47" string="of" />
            <token id="48" string="Bag" />
            <token id="49" string="One" />
            <token id="50" string="Arts" />
            <token id="51" string="," />
            <token id="52" string="the" />
            <token id="53" string="company" />
            <token id="54" string="Ono" />
            <token id="55" string="founded" />
            <token id="56" string="to" />
            <token id="57" string="promote" />
            <token id="58" string="Lennon" />
            <token id="59" string="'s" />
            <token id="60" string="art" />
            <token id="61" string="and" />
            <token id="62" string="image" />
            <token id="63" string="Marketing" />
            <token id="64" string="an" />
            <token id="65" string="icon" />
            <token id="66" string=";" />
            <token id="67" string="Since" />
            <token id="68" string="his" />
            <token id="69" string="death" />
            <token id="70" string="in" />
            <token id="71" string="1980" />
            <token id="72" string="," />
            <token id="73" string="Ono" />
            <token id="74" string="has" />
            <token id="75" string="steadily" />
            <token id="76" string="kept" />
            <token id="77" string="Lennon" />
            <token id="78" string="products" />
            <token id="79" string="coming" />
            <token id="80" string="out" />
            <token id="81" string=":" />
            <token id="82" string="the" />
            <token id="83" string="albums" />
            <token id="84" string="&quot;" />
            <token id="85" string="Milk" />
            <token id="86" string="and" />
            <token id="87" string="Honey" />
            <token id="88" string="&quot;" />
            <token id="89" string="and" />
            <token id="90" string="&quot;" />
            <token id="91" string="Menlove" />
            <token id="92" string="Avenue" />
            <token id="93" string="&quot;" />
            <token id="94" string="and" />
            <token id="95" string="the" />
            <token id="96" string="4-CD" />
            <token id="97" string="boxed" />
            <token id="98" string="set" />
            <token id="99" string="&quot;" />
            <token id="100" string="The" />
            <token id="101" string="John" />
            <token id="102" string="Lennon" />
            <token id="103" string="Collection" />
            <token id="104" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="28" string="Lennon-inspired merchandise" type="NP">
          <tokens>
            <token id="141" string="Lennon-inspired" />
            <token id="142" string="merchandise" />
          </tokens>
        </chunking>
        <chunking id="29" string="1980" type="NP">
          <tokens>
            <token id="71" string="1980" />
          </tokens>
        </chunking>
        <chunking id="30" string="which Ono says" type="SBAR">
          <tokens>
            <token id="128" string="which" />
            <token id="129" string="Ono" />
            <token id="130" string="says" />
          </tokens>
        </chunking>
        <chunking id="31" string="Lennon 's" type="NP">
          <tokens>
            <token id="58" string="Lennon" />
            <token id="59" string="'s" />
          </tokens>
        </chunking>
        <chunking id="32" string="his main interest in his final years" type="NP">
          <tokens>
            <token id="132" string="his" />
            <token id="133" string="main" />
            <token id="134" string="interest" />
            <token id="135" string="in" />
            <token id="136" string="his" />
            <token id="137" string="final" />
            <token id="138" string="years" />
          </tokens>
        </chunking>
        <chunking id="33" string="She" type="NP">
          <tokens>
            <token id="39" string="She" />
          </tokens>
        </chunking>
        <chunking id="34" string="the New York office of Bag One Arts" type="NP">
          <tokens>
            <token id="43" string="the" />
            <token id="44" string="New" />
            <token id="45" string="York" />
            <token id="46" string="office" />
            <token id="47" string="of" />
            <token id="48" string="Bag" />
            <token id="49" string="One" />
            <token id="50" string="Arts" />
          </tokens>
        </chunking>
        <chunking id="35" string="a line of John Lennon eyeglasses `` I told the fans that I 'm going to do 10 years of it" type="NP">
          <tokens>
            <token id="146" string="a" />
            <token id="147" string="line" />
            <token id="148" string="of" />
            <token id="149" string="John" />
            <token id="150" string="Lennon" />
            <token id="151" string="eyeglasses" />
            <token id="152" string="&quot;" />
            <token id="153" string="I" />
            <token id="154" string="told" />
            <token id="155" string="the" />
            <token id="156" string="fans" />
            <token id="157" string="that" />
            <token id="158" string="I" />
            <token id="159" string="'m" />
            <token id="160" string="going" />
            <token id="161" string="to" />
            <token id="162" string="do" />
            <token id="163" string="10" />
            <token id="164" string="years" />
            <token id="165" string="of" />
            <token id="166" string="it" />
          </tokens>
        </chunking>
        <chunking id="36" string="'m used to sort of knocking the door rather than having the door opened and having to cope with entering it , '' Ono says during a telephone interview She 's speaking from the New York office of Bag One Arts , the company Ono founded to promote Lennon 's art and image Marketing an icon" type="VP">
          <tokens>
            <token id="10" string="'m" />
            <token id="11" string="used" />
            <token id="12" string="to" />
            <token id="13" string="sort" />
            <token id="14" string="of" />
            <token id="15" string="knocking" />
            <token id="16" string="the" />
            <token id="17" string="door" />
            <token id="18" string="rather" />
            <token id="19" string="than" />
            <token id="20" string="having" />
            <token id="21" string="the" />
            <token id="22" string="door" />
            <token id="23" string="opened" />
            <token id="24" string="and" />
            <token id="25" string="having" />
            <token id="26" string="to" />
            <token id="27" string="cope" />
            <token id="28" string="with" />
            <token id="29" string="entering" />
            <token id="30" string="it" />
            <token id="31" string="," />
            <token id="32" string="&quot;" />
            <token id="33" string="Ono" />
            <token id="34" string="says" />
            <token id="35" string="during" />
            <token id="36" string="a" />
            <token id="37" string="telephone" />
            <token id="38" string="interview" />
            <token id="39" string="She" />
            <token id="40" string="'s" />
            <token id="41" string="speaking" />
            <token id="42" string="from" />
            <token id="43" string="the" />
            <token id="44" string="New" />
            <token id="45" string="York" />
            <token id="46" string="office" />
            <token id="47" string="of" />
            <token id="48" string="Bag" />
            <token id="49" string="One" />
            <token id="50" string="Arts" />
            <token id="51" string="," />
            <token id="52" string="the" />
            <token id="53" string="company" />
            <token id="54" string="Ono" />
            <token id="55" string="founded" />
            <token id="56" string="to" />
            <token id="57" string="promote" />
            <token id="58" string="Lennon" />
            <token id="59" string="'s" />
            <token id="60" string="art" />
            <token id="61" string="and" />
            <token id="62" string="image" />
            <token id="63" string="Marketing" />
            <token id="64" string="an" />
            <token id="65" string="icon" />
          </tokens>
        </chunking>
        <chunking id="37" string="entering it" type="VP">
          <tokens>
            <token id="29" string="entering" />
            <token id="30" string="it" />
          </tokens>
        </chunking>
        <chunking id="38" string="'s speaking from the New York office of Bag One Arts" type="VP">
          <tokens>
            <token id="40" string="'s" />
            <token id="41" string="speaking" />
            <token id="42" string="from" />
            <token id="43" string="the" />
            <token id="44" string="New" />
            <token id="45" string="York" />
            <token id="46" string="office" />
            <token id="47" string="of" />
            <token id="48" string="Bag" />
            <token id="49" string="One" />
            <token id="50" string="Arts" />
          </tokens>
        </chunking>
        <chunking id="39" string="says" type="VP">
          <tokens>
            <token id="130" string="says" />
          </tokens>
        </chunking>
        <chunking id="40" string="John Lennon eyeglasses" type="NP">
          <tokens>
            <token id="149" string="John" />
            <token id="150" string="Lennon" />
            <token id="151" string="eyeglasses" />
          </tokens>
        </chunking>
        <chunking id="41" string="her" type="NP">
          <tokens>
            <token id="7" string="her" />
          </tokens>
        </chunking>
        <chunking id="42" string="Bag One Arts" type="NP">
          <tokens>
            <token id="48" string="Bag" />
            <token id="49" string="One" />
            <token id="50" string="Arts" />
          </tokens>
        </chunking>
        <chunking id="43" string="Menlove Avenue" type="NP">
          <tokens>
            <token id="91" string="Menlove" />
            <token id="92" string="Avenue" />
          </tokens>
        </chunking>
        <chunking id="44" string="Mouth" type="NP">
          <tokens>
            <token id="113" string="Mouth" />
          </tokens>
        </chunking>
        <chunking id="45" string="Lennon 's art and image" type="NP">
          <tokens>
            <token id="58" string="Lennon" />
            <token id="59" string="'s" />
            <token id="60" string="art" />
            <token id="61" string="and" />
            <token id="62" string="image" />
          </tokens>
        </chunking>
        <chunking id="46" string="10 years of it" type="NP">
          <tokens>
            <token id="163" string="10" />
            <token id="164" string="years" />
            <token id="165" string="of" />
            <token id="166" string="it" />
          </tokens>
        </chunking>
        <chunking id="47" string="a collection of Lennon 's unpublished writings ; Lennon 's art , which Ono says" type="NP">
          <tokens>
            <token id="116" string="a" />
            <token id="117" string="collection" />
            <token id="118" string="of" />
            <token id="119" string="Lennon" />
            <token id="120" string="'s" />
            <token id="121" string="unpublished" />
            <token id="122" string="writings" />
            <token id="123" string=";" />
            <token id="124" string="Lennon" />
            <token id="125" string="'s" />
            <token id="126" string="art" />
            <token id="127" string="," />
            <token id="128" string="which" />
            <token id="129" string="Ono" />
            <token id="130" string="says" />
          </tokens>
        </chunking>
        <chunking id="48" string="a telephone interview She 's speaking from the New York office of Bag One Arts" type="NP">
          <tokens>
            <token id="36" string="a" />
            <token id="37" string="telephone" />
            <token id="38" string="interview" />
            <token id="39" string="She" />
            <token id="40" string="'s" />
            <token id="41" string="speaking" />
            <token id="42" string="from" />
            <token id="43" string="the" />
            <token id="44" string="New" />
            <token id="45" string="York" />
            <token id="46" string="office" />
            <token id="47" string="of" />
            <token id="48" string="Bag" />
            <token id="49" string="One" />
            <token id="50" string="Arts" />
          </tokens>
        </chunking>
        <chunking id="49" string="the book `` Skywriting by Word of Mouth , '' a collection of Lennon 's unpublished writings ; Lennon 's art , which Ono says was his main interest in his final years" type="NP">
          <tokens>
            <token id="106" string="the" />
            <token id="107" string="book" />
            <token id="108" string="&quot;" />
            <token id="109" string="Skywriting" />
            <token id="110" string="by" />
            <token id="111" string="Word" />
            <token id="112" string="of" />
            <token id="113" string="Mouth" />
            <token id="114" string="," />
            <token id="115" string="&quot;" />
            <token id="116" string="a" />
            <token id="117" string="collection" />
            <token id="118" string="of" />
            <token id="119" string="Lennon" />
            <token id="120" string="'s" />
            <token id="121" string="unpublished" />
            <token id="122" string="writings" />
            <token id="123" string=";" />
            <token id="124" string="Lennon" />
            <token id="125" string="'s" />
            <token id="126" string="art" />
            <token id="127" string="," />
            <token id="128" string="which" />
            <token id="129" string="Ono" />
            <token id="130" string="says" />
            <token id="131" string="was" />
            <token id="132" string="his" />
            <token id="133" string="main" />
            <token id="134" string="interest" />
            <token id="135" string="in" />
            <token id="136" string="his" />
            <token id="137" string="final" />
            <token id="138" string="years" />
          </tokens>
        </chunking>
        <chunking id="50" string="a difficult concept for her `` I 'm used to sort of knocking the door rather than having the door opened and having to cope with entering it , '' Ono says during a telephone interview She 's speaking from the New York office of Bag One Arts , the company Ono founded to promote Lennon 's art and image Marketing an icon ; Since his death in 1980 , Ono has steadily kept Lennon products coming out : the albums `` Milk and Honey '' and `` Menlove Avenue '' and the 4-CD boxed set `` The John Lennon Collection '' ; the book `` Skywriting by Word of Mouth , '' a collection of Lennon 's unpublished writings ; Lennon 's art , which Ono says was his main interest in his final years ; and Lennon-inspired merchandise , such as a line of John Lennon eyeglasses `` I told the fans that I 'm going to do 10 years of it" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="difficult" />
            <token id="5" string="concept" />
            <token id="6" string="for" />
            <token id="7" string="her" />
            <token id="8" string="&quot;" />
            <token id="9" string="I" />
            <token id="10" string="'m" />
            <token id="11" string="used" />
            <token id="12" string="to" />
            <token id="13" string="sort" />
            <token id="14" string="of" />
            <token id="15" string="knocking" />
            <token id="16" string="the" />
            <token id="17" string="door" />
            <token id="18" string="rather" />
            <token id="19" string="than" />
            <token id="20" string="having" />
            <token id="21" string="the" />
            <token id="22" string="door" />
            <token id="23" string="opened" />
            <token id="24" string="and" />
            <token id="25" string="having" />
            <token id="26" string="to" />
            <token id="27" string="cope" />
            <token id="28" string="with" />
            <token id="29" string="entering" />
            <token id="30" string="it" />
            <token id="31" string="," />
            <token id="32" string="&quot;" />
            <token id="33" string="Ono" />
            <token id="34" string="says" />
            <token id="35" string="during" />
            <token id="36" string="a" />
            <token id="37" string="telephone" />
            <token id="38" string="interview" />
            <token id="39" string="She" />
            <token id="40" string="'s" />
            <token id="41" string="speaking" />
            <token id="42" string="from" />
            <token id="43" string="the" />
            <token id="44" string="New" />
            <token id="45" string="York" />
            <token id="46" string="office" />
            <token id="47" string="of" />
            <token id="48" string="Bag" />
            <token id="49" string="One" />
            <token id="50" string="Arts" />
            <token id="51" string="," />
            <token id="52" string="the" />
            <token id="53" string="company" />
            <token id="54" string="Ono" />
            <token id="55" string="founded" />
            <token id="56" string="to" />
            <token id="57" string="promote" />
            <token id="58" string="Lennon" />
            <token id="59" string="'s" />
            <token id="60" string="art" />
            <token id="61" string="and" />
            <token id="62" string="image" />
            <token id="63" string="Marketing" />
            <token id="64" string="an" />
            <token id="65" string="icon" />
            <token id="66" string=";" />
            <token id="67" string="Since" />
            <token id="68" string="his" />
            <token id="69" string="death" />
            <token id="70" string="in" />
            <token id="71" string="1980" />
            <token id="72" string="," />
            <token id="73" string="Ono" />
            <token id="74" string="has" />
            <token id="75" string="steadily" />
            <token id="76" string="kept" />
            <token id="77" string="Lennon" />
            <token id="78" string="products" />
            <token id="79" string="coming" />
            <token id="80" string="out" />
            <token id="81" string=":" />
            <token id="82" string="the" />
            <token id="83" string="albums" />
            <token id="84" string="&quot;" />
            <token id="85" string="Milk" />
            <token id="86" string="and" />
            <token id="87" string="Honey" />
            <token id="88" string="&quot;" />
            <token id="89" string="and" />
            <token id="90" string="&quot;" />
            <token id="91" string="Menlove" />
            <token id="92" string="Avenue" />
            <token id="93" string="&quot;" />
            <token id="94" string="and" />
            <token id="95" string="the" />
            <token id="96" string="4-CD" />
            <token id="97" string="boxed" />
            <token id="98" string="set" />
            <token id="99" string="&quot;" />
            <token id="100" string="The" />
            <token id="101" string="John" />
            <token id="102" string="Lennon" />
            <token id="103" string="Collection" />
            <token id="104" string="&quot;" />
            <token id="105" string=";" />
            <token id="106" string="the" />
            <token id="107" string="book" />
            <token id="108" string="&quot;" />
            <token id="109" string="Skywriting" />
            <token id="110" string="by" />
            <token id="111" string="Word" />
            <token id="112" string="of" />
            <token id="113" string="Mouth" />
            <token id="114" string="," />
            <token id="115" string="&quot;" />
            <token id="116" string="a" />
            <token id="117" string="collection" />
            <token id="118" string="of" />
            <token id="119" string="Lennon" />
            <token id="120" string="'s" />
            <token id="121" string="unpublished" />
            <token id="122" string="writings" />
            <token id="123" string=";" />
            <token id="124" string="Lennon" />
            <token id="125" string="'s" />
            <token id="126" string="art" />
            <token id="127" string="," />
            <token id="128" string="which" />
            <token id="129" string="Ono" />
            <token id="130" string="says" />
            <token id="131" string="was" />
            <token id="132" string="his" />
            <token id="133" string="main" />
            <token id="134" string="interest" />
            <token id="135" string="in" />
            <token id="136" string="his" />
            <token id="137" string="final" />
            <token id="138" string="years" />
            <token id="139" string=";" />
            <token id="140" string="and" />
            <token id="141" string="Lennon-inspired" />
            <token id="142" string="merchandise" />
            <token id="143" string="," />
            <token id="144" string="such" />
            <token id="145" string="as" />
            <token id="146" string="a" />
            <token id="147" string="line" />
            <token id="148" string="of" />
            <token id="149" string="John" />
            <token id="150" string="Lennon" />
            <token id="151" string="eyeglasses" />
            <token id="152" string="&quot;" />
            <token id="153" string="I" />
            <token id="154" string="told" />
            <token id="155" string="the" />
            <token id="156" string="fans" />
            <token id="157" string="that" />
            <token id="158" string="I" />
            <token id="159" string="'m" />
            <token id="160" string="going" />
            <token id="161" string="to" />
            <token id="162" string="do" />
            <token id="163" string="10" />
            <token id="164" string="years" />
            <token id="165" string="of" />
            <token id="166" string="it" />
          </tokens>
        </chunking>
        <chunking id="51" string="Skywriting" type="NP">
          <tokens>
            <token id="109" string="Skywriting" />
          </tokens>
        </chunking>
        <chunking id="52" string="knocking the door rather than having the door opened and having to cope with entering it , '' Ono says during a telephone interview She 's speaking from the New York office of Bag One Arts , the company Ono founded to promote Lennon 's art and image Marketing an icon" type="VP">
          <tokens>
            <token id="15" string="knocking" />
            <token id="16" string="the" />
            <token id="17" string="door" />
            <token id="18" string="rather" />
            <token id="19" string="than" />
            <token id="20" string="having" />
            <token id="21" string="the" />
            <token id="22" string="door" />
            <token id="23" string="opened" />
            <token id="24" string="and" />
            <token id="25" string="having" />
            <token id="26" string="to" />
            <token id="27" string="cope" />
            <token id="28" string="with" />
            <token id="29" string="entering" />
            <token id="30" string="it" />
            <token id="31" string="," />
            <token id="32" string="&quot;" />
            <token id="33" string="Ono" />
            <token id="34" string="says" />
            <token id="35" string="during" />
            <token id="36" string="a" />
            <token id="37" string="telephone" />
            <token id="38" string="interview" />
            <token id="39" string="She" />
            <token id="40" string="'s" />
            <token id="41" string="speaking" />
            <token id="42" string="from" />
            <token id="43" string="the" />
            <token id="44" string="New" />
            <token id="45" string="York" />
            <token id="46" string="office" />
            <token id="47" string="of" />
            <token id="48" string="Bag" />
            <token id="49" string="One" />
            <token id="50" string="Arts" />
            <token id="51" string="," />
            <token id="52" string="the" />
            <token id="53" string="company" />
            <token id="54" string="Ono" />
            <token id="55" string="founded" />
            <token id="56" string="to" />
            <token id="57" string="promote" />
            <token id="58" string="Lennon" />
            <token id="59" string="'s" />
            <token id="60" string="art" />
            <token id="61" string="and" />
            <token id="62" string="image" />
            <token id="63" string="Marketing" />
            <token id="64" string="an" />
            <token id="65" string="icon" />
          </tokens>
        </chunking>
        <chunking id="53" string="Lennon products coming out : the albums `` Milk and Honey '' and `` Menlove Avenue '' and the 4-CD boxed set `` The John Lennon Collection" type="NP">
          <tokens>
            <token id="77" string="Lennon" />
            <token id="78" string="products" />
            <token id="79" string="coming" />
            <token id="80" string="out" />
            <token id="81" string=":" />
            <token id="82" string="the" />
            <token id="83" string="albums" />
            <token id="84" string="&quot;" />
            <token id="85" string="Milk" />
            <token id="86" string="and" />
            <token id="87" string="Honey" />
            <token id="88" string="&quot;" />
            <token id="89" string="and" />
            <token id="90" string="&quot;" />
            <token id="91" string="Menlove" />
            <token id="92" string="Avenue" />
            <token id="93" string="&quot;" />
            <token id="94" string="and" />
            <token id="95" string="the" />
            <token id="96" string="4-CD" />
            <token id="97" string="boxed" />
            <token id="98" string="set" />
            <token id="99" string="&quot;" />
            <token id="100" string="The" />
            <token id="101" string="John" />
            <token id="102" string="Lennon" />
            <token id="103" string="Collection" />
          </tokens>
        </chunking>
        <chunking id="54" string="do 10 years of it" type="VP">
          <tokens>
            <token id="162" string="do" />
            <token id="163" string="10" />
            <token id="164" string="years" />
            <token id="165" string="of" />
            <token id="166" string="it" />
          </tokens>
        </chunking>
        <chunking id="55" string="the door" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="door" />
          </tokens>
        </chunking>
        <chunking id="56" string="a collection" type="NP">
          <tokens>
            <token id="116" string="a" />
            <token id="117" string="collection" />
          </tokens>
        </chunking>
        <chunking id="57" string="speaking from the New York office of Bag One Arts" type="VP">
          <tokens>
            <token id="41" string="speaking" />
            <token id="42" string="from" />
            <token id="43" string="the" />
            <token id="44" string="New" />
            <token id="45" string="York" />
            <token id="46" string="office" />
            <token id="47" string="of" />
            <token id="48" string="Bag" />
            <token id="49" string="One" />
            <token id="50" string="Arts" />
          </tokens>
        </chunking>
        <chunking id="58" string="a collection of Lennon 's unpublished writings" type="NP">
          <tokens>
            <token id="116" string="a" />
            <token id="117" string="collection" />
            <token id="118" string="of" />
            <token id="119" string="Lennon" />
            <token id="120" string="'s" />
            <token id="121" string="unpublished" />
            <token id="122" string="writings" />
          </tokens>
        </chunking>
        <chunking id="59" string="it" type="NP">
          <tokens>
            <token id="30" string="it" />
          </tokens>
        </chunking>
        <chunking id="60" string="the albums" type="NP">
          <tokens>
            <token id="82" string="the" />
            <token id="83" string="albums" />
          </tokens>
        </chunking>
        <chunking id="61" string="`` Skywriting by Word of Mouth , '' a collection of Lennon 's unpublished writings ; Lennon 's art , which Ono says was his main interest in his final years" type="SBAR">
          <tokens>
            <token id="108" string="&quot;" />
            <token id="109" string="Skywriting" />
            <token id="110" string="by" />
            <token id="111" string="Word" />
            <token id="112" string="of" />
            <token id="113" string="Mouth" />
            <token id="114" string="," />
            <token id="115" string="&quot;" />
            <token id="116" string="a" />
            <token id="117" string="collection" />
            <token id="118" string="of" />
            <token id="119" string="Lennon" />
            <token id="120" string="'s" />
            <token id="121" string="unpublished" />
            <token id="122" string="writings" />
            <token id="123" string=";" />
            <token id="124" string="Lennon" />
            <token id="125" string="'s" />
            <token id="126" string="art" />
            <token id="127" string="," />
            <token id="128" string="which" />
            <token id="129" string="Ono" />
            <token id="130" string="says" />
            <token id="131" string="was" />
            <token id="132" string="his" />
            <token id="133" string="main" />
            <token id="134" string="interest" />
            <token id="135" string="in" />
            <token id="136" string="his" />
            <token id="137" string="final" />
            <token id="138" string="years" />
          </tokens>
        </chunking>
        <chunking id="62" string="opened" type="VP">
          <tokens>
            <token id="23" string="opened" />
          </tokens>
        </chunking>
        <chunking id="63" string="Lennon-inspired merchandise , such as a line of John Lennon eyeglasses `` I told the fans that I 'm going to do 10 years of it" type="NP">
          <tokens>
            <token id="141" string="Lennon-inspired" />
            <token id="142" string="merchandise" />
            <token id="143" string="," />
            <token id="144" string="such" />
            <token id="145" string="as" />
            <token id="146" string="a" />
            <token id="147" string="line" />
            <token id="148" string="of" />
            <token id="149" string="John" />
            <token id="150" string="Lennon" />
            <token id="151" string="eyeglasses" />
            <token id="152" string="&quot;" />
            <token id="153" string="I" />
            <token id="154" string="told" />
            <token id="155" string="the" />
            <token id="156" string="fans" />
            <token id="157" string="that" />
            <token id="158" string="I" />
            <token id="159" string="'m" />
            <token id="160" string="going" />
            <token id="161" string="to" />
            <token id="162" string="do" />
            <token id="163" string="10" />
            <token id="164" string="years" />
            <token id="165" string="of" />
            <token id="166" string="it" />
          </tokens>
        </chunking>
        <chunking id="64" string="sort of knocking the door rather than having the door opened and having to cope with entering it , '' Ono says during a telephone interview She 's speaking from the New York office of Bag One Arts , the company Ono founded to promote Lennon 's art and image Marketing an icon" type="NP">
          <tokens>
            <token id="13" string="sort" />
            <token id="14" string="of" />
            <token id="15" string="knocking" />
            <token id="16" string="the" />
            <token id="17" string="door" />
            <token id="18" string="rather" />
            <token id="19" string="than" />
            <token id="20" string="having" />
            <token id="21" string="the" />
            <token id="22" string="door" />
            <token id="23" string="opened" />
            <token id="24" string="and" />
            <token id="25" string="having" />
            <token id="26" string="to" />
            <token id="27" string="cope" />
            <token id="28" string="with" />
            <token id="29" string="entering" />
            <token id="30" string="it" />
            <token id="31" string="," />
            <token id="32" string="&quot;" />
            <token id="33" string="Ono" />
            <token id="34" string="says" />
            <token id="35" string="during" />
            <token id="36" string="a" />
            <token id="37" string="telephone" />
            <token id="38" string="interview" />
            <token id="39" string="She" />
            <token id="40" string="'s" />
            <token id="41" string="speaking" />
            <token id="42" string="from" />
            <token id="43" string="the" />
            <token id="44" string="New" />
            <token id="45" string="York" />
            <token id="46" string="office" />
            <token id="47" string="of" />
            <token id="48" string="Bag" />
            <token id="49" string="One" />
            <token id="50" string="Arts" />
            <token id="51" string="," />
            <token id="52" string="the" />
            <token id="53" string="company" />
            <token id="54" string="Ono" />
            <token id="55" string="founded" />
            <token id="56" string="to" />
            <token id="57" string="promote" />
            <token id="58" string="Lennon" />
            <token id="59" string="'s" />
            <token id="60" string="art" />
            <token id="61" string="and" />
            <token id="62" string="image" />
            <token id="63" string="Marketing" />
            <token id="64" string="an" />
            <token id="65" string="icon" />
          </tokens>
        </chunking>
        <chunking id="65" string="an icon" type="NP">
          <tokens>
            <token id="64" string="an" />
            <token id="65" string="icon" />
          </tokens>
        </chunking>
        <chunking id="66" string="used to sort of knocking the door rather than having the door opened and having to cope with entering it , '' Ono says during a telephone interview She 's speaking from the New York office of Bag One Arts , the company Ono founded to promote Lennon 's art and image Marketing an icon" type="VP">
          <tokens>
            <token id="11" string="used" />
            <token id="12" string="to" />
            <token id="13" string="sort" />
            <token id="14" string="of" />
            <token id="15" string="knocking" />
            <token id="16" string="the" />
            <token id="17" string="door" />
            <token id="18" string="rather" />
            <token id="19" string="than" />
            <token id="20" string="having" />
            <token id="21" string="the" />
            <token id="22" string="door" />
            <token id="23" string="opened" />
            <token id="24" string="and" />
            <token id="25" string="having" />
            <token id="26" string="to" />
            <token id="27" string="cope" />
            <token id="28" string="with" />
            <token id="29" string="entering" />
            <token id="30" string="it" />
            <token id="31" string="," />
            <token id="32" string="&quot;" />
            <token id="33" string="Ono" />
            <token id="34" string="says" />
            <token id="35" string="during" />
            <token id="36" string="a" />
            <token id="37" string="telephone" />
            <token id="38" string="interview" />
            <token id="39" string="She" />
            <token id="40" string="'s" />
            <token id="41" string="speaking" />
            <token id="42" string="from" />
            <token id="43" string="the" />
            <token id="44" string="New" />
            <token id="45" string="York" />
            <token id="46" string="office" />
            <token id="47" string="of" />
            <token id="48" string="Bag" />
            <token id="49" string="One" />
            <token id="50" string="Arts" />
            <token id="51" string="," />
            <token id="52" string="the" />
            <token id="53" string="company" />
            <token id="54" string="Ono" />
            <token id="55" string="founded" />
            <token id="56" string="to" />
            <token id="57" string="promote" />
            <token id="58" string="Lennon" />
            <token id="59" string="'s" />
            <token id="60" string="art" />
            <token id="61" string="and" />
            <token id="62" string="image" />
            <token id="63" string="Marketing" />
            <token id="64" string="an" />
            <token id="65" string="icon" />
          </tokens>
        </chunking>
        <chunking id="67" string="cope with entering it" type="VP">
          <tokens>
            <token id="27" string="cope" />
            <token id="28" string="with" />
            <token id="29" string="entering" />
            <token id="30" string="it" />
          </tokens>
        </chunking>
        <chunking id="68" string="founded to promote Lennon 's art and image Marketing an icon" type="VP">
          <tokens>
            <token id="55" string="founded" />
            <token id="56" string="to" />
            <token id="57" string="promote" />
            <token id="58" string="Lennon" />
            <token id="59" string="'s" />
            <token id="60" string="art" />
            <token id="61" string="and" />
            <token id="62" string="image" />
            <token id="63" string="Marketing" />
            <token id="64" string="an" />
            <token id="65" string="icon" />
          </tokens>
        </chunking>
        <chunking id="69" string="the 4-CD boxed set" type="NP">
          <tokens>
            <token id="95" string="the" />
            <token id="96" string="4-CD" />
            <token id="97" string="boxed" />
            <token id="98" string="set" />
          </tokens>
        </chunking>
        <chunking id="70" string="Lennon products" type="NP">
          <tokens>
            <token id="77" string="Lennon" />
            <token id="78" string="products" />
          </tokens>
        </chunking>
        <chunking id="71" string="coming out" type="VP">
          <tokens>
            <token id="79" string="coming" />
            <token id="80" string="out" />
          </tokens>
        </chunking>
        <chunking id="72" string="Lennon 's unpublished writings" type="NP">
          <tokens>
            <token id="119" string="Lennon" />
            <token id="120" string="'s" />
            <token id="121" string="unpublished" />
            <token id="122" string="writings" />
          </tokens>
        </chunking>
        <chunking id="73" string="the 4-CD boxed set `` The John Lennon Collection" type="NP">
          <tokens>
            <token id="95" string="the" />
            <token id="96" string="4-CD" />
            <token id="97" string="boxed" />
            <token id="98" string="set" />
            <token id="99" string="&quot;" />
            <token id="100" string="The" />
            <token id="101" string="John" />
            <token id="102" string="Lennon" />
            <token id="103" string="Collection" />
          </tokens>
        </chunking>
        <chunking id="74" string="`` Skywriting by Word of Mouth , '' a collection of Lennon 's unpublished writings ; Lennon 's art , which Ono says" type="NP">
          <tokens>
            <token id="108" string="&quot;" />
            <token id="109" string="Skywriting" />
            <token id="110" string="by" />
            <token id="111" string="Word" />
            <token id="112" string="of" />
            <token id="113" string="Mouth" />
            <token id="114" string="," />
            <token id="115" string="&quot;" />
            <token id="116" string="a" />
            <token id="117" string="collection" />
            <token id="118" string="of" />
            <token id="119" string="Lennon" />
            <token id="120" string="'s" />
            <token id="121" string="unpublished" />
            <token id="122" string="writings" />
            <token id="123" string=";" />
            <token id="124" string="Lennon" />
            <token id="125" string="'s" />
            <token id="126" string="art" />
            <token id="127" string="," />
            <token id="128" string="which" />
            <token id="129" string="Ono" />
            <token id="130" string="says" />
          </tokens>
        </chunking>
        <chunking id="75" string="a difficult concept for her `` I 'm used to sort of knocking the door rather than having the door opened and having to cope with entering it , '' Ono says during a telephone interview She 's speaking from the New York office of Bag One Arts , the company Ono founded to promote Lennon 's art and image Marketing an icon ; Since his death in 1980 , Ono has steadily kept Lennon products coming out : the albums `` Milk and Honey '' and `` Menlove Avenue '' and the 4-CD boxed set `` The John Lennon Collection ''" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="difficult" />
            <token id="5" string="concept" />
            <token id="6" string="for" />
            <token id="7" string="her" />
            <token id="8" string="&quot;" />
            <token id="9" string="I" />
            <token id="10" string="'m" />
            <token id="11" string="used" />
            <token id="12" string="to" />
            <token id="13" string="sort" />
            <token id="14" string="of" />
            <token id="15" string="knocking" />
            <token id="16" string="the" />
            <token id="17" string="door" />
            <token id="18" string="rather" />
            <token id="19" string="than" />
            <token id="20" string="having" />
            <token id="21" string="the" />
            <token id="22" string="door" />
            <token id="23" string="opened" />
            <token id="24" string="and" />
            <token id="25" string="having" />
            <token id="26" string="to" />
            <token id="27" string="cope" />
            <token id="28" string="with" />
            <token id="29" string="entering" />
            <token id="30" string="it" />
            <token id="31" string="," />
            <token id="32" string="&quot;" />
            <token id="33" string="Ono" />
            <token id="34" string="says" />
            <token id="35" string="during" />
            <token id="36" string="a" />
            <token id="37" string="telephone" />
            <token id="38" string="interview" />
            <token id="39" string="She" />
            <token id="40" string="'s" />
            <token id="41" string="speaking" />
            <token id="42" string="from" />
            <token id="43" string="the" />
            <token id="44" string="New" />
            <token id="45" string="York" />
            <token id="46" string="office" />
            <token id="47" string="of" />
            <token id="48" string="Bag" />
            <token id="49" string="One" />
            <token id="50" string="Arts" />
            <token id="51" string="," />
            <token id="52" string="the" />
            <token id="53" string="company" />
            <token id="54" string="Ono" />
            <token id="55" string="founded" />
            <token id="56" string="to" />
            <token id="57" string="promote" />
            <token id="58" string="Lennon" />
            <token id="59" string="'s" />
            <token id="60" string="art" />
            <token id="61" string="and" />
            <token id="62" string="image" />
            <token id="63" string="Marketing" />
            <token id="64" string="an" />
            <token id="65" string="icon" />
            <token id="66" string=";" />
            <token id="67" string="Since" />
            <token id="68" string="his" />
            <token id="69" string="death" />
            <token id="70" string="in" />
            <token id="71" string="1980" />
            <token id="72" string="," />
            <token id="73" string="Ono" />
            <token id="74" string="has" />
            <token id="75" string="steadily" />
            <token id="76" string="kept" />
            <token id="77" string="Lennon" />
            <token id="78" string="products" />
            <token id="79" string="coming" />
            <token id="80" string="out" />
            <token id="81" string=":" />
            <token id="82" string="the" />
            <token id="83" string="albums" />
            <token id="84" string="&quot;" />
            <token id="85" string="Milk" />
            <token id="86" string="and" />
            <token id="87" string="Honey" />
            <token id="88" string="&quot;" />
            <token id="89" string="and" />
            <token id="90" string="&quot;" />
            <token id="91" string="Menlove" />
            <token id="92" string="Avenue" />
            <token id="93" string="&quot;" />
            <token id="94" string="and" />
            <token id="95" string="the" />
            <token id="96" string="4-CD" />
            <token id="97" string="boxed" />
            <token id="98" string="set" />
            <token id="99" string="&quot;" />
            <token id="100" string="The" />
            <token id="101" string="John" />
            <token id="102" string="Lennon" />
            <token id="103" string="Collection" />
            <token id="104" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="76" string="Word" type="NP">
          <tokens>
            <token id="111" string="Word" />
          </tokens>
        </chunking>
        <chunking id="77" string="his main interest" type="NP">
          <tokens>
            <token id="132" string="his" />
            <token id="133" string="main" />
            <token id="134" string="interest" />
          </tokens>
        </chunking>
        <chunking id="78" string="is a difficult concept for her `` I 'm used to sort of knocking the door rather than having the door opened and having to cope with entering it , '' Ono says during a telephone interview She 's speaking from the New York office of Bag One Arts , the company Ono founded to promote Lennon 's art and image Marketing an icon ; Since his death in 1980 , Ono has steadily kept Lennon products coming out : the albums `` Milk and Honey '' and `` Menlove Avenue '' and the 4-CD boxed set `` The John Lennon Collection '' ; the book `` Skywriting by Word of Mouth , '' a collection of Lennon 's unpublished writings ; Lennon 's art , which Ono says was his main interest in his final years ; and Lennon-inspired merchandise , such as a line of John Lennon eyeglasses `` I told the fans that I 'm going to do 10 years of it" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="a" />
            <token id="4" string="difficult" />
            <token id="5" string="concept" />
            <token id="6" string="for" />
            <token id="7" string="her" />
            <token id="8" string="&quot;" />
            <token id="9" string="I" />
            <token id="10" string="'m" />
            <token id="11" string="used" />
            <token id="12" string="to" />
            <token id="13" string="sort" />
            <token id="14" string="of" />
            <token id="15" string="knocking" />
            <token id="16" string="the" />
            <token id="17" string="door" />
            <token id="18" string="rather" />
            <token id="19" string="than" />
            <token id="20" string="having" />
            <token id="21" string="the" />
            <token id="22" string="door" />
            <token id="23" string="opened" />
            <token id="24" string="and" />
            <token id="25" string="having" />
            <token id="26" string="to" />
            <token id="27" string="cope" />
            <token id="28" string="with" />
            <token id="29" string="entering" />
            <token id="30" string="it" />
            <token id="31" string="," />
            <token id="32" string="&quot;" />
            <token id="33" string="Ono" />
            <token id="34" string="says" />
            <token id="35" string="during" />
            <token id="36" string="a" />
            <token id="37" string="telephone" />
            <token id="38" string="interview" />
            <token id="39" string="She" />
            <token id="40" string="'s" />
            <token id="41" string="speaking" />
            <token id="42" string="from" />
            <token id="43" string="the" />
            <token id="44" string="New" />
            <token id="45" string="York" />
            <token id="46" string="office" />
            <token id="47" string="of" />
            <token id="48" string="Bag" />
            <token id="49" string="One" />
            <token id="50" string="Arts" />
            <token id="51" string="," />
            <token id="52" string="the" />
            <token id="53" string="company" />
            <token id="54" string="Ono" />
            <token id="55" string="founded" />
            <token id="56" string="to" />
            <token id="57" string="promote" />
            <token id="58" string="Lennon" />
            <token id="59" string="'s" />
            <token id="60" string="art" />
            <token id="61" string="and" />
            <token id="62" string="image" />
            <token id="63" string="Marketing" />
            <token id="64" string="an" />
            <token id="65" string="icon" />
            <token id="66" string=";" />
            <token id="67" string="Since" />
            <token id="68" string="his" />
            <token id="69" string="death" />
            <token id="70" string="in" />
            <token id="71" string="1980" />
            <token id="72" string="," />
            <token id="73" string="Ono" />
            <token id="74" string="has" />
            <token id="75" string="steadily" />
            <token id="76" string="kept" />
            <token id="77" string="Lennon" />
            <token id="78" string="products" />
            <token id="79" string="coming" />
            <token id="80" string="out" />
            <token id="81" string=":" />
            <token id="82" string="the" />
            <token id="83" string="albums" />
            <token id="84" string="&quot;" />
            <token id="85" string="Milk" />
            <token id="86" string="and" />
            <token id="87" string="Honey" />
            <token id="88" string="&quot;" />
            <token id="89" string="and" />
            <token id="90" string="&quot;" />
            <token id="91" string="Menlove" />
            <token id="92" string="Avenue" />
            <token id="93" string="&quot;" />
            <token id="94" string="and" />
            <token id="95" string="the" />
            <token id="96" string="4-CD" />
            <token id="97" string="boxed" />
            <token id="98" string="set" />
            <token id="99" string="&quot;" />
            <token id="100" string="The" />
            <token id="101" string="John" />
            <token id="102" string="Lennon" />
            <token id="103" string="Collection" />
            <token id="104" string="&quot;" />
            <token id="105" string=";" />
            <token id="106" string="the" />
            <token id="107" string="book" />
            <token id="108" string="&quot;" />
            <token id="109" string="Skywriting" />
            <token id="110" string="by" />
            <token id="111" string="Word" />
            <token id="112" string="of" />
            <token id="113" string="Mouth" />
            <token id="114" string="," />
            <token id="115" string="&quot;" />
            <token id="116" string="a" />
            <token id="117" string="collection" />
            <token id="118" string="of" />
            <token id="119" string="Lennon" />
            <token id="120" string="'s" />
            <token id="121" string="unpublished" />
            <token id="122" string="writings" />
            <token id="123" string=";" />
            <token id="124" string="Lennon" />
            <token id="125" string="'s" />
            <token id="126" string="art" />
            <token id="127" string="," />
            <token id="128" string="which" />
            <token id="129" string="Ono" />
            <token id="130" string="says" />
            <token id="131" string="was" />
            <token id="132" string="his" />
            <token id="133" string="main" />
            <token id="134" string="interest" />
            <token id="135" string="in" />
            <token id="136" string="his" />
            <token id="137" string="final" />
            <token id="138" string="years" />
            <token id="139" string=";" />
            <token id="140" string="and" />
            <token id="141" string="Lennon-inspired" />
            <token id="142" string="merchandise" />
            <token id="143" string="," />
            <token id="144" string="such" />
            <token id="145" string="as" />
            <token id="146" string="a" />
            <token id="147" string="line" />
            <token id="148" string="of" />
            <token id="149" string="John" />
            <token id="150" string="Lennon" />
            <token id="151" string="eyeglasses" />
            <token id="152" string="&quot;" />
            <token id="153" string="I" />
            <token id="154" string="told" />
            <token id="155" string="the" />
            <token id="156" string="fans" />
            <token id="157" string="that" />
            <token id="158" string="I" />
            <token id="159" string="'m" />
            <token id="160" string="going" />
            <token id="161" string="to" />
            <token id="162" string="do" />
            <token id="163" string="10" />
            <token id="164" string="years" />
            <token id="165" string="of" />
            <token id="166" string="it" />
          </tokens>
        </chunking>
        <chunking id="79" string="promote Lennon 's art and image Marketing an icon" type="VP">
          <tokens>
            <token id="57" string="promote" />
            <token id="58" string="Lennon" />
            <token id="59" string="'s" />
            <token id="60" string="art" />
            <token id="61" string="and" />
            <token id="62" string="image" />
            <token id="63" string="Marketing" />
            <token id="64" string="an" />
            <token id="65" string="icon" />
          </tokens>
        </chunking>
        <chunking id="80" string="his death in 1980" type="NP">
          <tokens>
            <token id="68" string="his" />
            <token id="69" string="death" />
            <token id="70" string="in" />
            <token id="71" string="1980" />
          </tokens>
        </chunking>
        <chunking id="81" string="his death" type="NP">
          <tokens>
            <token id="68" string="his" />
            <token id="69" string="death" />
          </tokens>
        </chunking>
        <chunking id="82" string="kept Lennon products coming out : the albums `` Milk and Honey '' and `` Menlove Avenue '' and the 4-CD boxed set `` The John Lennon Collection" type="VP">
          <tokens>
            <token id="76" string="kept" />
            <token id="77" string="Lennon" />
            <token id="78" string="products" />
            <token id="79" string="coming" />
            <token id="80" string="out" />
            <token id="81" string=":" />
            <token id="82" string="the" />
            <token id="83" string="albums" />
            <token id="84" string="&quot;" />
            <token id="85" string="Milk" />
            <token id="86" string="and" />
            <token id="87" string="Honey" />
            <token id="88" string="&quot;" />
            <token id="89" string="and" />
            <token id="90" string="&quot;" />
            <token id="91" string="Menlove" />
            <token id="92" string="Avenue" />
            <token id="93" string="&quot;" />
            <token id="94" string="and" />
            <token id="95" string="the" />
            <token id="96" string="4-CD" />
            <token id="97" string="boxed" />
            <token id="98" string="set" />
            <token id="99" string="&quot;" />
            <token id="100" string="The" />
            <token id="101" string="John" />
            <token id="102" string="Lennon" />
            <token id="103" string="Collection" />
          </tokens>
        </chunking>
        <chunking id="83" string="was his main interest in his final years" type="VP">
          <tokens>
            <token id="131" string="was" />
            <token id="132" string="his" />
            <token id="133" string="main" />
            <token id="134" string="interest" />
            <token id="135" string="in" />
            <token id="136" string="his" />
            <token id="137" string="final" />
            <token id="138" string="years" />
          </tokens>
        </chunking>
        <chunking id="84" string="a difficult concept" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="difficult" />
            <token id="5" string="concept" />
          </tokens>
        </chunking>
        <chunking id="85" string="I" type="NP">
          <tokens>
            <token id="9" string="I" />
          </tokens>
        </chunking>
        <chunking id="86" string="Marketing" type="NP">
          <tokens>
            <token id="63" string="Marketing" />
          </tokens>
        </chunking>
        <chunking id="87" string="`` Milk and Honey '' and `` Menlove Avenue ''" type="SBAR">
          <tokens>
            <token id="84" string="&quot;" />
            <token id="85" string="Milk" />
            <token id="86" string="and" />
            <token id="87" string="Honey" />
            <token id="88" string="&quot;" />
            <token id="89" string="and" />
            <token id="90" string="&quot;" />
            <token id="91" string="Menlove" />
            <token id="92" string="Avenue" />
            <token id="93" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="88" string="Skywriting by Word of Mouth" type="NP">
          <tokens>
            <token id="109" string="Skywriting" />
            <token id="110" string="by" />
            <token id="111" string="Word" />
            <token id="112" string="of" />
            <token id="113" string="Mouth" />
          </tokens>
        </chunking>
        <chunking id="89" string="Ono" type="NP">
          <tokens>
            <token id="33" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="90" string="the fans" type="NP">
          <tokens>
            <token id="155" string="the" />
            <token id="156" string="fans" />
          </tokens>
        </chunking>
        <chunking id="91" string="to do 10 years of it" type="VP">
          <tokens>
            <token id="161" string="to" />
            <token id="162" string="do" />
            <token id="163" string="10" />
            <token id="164" string="years" />
            <token id="165" string="of" />
            <token id="166" string="it" />
          </tokens>
        </chunking>
        <chunking id="92" string="the New York office" type="NP">
          <tokens>
            <token id="43" string="the" />
            <token id="44" string="New" />
            <token id="45" string="York" />
            <token id="46" string="office" />
          </tokens>
        </chunking>
        <chunking id="93" string="Word of Mouth" type="NP">
          <tokens>
            <token id="111" string="Word" />
            <token id="112" string="of" />
            <token id="113" string="Mouth" />
          </tokens>
        </chunking>
        <chunking id="94" string="having the door opened and having to cope with entering it , '' Ono says during a telephone interview She 's speaking from the New York office of Bag One Arts , the company Ono founded to promote Lennon 's art and image Marketing an icon" type="VP">
          <tokens>
            <token id="20" string="having" />
            <token id="21" string="the" />
            <token id="22" string="door" />
            <token id="23" string="opened" />
            <token id="24" string="and" />
            <token id="25" string="having" />
            <token id="26" string="to" />
            <token id="27" string="cope" />
            <token id="28" string="with" />
            <token id="29" string="entering" />
            <token id="30" string="it" />
            <token id="31" string="," />
            <token id="32" string="&quot;" />
            <token id="33" string="Ono" />
            <token id="34" string="says" />
            <token id="35" string="during" />
            <token id="36" string="a" />
            <token id="37" string="telephone" />
            <token id="38" string="interview" />
            <token id="39" string="She" />
            <token id="40" string="'s" />
            <token id="41" string="speaking" />
            <token id="42" string="from" />
            <token id="43" string="the" />
            <token id="44" string="New" />
            <token id="45" string="York" />
            <token id="46" string="office" />
            <token id="47" string="of" />
            <token id="48" string="Bag" />
            <token id="49" string="One" />
            <token id="50" string="Arts" />
            <token id="51" string="," />
            <token id="52" string="the" />
            <token id="53" string="company" />
            <token id="54" string="Ono" />
            <token id="55" string="founded" />
            <token id="56" string="to" />
            <token id="57" string="promote" />
            <token id="58" string="Lennon" />
            <token id="59" string="'s" />
            <token id="60" string="art" />
            <token id="61" string="and" />
            <token id="62" string="image" />
            <token id="63" string="Marketing" />
            <token id="64" string="an" />
            <token id="65" string="icon" />
          </tokens>
        </chunking>
        <chunking id="95" string="Milk" type="NP">
          <tokens>
            <token id="85" string="Milk" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">concept</governor>
          <dependent id="1">Acceptance</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">concept</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">concept</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">concept</governor>
          <dependent id="4">difficult</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">concept</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">her</governor>
          <dependent id="6">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">concept</governor>
          <dependent id="7">her</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="11">used</governor>
          <dependent id="9">I</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="11">used</governor>
          <dependent id="10">'m</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">her</governor>
          <dependent id="11">used</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">sort</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">used</governor>
          <dependent id="13">sort</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">knocking</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="13">sort</governor>
          <dependent id="15">knocking</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">door</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">knocking</governor>
          <dependent id="17">door</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">knocking</governor>
          <dependent id="18">rather</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="18">rather</governor>
          <dependent id="19">than</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">knocking</governor>
          <dependent id="20">having</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">door</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">opened</governor>
          <dependent id="22">door</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="20">having</governor>
          <dependent id="23">opened</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="23">opened</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="55">founded</governor>
          <dependent id="25">having</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">cope</governor>
          <dependent id="26">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="25">having</governor>
          <dependent id="27">cope</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">entering</governor>
          <dependent id="28">with</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="27">cope</governor>
          <dependent id="29">entering</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">entering</governor>
          <dependent id="30">it</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">says</governor>
          <dependent id="33">Ono</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="55">founded</governor>
          <dependent id="34">says</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">interview</governor>
          <dependent id="35">during</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">interview</governor>
          <dependent id="36">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">interview</governor>
          <dependent id="37">telephone</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">says</governor>
          <dependent id="38">interview</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="41">speaking</governor>
          <dependent id="39">She</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="41">speaking</governor>
          <dependent id="40">'s</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="38">interview</governor>
          <dependent id="41">speaking</dependent>
        </dependency>
        <dependency type="case">
          <governor id="46">office</governor>
          <dependent id="42">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="46">office</governor>
          <dependent id="43">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="46">office</governor>
          <dependent id="44">New</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="46">office</governor>
          <dependent id="45">York</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="41">speaking</governor>
          <dependent id="46">office</dependent>
        </dependency>
        <dependency type="case">
          <governor id="50">Arts</governor>
          <dependent id="47">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="50">Arts</governor>
          <dependent id="48">Bag</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="50">Arts</governor>
          <dependent id="49">One</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="46">office</governor>
          <dependent id="50">Arts</dependent>
        </dependency>
        <dependency type="det">
          <governor id="54">Ono</governor>
          <dependent id="52">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="54">Ono</governor>
          <dependent id="53">company</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="55">founded</governor>
          <dependent id="54">Ono</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="23">opened</governor>
          <dependent id="55">founded</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="57">promote</governor>
          <dependent id="56">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="55">founded</governor>
          <dependent id="57">promote</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="60">art</governor>
          <dependent id="58">Lennon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="58">Lennon</governor>
          <dependent id="59">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="57">promote</governor>
          <dependent id="60">art</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="60">art</governor>
          <dependent id="61">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="60">art</governor>
          <dependent id="62">image</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="57">promote</governor>
          <dependent id="63">Marketing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="65">icon</governor>
          <dependent id="64">an</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="63">Marketing</governor>
          <dependent id="65">icon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="69">death</governor>
          <dependent id="67">Since</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="69">death</governor>
          <dependent id="68">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="76">kept</governor>
          <dependent id="69">death</dependent>
        </dependency>
        <dependency type="case">
          <governor id="71">1980</governor>
          <dependent id="70">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="69">death</governor>
          <dependent id="71">1980</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="76">kept</governor>
          <dependent id="73">Ono</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="76">kept</governor>
          <dependent id="74">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="76">kept</governor>
          <dependent id="75">steadily</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="11">used</governor>
          <dependent id="76">kept</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="78">products</governor>
          <dependent id="77">Lennon</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="76">kept</governor>
          <dependent id="78">products</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="78">products</governor>
          <dependent id="79">coming</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="79">coming</governor>
          <dependent id="80">out</dependent>
        </dependency>
        <dependency type="det">
          <governor id="83">albums</governor>
          <dependent id="82">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="78">products</governor>
          <dependent id="83">albums</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="83">albums</governor>
          <dependent id="85">Milk</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="85">Milk</governor>
          <dependent id="86">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="85">Milk</governor>
          <dependent id="87">Honey</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="85">Milk</governor>
          <dependent id="89">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="92">Avenue</governor>
          <dependent id="91">Menlove</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="85">Milk</governor>
          <dependent id="92">Avenue</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="78">products</governor>
          <dependent id="94">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="98">set</governor>
          <dependent id="95">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="98">set</governor>
          <dependent id="96">4-CD</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="98">set</governor>
          <dependent id="97">boxed</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="78">products</governor>
          <dependent id="98">set</dependent>
        </dependency>
        <dependency type="det">
          <governor id="103">Collection</governor>
          <dependent id="100">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="103">Collection</governor>
          <dependent id="101">John</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="103">Collection</governor>
          <dependent id="102">Lennon</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="98">set</governor>
          <dependent id="103">Collection</dependent>
        </dependency>
        <dependency type="det">
          <governor id="107">book</governor>
          <dependent id="106">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">concept</governor>
          <dependent id="107">book</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="134">interest</governor>
          <dependent id="109">Skywriting</dependent>
        </dependency>
        <dependency type="case">
          <governor id="111">Word</governor>
          <dependent id="110">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="109">Skywriting</governor>
          <dependent id="111">Word</dependent>
        </dependency>
        <dependency type="case">
          <governor id="113">Mouth</governor>
          <dependent id="112">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="111">Word</governor>
          <dependent id="113">Mouth</dependent>
        </dependency>
        <dependency type="det">
          <governor id="117">collection</governor>
          <dependent id="116">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="109">Skywriting</governor>
          <dependent id="117">collection</dependent>
        </dependency>
        <dependency type="case">
          <governor id="122">writings</governor>
          <dependent id="118">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="122">writings</governor>
          <dependent id="119">Lennon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="119">Lennon</governor>
          <dependent id="120">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="122">writings</governor>
          <dependent id="121">unpublished</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="117">collection</governor>
          <dependent id="122">writings</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="126">art</governor>
          <dependent id="124">Lennon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="124">Lennon</governor>
          <dependent id="125">'s</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="117">collection</governor>
          <dependent id="126">art</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="130">says</governor>
          <dependent id="128">which</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="130">says</governor>
          <dependent id="129">Ono</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="126">art</governor>
          <dependent id="130">says</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="134">interest</governor>
          <dependent id="131">was</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="134">interest</governor>
          <dependent id="132">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="134">interest</governor>
          <dependent id="133">main</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="107">book</governor>
          <dependent id="134">interest</dependent>
        </dependency>
        <dependency type="case">
          <governor id="138">years</governor>
          <dependent id="135">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="138">years</governor>
          <dependent id="136">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="138">years</governor>
          <dependent id="137">final</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="134">interest</governor>
          <dependent id="138">years</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">concept</governor>
          <dependent id="140">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="142">merchandise</governor>
          <dependent id="141">Lennon-inspired</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">concept</governor>
          <dependent id="142">merchandise</dependent>
        </dependency>
        <dependency type="case">
          <governor id="147">line</governor>
          <dependent id="144">such</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="144">such</governor>
          <dependent id="145">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="147">line</governor>
          <dependent id="146">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="142">merchandise</governor>
          <dependent id="147">line</dependent>
        </dependency>
        <dependency type="case">
          <governor id="151">eyeglasses</governor>
          <dependent id="148">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="151">eyeglasses</governor>
          <dependent id="149">John</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="151">eyeglasses</governor>
          <dependent id="150">Lennon</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="147">line</governor>
          <dependent id="151">eyeglasses</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="154">told</governor>
          <dependent id="153">I</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="147">line</governor>
          <dependent id="154">told</dependent>
        </dependency>
        <dependency type="det">
          <governor id="156">fans</governor>
          <dependent id="155">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="154">told</governor>
          <dependent id="156">fans</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="160">going</governor>
          <dependent id="157">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="160">going</governor>
          <dependent id="158">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="160">going</governor>
          <dependent id="159">'m</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="154">told</governor>
          <dependent id="160">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="162">do</governor>
          <dependent id="161">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="160">going</governor>
          <dependent id="162">do</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="164">years</governor>
          <dependent id="163">10</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="162">do</governor>
          <dependent id="164">years</dependent>
        </dependency>
        <dependency type="case">
          <governor id="166">it</governor>
          <dependent id="165">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="164">years</governor>
          <dependent id="166">it</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="New York" type="LOCATION" score="0.0">
          <tokens>
            <token id="44" string="New" />
            <token id="45" string="York" />
          </tokens>
        </entity>
        <entity id="2" string="John Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="101" string="John" />
            <token id="102" string="Lennon" />
          </tokens>
        </entity>
        <entity id="3" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="58" string="Lennon" />
          </tokens>
        </entity>
        <entity id="4" string="Bag One Arts" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="48" string="Bag" />
            <token id="49" string="One" />
            <token id="50" string="Arts" />
          </tokens>
        </entity>
        <entity id="5" string="1980" type="DATE" score="0.0">
          <tokens>
            <token id="71" string="1980" />
          </tokens>
        </entity>
        <entity id="6" string="Lennon-inspired" type="MISC" score="0.0">
          <tokens>
            <token id="141" string="Lennon-inspired" />
          </tokens>
        </entity>
        <entity id="7" string="10 years" type="DURATION" score="0.0">
          <tokens>
            <token id="163" string="10" />
            <token id="164" string="years" />
          </tokens>
        </entity>
        <entity id="8" string="years" type="DURATION" score="0.0">
          <tokens>
            <token id="138" string="years" />
          </tokens>
        </entity>
        <entity id="9" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="33" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>Every year, hopefully, give a new product and share it with the fans,&amp;quot; Ono says.</content>
      <tokens>
        <token id="1" string="Every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="2" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="hopefully" lemma="hopefully" stem="hopefulli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="give" lemma="give" stem="give" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="product" lemma="product" stem="product" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="share" lemma="share" stem="share" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="fans" lemma="fan" stem="fan" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT Every) (NN year)) (, ,) (ADVP (RB hopefully)) (, ,) (S (VP (VB give) (NP (DT a) (JJ new) (NN product) (CC and) (NN share)) (NP (PRP it)) (PP (IN with) (NP (DT the) (NNS fans))))) (, ,) ('' '') (NP (NNP Ono)) (VP (VBZ says)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the fans" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="fans" />
          </tokens>
        </chunking>
        <chunking id="2" string="says" type="VP">
          <tokens>
            <token id="19" string="says" />
          </tokens>
        </chunking>
        <chunking id="3" string="give a new product and share it with the fans" type="VP">
          <tokens>
            <token id="6" string="give" />
            <token id="7" string="a" />
            <token id="8" string="new" />
            <token id="9" string="product" />
            <token id="10" string="and" />
            <token id="11" string="share" />
            <token id="12" string="it" />
            <token id="13" string="with" />
            <token id="14" string="the" />
            <token id="15" string="fans" />
          </tokens>
        </chunking>
        <chunking id="4" string="a new product and share" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="new" />
            <token id="9" string="product" />
            <token id="10" string="and" />
            <token id="11" string="share" />
          </tokens>
        </chunking>
        <chunking id="5" string="Every year" type="NP">
          <tokens>
            <token id="1" string="Every" />
            <token id="2" string="year" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="12" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="Ono" type="NP">
          <tokens>
            <token id="18" string="Ono" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">year</governor>
          <dependent id="1">Every</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="19">says</governor>
          <dependent id="2">year</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">says</governor>
          <dependent id="4">hopefully</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">says</governor>
          <dependent id="6">give</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">product</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">product</governor>
          <dependent id="8">new</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="6">give</governor>
          <dependent id="9">product</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">product</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">product</governor>
          <dependent id="11">share</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">give</governor>
          <dependent id="12">it</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">fans</governor>
          <dependent id="13">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">fans</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">give</governor>
          <dependent id="15">fans</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">says</governor>
          <dependent id="18">Ono</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">says</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Every year" type="SET" score="0.0">
          <tokens>
            <token id="1" string="Every" />
            <token id="2" string="year" />
          </tokens>
        </entity>
        <entity id="2" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>&amp;quot;Some years, we had two or three products of John that came out.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="8" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="10" string="products" lemma="product" stem="product" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP-TMP (DT Some) (NNS years)) (, ,) (NP (PRP we)) (VP (VBD had) (NP (NP (CD two) (CC or) (CD three) (NNS products)) (PP (IN of) (NP (NNP John))) (SBAR (WHNP (WDT that)) (S (VP (VBD came) (PRT (RP out))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="came out" type="VP">
          <tokens>
            <token id="14" string="came" />
            <token id="15" string="out" />
          </tokens>
        </chunking>
        <chunking id="2" string="John" type="NP">
          <tokens>
            <token id="12" string="John" />
          </tokens>
        </chunking>
        <chunking id="3" string="that came out" type="SBAR">
          <tokens>
            <token id="13" string="that" />
            <token id="14" string="came" />
            <token id="15" string="out" />
          </tokens>
        </chunking>
        <chunking id="4" string="we" type="NP">
          <tokens>
            <token id="5" string="we" />
          </tokens>
        </chunking>
        <chunking id="5" string="had two or three products of John that came out" type="VP">
          <tokens>
            <token id="6" string="had" />
            <token id="7" string="two" />
            <token id="8" string="or" />
            <token id="9" string="three" />
            <token id="10" string="products" />
            <token id="11" string="of" />
            <token id="12" string="John" />
            <token id="13" string="that" />
            <token id="14" string="came" />
            <token id="15" string="out" />
          </tokens>
        </chunking>
        <chunking id="6" string="two or three products" type="NP">
          <tokens>
            <token id="7" string="two" />
            <token id="8" string="or" />
            <token id="9" string="three" />
            <token id="10" string="products" />
          </tokens>
        </chunking>
        <chunking id="7" string="two or three products of John that came out" type="NP">
          <tokens>
            <token id="7" string="two" />
            <token id="8" string="or" />
            <token id="9" string="three" />
            <token id="10" string="products" />
            <token id="11" string="of" />
            <token id="12" string="John" />
            <token id="13" string="that" />
            <token id="14" string="came" />
            <token id="15" string="out" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">years</governor>
          <dependent id="2">Some</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="6">had</governor>
          <dependent id="3">years</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">had</governor>
          <dependent id="5">we</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">had</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">products</governor>
          <dependent id="7">two</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">two</governor>
          <dependent id="8">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">two</governor>
          <dependent id="9">three</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">had</governor>
          <dependent id="10">products</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">John</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">products</governor>
          <dependent id="12">John</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">came</governor>
          <dependent id="13">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">products</governor>
          <dependent id="14">came</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="14">came</governor>
          <dependent id="15">out</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="John" />
          </tokens>
        </entity>
        <entity id="2" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="two" />
          </tokens>
        </entity>
        <entity id="3" string="years" type="DURATION" score="0.0">
          <tokens>
            <token id="3" string="years" />
          </tokens>
        </entity>
        <entity id="4" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="three" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>; The 10-year promise ended with last year&amp;apost;s year-long celebration of Lennon&amp;apost;s 50th birthday.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="10-year" lemma="10-year" stem="10-year" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="4" string="promise" lemma="promise" stem="promis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="ended" lemma="end" stem="end" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="8" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="9" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="year-long" lemma="year-long" stem="year-long" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="celebration" lemma="celebration" stem="celebr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="50th" lemma="50th" stem="50th" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="birthday" lemma="birthday" stem="birthdai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (NP (DT The) (JJ 10-year) (NN promise)) (VP (VBN ended) (PP (IN with) (NP (NP (NP (JJ last) (NN year) (POS 's)) (JJ year-long) (NN celebration)) (PP (IN of) (NP (NP (NNP Lennon) (POS 's)) (JJ 50th) (NN birthday)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="last year 's" type="NP">
          <tokens>
            <token id="7" string="last" />
            <token id="8" string="year" />
            <token id="9" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="The 10-year promise" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="10-year" />
            <token id="4" string="promise" />
          </tokens>
        </chunking>
        <chunking id="3" string="last year 's year-long celebration of Lennon 's 50th birthday" type="NP">
          <tokens>
            <token id="7" string="last" />
            <token id="8" string="year" />
            <token id="9" string="'s" />
            <token id="10" string="year-long" />
            <token id="11" string="celebration" />
            <token id="12" string="of" />
            <token id="13" string="Lennon" />
            <token id="14" string="'s" />
            <token id="15" string="50th" />
            <token id="16" string="birthday" />
          </tokens>
        </chunking>
        <chunking id="4" string="ended with last year 's year-long celebration of Lennon 's 50th birthday" type="VP">
          <tokens>
            <token id="5" string="ended" />
            <token id="6" string="with" />
            <token id="7" string="last" />
            <token id="8" string="year" />
            <token id="9" string="'s" />
            <token id="10" string="year-long" />
            <token id="11" string="celebration" />
            <token id="12" string="of" />
            <token id="13" string="Lennon" />
            <token id="14" string="'s" />
            <token id="15" string="50th" />
            <token id="16" string="birthday" />
          </tokens>
        </chunking>
        <chunking id="5" string="Lennon 's" type="NP">
          <tokens>
            <token id="13" string="Lennon" />
            <token id="14" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="last year 's year-long celebration" type="NP">
          <tokens>
            <token id="7" string="last" />
            <token id="8" string="year" />
            <token id="9" string="'s" />
            <token id="10" string="year-long" />
            <token id="11" string="celebration" />
          </tokens>
        </chunking>
        <chunking id="7" string="Lennon 's 50th birthday" type="NP">
          <tokens>
            <token id="13" string="Lennon" />
            <token id="14" string="'s" />
            <token id="15" string="50th" />
            <token id="16" string="birthday" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">promise</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">promise</governor>
          <dependent id="3">10-year</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">ended</governor>
          <dependent id="4">promise</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">ended</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">celebration</governor>
          <dependent id="6">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">year</governor>
          <dependent id="7">last</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">celebration</governor>
          <dependent id="8">year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">year</governor>
          <dependent id="9">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">celebration</governor>
          <dependent id="10">year-long</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">ended</governor>
          <dependent id="11">celebration</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">birthday</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">birthday</governor>
          <dependent id="13">Lennon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Lennon</governor>
          <dependent id="14">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">birthday</governor>
          <dependent id="15">50th</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">celebration</governor>
          <dependent id="16">birthday</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="10-year" type="DURATION" score="0.0">
          <tokens>
            <token id="3" string="10-year" />
          </tokens>
        </entity>
        <entity id="3" string="50th birthday" type="DATE" score="0.0">
          <tokens>
            <token id="15" string="50th" />
            <token id="16" string="birthday" />
          </tokens>
        </entity>
        <entity id="4" string="last year" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="last" />
            <token id="8" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>In 1991, Ono says, she has tried to &amp;quot;relax a little and do my own stuff.&amp;quot;</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="1991" lemma="1991" stem="1991" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="tried" lemma="try" stem="tri" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="relax" lemma="relax" stem="relax" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="little" lemma="little" stem="littl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="stuff" lemma="stuff" stem="stuff" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (CD 1991))) (PRN (, ,) (NP (NNP Ono)) (VP (VBZ says)) (, ,)) (NP (PRP she)) (VP (VBZ has) (VP (VBN tried) (S (VP (TO to) (`` ``) (VP (VP (VB relax) (NP (DT a) (JJ little))) (CC and) (VP (VB do) (NP (PRP$ my) (JJ own) (NN stuff)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="my own stuff" type="NP">
          <tokens>
            <token id="17" string="my" />
            <token id="18" string="own" />
            <token id="19" string="stuff" />
          </tokens>
        </chunking>
        <chunking id="2" string="says" type="VP">
          <tokens>
            <token id="5" string="says" />
          </tokens>
        </chunking>
        <chunking id="3" string="has tried to `` relax a little and do my own stuff" type="VP">
          <tokens>
            <token id="8" string="has" />
            <token id="9" string="tried" />
            <token id="10" string="to" />
            <token id="11" string="&quot;" />
            <token id="12" string="relax" />
            <token id="13" string="a" />
            <token id="14" string="little" />
            <token id="15" string="and" />
            <token id="16" string="do" />
            <token id="17" string="my" />
            <token id="18" string="own" />
            <token id="19" string="stuff" />
          </tokens>
        </chunking>
        <chunking id="4" string="a little" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="little" />
          </tokens>
        </chunking>
        <chunking id="5" string="to `` relax a little and do my own stuff" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="&quot;" />
            <token id="12" string="relax" />
            <token id="13" string="a" />
            <token id="14" string="little" />
            <token id="15" string="and" />
            <token id="16" string="do" />
            <token id="17" string="my" />
            <token id="18" string="own" />
            <token id="19" string="stuff" />
          </tokens>
        </chunking>
        <chunking id="6" string="1991" type="NP">
          <tokens>
            <token id="2" string="1991" />
          </tokens>
        </chunking>
        <chunking id="7" string="tried to `` relax a little and do my own stuff" type="VP">
          <tokens>
            <token id="9" string="tried" />
            <token id="10" string="to" />
            <token id="11" string="&quot;" />
            <token id="12" string="relax" />
            <token id="13" string="a" />
            <token id="14" string="little" />
            <token id="15" string="and" />
            <token id="16" string="do" />
            <token id="17" string="my" />
            <token id="18" string="own" />
            <token id="19" string="stuff" />
          </tokens>
        </chunking>
        <chunking id="8" string="relax a little" type="VP">
          <tokens>
            <token id="12" string="relax" />
            <token id="13" string="a" />
            <token id="14" string="little" />
          </tokens>
        </chunking>
        <chunking id="9" string="relax a little and do my own stuff" type="VP">
          <tokens>
            <token id="12" string="relax" />
            <token id="13" string="a" />
            <token id="14" string="little" />
            <token id="15" string="and" />
            <token id="16" string="do" />
            <token id="17" string="my" />
            <token id="18" string="own" />
            <token id="19" string="stuff" />
          </tokens>
        </chunking>
        <chunking id="10" string="do my own stuff" type="VP">
          <tokens>
            <token id="16" string="do" />
            <token id="17" string="my" />
            <token id="18" string="own" />
            <token id="19" string="stuff" />
          </tokens>
        </chunking>
        <chunking id="11" string="Ono" type="NP">
          <tokens>
            <token id="4" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="12" string="she" type="NP">
          <tokens>
            <token id="7" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">1991</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">tried</governor>
          <dependent id="2">1991</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">says</governor>
          <dependent id="4">Ono</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="9">tried</governor>
          <dependent id="5">says</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">tried</governor>
          <dependent id="7">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">tried</governor>
          <dependent id="8">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">tried</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">relax</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">tried</governor>
          <dependent id="12">relax</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">little</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">relax</governor>
          <dependent id="14">little</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">relax</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">relax</governor>
          <dependent id="16">do</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">stuff</governor>
          <dependent id="17">my</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">stuff</governor>
          <dependent id="18">own</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">do</governor>
          <dependent id="19">stuff</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1991" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="1991" />
          </tokens>
        </entity>
        <entity id="2" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>; Ono, 57, has been going into a recording studio every day to work on the proposed boxed-set of her music.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="57" lemma="57" stem="57" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="recording" lemma="recording" stem="record" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="studio" lemma="studio" stem="studio" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="14" string="day" lemma="day" stem="dai" pos="NN" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="work" lemma="work" stem="work" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="proposed" lemma="propose" stem="propos" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="boxed-set" lemma="boxed-set" stem="boxed-set" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="23" string="music" lemma="music" stem="music" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (S (NP (NP (NNP Ono)) (, ,) (NP (CD 57)) (, ,)) (VP (VBZ has) (VP (VBN been) (VP (VBG going) (PP (IN into) (NP (NP (DT a) (NN recording) (NN studio)) (NP (DT every) (NN day)))) (S (VP (TO to) (VP (VB work) (PP (IN on) (NP (NP (DT the) (VBN proposed) (NN boxed-set)) (PP (IN of) (NP (PRP$ her) (NN music)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="been going into a recording studio every day to work on the proposed boxed-set of her music" type="VP">
          <tokens>
            <token id="7" string="been" />
            <token id="8" string="going" />
            <token id="9" string="into" />
            <token id="10" string="a" />
            <token id="11" string="recording" />
            <token id="12" string="studio" />
            <token id="13" string="every" />
            <token id="14" string="day" />
            <token id="15" string="to" />
            <token id="16" string="work" />
            <token id="17" string="on" />
            <token id="18" string="the" />
            <token id="19" string="proposed" />
            <token id="20" string="boxed-set" />
            <token id="21" string="of" />
            <token id="22" string="her" />
            <token id="23" string="music" />
          </tokens>
        </chunking>
        <chunking id="2" string="57" type="NP">
          <tokens>
            <token id="4" string="57" />
          </tokens>
        </chunking>
        <chunking id="3" string="her music" type="NP">
          <tokens>
            <token id="22" string="her" />
            <token id="23" string="music" />
          </tokens>
        </chunking>
        <chunking id="4" string="work on the proposed boxed-set of her music" type="VP">
          <tokens>
            <token id="16" string="work" />
            <token id="17" string="on" />
            <token id="18" string="the" />
            <token id="19" string="proposed" />
            <token id="20" string="boxed-set" />
            <token id="21" string="of" />
            <token id="22" string="her" />
            <token id="23" string="music" />
          </tokens>
        </chunking>
        <chunking id="5" string="the proposed boxed-set of her music" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="proposed" />
            <token id="20" string="boxed-set" />
            <token id="21" string="of" />
            <token id="22" string="her" />
            <token id="23" string="music" />
          </tokens>
        </chunking>
        <chunking id="6" string="Ono" type="NP">
          <tokens>
            <token id="2" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="7" string="going into a recording studio every day to work on the proposed boxed-set of her music" type="VP">
          <tokens>
            <token id="8" string="going" />
            <token id="9" string="into" />
            <token id="10" string="a" />
            <token id="11" string="recording" />
            <token id="12" string="studio" />
            <token id="13" string="every" />
            <token id="14" string="day" />
            <token id="15" string="to" />
            <token id="16" string="work" />
            <token id="17" string="on" />
            <token id="18" string="the" />
            <token id="19" string="proposed" />
            <token id="20" string="boxed-set" />
            <token id="21" string="of" />
            <token id="22" string="her" />
            <token id="23" string="music" />
          </tokens>
        </chunking>
        <chunking id="8" string="a recording studio" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="recording" />
            <token id="12" string="studio" />
          </tokens>
        </chunking>
        <chunking id="9" string="has been going into a recording studio every day to work on the proposed boxed-set of her music" type="VP">
          <tokens>
            <token id="6" string="has" />
            <token id="7" string="been" />
            <token id="8" string="going" />
            <token id="9" string="into" />
            <token id="10" string="a" />
            <token id="11" string="recording" />
            <token id="12" string="studio" />
            <token id="13" string="every" />
            <token id="14" string="day" />
            <token id="15" string="to" />
            <token id="16" string="work" />
            <token id="17" string="on" />
            <token id="18" string="the" />
            <token id="19" string="proposed" />
            <token id="20" string="boxed-set" />
            <token id="21" string="of" />
            <token id="22" string="her" />
            <token id="23" string="music" />
          </tokens>
        </chunking>
        <chunking id="10" string="a recording studio every day" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="recording" />
            <token id="12" string="studio" />
            <token id="13" string="every" />
            <token id="14" string="day" />
          </tokens>
        </chunking>
        <chunking id="11" string="every day" type="NP">
          <tokens>
            <token id="13" string="every" />
            <token id="14" string="day" />
          </tokens>
        </chunking>
        <chunking id="12" string="the proposed boxed-set" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="proposed" />
            <token id="20" string="boxed-set" />
          </tokens>
        </chunking>
        <chunking id="13" string="Ono , 57 ," type="NP">
          <tokens>
            <token id="2" string="Ono" />
            <token id="3" string="," />
            <token id="4" string="57" />
            <token id="5" string="," />
          </tokens>
        </chunking>
        <chunking id="14" string="to work on the proposed boxed-set of her music" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="work" />
            <token id="17" string="on" />
            <token id="18" string="the" />
            <token id="19" string="proposed" />
            <token id="20" string="boxed-set" />
            <token id="21" string="of" />
            <token id="22" string="her" />
            <token id="23" string="music" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="8">going</governor>
          <dependent id="2">Ono</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="2">Ono</governor>
          <dependent id="4">57</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">going</governor>
          <dependent id="6">has</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">going</governor>
          <dependent id="7">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">going</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">studio</governor>
          <dependent id="9">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">studio</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">studio</governor>
          <dependent id="11">recording</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">going</governor>
          <dependent id="12">studio</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">day</governor>
          <dependent id="13">every</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">studio</governor>
          <dependent id="14">day</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">work</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">going</governor>
          <dependent id="16">work</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">boxed-set</governor>
          <dependent id="17">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">boxed-set</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">boxed-set</governor>
          <dependent id="19">proposed</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">work</governor>
          <dependent id="20">boxed-set</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">music</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">music</governor>
          <dependent id="22">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">boxed-set</governor>
          <dependent id="23">music</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="57" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="57" />
          </tokens>
        </entity>
        <entity id="2" string="every day" type="SET" score="0.0">
          <tokens>
            <token id="13" string="every" />
            <token id="14" string="day" />
          </tokens>
        </entity>
        <entity id="3" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>She continues to produce art and recently had a museum exhibit in Iceland Ono began her art career as an abstract impressionist, then went avant-garde.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="continues" lemma="continue" stem="continu" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="produce" lemma="produce" stem="produc" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="art" lemma="art" stem="art" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="recently" lemma="recently" stem="recent" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="museum" lemma="museum" stem="museum" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="exhibit" lemma="exhibit" stem="exhibit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Iceland" lemma="Iceland" stem="iceland" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="14" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="art" lemma="art" stem="art" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="career" lemma="career" stem="career" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="abstract" lemma="abstract" stem="abstract" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="impressionist" lemma="impressionist" stem="impressionist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="avant-garde" lemma="avant-garde" stem="avant-gard" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VP (VBZ continues) (S (VP (TO to) (VP (VB produce) (NP (NN art)))))) (CC and) (VP (ADVP (RB recently)) (VP (VBD had) (NP (NP (DT a) (NN museum) (NN exhibit)) (PP (IN in) (NP (NP (NNP Iceland) (NNP Ono)) (VP (VBD began) (NP (PRP$ her) (NN art) (NN career)) (PP (IN as) (NP (DT an) (ADJP (JJ abstract) (JJ impressionist))))))))) (, ,) (VP (ADVP (RB then)) (VBD went) (ADJP (JJ avant-garde))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="art" type="NP">
          <tokens>
            <token id="5" string="art" />
          </tokens>
        </chunking>
        <chunking id="2" string="a museum exhibit" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="museum" />
            <token id="11" string="exhibit" />
          </tokens>
        </chunking>
        <chunking id="3" string="recently had a museum exhibit in Iceland Ono began her art career as an abstract impressionist , then went avant-garde" type="VP">
          <tokens>
            <token id="7" string="recently" />
            <token id="8" string="had" />
            <token id="9" string="a" />
            <token id="10" string="museum" />
            <token id="11" string="exhibit" />
            <token id="12" string="in" />
            <token id="13" string="Iceland" />
            <token id="14" string="Ono" />
            <token id="15" string="began" />
            <token id="16" string="her" />
            <token id="17" string="art" />
            <token id="18" string="career" />
            <token id="19" string="as" />
            <token id="20" string="an" />
            <token id="21" string="abstract" />
            <token id="22" string="impressionist" />
            <token id="23" string="," />
            <token id="24" string="then" />
            <token id="25" string="went" />
            <token id="26" string="avant-garde" />
          </tokens>
        </chunking>
        <chunking id="4" string="began her art career as an abstract impressionist" type="VP">
          <tokens>
            <token id="15" string="began" />
            <token id="16" string="her" />
            <token id="17" string="art" />
            <token id="18" string="career" />
            <token id="19" string="as" />
            <token id="20" string="an" />
            <token id="21" string="abstract" />
            <token id="22" string="impressionist" />
          </tokens>
        </chunking>
        <chunking id="5" string="then went avant-garde" type="VP">
          <tokens>
            <token id="24" string="then" />
            <token id="25" string="went" />
            <token id="26" string="avant-garde" />
          </tokens>
        </chunking>
        <chunking id="6" string="to produce art" type="VP">
          <tokens>
            <token id="3" string="to" />
            <token id="4" string="produce" />
            <token id="5" string="art" />
          </tokens>
        </chunking>
        <chunking id="7" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="8" string="produce art" type="VP">
          <tokens>
            <token id="4" string="produce" />
            <token id="5" string="art" />
          </tokens>
        </chunking>
        <chunking id="9" string="her art career" type="NP">
          <tokens>
            <token id="16" string="her" />
            <token id="17" string="art" />
            <token id="18" string="career" />
          </tokens>
        </chunking>
        <chunking id="10" string="a museum exhibit in Iceland Ono began her art career as an abstract impressionist" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="museum" />
            <token id="11" string="exhibit" />
            <token id="12" string="in" />
            <token id="13" string="Iceland" />
            <token id="14" string="Ono" />
            <token id="15" string="began" />
            <token id="16" string="her" />
            <token id="17" string="art" />
            <token id="18" string="career" />
            <token id="19" string="as" />
            <token id="20" string="an" />
            <token id="21" string="abstract" />
            <token id="22" string="impressionist" />
          </tokens>
        </chunking>
        <chunking id="11" string="abstract impressionist" type="ADJP">
          <tokens>
            <token id="21" string="abstract" />
            <token id="22" string="impressionist" />
          </tokens>
        </chunking>
        <chunking id="12" string="an abstract impressionist" type="NP">
          <tokens>
            <token id="20" string="an" />
            <token id="21" string="abstract" />
            <token id="22" string="impressionist" />
          </tokens>
        </chunking>
        <chunking id="13" string="Iceland Ono began her art career as an abstract impressionist" type="NP">
          <tokens>
            <token id="13" string="Iceland" />
            <token id="14" string="Ono" />
            <token id="15" string="began" />
            <token id="16" string="her" />
            <token id="17" string="art" />
            <token id="18" string="career" />
            <token id="19" string="as" />
            <token id="20" string="an" />
            <token id="21" string="abstract" />
            <token id="22" string="impressionist" />
          </tokens>
        </chunking>
        <chunking id="14" string="avant-garde" type="ADJP">
          <tokens>
            <token id="26" string="avant-garde" />
          </tokens>
        </chunking>
        <chunking id="15" string="continues to produce art and recently had a museum exhibit in Iceland Ono began her art career as an abstract impressionist , then went avant-garde" type="VP">
          <tokens>
            <token id="2" string="continues" />
            <token id="3" string="to" />
            <token id="4" string="produce" />
            <token id="5" string="art" />
            <token id="6" string="and" />
            <token id="7" string="recently" />
            <token id="8" string="had" />
            <token id="9" string="a" />
            <token id="10" string="museum" />
            <token id="11" string="exhibit" />
            <token id="12" string="in" />
            <token id="13" string="Iceland" />
            <token id="14" string="Ono" />
            <token id="15" string="began" />
            <token id="16" string="her" />
            <token id="17" string="art" />
            <token id="18" string="career" />
            <token id="19" string="as" />
            <token id="20" string="an" />
            <token id="21" string="abstract" />
            <token id="22" string="impressionist" />
            <token id="23" string="," />
            <token id="24" string="then" />
            <token id="25" string="went" />
            <token id="26" string="avant-garde" />
          </tokens>
        </chunking>
        <chunking id="16" string="Iceland Ono" type="NP">
          <tokens>
            <token id="13" string="Iceland" />
            <token id="14" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="17" string="continues to produce art" type="VP">
          <tokens>
            <token id="2" string="continues" />
            <token id="3" string="to" />
            <token id="4" string="produce" />
            <token id="5" string="art" />
          </tokens>
        </chunking>
        <chunking id="18" string="had a museum exhibit in Iceland Ono began her art career as an abstract impressionist" type="VP">
          <tokens>
            <token id="8" string="had" />
            <token id="9" string="a" />
            <token id="10" string="museum" />
            <token id="11" string="exhibit" />
            <token id="12" string="in" />
            <token id="13" string="Iceland" />
            <token id="14" string="Ono" />
            <token id="15" string="began" />
            <token id="16" string="her" />
            <token id="17" string="art" />
            <token id="18" string="career" />
            <token id="19" string="as" />
            <token id="20" string="an" />
            <token id="21" string="abstract" />
            <token id="22" string="impressionist" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">continues</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">continues</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="4">produce</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">continues</governor>
          <dependent id="4">produce</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">produce</governor>
          <dependent id="5">art</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">continues</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">had</governor>
          <dependent id="7">recently</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">continues</governor>
          <dependent id="8">had</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">exhibit</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">exhibit</governor>
          <dependent id="10">museum</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">had</governor>
          <dependent id="11">exhibit</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Ono</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Ono</governor>
          <dependent id="13">Iceland</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">exhibit</governor>
          <dependent id="14">Ono</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">Ono</governor>
          <dependent id="15">began</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">career</governor>
          <dependent id="16">her</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">career</governor>
          <dependent id="17">art</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">began</governor>
          <dependent id="18">career</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">impressionist</governor>
          <dependent id="19">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">impressionist</governor>
          <dependent id="20">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">impressionist</governor>
          <dependent id="21">abstract</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">began</governor>
          <dependent id="22">impressionist</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">went</governor>
          <dependent id="24">then</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">had</governor>
          <dependent id="25">went</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="25">went</governor>
          <dependent id="26">avant-garde</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="recently" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="recently" />
          </tokens>
        </entity>
        <entity id="2" string="Iceland" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Iceland" />
          </tokens>
        </entity>
        <entity id="3" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>She began doing performance art in the early &amp;apost;60s, long before the form was legitimized by art critics and government grants A life in two worlds; Ono declines to put a label on her current works.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="doing" lemma="do" stem="do" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="performance" lemma="performance" stem="perform" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="art" lemma="art" stem="art" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="early" lemma="early" stem="earli" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="'60s" lemma="'60" stem="'60" pos="NNS" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="long" lemma="long" stem="long" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="form" lemma="form" stem="form" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="legitimized" lemma="legitimize" stem="legitim" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="art" lemma="art" stem="art" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="critics" lemma="critic" stem="critic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="grants" lemma="grant" stem="grant" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="27" string="worlds" lemma="world" stem="world" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="30" string="declines" lemma="decline" stem="declin" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="put" lemma="put" stem="put" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="label" lemma="label" stem="label" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="37" string="current" lemma="current" stem="current" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="38" string="works" lemma="work" stem="work" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP She)) (VP (VBD began) (S (VP (VBG doing) (NP (NN performance) (NN art)) (PP (IN in) (NP (DT the) (JJ early) (NNS '60s))))) (, ,) (SBAR (RB long) (IN before) (S (NP (DT the) (NN form)) (VP (VBD was) (VP (VBN legitimized) (PP (IN by) (NP (NN art) (NNS critics) (CC and) (NN government) (NNS grants))) (NP-TMP (DT A) (NN life)) (PP (IN in) (NP (CD two) (NNS worlds))))))))) (: ;) (S (NP (NNP Ono)) (VP (VBZ declines) (S (VP (TO to) (VP (VB put) (NP (DT a) (NN label)) (PP (IN on) (NP (PRP$ her) (JJ current) (NNS works)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="long before the form was legitimized by art critics and government grants A life in two worlds" type="SBAR">
          <tokens>
            <token id="11" string="long" />
            <token id="12" string="before" />
            <token id="13" string="the" />
            <token id="14" string="form" />
            <token id="15" string="was" />
            <token id="16" string="legitimized" />
            <token id="17" string="by" />
            <token id="18" string="art" />
            <token id="19" string="critics" />
            <token id="20" string="and" />
            <token id="21" string="government" />
            <token id="22" string="grants" />
            <token id="23" string="A" />
            <token id="24" string="life" />
            <token id="25" string="in" />
            <token id="26" string="two" />
            <token id="27" string="worlds" />
          </tokens>
        </chunking>
        <chunking id="2" string="was legitimized by art critics and government grants A life in two worlds" type="VP">
          <tokens>
            <token id="15" string="was" />
            <token id="16" string="legitimized" />
            <token id="17" string="by" />
            <token id="18" string="art" />
            <token id="19" string="critics" />
            <token id="20" string="and" />
            <token id="21" string="government" />
            <token id="22" string="grants" />
            <token id="23" string="A" />
            <token id="24" string="life" />
            <token id="25" string="in" />
            <token id="26" string="two" />
            <token id="27" string="worlds" />
          </tokens>
        </chunking>
        <chunking id="3" string="legitimized by art critics and government grants A life in two worlds" type="VP">
          <tokens>
            <token id="16" string="legitimized" />
            <token id="17" string="by" />
            <token id="18" string="art" />
            <token id="19" string="critics" />
            <token id="20" string="and" />
            <token id="21" string="government" />
            <token id="22" string="grants" />
            <token id="23" string="A" />
            <token id="24" string="life" />
            <token id="25" string="in" />
            <token id="26" string="two" />
            <token id="27" string="worlds" />
          </tokens>
        </chunking>
        <chunking id="4" string="a label" type="NP">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="label" />
          </tokens>
        </chunking>
        <chunking id="5" string="to put a label on her current works" type="VP">
          <tokens>
            <token id="31" string="to" />
            <token id="32" string="put" />
            <token id="33" string="a" />
            <token id="34" string="label" />
            <token id="35" string="on" />
            <token id="36" string="her" />
            <token id="37" string="current" />
            <token id="38" string="works" />
          </tokens>
        </chunking>
        <chunking id="6" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="7" string="the form" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="form" />
          </tokens>
        </chunking>
        <chunking id="8" string="Ono" type="NP">
          <tokens>
            <token id="29" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="9" string="two worlds" type="NP">
          <tokens>
            <token id="26" string="two" />
            <token id="27" string="worlds" />
          </tokens>
        </chunking>
        <chunking id="10" string="declines to put a label on her current works" type="VP">
          <tokens>
            <token id="30" string="declines" />
            <token id="31" string="to" />
            <token id="32" string="put" />
            <token id="33" string="a" />
            <token id="34" string="label" />
            <token id="35" string="on" />
            <token id="36" string="her" />
            <token id="37" string="current" />
            <token id="38" string="works" />
          </tokens>
        </chunking>
        <chunking id="11" string="the early '60s" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="early" />
            <token id="9" string="'60s" />
          </tokens>
        </chunking>
        <chunking id="12" string="put a label on her current works" type="VP">
          <tokens>
            <token id="32" string="put" />
            <token id="33" string="a" />
            <token id="34" string="label" />
            <token id="35" string="on" />
            <token id="36" string="her" />
            <token id="37" string="current" />
            <token id="38" string="works" />
          </tokens>
        </chunking>
        <chunking id="13" string="her current works" type="NP">
          <tokens>
            <token id="36" string="her" />
            <token id="37" string="current" />
            <token id="38" string="works" />
          </tokens>
        </chunking>
        <chunking id="14" string="began doing performance art in the early '60s , long before the form was legitimized by art critics and government grants A life in two worlds" type="VP">
          <tokens>
            <token id="2" string="began" />
            <token id="3" string="doing" />
            <token id="4" string="performance" />
            <token id="5" string="art" />
            <token id="6" string="in" />
            <token id="7" string="the" />
            <token id="8" string="early" />
            <token id="9" string="'60s" />
            <token id="10" string="," />
            <token id="11" string="long" />
            <token id="12" string="before" />
            <token id="13" string="the" />
            <token id="14" string="form" />
            <token id="15" string="was" />
            <token id="16" string="legitimized" />
            <token id="17" string="by" />
            <token id="18" string="art" />
            <token id="19" string="critics" />
            <token id="20" string="and" />
            <token id="21" string="government" />
            <token id="22" string="grants" />
            <token id="23" string="A" />
            <token id="24" string="life" />
            <token id="25" string="in" />
            <token id="26" string="two" />
            <token id="27" string="worlds" />
          </tokens>
        </chunking>
        <chunking id="15" string="doing performance art in the early '60s" type="VP">
          <tokens>
            <token id="3" string="doing" />
            <token id="4" string="performance" />
            <token id="5" string="art" />
            <token id="6" string="in" />
            <token id="7" string="the" />
            <token id="8" string="early" />
            <token id="9" string="'60s" />
          </tokens>
        </chunking>
        <chunking id="16" string="performance art" type="NP">
          <tokens>
            <token id="4" string="performance" />
            <token id="5" string="art" />
          </tokens>
        </chunking>
        <chunking id="17" string="art critics and government grants" type="NP">
          <tokens>
            <token id="18" string="art" />
            <token id="19" string="critics" />
            <token id="20" string="and" />
            <token id="21" string="government" />
            <token id="22" string="grants" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">began</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">began</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">began</governor>
          <dependent id="3">doing</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">art</governor>
          <dependent id="4">performance</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">doing</governor>
          <dependent id="5">art</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">'60s</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">'60s</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">'60s</governor>
          <dependent id="8">early</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">doing</governor>
          <dependent id="9">'60s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">legitimized</governor>
          <dependent id="11">long</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">legitimized</governor>
          <dependent id="12">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">form</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="16">legitimized</governor>
          <dependent id="14">form</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="16">legitimized</governor>
          <dependent id="15">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">began</governor>
          <dependent id="16">legitimized</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">critics</governor>
          <dependent id="17">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">critics</governor>
          <dependent id="18">art</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">legitimized</governor>
          <dependent id="19">critics</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">critics</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">grants</governor>
          <dependent id="21">government</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">critics</governor>
          <dependent id="22">grants</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">life</governor>
          <dependent id="23">A</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="16">legitimized</governor>
          <dependent id="24">life</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">worlds</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="27">worlds</governor>
          <dependent id="26">two</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">legitimized</governor>
          <dependent id="27">worlds</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">declines</governor>
          <dependent id="29">Ono</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="2">began</governor>
          <dependent id="30">declines</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="32">put</governor>
          <dependent id="31">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="30">declines</governor>
          <dependent id="32">put</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">label</governor>
          <dependent id="33">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="32">put</governor>
          <dependent id="34">label</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">works</governor>
          <dependent id="35">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="38">works</governor>
          <dependent id="36">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">works</governor>
          <dependent id="37">current</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">put</governor>
          <dependent id="38">works</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="'60s" type="SET" score="0.0">
          <tokens>
            <token id="9" string="'60s" />
          </tokens>
        </entity>
        <entity id="2" string="current" type="DATE" score="0.0">
          <tokens>
            <token id="37" string="current" />
          </tokens>
        </entity>
        <entity id="3" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="26" string="two" />
          </tokens>
        </entity>
        <entity id="4" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="29" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>She says that&amp;apost;s for the critics to decide.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="critics" lemma="critic" stem="critic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="decide" lemma="decide" stem="decid" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VBZ says) (SBAR (S (NP (DT that)) (VP (VBZ 's) (PP (IN for) (NP (DT the) (NNS critics))) (S (VP (TO to) (VP (VB decide)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that" type="NP">
          <tokens>
            <token id="3" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="to decide" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="decide" />
          </tokens>
        </chunking>
        <chunking id="3" string="the critics" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="critics" />
          </tokens>
        </chunking>
        <chunking id="4" string="decide" type="VP">
          <tokens>
            <token id="9" string="decide" />
          </tokens>
        </chunking>
        <chunking id="5" string="'s for the critics to decide" type="VP">
          <tokens>
            <token id="4" string="'s" />
            <token id="5" string="for" />
            <token id="6" string="the" />
            <token id="7" string="critics" />
            <token id="8" string="to" />
            <token id="9" string="decide" />
          </tokens>
        </chunking>
        <chunking id="6" string="says that 's for the critics to decide" type="VP">
          <tokens>
            <token id="2" string="says" />
            <token id="3" string="that" />
            <token id="4" string="'s" />
            <token id="5" string="for" />
            <token id="6" string="the" />
            <token id="7" string="critics" />
            <token id="8" string="to" />
            <token id="9" string="decide" />
          </tokens>
        </chunking>
        <chunking id="7" string="that 's for the critics to decide" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="'s" />
            <token id="5" string="for" />
            <token id="6" string="the" />
            <token id="7" string="critics" />
            <token id="8" string="to" />
            <token id="9" string="decide" />
          </tokens>
        </chunking>
        <chunking id="8" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">says</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">says</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">critics</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">critics</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">critics</governor>
          <dependent id="5">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">critics</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">says</governor>
          <dependent id="7">critics</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">decide</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">critics</governor>
          <dependent id="9">decide</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>&amp;quot;I just like to create,&amp;quot; she says Ono still lives in the Dakota apartment house in New York, the site of Lennon&amp;apost;s murder by a crazed fan On Dec. 8, 1980, the couple was returning home from the recording studio where they had been remixing &amp;quot;Walking on Thin Ice,&amp;quot; one of the songs that would appear on Ono&amp;apost;s most successful album, &amp;quot;Season of Glass.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="like" lemma="like" stem="like" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="create" lemma="create" stem="creat" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="lives" lemma="live" stem="live" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Dakota" lemma="Dakota" stem="dakota" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="17" string="apartment" lemma="apartment" stem="apart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="house" lemma="house" stem="hous" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="21" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="site" lemma="site" stem="site" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="27" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="murder" lemma="murder" stem="murder" pos="NN" type="Word" isStopWord="false" ner="CRIMINAL_CHARGE" is_referenced="false" is_refers="true" />
        <token id="29" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="crazed" lemma="crazed" stem="craze" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="32" string="fan" lemma="fan" stem="fan" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="33" string="On" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="Dec." lemma="Dec." stem="dec." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="35" string="8" lemma="8" stem="8" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="36" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="37" string="1980" lemma="1980" stem="1980" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="38" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="39" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="40" string="couple" lemma="couple" stem="coupl" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="41" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="42" string="returning" lemma="return" stem="return" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="43" string="home" lemma="home" stem="home" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="44" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="45" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="46" string="recording" lemma="recording" stem="record" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="47" string="studio" lemma="studio" stem="studio" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="48" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="49" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="50" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="51" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="52" string="remixing" lemma="remix" stem="remix" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="53" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="54" string="Walking" lemma="walk" stem="walk" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="55" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="56" string="Thin" lemma="Thin" stem="thin" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="57" string="Ice" lemma="Ice" stem="ice" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="58" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="59" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="60" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="61" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="62" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="63" string="songs" lemma="song" stem="song" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="64" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="65" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="66" string="appear" lemma="appear" stem="appear" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="67" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="68" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="69" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="70" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="71" string="successful" lemma="successful" stem="success" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="72" string="album" lemma="album" stem="album" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="73" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="74" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="75" string="Season" lemma="season" stem="season" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="76" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="77" string="Glass" lemma="glass" stem="glass" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="78" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="79" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (`` ``) (S (NP (PRP I)) (ADVP (RB just)) (VP (VBP like) (S (VP (TO to) (VP (VB create)))))) (PRN (, ,) ('' '') (S (NP (PRP she)) (VP (VBZ says) (SBAR (S (NP (NNP Ono)) (ADVP (RB still)) (VP (VBZ lives) (PP (IN in) (NP (NP (DT the) (NNP Dakota) (NN apartment) (NN house)) (PP (IN in) (NP (NP (NNP New) (NNP York)) (, ,) (NP (NP (DT the) (NN site)) (PP (IN of) (NP (NP (NP (NNP Lennon) (POS 's)) (NN murder)) (PP (IN by) (NP (DT a) (JJ crazed) (NN fan))))) (UCP (PP (IN On) (NP (NP (NNP Dec.) (CD 8) (, ,) (CD 1980) (, ,)) (SBAR (S (NP (DT the) (NN couple)) (VP (VBD was) (VP (VBG returning) (NP (NN home)) (PP (IN from) (NP (NP (DT the) (NN recording) (NN studio)) (SBAR (WHADVP (WRB where)) (S (NP (PRP they)) (VP (VBD had) (VP (VBN been) (VP (VBG remixing) (NP (`` ``) (NP (VBG Walking)) (PP (IN on) (NP (NNP Thin) (NNP Ice))))))))))))))))) (, ,) ('' '') (NP (NP (CD one)) (PP (IN of) (NP (DT the) (NNS songs))) (SBAR (WHNP (WDT that)) (S (VP (MD would) (VP (VB appear) (PP (IN on) (NP (NP (NNP Ono) (POS 's)) (ADJP (RBS most) (JJ successful)) (NN album))))))))))))))))))) (, ,)) (`` ``) (NP (NP (NN Season)) (PP (IN of) (NP (NN Glass)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Dec. 8 , 1980 , the couple was returning home from the recording studio where they had been remixing `` Walking on Thin Ice" type="NP">
          <tokens>
            <token id="34" string="Dec." />
            <token id="35" string="8" />
            <token id="36" string="," />
            <token id="37" string="1980" />
            <token id="38" string="," />
            <token id="39" string="the" />
            <token id="40" string="couple" />
            <token id="41" string="was" />
            <token id="42" string="returning" />
            <token id="43" string="home" />
            <token id="44" string="from" />
            <token id="45" string="the" />
            <token id="46" string="recording" />
            <token id="47" string="studio" />
            <token id="48" string="where" />
            <token id="49" string="they" />
            <token id="50" string="had" />
            <token id="51" string="been" />
            <token id="52" string="remixing" />
            <token id="53" string="&quot;" />
            <token id="54" string="Walking" />
            <token id="55" string="on" />
            <token id="56" string="Thin" />
            <token id="57" string="Ice" />
          </tokens>
        </chunking>
        <chunking id="2" string="a crazed fan" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="crazed" />
            <token id="32" string="fan" />
          </tokens>
        </chunking>
        <chunking id="3" string="one" type="NP">
          <tokens>
            <token id="60" string="one" />
          </tokens>
        </chunking>
        <chunking id="4" string="lives in the Dakota apartment house in New York , the site of Lennon 's murder by a crazed fan On Dec. 8 , 1980 , the couple was returning home from the recording studio where they had been remixing `` Walking on Thin Ice , '' one of the songs that would appear on Ono 's most successful album" type="VP">
          <tokens>
            <token id="13" string="lives" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="Dakota" />
            <token id="17" string="apartment" />
            <token id="18" string="house" />
            <token id="19" string="in" />
            <token id="20" string="New" />
            <token id="21" string="York" />
            <token id="22" string="," />
            <token id="23" string="the" />
            <token id="24" string="site" />
            <token id="25" string="of" />
            <token id="26" string="Lennon" />
            <token id="27" string="'s" />
            <token id="28" string="murder" />
            <token id="29" string="by" />
            <token id="30" string="a" />
            <token id="31" string="crazed" />
            <token id="32" string="fan" />
            <token id="33" string="On" />
            <token id="34" string="Dec." />
            <token id="35" string="8" />
            <token id="36" string="," />
            <token id="37" string="1980" />
            <token id="38" string="," />
            <token id="39" string="the" />
            <token id="40" string="couple" />
            <token id="41" string="was" />
            <token id="42" string="returning" />
            <token id="43" string="home" />
            <token id="44" string="from" />
            <token id="45" string="the" />
            <token id="46" string="recording" />
            <token id="47" string="studio" />
            <token id="48" string="where" />
            <token id="49" string="they" />
            <token id="50" string="had" />
            <token id="51" string="been" />
            <token id="52" string="remixing" />
            <token id="53" string="&quot;" />
            <token id="54" string="Walking" />
            <token id="55" string="on" />
            <token id="56" string="Thin" />
            <token id="57" string="Ice" />
            <token id="58" string="," />
            <token id="59" string="&quot;" />
            <token id="60" string="one" />
            <token id="61" string="of" />
            <token id="62" string="the" />
            <token id="63" string="songs" />
            <token id="64" string="that" />
            <token id="65" string="would" />
            <token id="66" string="appear" />
            <token id="67" string="on" />
            <token id="68" string="Ono" />
            <token id="69" string="'s" />
            <token id="70" string="most" />
            <token id="71" string="successful" />
            <token id="72" string="album" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Dakota apartment house in New York , the site of Lennon 's murder by a crazed fan On Dec. 8 , 1980 , the couple was returning home from the recording studio where they had been remixing `` Walking on Thin Ice , '' one of the songs that would appear on Ono 's most successful album" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="Dakota" />
            <token id="17" string="apartment" />
            <token id="18" string="house" />
            <token id="19" string="in" />
            <token id="20" string="New" />
            <token id="21" string="York" />
            <token id="22" string="," />
            <token id="23" string="the" />
            <token id="24" string="site" />
            <token id="25" string="of" />
            <token id="26" string="Lennon" />
            <token id="27" string="'s" />
            <token id="28" string="murder" />
            <token id="29" string="by" />
            <token id="30" string="a" />
            <token id="31" string="crazed" />
            <token id="32" string="fan" />
            <token id="33" string="On" />
            <token id="34" string="Dec." />
            <token id="35" string="8" />
            <token id="36" string="," />
            <token id="37" string="1980" />
            <token id="38" string="," />
            <token id="39" string="the" />
            <token id="40" string="couple" />
            <token id="41" string="was" />
            <token id="42" string="returning" />
            <token id="43" string="home" />
            <token id="44" string="from" />
            <token id="45" string="the" />
            <token id="46" string="recording" />
            <token id="47" string="studio" />
            <token id="48" string="where" />
            <token id="49" string="they" />
            <token id="50" string="had" />
            <token id="51" string="been" />
            <token id="52" string="remixing" />
            <token id="53" string="&quot;" />
            <token id="54" string="Walking" />
            <token id="55" string="on" />
            <token id="56" string="Thin" />
            <token id="57" string="Ice" />
            <token id="58" string="," />
            <token id="59" string="&quot;" />
            <token id="60" string="one" />
            <token id="61" string="of" />
            <token id="62" string="the" />
            <token id="63" string="songs" />
            <token id="64" string="that" />
            <token id="65" string="would" />
            <token id="66" string="appear" />
            <token id="67" string="on" />
            <token id="68" string="Ono" />
            <token id="69" string="'s" />
            <token id="70" string="most" />
            <token id="71" string="successful" />
            <token id="72" string="album" />
          </tokens>
        </chunking>
        <chunking id="6" string="been remixing `` Walking on Thin Ice" type="VP">
          <tokens>
            <token id="51" string="been" />
            <token id="52" string="remixing" />
            <token id="53" string="&quot;" />
            <token id="54" string="Walking" />
            <token id="55" string="on" />
            <token id="56" string="Thin" />
            <token id="57" string="Ice" />
          </tokens>
        </chunking>
        <chunking id="7" string="Walking" type="NP">
          <tokens>
            <token id="54" string="Walking" />
          </tokens>
        </chunking>
        <chunking id="8" string="the recording studio where they had been remixing `` Walking on Thin Ice" type="NP">
          <tokens>
            <token id="45" string="the" />
            <token id="46" string="recording" />
            <token id="47" string="studio" />
            <token id="48" string="where" />
            <token id="49" string="they" />
            <token id="50" string="had" />
            <token id="51" string="been" />
            <token id="52" string="remixing" />
            <token id="53" string="&quot;" />
            <token id="54" string="Walking" />
            <token id="55" string="on" />
            <token id="56" string="Thin" />
            <token id="57" string="Ice" />
          </tokens>
        </chunking>
        <chunking id="9" string="Ono 's" type="NP">
          <tokens>
            <token id="68" string="Ono" />
            <token id="69" string="'s" />
          </tokens>
        </chunking>
        <chunking id="10" string="Thin Ice" type="NP">
          <tokens>
            <token id="56" string="Thin" />
            <token id="57" string="Ice" />
          </tokens>
        </chunking>
        <chunking id="11" string="was returning home from the recording studio where they had been remixing `` Walking on Thin Ice" type="VP">
          <tokens>
            <token id="41" string="was" />
            <token id="42" string="returning" />
            <token id="43" string="home" />
            <token id="44" string="from" />
            <token id="45" string="the" />
            <token id="46" string="recording" />
            <token id="47" string="studio" />
            <token id="48" string="where" />
            <token id="49" string="they" />
            <token id="50" string="had" />
            <token id="51" string="been" />
            <token id="52" string="remixing" />
            <token id="53" string="&quot;" />
            <token id="54" string="Walking" />
            <token id="55" string="on" />
            <token id="56" string="Thin" />
            <token id="57" string="Ice" />
          </tokens>
        </chunking>
        <chunking id="12" string="the couple" type="NP">
          <tokens>
            <token id="39" string="the" />
            <token id="40" string="couple" />
          </tokens>
        </chunking>
        <chunking id="13" string="remixing `` Walking on Thin Ice" type="VP">
          <tokens>
            <token id="52" string="remixing" />
            <token id="53" string="&quot;" />
            <token id="54" string="Walking" />
            <token id="55" string="on" />
            <token id="56" string="Thin" />
            <token id="57" string="Ice" />
          </tokens>
        </chunking>
        <chunking id="14" string="Season of Glass" type="NP">
          <tokens>
            <token id="75" string="Season" />
            <token id="76" string="of" />
            <token id="77" string="Glass" />
          </tokens>
        </chunking>
        <chunking id="15" string="had been remixing `` Walking on Thin Ice" type="VP">
          <tokens>
            <token id="50" string="had" />
            <token id="51" string="been" />
            <token id="52" string="remixing" />
            <token id="53" string="&quot;" />
            <token id="54" string="Walking" />
            <token id="55" string="on" />
            <token id="56" string="Thin" />
            <token id="57" string="Ice" />
          </tokens>
        </chunking>
        <chunking id="16" string="the Dakota apartment house" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="Dakota" />
            <token id="17" string="apartment" />
            <token id="18" string="house" />
          </tokens>
        </chunking>
        <chunking id="17" string="Lennon 's" type="NP">
          <tokens>
            <token id="26" string="Lennon" />
            <token id="27" string="'s" />
          </tokens>
        </chunking>
        <chunking id="18" string="returning home from the recording studio where they had been remixing `` Walking on Thin Ice" type="VP">
          <tokens>
            <token id="42" string="returning" />
            <token id="43" string="home" />
            <token id="44" string="from" />
            <token id="45" string="the" />
            <token id="46" string="recording" />
            <token id="47" string="studio" />
            <token id="48" string="where" />
            <token id="49" string="they" />
            <token id="50" string="had" />
            <token id="51" string="been" />
            <token id="52" string="remixing" />
            <token id="53" string="&quot;" />
            <token id="54" string="Walking" />
            <token id="55" string="on" />
            <token id="56" string="Thin" />
            <token id="57" string="Ice" />
          </tokens>
        </chunking>
        <chunking id="19" string="to create" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="create" />
          </tokens>
        </chunking>
        <chunking id="20" string="New York , the site of Lennon 's murder by a crazed fan On Dec. 8 , 1980 , the couple was returning home from the recording studio where they had been remixing `` Walking on Thin Ice , '' one of the songs that would appear on Ono 's most successful album" type="NP">
          <tokens>
            <token id="20" string="New" />
            <token id="21" string="York" />
            <token id="22" string="," />
            <token id="23" string="the" />
            <token id="24" string="site" />
            <token id="25" string="of" />
            <token id="26" string="Lennon" />
            <token id="27" string="'s" />
            <token id="28" string="murder" />
            <token id="29" string="by" />
            <token id="30" string="a" />
            <token id="31" string="crazed" />
            <token id="32" string="fan" />
            <token id="33" string="On" />
            <token id="34" string="Dec." />
            <token id="35" string="8" />
            <token id="36" string="," />
            <token id="37" string="1980" />
            <token id="38" string="," />
            <token id="39" string="the" />
            <token id="40" string="couple" />
            <token id="41" string="was" />
            <token id="42" string="returning" />
            <token id="43" string="home" />
            <token id="44" string="from" />
            <token id="45" string="the" />
            <token id="46" string="recording" />
            <token id="47" string="studio" />
            <token id="48" string="where" />
            <token id="49" string="they" />
            <token id="50" string="had" />
            <token id="51" string="been" />
            <token id="52" string="remixing" />
            <token id="53" string="&quot;" />
            <token id="54" string="Walking" />
            <token id="55" string="on" />
            <token id="56" string="Thin" />
            <token id="57" string="Ice" />
            <token id="58" string="," />
            <token id="59" string="&quot;" />
            <token id="60" string="one" />
            <token id="61" string="of" />
            <token id="62" string="the" />
            <token id="63" string="songs" />
            <token id="64" string="that" />
            <token id="65" string="would" />
            <token id="66" string="appear" />
            <token id="67" string="on" />
            <token id="68" string="Ono" />
            <token id="69" string="'s" />
            <token id="70" string="most" />
            <token id="71" string="successful" />
            <token id="72" string="album" />
          </tokens>
        </chunking>
        <chunking id="21" string="that would appear on Ono 's most successful album" type="SBAR">
          <tokens>
            <token id="64" string="that" />
            <token id="65" string="would" />
            <token id="66" string="appear" />
            <token id="67" string="on" />
            <token id="68" string="Ono" />
            <token id="69" string="'s" />
            <token id="70" string="most" />
            <token id="71" string="successful" />
            <token id="72" string="album" />
          </tokens>
        </chunking>
        <chunking id="22" string="would appear on Ono 's most successful album" type="VP">
          <tokens>
            <token id="65" string="would" />
            <token id="66" string="appear" />
            <token id="67" string="on" />
            <token id="68" string="Ono" />
            <token id="69" string="'s" />
            <token id="70" string="most" />
            <token id="71" string="successful" />
            <token id="72" string="album" />
          </tokens>
        </chunking>
        <chunking id="23" string="where" type="WHADVP">
          <tokens>
            <token id="48" string="where" />
          </tokens>
        </chunking>
        <chunking id="24" string="most successful" type="ADJP">
          <tokens>
            <token id="70" string="most" />
            <token id="71" string="successful" />
          </tokens>
        </chunking>
        <chunking id="25" string="Lennon 's murder by a crazed fan" type="NP">
          <tokens>
            <token id="26" string="Lennon" />
            <token id="27" string="'s" />
            <token id="28" string="murder" />
            <token id="29" string="by" />
            <token id="30" string="a" />
            <token id="31" string="crazed" />
            <token id="32" string="fan" />
          </tokens>
        </chunking>
        <chunking id="26" string="New York" type="NP">
          <tokens>
            <token id="20" string="New" />
            <token id="21" string="York" />
          </tokens>
        </chunking>
        <chunking id="27" string="the site of Lennon 's murder by a crazed fan On Dec. 8 , 1980 , the couple was returning home from the recording studio where they had been remixing `` Walking on Thin Ice , '' one of the songs that would appear on Ono 's most successful album" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="site" />
            <token id="25" string="of" />
            <token id="26" string="Lennon" />
            <token id="27" string="'s" />
            <token id="28" string="murder" />
            <token id="29" string="by" />
            <token id="30" string="a" />
            <token id="31" string="crazed" />
            <token id="32" string="fan" />
            <token id="33" string="On" />
            <token id="34" string="Dec." />
            <token id="35" string="8" />
            <token id="36" string="," />
            <token id="37" string="1980" />
            <token id="38" string="," />
            <token id="39" string="the" />
            <token id="40" string="couple" />
            <token id="41" string="was" />
            <token id="42" string="returning" />
            <token id="43" string="home" />
            <token id="44" string="from" />
            <token id="45" string="the" />
            <token id="46" string="recording" />
            <token id="47" string="studio" />
            <token id="48" string="where" />
            <token id="49" string="they" />
            <token id="50" string="had" />
            <token id="51" string="been" />
            <token id="52" string="remixing" />
            <token id="53" string="&quot;" />
            <token id="54" string="Walking" />
            <token id="55" string="on" />
            <token id="56" string="Thin" />
            <token id="57" string="Ice" />
            <token id="58" string="," />
            <token id="59" string="&quot;" />
            <token id="60" string="one" />
            <token id="61" string="of" />
            <token id="62" string="the" />
            <token id="63" string="songs" />
            <token id="64" string="that" />
            <token id="65" string="would" />
            <token id="66" string="appear" />
            <token id="67" string="on" />
            <token id="68" string="Ono" />
            <token id="69" string="'s" />
            <token id="70" string="most" />
            <token id="71" string="successful" />
            <token id="72" string="album" />
          </tokens>
        </chunking>
        <chunking id="28" string="Lennon 's murder" type="NP">
          <tokens>
            <token id="26" string="Lennon" />
            <token id="27" string="'s" />
            <token id="28" string="murder" />
          </tokens>
        </chunking>
        <chunking id="29" string="one of the songs that would appear on Ono 's most successful album" type="NP">
          <tokens>
            <token id="60" string="one" />
            <token id="61" string="of" />
            <token id="62" string="the" />
            <token id="63" string="songs" />
            <token id="64" string="that" />
            <token id="65" string="would" />
            <token id="66" string="appear" />
            <token id="67" string="on" />
            <token id="68" string="Ono" />
            <token id="69" string="'s" />
            <token id="70" string="most" />
            <token id="71" string="successful" />
            <token id="72" string="album" />
          </tokens>
        </chunking>
        <chunking id="30" string="Ono still lives in the Dakota apartment house in New York , the site of Lennon 's murder by a crazed fan On Dec. 8 , 1980 , the couple was returning home from the recording studio where they had been remixing `` Walking on Thin Ice , '' one of the songs that would appear on Ono 's most successful album" type="SBAR">
          <tokens>
            <token id="11" string="Ono" />
            <token id="12" string="still" />
            <token id="13" string="lives" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="Dakota" />
            <token id="17" string="apartment" />
            <token id="18" string="house" />
            <token id="19" string="in" />
            <token id="20" string="New" />
            <token id="21" string="York" />
            <token id="22" string="," />
            <token id="23" string="the" />
            <token id="24" string="site" />
            <token id="25" string="of" />
            <token id="26" string="Lennon" />
            <token id="27" string="'s" />
            <token id="28" string="murder" />
            <token id="29" string="by" />
            <token id="30" string="a" />
            <token id="31" string="crazed" />
            <token id="32" string="fan" />
            <token id="33" string="On" />
            <token id="34" string="Dec." />
            <token id="35" string="8" />
            <token id="36" string="," />
            <token id="37" string="1980" />
            <token id="38" string="," />
            <token id="39" string="the" />
            <token id="40" string="couple" />
            <token id="41" string="was" />
            <token id="42" string="returning" />
            <token id="43" string="home" />
            <token id="44" string="from" />
            <token id="45" string="the" />
            <token id="46" string="recording" />
            <token id="47" string="studio" />
            <token id="48" string="where" />
            <token id="49" string="they" />
            <token id="50" string="had" />
            <token id="51" string="been" />
            <token id="52" string="remixing" />
            <token id="53" string="&quot;" />
            <token id="54" string="Walking" />
            <token id="55" string="on" />
            <token id="56" string="Thin" />
            <token id="57" string="Ice" />
            <token id="58" string="," />
            <token id="59" string="&quot;" />
            <token id="60" string="one" />
            <token id="61" string="of" />
            <token id="62" string="the" />
            <token id="63" string="songs" />
            <token id="64" string="that" />
            <token id="65" string="would" />
            <token id="66" string="appear" />
            <token id="67" string="on" />
            <token id="68" string="Ono" />
            <token id="69" string="'s" />
            <token id="70" string="most" />
            <token id="71" string="successful" />
            <token id="72" string="album" />
          </tokens>
        </chunking>
        <chunking id="31" string="she" type="NP">
          <tokens>
            <token id="9" string="she" />
          </tokens>
        </chunking>
        <chunking id="32" string="home" type="NP">
          <tokens>
            <token id="43" string="home" />
          </tokens>
        </chunking>
        <chunking id="33" string="Dec. 8 , 1980 ," type="NP">
          <tokens>
            <token id="34" string="Dec." />
            <token id="35" string="8" />
            <token id="36" string="," />
            <token id="37" string="1980" />
            <token id="38" string="," />
          </tokens>
        </chunking>
        <chunking id="34" string="the site" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="site" />
          </tokens>
        </chunking>
        <chunking id="35" string="the songs" type="NP">
          <tokens>
            <token id="62" string="the" />
            <token id="63" string="songs" />
          </tokens>
        </chunking>
        <chunking id="36" string="appear on Ono 's most successful album" type="VP">
          <tokens>
            <token id="66" string="appear" />
            <token id="67" string="on" />
            <token id="68" string="Ono" />
            <token id="69" string="'s" />
            <token id="70" string="most" />
            <token id="71" string="successful" />
            <token id="72" string="album" />
          </tokens>
        </chunking>
        <chunking id="37" string="like to create" type="VP">
          <tokens>
            <token id="4" string="like" />
            <token id="5" string="to" />
            <token id="6" string="create" />
          </tokens>
        </chunking>
        <chunking id="38" string="Glass" type="NP">
          <tokens>
            <token id="77" string="Glass" />
          </tokens>
        </chunking>
        <chunking id="39" string="`` Walking on Thin Ice" type="NP">
          <tokens>
            <token id="53" string="&quot;" />
            <token id="54" string="Walking" />
            <token id="55" string="on" />
            <token id="56" string="Thin" />
            <token id="57" string="Ice" />
          </tokens>
        </chunking>
        <chunking id="40" string="the couple was returning home from the recording studio where they had been remixing `` Walking on Thin Ice" type="SBAR">
          <tokens>
            <token id="39" string="the" />
            <token id="40" string="couple" />
            <token id="41" string="was" />
            <token id="42" string="returning" />
            <token id="43" string="home" />
            <token id="44" string="from" />
            <token id="45" string="the" />
            <token id="46" string="recording" />
            <token id="47" string="studio" />
            <token id="48" string="where" />
            <token id="49" string="they" />
            <token id="50" string="had" />
            <token id="51" string="been" />
            <token id="52" string="remixing" />
            <token id="53" string="&quot;" />
            <token id="54" string="Walking" />
            <token id="55" string="on" />
            <token id="56" string="Thin" />
            <token id="57" string="Ice" />
          </tokens>
        </chunking>
        <chunking id="41" string="Ono 's most successful album" type="NP">
          <tokens>
            <token id="68" string="Ono" />
            <token id="69" string="'s" />
            <token id="70" string="most" />
            <token id="71" string="successful" />
            <token id="72" string="album" />
          </tokens>
        </chunking>
        <chunking id="42" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="43" string="where they had been remixing `` Walking on Thin Ice" type="SBAR">
          <tokens>
            <token id="48" string="where" />
            <token id="49" string="they" />
            <token id="50" string="had" />
            <token id="51" string="been" />
            <token id="52" string="remixing" />
            <token id="53" string="&quot;" />
            <token id="54" string="Walking" />
            <token id="55" string="on" />
            <token id="56" string="Thin" />
            <token id="57" string="Ice" />
          </tokens>
        </chunking>
        <chunking id="44" string="Ono" type="NP">
          <tokens>
            <token id="11" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="45" string="says Ono still lives in the Dakota apartment house in New York , the site of Lennon 's murder by a crazed fan On Dec. 8 , 1980 , the couple was returning home from the recording studio where they had been remixing `` Walking on Thin Ice , '' one of the songs that would appear on Ono 's most successful album" type="VP">
          <tokens>
            <token id="10" string="says" />
            <token id="11" string="Ono" />
            <token id="12" string="still" />
            <token id="13" string="lives" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="Dakota" />
            <token id="17" string="apartment" />
            <token id="18" string="house" />
            <token id="19" string="in" />
            <token id="20" string="New" />
            <token id="21" string="York" />
            <token id="22" string="," />
            <token id="23" string="the" />
            <token id="24" string="site" />
            <token id="25" string="of" />
            <token id="26" string="Lennon" />
            <token id="27" string="'s" />
            <token id="28" string="murder" />
            <token id="29" string="by" />
            <token id="30" string="a" />
            <token id="31" string="crazed" />
            <token id="32" string="fan" />
            <token id="33" string="On" />
            <token id="34" string="Dec." />
            <token id="35" string="8" />
            <token id="36" string="," />
            <token id="37" string="1980" />
            <token id="38" string="," />
            <token id="39" string="the" />
            <token id="40" string="couple" />
            <token id="41" string="was" />
            <token id="42" string="returning" />
            <token id="43" string="home" />
            <token id="44" string="from" />
            <token id="45" string="the" />
            <token id="46" string="recording" />
            <token id="47" string="studio" />
            <token id="48" string="where" />
            <token id="49" string="they" />
            <token id="50" string="had" />
            <token id="51" string="been" />
            <token id="52" string="remixing" />
            <token id="53" string="&quot;" />
            <token id="54" string="Walking" />
            <token id="55" string="on" />
            <token id="56" string="Thin" />
            <token id="57" string="Ice" />
            <token id="58" string="," />
            <token id="59" string="&quot;" />
            <token id="60" string="one" />
            <token id="61" string="of" />
            <token id="62" string="the" />
            <token id="63" string="songs" />
            <token id="64" string="that" />
            <token id="65" string="would" />
            <token id="66" string="appear" />
            <token id="67" string="on" />
            <token id="68" string="Ono" />
            <token id="69" string="'s" />
            <token id="70" string="most" />
            <token id="71" string="successful" />
            <token id="72" string="album" />
          </tokens>
        </chunking>
        <chunking id="46" string="they" type="NP">
          <tokens>
            <token id="49" string="they" />
          </tokens>
        </chunking>
        <chunking id="47" string="the recording studio" type="NP">
          <tokens>
            <token id="45" string="the" />
            <token id="46" string="recording" />
            <token id="47" string="studio" />
          </tokens>
        </chunking>
        <chunking id="48" string="Season" type="NP">
          <tokens>
            <token id="75" string="Season" />
          </tokens>
        </chunking>
        <chunking id="49" string="create" type="VP">
          <tokens>
            <token id="6" string="create" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">like</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">like</governor>
          <dependent id="3">just</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="75">Season</governor>
          <dependent id="4">like</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">create</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">like</governor>
          <dependent id="6">create</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">says</governor>
          <dependent id="9">she</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="75">Season</governor>
          <dependent id="10">says</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">lives</governor>
          <dependent id="11">Ono</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">lives</governor>
          <dependent id="12">still</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">says</governor>
          <dependent id="13">lives</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">house</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">house</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">house</governor>
          <dependent id="16">Dakota</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">house</governor>
          <dependent id="17">apartment</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">lives</governor>
          <dependent id="18">house</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">York</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">York</governor>
          <dependent id="20">New</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">house</governor>
          <dependent id="21">York</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">site</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="21">York</governor>
          <dependent id="24">site</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">murder</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="28">murder</governor>
          <dependent id="26">Lennon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">Lennon</governor>
          <dependent id="27">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">site</governor>
          <dependent id="28">murder</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">fan</governor>
          <dependent id="29">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">fan</governor>
          <dependent id="30">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">fan</governor>
          <dependent id="31">crazed</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">murder</governor>
          <dependent id="32">fan</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">Dec.</governor>
          <dependent id="33">On</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">site</governor>
          <dependent id="34">Dec.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="34">Dec.</governor>
          <dependent id="35">8</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="34">Dec.</governor>
          <dependent id="37">1980</dependent>
        </dependency>
        <dependency type="det">
          <governor id="40">couple</governor>
          <dependent id="39">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="42">returning</governor>
          <dependent id="40">couple</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="42">returning</governor>
          <dependent id="41">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="34">Dec.</governor>
          <dependent id="42">returning</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="42">returning</governor>
          <dependent id="43">home</dependent>
        </dependency>
        <dependency type="case">
          <governor id="47">studio</governor>
          <dependent id="44">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="47">studio</governor>
          <dependent id="45">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="47">studio</governor>
          <dependent id="46">recording</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="42">returning</governor>
          <dependent id="47">studio</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="52">remixing</governor>
          <dependent id="48">where</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="52">remixing</governor>
          <dependent id="49">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="52">remixing</governor>
          <dependent id="50">had</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="52">remixing</governor>
          <dependent id="51">been</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="47">studio</governor>
          <dependent id="52">remixing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="52">remixing</governor>
          <dependent id="54">Walking</dependent>
        </dependency>
        <dependency type="case">
          <governor id="57">Ice</governor>
          <dependent id="55">on</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="57">Ice</governor>
          <dependent id="56">Thin</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="54">Walking</governor>
          <dependent id="57">Ice</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="34">Dec.</governor>
          <dependent id="60">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="63">songs</governor>
          <dependent id="61">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="63">songs</governor>
          <dependent id="62">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="60">one</governor>
          <dependent id="63">songs</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="66">appear</governor>
          <dependent id="64">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="66">appear</governor>
          <dependent id="65">would</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="60">one</governor>
          <dependent id="66">appear</dependent>
        </dependency>
        <dependency type="case">
          <governor id="72">album</governor>
          <dependent id="67">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="72">album</governor>
          <dependent id="68">Ono</dependent>
        </dependency>
        <dependency type="case">
          <governor id="68">Ono</governor>
          <dependent id="69">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="71">successful</governor>
          <dependent id="70">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="72">album</governor>
          <dependent id="71">successful</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="66">appear</governor>
          <dependent id="72">album</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="75">Season</dependent>
        </dependency>
        <dependency type="case">
          <governor id="77">Glass</governor>
          <dependent id="76">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="75">Season</governor>
          <dependent id="77">Glass</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="New York" type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="New" />
            <token id="21" string="York" />
          </tokens>
        </entity>
        <entity id="2" string="murder" type="CRIMINAL_CHARGE" score="0.0">
          <tokens>
            <token id="28" string="murder" />
          </tokens>
        </entity>
        <entity id="3" string="Dec. 8 , 1980" type="DATE" score="0.0">
          <tokens>
            <token id="34" string="Dec." />
            <token id="35" string="8" />
            <token id="36" string="," />
            <token id="37" string="1980" />
          </tokens>
        </entity>
        <entity id="4" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="26" string="Lennon" />
          </tokens>
        </entity>
        <entity id="5" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="60" string="one" />
          </tokens>
        </entity>
        <entity id="6" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Ono" />
          </tokens>
        </entity>
        <entity id="7" string="Dakota" type="LOCATION" score="0.0">
          <tokens>
            <token id="16" string="Dakota" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>As they approached the entrance to the building, someone called out &amp;quot;Mr. Lennon?&amp;quot;</content>
      <tokens>
        <token id="1" string="As" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="approached" lemma="approach" stem="approach" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="entrance" lemma="entrance" stem="entranc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="building" lemma="building" stem="build" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="someone" lemma="someone" stem="someon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="called" lemma="call" stem="call" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="16" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (X (SBAR (IN As) (S (NP (PRP they)) (VP (VBD approached) (NP (DT the) (NN entrance)) (PP (TO to) (NP (DT the) (NN building)))))) (, ,) (NP (NP (NN someone)) (VP (VBN called) (PRT (RP out)) (`` ``) (NP (NNP Mr.) (NNP Lennon)))) (. ?) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="2" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="called out `` Mr. Lennon" type="VP">
          <tokens>
            <token id="11" string="called" />
            <token id="12" string="out" />
            <token id="13" string="&quot;" />
            <token id="14" string="Mr." />
            <token id="15" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="3" string="someone" type="NP">
          <tokens>
            <token id="10" string="someone" />
          </tokens>
        </chunking>
        <chunking id="4" string="someone called out `` Mr. Lennon" type="NP">
          <tokens>
            <token id="10" string="someone" />
            <token id="11" string="called" />
            <token id="12" string="out" />
            <token id="13" string="&quot;" />
            <token id="14" string="Mr." />
            <token id="15" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="5" string="As they approached the entrance to the building" type="SBAR">
          <tokens>
            <token id="1" string="As" />
            <token id="2" string="they" />
            <token id="3" string="approached" />
            <token id="4" string="the" />
            <token id="5" string="entrance" />
            <token id="6" string="to" />
            <token id="7" string="the" />
            <token id="8" string="building" />
          </tokens>
        </chunking>
        <chunking id="6" string="approached the entrance to the building" type="VP">
          <tokens>
            <token id="3" string="approached" />
            <token id="4" string="the" />
            <token id="5" string="entrance" />
            <token id="6" string="to" />
            <token id="7" string="the" />
            <token id="8" string="building" />
          </tokens>
        </chunking>
        <chunking id="7" string="the building" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="building" />
          </tokens>
        </chunking>
        <chunking id="8" string="the entrance" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="entrance" />
          </tokens>
        </chunking>
        <chunking id="9" string="Mr. Lennon" type="NP">
          <tokens>
            <token id="14" string="Mr." />
            <token id="15" string="Lennon" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="3">approached</governor>
          <dependent id="1">As</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">approached</governor>
          <dependent id="2">they</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">someone</governor>
          <dependent id="3">approached</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">entrance</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">approached</governor>
          <dependent id="5">entrance</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">building</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">building</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">approached</governor>
          <dependent id="8">building</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">someone</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="10">someone</governor>
          <dependent id="11">called</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="11">called</governor>
          <dependent id="12">out</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Lennon</governor>
          <dependent id="14">Mr.</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">called</governor>
          <dependent id="15">Lennon</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Lennon" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>Lennon turned, and Mark David Chapman shot him five times with a .38 revolver After Lennon&amp;apost;s death, there was speculation that Ono would leave the United States forever.</content>
      <tokens>
        <token id="1" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="turned" lemma="turn" stem="turn" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Mark" lemma="Mark" stem="mark" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="David" lemma="David" stem="david" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="Chapman" lemma="Chapman" stem="chapman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="shot" lemma="shoot" stem="shot" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="11" string="times" lemma="time" stem="time" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string=".38" lemma=".38" stem=".38" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="15" string="revolver" lemma="revolver" stem="revolv" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="After" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="18" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="death" lemma="death" stem="death" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="speculation" lemma="speculation" stem="specul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="26" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="leave" lemma="leave" stem="leav" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="United" lemma="United" stem="unite" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="30" string="States" lemma="States" stem="state" pos="NNPS" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="31" string="forever" lemma="forever" stem="forev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Lennon)) (VP (VBD turned))) (, ,) (CC and) (S (NP (NNP Mark) (NNP David) (NNP Chapman)) (VP (VBD shot) (NP (PRP him)) (NP-TMP (CD five) (NNS times)) (PP (IN with) (NP (DT a) (CD .38) (NN revolver))))) (PP (IN After) (NP (NP (NNP Lennon) (POS 's)) (NN death))) (, ,) (S (NP (EX there)) (VP (VBD was) (NP (NN speculation)) (SBAR (IN that) (S (NP (NNP Ono)) (VP (MD would) (VP (VB leave) (NP (DT the) (NNP United) (NNPS States)) (ADVP (RB forever)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="speculation" type="NP">
          <tokens>
            <token id="23" string="speculation" />
          </tokens>
        </chunking>
        <chunking id="2" string="turned" type="VP">
          <tokens>
            <token id="2" string="turned" />
          </tokens>
        </chunking>
        <chunking id="3" string="Lennon" type="NP">
          <tokens>
            <token id="1" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="4" string="a .38 revolver" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string=".38" />
            <token id="15" string="revolver" />
          </tokens>
        </chunking>
        <chunking id="5" string="would leave the United States forever" type="VP">
          <tokens>
            <token id="26" string="would" />
            <token id="27" string="leave" />
            <token id="28" string="the" />
            <token id="29" string="United" />
            <token id="30" string="States" />
            <token id="31" string="forever" />
          </tokens>
        </chunking>
        <chunking id="6" string="Mark David Chapman" type="NP">
          <tokens>
            <token id="5" string="Mark" />
            <token id="6" string="David" />
            <token id="7" string="Chapman" />
          </tokens>
        </chunking>
        <chunking id="7" string="him" type="NP">
          <tokens>
            <token id="9" string="him" />
          </tokens>
        </chunking>
        <chunking id="8" string="Lennon 's" type="NP">
          <tokens>
            <token id="17" string="Lennon" />
            <token id="18" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="was speculation that Ono would leave the United States forever" type="VP">
          <tokens>
            <token id="22" string="was" />
            <token id="23" string="speculation" />
            <token id="24" string="that" />
            <token id="25" string="Ono" />
            <token id="26" string="would" />
            <token id="27" string="leave" />
            <token id="28" string="the" />
            <token id="29" string="United" />
            <token id="30" string="States" />
            <token id="31" string="forever" />
          </tokens>
        </chunking>
        <chunking id="10" string="Ono" type="NP">
          <tokens>
            <token id="25" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="11" string="there" type="NP">
          <tokens>
            <token id="21" string="there" />
          </tokens>
        </chunking>
        <chunking id="12" string="the United States" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="United" />
            <token id="30" string="States" />
          </tokens>
        </chunking>
        <chunking id="13" string="that Ono would leave the United States forever" type="SBAR">
          <tokens>
            <token id="24" string="that" />
            <token id="25" string="Ono" />
            <token id="26" string="would" />
            <token id="27" string="leave" />
            <token id="28" string="the" />
            <token id="29" string="United" />
            <token id="30" string="States" />
            <token id="31" string="forever" />
          </tokens>
        </chunking>
        <chunking id="14" string="Lennon 's death" type="NP">
          <tokens>
            <token id="17" string="Lennon" />
            <token id="18" string="'s" />
            <token id="19" string="death" />
          </tokens>
        </chunking>
        <chunking id="15" string="shot him five times with a .38 revolver" type="VP">
          <tokens>
            <token id="8" string="shot" />
            <token id="9" string="him" />
            <token id="10" string="five" />
            <token id="11" string="times" />
            <token id="12" string="with" />
            <token id="13" string="a" />
            <token id="14" string=".38" />
            <token id="15" string="revolver" />
          </tokens>
        </chunking>
        <chunking id="16" string="leave the United States forever" type="VP">
          <tokens>
            <token id="27" string="leave" />
            <token id="28" string="the" />
            <token id="29" string="United" />
            <token id="30" string="States" />
            <token id="31" string="forever" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">turned</governor>
          <dependent id="1">Lennon</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">turned</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">turned</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Chapman</governor>
          <dependent id="5">Mark</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Chapman</governor>
          <dependent id="6">David</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">shot</governor>
          <dependent id="7">Chapman</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">turned</governor>
          <dependent id="8">shot</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">shot</governor>
          <dependent id="9">him</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">times</governor>
          <dependent id="10">five</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="8">shot</governor>
          <dependent id="11">times</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">revolver</governor>
          <dependent id="12">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">revolver</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">revolver</governor>
          <dependent id="14">.38</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">shot</governor>
          <dependent id="15">revolver</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">death</governor>
          <dependent id="16">After</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">death</governor>
          <dependent id="17">Lennon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Lennon</governor>
          <dependent id="18">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">turned</governor>
          <dependent id="19">death</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="22">was</governor>
          <dependent id="21">there</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">turned</governor>
          <dependent id="22">was</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">was</governor>
          <dependent id="23">speculation</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">leave</governor>
          <dependent id="24">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">leave</governor>
          <dependent id="25">Ono</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="27">leave</governor>
          <dependent id="26">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">was</governor>
          <dependent id="27">leave</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">States</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">States</governor>
          <dependent id="29">United</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">leave</governor>
          <dependent id="30">States</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="27">leave</governor>
          <dependent id="31">forever</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string=".38" type="NUMBER" score="0.0">
          <tokens>
            <token id="14" string=".38" />
          </tokens>
        </entity>
        <entity id="2" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Lennon" />
          </tokens>
        </entity>
        <entity id="3" string="United States" type="LOCATION" score="0.0">
          <tokens>
            <token id="29" string="United" />
            <token id="30" string="States" />
          </tokens>
        </entity>
        <entity id="4" string="Mark David Chapman" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Mark" />
            <token id="6" string="David" />
            <token id="7" string="Chapman" />
          </tokens>
        </entity>
        <entity id="5" string="five" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="five" />
          </tokens>
        </entity>
        <entity id="6" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>She did begin living part-time in Geneva &amp;quot;My theory was that I would live more and more in Geneva,&amp;quot; Ono says.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="begin" lemma="begin" stem="begin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="living" lemma="live" stem="live" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="part-time" lemma="part-time" stem="part-tim" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Geneva" lemma="Geneva" stem="geneva" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="8" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="My" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="10" string="theory" lemma="theory" stem="theori" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="live" lemma="live" stem="live" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Geneva" lemma="Geneva" stem="geneva" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="24" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP She)) (VP (VBD did) (VP (VB begin) (S (VP (VBG living) (ADVP (JJ part-time) (PP (IN in) (NP (NNP Geneva)))) (SBAR (`` ``) (S (NP (PRP$ My) (NN theory)) (VP (VBD was) (SBAR (IN that) (S (NP (PRP I)) (VP (MD would) (VP (VB live) (ADVP (ADVP (JJR more)) (CC and) (ADVP (RBR more))) (PP (IN in) (NP (NNP Geneva))))))))))))))) (, ,) ('' '') (NP (NNP Ono)) (VP (VBZ says)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="live more and more in Geneva" type="VP">
          <tokens>
            <token id="15" string="live" />
            <token id="16" string="more" />
            <token id="17" string="and" />
            <token id="18" string="more" />
            <token id="19" string="in" />
            <token id="20" string="Geneva" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="13" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="living part-time in Geneva `` My theory was that I would live more and more in Geneva" type="VP">
          <tokens>
            <token id="4" string="living" />
            <token id="5" string="part-time" />
            <token id="6" string="in" />
            <token id="7" string="Geneva" />
            <token id="8" string="&quot;" />
            <token id="9" string="My" />
            <token id="10" string="theory" />
            <token id="11" string="was" />
            <token id="12" string="that" />
            <token id="13" string="I" />
            <token id="14" string="would" />
            <token id="15" string="live" />
            <token id="16" string="more" />
            <token id="17" string="and" />
            <token id="18" string="more" />
            <token id="19" string="in" />
            <token id="20" string="Geneva" />
          </tokens>
        </chunking>
        <chunking id="4" string="begin living part-time in Geneva `` My theory was that I would live more and more in Geneva" type="VP">
          <tokens>
            <token id="3" string="begin" />
            <token id="4" string="living" />
            <token id="5" string="part-time" />
            <token id="6" string="in" />
            <token id="7" string="Geneva" />
            <token id="8" string="&quot;" />
            <token id="9" string="My" />
            <token id="10" string="theory" />
            <token id="11" string="was" />
            <token id="12" string="that" />
            <token id="13" string="I" />
            <token id="14" string="would" />
            <token id="15" string="live" />
            <token id="16" string="more" />
            <token id="17" string="and" />
            <token id="18" string="more" />
            <token id="19" string="in" />
            <token id="20" string="Geneva" />
          </tokens>
        </chunking>
        <chunking id="5" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="6" string="Ono" type="NP">
          <tokens>
            <token id="23" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="7" string="says" type="VP">
          <tokens>
            <token id="24" string="says" />
          </tokens>
        </chunking>
        <chunking id="8" string="`` My theory was that I would live more and more in Geneva" type="SBAR">
          <tokens>
            <token id="8" string="&quot;" />
            <token id="9" string="My" />
            <token id="10" string="theory" />
            <token id="11" string="was" />
            <token id="12" string="that" />
            <token id="13" string="I" />
            <token id="14" string="would" />
            <token id="15" string="live" />
            <token id="16" string="more" />
            <token id="17" string="and" />
            <token id="18" string="more" />
            <token id="19" string="in" />
            <token id="20" string="Geneva" />
          </tokens>
        </chunking>
        <chunking id="9" string="Geneva" type="NP">
          <tokens>
            <token id="7" string="Geneva" />
          </tokens>
        </chunking>
        <chunking id="10" string="would live more and more in Geneva" type="VP">
          <tokens>
            <token id="14" string="would" />
            <token id="15" string="live" />
            <token id="16" string="more" />
            <token id="17" string="and" />
            <token id="18" string="more" />
            <token id="19" string="in" />
            <token id="20" string="Geneva" />
          </tokens>
        </chunking>
        <chunking id="11" string="did begin living part-time in Geneva `` My theory was that I would live more and more in Geneva" type="VP">
          <tokens>
            <token id="2" string="did" />
            <token id="3" string="begin" />
            <token id="4" string="living" />
            <token id="5" string="part-time" />
            <token id="6" string="in" />
            <token id="7" string="Geneva" />
            <token id="8" string="&quot;" />
            <token id="9" string="My" />
            <token id="10" string="theory" />
            <token id="11" string="was" />
            <token id="12" string="that" />
            <token id="13" string="I" />
            <token id="14" string="would" />
            <token id="15" string="live" />
            <token id="16" string="more" />
            <token id="17" string="and" />
            <token id="18" string="more" />
            <token id="19" string="in" />
            <token id="20" string="Geneva" />
          </tokens>
        </chunking>
        <chunking id="12" string="was that I would live more and more in Geneva" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="that" />
            <token id="13" string="I" />
            <token id="14" string="would" />
            <token id="15" string="live" />
            <token id="16" string="more" />
            <token id="17" string="and" />
            <token id="18" string="more" />
            <token id="19" string="in" />
            <token id="20" string="Geneva" />
          </tokens>
        </chunking>
        <chunking id="13" string="that I would live more and more in Geneva" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="I" />
            <token id="14" string="would" />
            <token id="15" string="live" />
            <token id="16" string="more" />
            <token id="17" string="and" />
            <token id="18" string="more" />
            <token id="19" string="in" />
            <token id="20" string="Geneva" />
          </tokens>
        </chunking>
        <chunking id="14" string="My theory" type="NP">
          <tokens>
            <token id="9" string="My" />
            <token id="10" string="theory" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">begin</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">begin</governor>
          <dependent id="2">did</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="24">says</governor>
          <dependent id="3">begin</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">begin</governor>
          <dependent id="4">living</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">living</governor>
          <dependent id="5">part-time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Geneva</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">part-time</governor>
          <dependent id="7">Geneva</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">theory</governor>
          <dependent id="9">My</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">was</governor>
          <dependent id="10">theory</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">living</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">live</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">live</governor>
          <dependent id="13">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">live</governor>
          <dependent id="14">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">was</governor>
          <dependent id="15">live</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">and</governor>
          <dependent id="16">more</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">live</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">and</governor>
          <dependent id="18">more</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Geneva</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">live</governor>
          <dependent id="20">Geneva</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">says</governor>
          <dependent id="23">Ono</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="24">says</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Geneva" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="Geneva" />
          </tokens>
        </entity>
        <entity id="2" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>&amp;quot;But it seems like circumstances are making me come back more and more to New York.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="seems" lemma="seem" stem="seem" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="circumstances" lemma="circumstance" stem="circumst" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="making" lemma="make" stem="make" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="come" lemma="come" stem="come" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="17" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (CC But) (NP (PRP it)) (VP (VBZ seems) (SBAR (IN like) (S (NP (NNS circumstances)) (VP (VBP are) (VP (VBG making) (S (NP (PRP me)) (VP (VB come) (ADVP (ADVP (RB back) (RBR more) (CC and) (RBR more)) (PP (TO to) (NP (NNP New) (NNP York))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="New York" type="NP">
          <tokens>
            <token id="16" string="New" />
            <token id="17" string="York" />
          </tokens>
        </chunking>
        <chunking id="2" string="seems like circumstances are making me come back more and more to New York" type="VP">
          <tokens>
            <token id="4" string="seems" />
            <token id="5" string="like" />
            <token id="6" string="circumstances" />
            <token id="7" string="are" />
            <token id="8" string="making" />
            <token id="9" string="me" />
            <token id="10" string="come" />
            <token id="11" string="back" />
            <token id="12" string="more" />
            <token id="13" string="and" />
            <token id="14" string="more" />
            <token id="15" string="to" />
            <token id="16" string="New" />
            <token id="17" string="York" />
          </tokens>
        </chunking>
        <chunking id="3" string="circumstances" type="NP">
          <tokens>
            <token id="6" string="circumstances" />
          </tokens>
        </chunking>
        <chunking id="4" string="come back more and more to New York" type="VP">
          <tokens>
            <token id="10" string="come" />
            <token id="11" string="back" />
            <token id="12" string="more" />
            <token id="13" string="and" />
            <token id="14" string="more" />
            <token id="15" string="to" />
            <token id="16" string="New" />
            <token id="17" string="York" />
          </tokens>
        </chunking>
        <chunking id="5" string="like circumstances are making me come back more and more to New York" type="SBAR">
          <tokens>
            <token id="5" string="like" />
            <token id="6" string="circumstances" />
            <token id="7" string="are" />
            <token id="8" string="making" />
            <token id="9" string="me" />
            <token id="10" string="come" />
            <token id="11" string="back" />
            <token id="12" string="more" />
            <token id="13" string="and" />
            <token id="14" string="more" />
            <token id="15" string="to" />
            <token id="16" string="New" />
            <token id="17" string="York" />
          </tokens>
        </chunking>
        <chunking id="6" string="are making me come back more and more to New York" type="VP">
          <tokens>
            <token id="7" string="are" />
            <token id="8" string="making" />
            <token id="9" string="me" />
            <token id="10" string="come" />
            <token id="11" string="back" />
            <token id="12" string="more" />
            <token id="13" string="and" />
            <token id="14" string="more" />
            <token id="15" string="to" />
            <token id="16" string="New" />
            <token id="17" string="York" />
          </tokens>
        </chunking>
        <chunking id="7" string="me" type="NP">
          <tokens>
            <token id="9" string="me" />
          </tokens>
        </chunking>
        <chunking id="8" string="making me come back more and more to New York" type="VP">
          <tokens>
            <token id="8" string="making" />
            <token id="9" string="me" />
            <token id="10" string="come" />
            <token id="11" string="back" />
            <token id="12" string="more" />
            <token id="13" string="and" />
            <token id="14" string="more" />
            <token id="15" string="to" />
            <token id="16" string="New" />
            <token id="17" string="York" />
          </tokens>
        </chunking>
        <chunking id="9" string="it" type="NP">
          <tokens>
            <token id="3" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">seems</governor>
          <dependent id="2">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">seems</governor>
          <dependent id="3">it</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">seems</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">making</governor>
          <dependent id="5">like</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">making</governor>
          <dependent id="6">circumstances</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">making</governor>
          <dependent id="7">are</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">seems</governor>
          <dependent id="8">making</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">come</governor>
          <dependent id="9">me</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">making</governor>
          <dependent id="10">come</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">more</governor>
          <dependent id="11">back</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">come</governor>
          <dependent id="12">more</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">more</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">more</governor>
          <dependent id="14">more</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">York</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">York</governor>
          <dependent id="16">New</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">more</governor>
          <dependent id="17">York</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="New York" type="LOCATION" score="0.0">
          <tokens>
            <token id="16" string="New" />
            <token id="17" string="York" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>This is my hometown, that&amp;apost;s how I feel about it.</content>
      <tokens>
        <token id="1" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="hometown" lemma="hometown" stem="hometown" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="feel" lemma="feel" stem="feel" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT This)) (VP (VBZ is) (NP (PRP$ my) (NN hometown)))) (, ,) (NP (DT that)) (VP (VBZ 's) (SBAR (WHADVP (WRB how)) (S (NP (PRP I)) (VP (VBP feel) (PP (IN about) (NP (PRP it))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that" type="NP">
          <tokens>
            <token id="6" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="feel about it" type="VP">
          <tokens>
            <token id="10" string="feel" />
            <token id="11" string="about" />
            <token id="12" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="'s how I feel about it" type="VP">
          <tokens>
            <token id="7" string="'s" />
            <token id="8" string="how" />
            <token id="9" string="I" />
            <token id="10" string="feel" />
            <token id="11" string="about" />
            <token id="12" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="how I feel about it" type="SBAR">
          <tokens>
            <token id="8" string="how" />
            <token id="9" string="I" />
            <token id="10" string="feel" />
            <token id="11" string="about" />
            <token id="12" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="9" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="This" type="NP">
          <tokens>
            <token id="1" string="This" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="12" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="my hometown" type="NP">
          <tokens>
            <token id="3" string="my" />
            <token id="4" string="hometown" />
          </tokens>
        </chunking>
        <chunking id="9" string="is my hometown" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="my" />
            <token id="4" string="hometown" />
          </tokens>
        </chunking>
        <chunking id="10" string="how" type="WHADVP">
          <tokens>
            <token id="8" string="how" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">hometown</governor>
          <dependent id="1">This</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">hometown</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">hometown</governor>
          <dependent id="3">my</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">'s</governor>
          <dependent id="4">hometown</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">'s</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">feel</governor>
          <dependent id="8">how</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">feel</governor>
          <dependent id="9">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">'s</governor>
          <dependent id="10">feel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">it</governor>
          <dependent id="11">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">feel</governor>
          <dependent id="12">it</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>It&amp;apost;s a place where I can work very well.&amp;quot;</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="place" lemma="place" stem="place" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="work" lemma="work" stem="work" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ 's) (NP (NP (DT a) (NN place)) (SBAR (WHADVP (WRB where)) (S (NP (PRP I)) (VP (MD can) (VP (VB work) (ADVP (RB very) (RB well)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="can work very well" type="VP">
          <tokens>
            <token id="7" string="can" />
            <token id="8" string="work" />
            <token id="9" string="very" />
            <token id="10" string="well" />
          </tokens>
        </chunking>
        <chunking id="2" string="a place where I can work very well" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="place" />
            <token id="5" string="where" />
            <token id="6" string="I" />
            <token id="7" string="can" />
            <token id="8" string="work" />
            <token id="9" string="very" />
            <token id="10" string="well" />
          </tokens>
        </chunking>
        <chunking id="3" string="a place" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="place" />
          </tokens>
        </chunking>
        <chunking id="4" string="'s a place where I can work very well" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="a" />
            <token id="4" string="place" />
            <token id="5" string="where" />
            <token id="6" string="I" />
            <token id="7" string="can" />
            <token id="8" string="work" />
            <token id="9" string="very" />
            <token id="10" string="well" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="6" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="7" string="where" type="WHADVP">
          <tokens>
            <token id="5" string="where" />
          </tokens>
        </chunking>
        <chunking id="8" string="where I can work very well" type="SBAR">
          <tokens>
            <token id="5" string="where" />
            <token id="6" string="I" />
            <token id="7" string="can" />
            <token id="8" string="work" />
            <token id="9" string="very" />
            <token id="10" string="well" />
          </tokens>
        </chunking>
        <chunking id="9" string="work very well" type="VP">
          <tokens>
            <token id="8" string="work" />
            <token id="9" string="very" />
            <token id="10" string="well" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">place</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">place</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">place</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">place</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">work</governor>
          <dependent id="5">where</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">work</governor>
          <dependent id="6">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">work</governor>
          <dependent id="7">can</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">place</governor>
          <dependent id="8">work</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">well</governor>
          <dependent id="9">very</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">work</governor>
          <dependent id="10">well</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>; Ono was born in Tokyo -- her name means &amp;quot;Ocean Child&amp;quot; -- and came with her family to the United States in 1936.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="born" lemma="bear" stem="born" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Tokyo" lemma="Tokyo" stem="tokyo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="7" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="name" lemma="name" stem="name" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="means" lemma="mean" stem="mean" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Ocean" lemma="Ocean" stem="ocean" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="Child" lemma="Child" stem="child" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="United" lemma="United" stem="unite" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="24" string="States" lemma="States" stem="state" pos="NNPS" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="1936" lemma="1936" stem="1936" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (NP (NNP Ono)) (VP (VBD was) (VP (VP (VBN born) (PP (IN in) (NP (NNP Tokyo)))) (PRN (: --) (S (NP (PRP$ her) (NN name)) (VP (VBZ means) (S (`` ``) (NP (NNP Ocean) (NNP Child)) ('' '')))) (: --)) (CC and) (VP (VBD came) (PP (IN with) (NP (PRP$ her) (NN family))) (PP (TO to) (NP (DT the) (NNP United) (NNPS States))) (PP (IN in) (NP (CD 1936)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was born in Tokyo -- her name means `` Ocean Child '' -- and came with her family to the United States in 1936" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="born" />
            <token id="5" string="in" />
            <token id="6" string="Tokyo" />
            <token id="7" string="--" />
            <token id="8" string="her" />
            <token id="9" string="name" />
            <token id="10" string="means" />
            <token id="11" string="&quot;" />
            <token id="12" string="Ocean" />
            <token id="13" string="Child" />
            <token id="14" string="&quot;" />
            <token id="15" string="--" />
            <token id="16" string="and" />
            <token id="17" string="came" />
            <token id="18" string="with" />
            <token id="19" string="her" />
            <token id="20" string="family" />
            <token id="21" string="to" />
            <token id="22" string="the" />
            <token id="23" string="United" />
            <token id="24" string="States" />
            <token id="25" string="in" />
            <token id="26" string="1936" />
          </tokens>
        </chunking>
        <chunking id="2" string="the United States" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="United" />
            <token id="24" string="States" />
          </tokens>
        </chunking>
        <chunking id="3" string="born in Tokyo -- her name means `` Ocean Child '' -- and came with her family to the United States in 1936" type="VP">
          <tokens>
            <token id="4" string="born" />
            <token id="5" string="in" />
            <token id="6" string="Tokyo" />
            <token id="7" string="--" />
            <token id="8" string="her" />
            <token id="9" string="name" />
            <token id="10" string="means" />
            <token id="11" string="&quot;" />
            <token id="12" string="Ocean" />
            <token id="13" string="Child" />
            <token id="14" string="&quot;" />
            <token id="15" string="--" />
            <token id="16" string="and" />
            <token id="17" string="came" />
            <token id="18" string="with" />
            <token id="19" string="her" />
            <token id="20" string="family" />
            <token id="21" string="to" />
            <token id="22" string="the" />
            <token id="23" string="United" />
            <token id="24" string="States" />
            <token id="25" string="in" />
            <token id="26" string="1936" />
          </tokens>
        </chunking>
        <chunking id="4" string="her family" type="NP">
          <tokens>
            <token id="19" string="her" />
            <token id="20" string="family" />
          </tokens>
        </chunking>
        <chunking id="5" string="Tokyo" type="NP">
          <tokens>
            <token id="6" string="Tokyo" />
          </tokens>
        </chunking>
        <chunking id="6" string="came with her family to the United States in 1936" type="VP">
          <tokens>
            <token id="17" string="came" />
            <token id="18" string="with" />
            <token id="19" string="her" />
            <token id="20" string="family" />
            <token id="21" string="to" />
            <token id="22" string="the" />
            <token id="23" string="United" />
            <token id="24" string="States" />
            <token id="25" string="in" />
            <token id="26" string="1936" />
          </tokens>
        </chunking>
        <chunking id="7" string="means `` Ocean Child ''" type="VP">
          <tokens>
            <token id="10" string="means" />
            <token id="11" string="&quot;" />
            <token id="12" string="Ocean" />
            <token id="13" string="Child" />
            <token id="14" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="8" string="born in Tokyo" type="VP">
          <tokens>
            <token id="4" string="born" />
            <token id="5" string="in" />
            <token id="6" string="Tokyo" />
          </tokens>
        </chunking>
        <chunking id="9" string="her name" type="NP">
          <tokens>
            <token id="8" string="her" />
            <token id="9" string="name" />
          </tokens>
        </chunking>
        <chunking id="10" string="Ocean Child" type="NP">
          <tokens>
            <token id="12" string="Ocean" />
            <token id="13" string="Child" />
          </tokens>
        </chunking>
        <chunking id="11" string="1936" type="NP">
          <tokens>
            <token id="26" string="1936" />
          </tokens>
        </chunking>
        <chunking id="12" string="Ono" type="NP">
          <tokens>
            <token id="2" string="Ono" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="4">born</governor>
          <dependent id="2">Ono</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">born</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">born</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Tokyo</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">born</governor>
          <dependent id="6">Tokyo</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">name</governor>
          <dependent id="8">her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">means</governor>
          <dependent id="9">name</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="4">born</governor>
          <dependent id="10">means</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Child</governor>
          <dependent id="12">Ocean</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">means</governor>
          <dependent id="13">Child</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">born</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">born</governor>
          <dependent id="17">came</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">family</governor>
          <dependent id="18">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="20">family</governor>
          <dependent id="19">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">came</governor>
          <dependent id="20">family</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">States</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">States</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">States</governor>
          <dependent id="23">United</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">came</governor>
          <dependent id="24">States</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">1936</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">came</governor>
          <dependent id="26">1936</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="United States" type="LOCATION" score="0.0">
          <tokens>
            <token id="23" string="United" />
            <token id="24" string="States" />
          </tokens>
        </entity>
        <entity id="2" string="Tokyo" type="LOCATION" score="0.0">
          <tokens>
            <token id="6" string="Tokyo" />
          </tokens>
        </entity>
        <entity id="3" string="1936" type="DATE" score="0.0">
          <tokens>
            <token id="26" string="1936" />
          </tokens>
        </entity>
        <entity id="4" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>Ono lived with her family in San Francisco and New York until the Japanese attack of Pearl Harbor forced them to return home In 1951, the Onos returned to New York.</content>
      <tokens>
        <token id="1" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="lived" lemma="live" stem="live" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="San" lemma="San" stem="san" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="8" string="Francisco" lemma="Francisco" stem="francisco" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="11" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="12" string="until" lemma="until" stem="until" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Japanese" lemma="japanese" stem="japanes" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="15" string="attack" lemma="attack" stem="attack" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Pearl" lemma="Pearl" stem="pearl" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="18" string="Harbor" lemma="Harbor" stem="harbor" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="19" string="forced" lemma="force" stem="forc" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="return" lemma="return" stem="return" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="home" lemma="home" stem="home" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="1951" lemma="1951" stem="1951" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Onos" lemma="Onos" stem="ono" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="returned" lemma="return" stem="return" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="32" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Ono)) (VP (VBD lived) (PP (IN with) (NP (NP (PRP$ her) (NN family)) (PP (IN in) (NP (NP (NNP San) (NNP Francisco)) (CC and) (NP (NNP New) (NNP York)))))) (SBAR (IN until) (S (NP (NP (DT the) (JJ Japanese) (NN attack)) (PP (IN of) (NP (NNP Pearl) (NNP Harbor)))) (VP (VBD forced) (S (NP (PRP them)) (VP (TO to) (VP (VB return) (S (NP (NN home)) (PP (IN In) (NP (CD 1951)))))))))))) (, ,) (NP (DT the) (NNP Onos)) (VP (VBD returned) (PP (TO to) (NP (NNP New) (NNP York)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="New York" type="NP">
          <tokens>
            <token id="10" string="New" />
            <token id="11" string="York" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Onos" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="Onos" />
          </tokens>
        </chunking>
        <chunking id="3" string="return home In 1951" type="VP">
          <tokens>
            <token id="22" string="return" />
            <token id="23" string="home" />
            <token id="24" string="In" />
            <token id="25" string="1951" />
          </tokens>
        </chunking>
        <chunking id="4" string="to return home In 1951" type="VP">
          <tokens>
            <token id="21" string="to" />
            <token id="22" string="return" />
            <token id="23" string="home" />
            <token id="24" string="In" />
            <token id="25" string="1951" />
          </tokens>
        </chunking>
        <chunking id="5" string="San Francisco and New York" type="NP">
          <tokens>
            <token id="7" string="San" />
            <token id="8" string="Francisco" />
            <token id="9" string="and" />
            <token id="10" string="New" />
            <token id="11" string="York" />
          </tokens>
        </chunking>
        <chunking id="6" string="until the Japanese attack of Pearl Harbor forced them to return home In 1951" type="SBAR">
          <tokens>
            <token id="12" string="until" />
            <token id="13" string="the" />
            <token id="14" string="Japanese" />
            <token id="15" string="attack" />
            <token id="16" string="of" />
            <token id="17" string="Pearl" />
            <token id="18" string="Harbor" />
            <token id="19" string="forced" />
            <token id="20" string="them" />
            <token id="21" string="to" />
            <token id="22" string="return" />
            <token id="23" string="home" />
            <token id="24" string="In" />
            <token id="25" string="1951" />
          </tokens>
        </chunking>
        <chunking id="7" string="the Japanese attack of Pearl Harbor" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="Japanese" />
            <token id="15" string="attack" />
            <token id="16" string="of" />
            <token id="17" string="Pearl" />
            <token id="18" string="Harbor" />
          </tokens>
        </chunking>
        <chunking id="8" string="forced them to return home In 1951" type="VP">
          <tokens>
            <token id="19" string="forced" />
            <token id="20" string="them" />
            <token id="21" string="to" />
            <token id="22" string="return" />
            <token id="23" string="home" />
            <token id="24" string="In" />
            <token id="25" string="1951" />
          </tokens>
        </chunking>
        <chunking id="9" string="the Japanese attack" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="Japanese" />
            <token id="15" string="attack" />
          </tokens>
        </chunking>
        <chunking id="10" string="them" type="NP">
          <tokens>
            <token id="20" string="them" />
          </tokens>
        </chunking>
        <chunking id="11" string="Ono" type="NP">
          <tokens>
            <token id="1" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="12" string="home" type="NP">
          <tokens>
            <token id="23" string="home" />
          </tokens>
        </chunking>
        <chunking id="13" string="her family in San Francisco and New York" type="NP">
          <tokens>
            <token id="4" string="her" />
            <token id="5" string="family" />
            <token id="6" string="in" />
            <token id="7" string="San" />
            <token id="8" string="Francisco" />
            <token id="9" string="and" />
            <token id="10" string="New" />
            <token id="11" string="York" />
          </tokens>
        </chunking>
        <chunking id="14" string="San Francisco" type="NP">
          <tokens>
            <token id="7" string="San" />
            <token id="8" string="Francisco" />
          </tokens>
        </chunking>
        <chunking id="15" string="1951" type="NP">
          <tokens>
            <token id="25" string="1951" />
          </tokens>
        </chunking>
        <chunking id="16" string="her family" type="NP">
          <tokens>
            <token id="4" string="her" />
            <token id="5" string="family" />
          </tokens>
        </chunking>
        <chunking id="17" string="returned to New York" type="VP">
          <tokens>
            <token id="29" string="returned" />
            <token id="30" string="to" />
            <token id="31" string="New" />
            <token id="32" string="York" />
          </tokens>
        </chunking>
        <chunking id="18" string="lived with her family in San Francisco and New York until the Japanese attack of Pearl Harbor forced them to return home In 1951" type="VP">
          <tokens>
            <token id="2" string="lived" />
            <token id="3" string="with" />
            <token id="4" string="her" />
            <token id="5" string="family" />
            <token id="6" string="in" />
            <token id="7" string="San" />
            <token id="8" string="Francisco" />
            <token id="9" string="and" />
            <token id="10" string="New" />
            <token id="11" string="York" />
            <token id="12" string="until" />
            <token id="13" string="the" />
            <token id="14" string="Japanese" />
            <token id="15" string="attack" />
            <token id="16" string="of" />
            <token id="17" string="Pearl" />
            <token id="18" string="Harbor" />
            <token id="19" string="forced" />
            <token id="20" string="them" />
            <token id="21" string="to" />
            <token id="22" string="return" />
            <token id="23" string="home" />
            <token id="24" string="In" />
            <token id="25" string="1951" />
          </tokens>
        </chunking>
        <chunking id="19" string="Pearl Harbor" type="NP">
          <tokens>
            <token id="17" string="Pearl" />
            <token id="18" string="Harbor" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">lived</governor>
          <dependent id="1">Ono</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="29">returned</governor>
          <dependent id="2">lived</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">family</governor>
          <dependent id="3">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">family</governor>
          <dependent id="4">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">lived</governor>
          <dependent id="5">family</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Francisco</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Francisco</governor>
          <dependent id="7">San</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">family</governor>
          <dependent id="8">Francisco</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">Francisco</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">York</governor>
          <dependent id="10">New</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">Francisco</governor>
          <dependent id="11">York</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">forced</governor>
          <dependent id="12">until</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">attack</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">attack</governor>
          <dependent id="14">Japanese</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">forced</governor>
          <dependent id="15">attack</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Harbor</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Harbor</governor>
          <dependent id="17">Pearl</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">attack</governor>
          <dependent id="18">Harbor</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">lived</governor>
          <dependent id="19">forced</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">forced</governor>
          <dependent id="20">them</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">return</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="19">forced</governor>
          <dependent id="22">return</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="22">return</governor>
          <dependent id="23">home</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">1951</governor>
          <dependent id="24">In</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="23">home</governor>
          <dependent id="25">1951</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">Onos</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">returned</governor>
          <dependent id="28">Onos</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="29">returned</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">York</governor>
          <dependent id="30">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">York</governor>
          <dependent id="31">New</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">returned</governor>
          <dependent id="32">York</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="New York" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="New" />
            <token id="11" string="York" />
          </tokens>
        </entity>
        <entity id="2" string="1951" type="DATE" score="0.0">
          <tokens>
            <token id="25" string="1951" />
          </tokens>
        </entity>
        <entity id="3" string="attack" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="15" string="attack" />
          </tokens>
        </entity>
        <entity id="4" string="Japanese" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="14" string="Japanese" />
          </tokens>
        </entity>
        <entity id="5" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Ono" />
          </tokens>
        </entity>
        <entity id="6" string="San Francisco" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="San" />
            <token id="8" string="Francisco" />
          </tokens>
        </entity>
        <entity id="7" string="Pearl Harbor" type="LOCATION" score="0.0">
          <tokens>
            <token id="17" string="Pearl" />
            <token id="18" string="Harbor" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>Yoko married a Japanese composer when she was 23.</content>
      <tokens>
        <token id="1" string="Yoko" lemma="Yoko" stem="yoko" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="married" lemma="marry" stem="marri" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Japanese" lemma="japanese" stem="japanes" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="5" string="composer" lemma="composer" stem="compos" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="23" lemma="23" stem="23" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Yoko)) (VP (VBD married) (NP (DT a) (JJ Japanese) (NN composer)) (SBAR (WHADVP (WRB when)) (S (NP (PRP she)) (VP (VBD was) (NP (CD 23)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="23" type="NP">
          <tokens>
            <token id="9" string="23" />
          </tokens>
        </chunking>
        <chunking id="2" string="Yoko" type="NP">
          <tokens>
            <token id="1" string="Yoko" />
          </tokens>
        </chunking>
        <chunking id="3" string="married a Japanese composer when she was 23" type="VP">
          <tokens>
            <token id="2" string="married" />
            <token id="3" string="a" />
            <token id="4" string="Japanese" />
            <token id="5" string="composer" />
            <token id="6" string="when" />
            <token id="7" string="she" />
            <token id="8" string="was" />
            <token id="9" string="23" />
          </tokens>
        </chunking>
        <chunking id="4" string="when she was 23" type="SBAR">
          <tokens>
            <token id="6" string="when" />
            <token id="7" string="she" />
            <token id="8" string="was" />
            <token id="9" string="23" />
          </tokens>
        </chunking>
        <chunking id="5" string="was 23" type="VP">
          <tokens>
            <token id="8" string="was" />
            <token id="9" string="23" />
          </tokens>
        </chunking>
        <chunking id="6" string="when" type="WHADVP">
          <tokens>
            <token id="6" string="when" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="7" string="she" />
          </tokens>
        </chunking>
        <chunking id="8" string="a Japanese composer" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="Japanese" />
            <token id="5" string="composer" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">married</governor>
          <dependent id="1">Yoko</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">married</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">composer</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">composer</governor>
          <dependent id="4">Japanese</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">married</governor>
          <dependent id="5">composer</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">23</governor>
          <dependent id="6">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">23</governor>
          <dependent id="7">she</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">23</governor>
          <dependent id="8">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">married</governor>
          <dependent id="9">23</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="23" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="23" />
          </tokens>
        </entity>
        <entity id="2" string="Yoko" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Yoko" />
          </tokens>
        </entity>
        <entity id="3" string="Japanese" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="4" string="Japanese" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="false">
      <content>The marriage lasted seven years.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="marriage" lemma="marriage" stem="marriag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="lasted" lemma="last" stem="last" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="seven" lemma="seven" stem="seven" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="5" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN marriage)) (VP (VBD lasted) (NP (CD seven) (NNS years))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="lasted seven years" type="VP">
          <tokens>
            <token id="3" string="lasted" />
            <token id="4" string="seven" />
            <token id="5" string="years" />
          </tokens>
        </chunking>
        <chunking id="2" string="seven years" type="NP">
          <tokens>
            <token id="4" string="seven" />
            <token id="5" string="years" />
          </tokens>
        </chunking>
        <chunking id="3" string="The marriage" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="marriage" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">marriage</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">lasted</governor>
          <dependent id="2">marriage</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">lasted</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">years</governor>
          <dependent id="4">seven</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="3">lasted</governor>
          <dependent id="5">years</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="seven years" type="DURATION" score="0.0">
          <tokens>
            <token id="4" string="seven" />
            <token id="5" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>Ono married a second time in 1963, to avant-garde artist Tony Cox.</content>
      <tokens>
        <token id="1" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="married" lemma="marry" stem="marri" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="4" string="second" lemma="second" stem="second" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="5" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="1963" lemma="1963" stem="1963" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="avant-garde" lemma="avant-garde" stem="avant-gard" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="artist" lemma="artist" stem="artist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="Tony" lemma="Tony" stem="toni" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="13" string="Cox" lemma="Cox" stem="cox" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Ono)) (VP (VBD married) (NP (DT a) (JJ second) (NN time)) (PP (IN in) (NP (CD 1963))) (, ,) (PP (TO to) (NP (JJ avant-garde) (NN artist) (NNP Tony) (NNP Cox)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="avant-garde artist Tony Cox" type="NP">
          <tokens>
            <token id="10" string="avant-garde" />
            <token id="11" string="artist" />
            <token id="12" string="Tony" />
            <token id="13" string="Cox" />
          </tokens>
        </chunking>
        <chunking id="2" string="1963" type="NP">
          <tokens>
            <token id="7" string="1963" />
          </tokens>
        </chunking>
        <chunking id="3" string="married a second time in 1963 , to avant-garde artist Tony Cox" type="VP">
          <tokens>
            <token id="2" string="married" />
            <token id="3" string="a" />
            <token id="4" string="second" />
            <token id="5" string="time" />
            <token id="6" string="in" />
            <token id="7" string="1963" />
            <token id="8" string="," />
            <token id="9" string="to" />
            <token id="10" string="avant-garde" />
            <token id="11" string="artist" />
            <token id="12" string="Tony" />
            <token id="13" string="Cox" />
          </tokens>
        </chunking>
        <chunking id="4" string="a second time" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="second" />
            <token id="5" string="time" />
          </tokens>
        </chunking>
        <chunking id="5" string="Ono" type="NP">
          <tokens>
            <token id="1" string="Ono" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">married</governor>
          <dependent id="1">Ono</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">married</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">time</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">time</governor>
          <dependent id="4">second</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">married</governor>
          <dependent id="5">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">1963</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">married</governor>
          <dependent id="7">1963</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Cox</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">Cox</governor>
          <dependent id="10">avant-garde</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Cox</governor>
          <dependent id="11">artist</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Cox</governor>
          <dependent id="12">Tony</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">married</governor>
          <dependent id="13">Cox</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1963" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="1963" />
          </tokens>
        </entity>
        <entity id="2" string="Tony Cox" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Tony" />
            <token id="13" string="Cox" />
          </tokens>
        </entity>
        <entity id="3" string="a second" type="DURATION" score="0.0">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="second" />
          </tokens>
        </entity>
        <entity id="4" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="false">
      <content>The couple had one child, a daughter named Kyoko.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="couple" lemma="couple" stem="coupl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="5" string="child" lemma="child" stem="child" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="daughter" lemma="daughter" stem="daughter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="named" lemma="name" stem="name" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Kyoko" lemma="Kyoko" stem="kyoko" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN couple)) (VP (VBD had) (NP (NP (CD one) (NN child)) (, ,) (NP (NP (DT a) (NN daughter)) (VP (VBN named) (NP (NNP Kyoko)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="one child" type="NP">
          <tokens>
            <token id="4" string="one" />
            <token id="5" string="child" />
          </tokens>
        </chunking>
        <chunking id="2" string="a daughter" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="daughter" />
          </tokens>
        </chunking>
        <chunking id="3" string="one child , a daughter named Kyoko" type="NP">
          <tokens>
            <token id="4" string="one" />
            <token id="5" string="child" />
            <token id="6" string="," />
            <token id="7" string="a" />
            <token id="8" string="daughter" />
            <token id="9" string="named" />
            <token id="10" string="Kyoko" />
          </tokens>
        </chunking>
        <chunking id="4" string="The couple" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="couple" />
          </tokens>
        </chunking>
        <chunking id="5" string="named Kyoko" type="VP">
          <tokens>
            <token id="9" string="named" />
            <token id="10" string="Kyoko" />
          </tokens>
        </chunking>
        <chunking id="6" string="a daughter named Kyoko" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="daughter" />
            <token id="9" string="named" />
            <token id="10" string="Kyoko" />
          </tokens>
        </chunking>
        <chunking id="7" string="Kyoko" type="NP">
          <tokens>
            <token id="10" string="Kyoko" />
          </tokens>
        </chunking>
        <chunking id="8" string="had one child , a daughter named Kyoko" type="VP">
          <tokens>
            <token id="3" string="had" />
            <token id="4" string="one" />
            <token id="5" string="child" />
            <token id="6" string="," />
            <token id="7" string="a" />
            <token id="8" string="daughter" />
            <token id="9" string="named" />
            <token id="10" string="Kyoko" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">couple</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">had</governor>
          <dependent id="2">couple</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">had</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">child</governor>
          <dependent id="4">one</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">had</governor>
          <dependent id="5">child</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">daughter</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">child</governor>
          <dependent id="8">daughter</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="8">daughter</governor>
          <dependent id="9">named</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">named</governor>
          <dependent id="10">Kyoko</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="Kyoko" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Kyoko" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>In 1966, Ono and Lennon met.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="1966" lemma="1966" stem="1966" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="met" lemma="meet" stem="met" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (CD 1966))) (, ,) (NP (NNP Ono) (CC and) (NNP Lennon)) (VP (VBD met)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="1966" type="NP">
          <tokens>
            <token id="2" string="1966" />
          </tokens>
        </chunking>
        <chunking id="2" string="Ono and Lennon" type="NP">
          <tokens>
            <token id="4" string="Ono" />
            <token id="5" string="and" />
            <token id="6" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="3" string="met" type="VP">
          <tokens>
            <token id="7" string="met" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">1966</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">met</governor>
          <dependent id="2">1966</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">met</governor>
          <dependent id="4">Ono</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">Ono</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">Ono</governor>
          <dependent id="6">Lennon</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">met</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1966" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="1966" />
          </tokens>
        </entity>
        <entity id="2" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Lennon" />
          </tokens>
        </entity>
        <entity id="3" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>He too was married and had a child, Julian.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="married" lemma="marry" stem="marri" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="child" lemma="child" stem="child" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Julian" lemma="Julian" stem="julian" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (ADVP (RB too)) (VP (VP (VBD was) (VP (VBN married))) (CC and) (VP (VBD had) (NP (NP (DT a) (NN child)) (, ,) (NP (NNP Julian))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was married" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="married" />
          </tokens>
        </chunking>
        <chunking id="2" string="had a child , Julian" type="VP">
          <tokens>
            <token id="6" string="had" />
            <token id="7" string="a" />
            <token id="8" string="child" />
            <token id="9" string="," />
            <token id="10" string="Julian" />
          </tokens>
        </chunking>
        <chunking id="3" string="a child , Julian" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="child" />
            <token id="9" string="," />
            <token id="10" string="Julian" />
          </tokens>
        </chunking>
        <chunking id="4" string="a child" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="child" />
          </tokens>
        </chunking>
        <chunking id="5" string="married" type="VP">
          <tokens>
            <token id="4" string="married" />
          </tokens>
        </chunking>
        <chunking id="6" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="7" string="Julian" type="NP">
          <tokens>
            <token id="10" string="Julian" />
          </tokens>
        </chunking>
        <chunking id="8" string="was married and had a child , Julian" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="married" />
            <token id="5" string="and" />
            <token id="6" string="had" />
            <token id="7" string="a" />
            <token id="8" string="child" />
            <token id="9" string="," />
            <token id="10" string="Julian" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="4">married</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">married</governor>
          <dependent id="2">too</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">married</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">married</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">married</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">married</governor>
          <dependent id="6">had</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">child</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">had</governor>
          <dependent id="8">child</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">child</governor>
          <dependent id="10">Julian</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Julian" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Julian" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>Ono and Lennon were married in 1970 There has been much speculation on Ono and Lennon&amp;apost;s relationship.</content>
      <tokens>
        <token id="1" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="married" lemma="marry" stem="marri" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="1970" lemma="1970" stem="1970" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="much" lemma="much" stem="much" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="speculation" lemma="speculation" stem="specul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="17" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="18" string="relationship" lemma="relationship" stem="relationship" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Ono) (CC and) (NNP Lennon)) (VP (VBD were) (VP (VBN married) (PP (IN in) (NP (CD 1970)))))) (NP (EX There)) (VP (VBZ has) (VP (VBN been) (NP (NP (NP (JJ much) (NN speculation)) (PP (IN on) (NP (NNP Ono)))) (CC and) (NP (NP (NNP Lennon) (POS 's)) (NN relationship))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="married in 1970" type="VP">
          <tokens>
            <token id="5" string="married" />
            <token id="6" string="in" />
            <token id="7" string="1970" />
          </tokens>
        </chunking>
        <chunking id="2" string="much speculation on Ono" type="NP">
          <tokens>
            <token id="11" string="much" />
            <token id="12" string="speculation" />
            <token id="13" string="on" />
            <token id="14" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="3" string="been much speculation on Ono and Lennon 's relationship" type="VP">
          <tokens>
            <token id="10" string="been" />
            <token id="11" string="much" />
            <token id="12" string="speculation" />
            <token id="13" string="on" />
            <token id="14" string="Ono" />
            <token id="15" string="and" />
            <token id="16" string="Lennon" />
            <token id="17" string="'s" />
            <token id="18" string="relationship" />
          </tokens>
        </chunking>
        <chunking id="4" string="were married in 1970" type="VP">
          <tokens>
            <token id="4" string="were" />
            <token id="5" string="married" />
            <token id="6" string="in" />
            <token id="7" string="1970" />
          </tokens>
        </chunking>
        <chunking id="5" string="much speculation on Ono and Lennon 's relationship" type="NP">
          <tokens>
            <token id="11" string="much" />
            <token id="12" string="speculation" />
            <token id="13" string="on" />
            <token id="14" string="Ono" />
            <token id="15" string="and" />
            <token id="16" string="Lennon" />
            <token id="17" string="'s" />
            <token id="18" string="relationship" />
          </tokens>
        </chunking>
        <chunking id="6" string="Lennon 's" type="NP">
          <tokens>
            <token id="16" string="Lennon" />
            <token id="17" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="Ono" type="NP">
          <tokens>
            <token id="14" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="8" string="There" type="NP">
          <tokens>
            <token id="8" string="There" />
          </tokens>
        </chunking>
        <chunking id="9" string="much speculation" type="NP">
          <tokens>
            <token id="11" string="much" />
            <token id="12" string="speculation" />
          </tokens>
        </chunking>
        <chunking id="10" string="Ono and Lennon" type="NP">
          <tokens>
            <token id="1" string="Ono" />
            <token id="2" string="and" />
            <token id="3" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="11" string="1970" type="NP">
          <tokens>
            <token id="7" string="1970" />
          </tokens>
        </chunking>
        <chunking id="12" string="Lennon 's relationship" type="NP">
          <tokens>
            <token id="16" string="Lennon" />
            <token id="17" string="'s" />
            <token id="18" string="relationship" />
          </tokens>
        </chunking>
        <chunking id="13" string="has been much speculation on Ono and Lennon 's relationship" type="VP">
          <tokens>
            <token id="9" string="has" />
            <token id="10" string="been" />
            <token id="11" string="much" />
            <token id="12" string="speculation" />
            <token id="13" string="on" />
            <token id="14" string="Ono" />
            <token id="15" string="and" />
            <token id="16" string="Lennon" />
            <token id="17" string="'s" />
            <token id="18" string="relationship" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="5">married</governor>
          <dependent id="1">Ono</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Ono</governor>
          <dependent id="2">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Ono</governor>
          <dependent id="3">Lennon</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">married</governor>
          <dependent id="4">were</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">speculation</governor>
          <dependent id="5">married</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">1970</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">married</governor>
          <dependent id="7">1970</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="12">speculation</governor>
          <dependent id="8">There</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">speculation</governor>
          <dependent id="9">has</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">speculation</governor>
          <dependent id="10">been</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">speculation</governor>
          <dependent id="11">much</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">speculation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Ono</governor>
          <dependent id="13">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">speculation</governor>
          <dependent id="14">Ono</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">speculation</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">relationship</governor>
          <dependent id="16">Lennon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Lennon</governor>
          <dependent id="17">'s</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">speculation</governor>
          <dependent id="18">relationship</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="1970" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="1970" />
          </tokens>
        </entity>
        <entity id="3" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>Some say she controlled him.</content>
      <tokens>
        <token id="1" string="Some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="controlled" lemma="control" stem="control" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT Some)) (VP (VBP say) (SBAR (S (NP (PRP she)) (VP (VBD controlled) (NP (PRP him)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="say she controlled him" type="VP">
          <tokens>
            <token id="2" string="say" />
            <token id="3" string="she" />
            <token id="4" string="controlled" />
            <token id="5" string="him" />
          </tokens>
        </chunking>
        <chunking id="2" string="she controlled him" type="SBAR">
          <tokens>
            <token id="3" string="she" />
            <token id="4" string="controlled" />
            <token id="5" string="him" />
          </tokens>
        </chunking>
        <chunking id="3" string="Some" type="NP">
          <tokens>
            <token id="1" string="Some" />
          </tokens>
        </chunking>
        <chunking id="4" string="him" type="NP">
          <tokens>
            <token id="5" string="him" />
          </tokens>
        </chunking>
        <chunking id="5" string="she" type="NP">
          <tokens>
            <token id="3" string="she" />
          </tokens>
        </chunking>
        <chunking id="6" string="controlled him" type="VP">
          <tokens>
            <token id="4" string="controlled" />
            <token id="5" string="him" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">say</governor>
          <dependent id="1">Some</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">say</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">controlled</governor>
          <dependent id="3">she</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">say</governor>
          <dependent id="4">controlled</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">controlled</governor>
          <dependent id="5">him</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>&amp;quot;John was an extremely strong person,&amp;quot; Ono says.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="extremely" lemma="extremely" stem="extrem" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="strong" lemma="strong" stem="strong" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="person" lemma="person" stem="person" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (NNP John)) (VP (VBD was) (NP (DT an) (ADJP (RB extremely) (JJ strong)) (NN person)))) (, ,) ('' '') (NP (NNP Ono)) (VP (VBZ says)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="says" type="VP">
          <tokens>
            <token id="11" string="says" />
          </tokens>
        </chunking>
        <chunking id="2" string="extremely strong" type="ADJP">
          <tokens>
            <token id="5" string="extremely" />
            <token id="6" string="strong" />
          </tokens>
        </chunking>
        <chunking id="3" string="an extremely strong person" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="extremely" />
            <token id="6" string="strong" />
            <token id="7" string="person" />
          </tokens>
        </chunking>
        <chunking id="4" string="John" type="NP">
          <tokens>
            <token id="2" string="John" />
          </tokens>
        </chunking>
        <chunking id="5" string="was an extremely strong person" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="an" />
            <token id="5" string="extremely" />
            <token id="6" string="strong" />
            <token id="7" string="person" />
          </tokens>
        </chunking>
        <chunking id="6" string="Ono" type="NP">
          <tokens>
            <token id="10" string="Ono" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">person</governor>
          <dependent id="2">John</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">person</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">person</governor>
          <dependent id="4">an</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">strong</governor>
          <dependent id="5">extremely</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">person</governor>
          <dependent id="6">strong</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">says</governor>
          <dependent id="7">person</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">says</governor>
          <dependent id="10">Ono</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">says</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="John" />
          </tokens>
        </entity>
        <entity id="2" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>&amp;quot;There was no way to dominate him, even if I wanted to.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="dominate" lemma="dominate" stem="domin" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (EX There)) (VP (VBD was) (NP (DT no) (NN way) (S (VP (TO to) (VP (VB dominate) (NP (PRP him)))))) (, ,) (SBAR (RB even) (IN if) (S (NP (PRP I)) (VP (VBD wanted) (PP (TO to)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="to dominate him" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="dominate" />
            <token id="8" string="him" />
          </tokens>
        </chunking>
        <chunking id="2" string="dominate him" type="VP">
          <tokens>
            <token id="7" string="dominate" />
            <token id="8" string="him" />
          </tokens>
        </chunking>
        <chunking id="3" string="There" type="NP">
          <tokens>
            <token id="2" string="There" />
          </tokens>
        </chunking>
        <chunking id="4" string="no way to dominate him" type="NP">
          <tokens>
            <token id="4" string="no" />
            <token id="5" string="way" />
            <token id="6" string="to" />
            <token id="7" string="dominate" />
            <token id="8" string="him" />
          </tokens>
        </chunking>
        <chunking id="5" string="wanted to" type="VP">
          <tokens>
            <token id="13" string="wanted" />
            <token id="14" string="to" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="12" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="him" type="NP">
          <tokens>
            <token id="8" string="him" />
          </tokens>
        </chunking>
        <chunking id="8" string="even if I wanted to" type="SBAR">
          <tokens>
            <token id="10" string="even" />
            <token id="11" string="if" />
            <token id="12" string="I" />
            <token id="13" string="wanted" />
            <token id="14" string="to" />
          </tokens>
        </chunking>
        <chunking id="9" string="was no way to dominate him , even if I wanted to" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="no" />
            <token id="5" string="way" />
            <token id="6" string="to" />
            <token id="7" string="dominate" />
            <token id="8" string="him" />
            <token id="9" string="," />
            <token id="10" string="even" />
            <token id="11" string="if" />
            <token id="12" string="I" />
            <token id="13" string="wanted" />
            <token id="14" string="to" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="3">was</governor>
          <dependent id="2">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">way</governor>
          <dependent id="4">no</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">was</governor>
          <dependent id="5">way</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">dominate</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">way</governor>
          <dependent id="7">dominate</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">dominate</governor>
          <dependent id="8">him</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">wanted</governor>
          <dependent id="10">even</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">wanted</governor>
          <dependent id="11">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">wanted</governor>
          <dependent id="12">I</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">was</governor>
          <dependent id="13">wanted</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">wanted</governor>
          <dependent id="14">to</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>; Others say Lennon used his relationship with Ono as an escape from things in his life that he felt were controlling him -- such as the Beatles In May 1968, when the Beatles came together at the studio to work on &amp;quot;The Beatles,&amp;quot; the two-record set commonly called &amp;quot;The White Album,&amp;quot; Ono was at Lennon&amp;apost;s side.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Others" lemma="other" stem="other" pos="NNS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="used" lemma="use" stem="us" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="relationship" lemma="relationship" stem="relationship" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="escape" lemma="escape" stem="escap" pos="NN" type="Word" isStopWord="false" ner="CRIMINAL_CHARGE" is_referenced="false" is_refers="false" />
        <token id="13" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="things" lemma="thing" stem="thing" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="felt" lemma="feel" stem="felt" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="controlling" lemma="control" stem="control" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="Beatles" lemma="Beatles" stem="beatl" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="May" lemma="May" stem="mai" pos="NNP" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="31" string="1968" lemma="1968" stem="1968" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="32" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="Beatles" lemma="Beatles" stem="beatl" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="36" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="together" lemma="together" stem="togeth" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="40" string="studio" lemma="studio" stem="studio" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="41" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="work" lemma="work" stem="work" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="45" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="46" string="Beatles" lemma="Beatles" stem="beatl" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="47" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="48" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="49" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="50" string="two-record" lemma="two-record" stem="two-record" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="51" string="set" lemma="set" stem="set" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="52" string="commonly" lemma="commonly" stem="commonli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="53" string="called" lemma="call" stem="call" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="54" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="55" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="56" string="White" lemma="White" stem="white" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="57" string="Album" lemma="Album" stem="album" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="58" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="59" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="60" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="61" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="62" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="63" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="64" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="65" string="side" lemma="side" stem="side" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="66" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (S (NP (NNS Others)) (VP (VBP say) (SBAR (S (NP (NNP Lennon)) (VP (VBD used) (NP (PRP$ his) (NN relationship)) (PP (IN with) (NP (NNP Ono))) (PP (IN as) (NP (NP (DT an) (NN escape)) (PP (IN from) (NP (NP (NNS things)) (PP (IN in) (NP (PRP$ his) (NN life))))))) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD felt) (SBAR (S (VP (VBD were) (VP (VBG controlling) (NP (PRP him)))))))))))))) (: --) (S (PP (JJ such) (PP (IN as) (NP (DT the) (NNP Beatles)))) (PP (IN In) (NP (NNP May) (CD 1968))) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (DT the) (NNPS Beatles)) (VP (VBD came) (ADVP (RB together)) (PP (IN at) (NP (DT the) (NN studio))) (S (VP (TO to) (VP (VB work) (PP (IN on) (NP (`` ``) (NP (DT The) (NNPS Beatles)) (, ,) ('' '') (NP (NP (DT the) (JJ two-record) (NN set)) (RRC (ADVP (RB commonly)) (VP (VBN called) (S (`` ``) (NP (DT The) (NNP White) (NNP Album)))))))))))))) (, ,) ('' '') (NP (NNP Ono)) (VP (VBD was) (PP (IN at) (NP (NP (NNP Lennon) (POS 's)) (NN side))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Others" type="NP">
          <tokens>
            <token id="2" string="Others" />
          </tokens>
        </chunking>
        <chunking id="2" string="his relationship" type="NP">
          <tokens>
            <token id="6" string="his" />
            <token id="7" string="relationship" />
          </tokens>
        </chunking>
        <chunking id="3" string="the two-record set commonly called `` The White Album" type="NP">
          <tokens>
            <token id="49" string="the" />
            <token id="50" string="two-record" />
            <token id="51" string="set" />
            <token id="52" string="commonly" />
            <token id="53" string="called" />
            <token id="54" string="&quot;" />
            <token id="55" string="The" />
            <token id="56" string="White" />
            <token id="57" string="Album" />
          </tokens>
        </chunking>
        <chunking id="4" string="an escape from things in his life" type="NP">
          <tokens>
            <token id="11" string="an" />
            <token id="12" string="escape" />
            <token id="13" string="from" />
            <token id="14" string="things" />
            <token id="15" string="in" />
            <token id="16" string="his" />
            <token id="17" string="life" />
          </tokens>
        </chunking>
        <chunking id="5" string="the two-record set" type="NP">
          <tokens>
            <token id="49" string="the" />
            <token id="50" string="two-record" />
            <token id="51" string="set" />
          </tokens>
        </chunking>
        <chunking id="6" string="used his relationship with Ono as an escape from things in his life that he felt were controlling him" type="VP">
          <tokens>
            <token id="5" string="used" />
            <token id="6" string="his" />
            <token id="7" string="relationship" />
            <token id="8" string="with" />
            <token id="9" string="Ono" />
            <token id="10" string="as" />
            <token id="11" string="an" />
            <token id="12" string="escape" />
            <token id="13" string="from" />
            <token id="14" string="things" />
            <token id="15" string="in" />
            <token id="16" string="his" />
            <token id="17" string="life" />
            <token id="18" string="that" />
            <token id="19" string="he" />
            <token id="20" string="felt" />
            <token id="21" string="were" />
            <token id="22" string="controlling" />
            <token id="23" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="the studio" type="NP">
          <tokens>
            <token id="39" string="the" />
            <token id="40" string="studio" />
          </tokens>
        </chunking>
        <chunking id="8" string="May 1968" type="NP">
          <tokens>
            <token id="30" string="May" />
            <token id="31" string="1968" />
          </tokens>
        </chunking>
        <chunking id="9" string="called `` The White Album" type="VP">
          <tokens>
            <token id="53" string="called" />
            <token id="54" string="&quot;" />
            <token id="55" string="The" />
            <token id="56" string="White" />
            <token id="57" string="Album" />
          </tokens>
        </chunking>
        <chunking id="10" string="Lennon 's side" type="NP">
          <tokens>
            <token id="63" string="Lennon" />
            <token id="64" string="'s" />
            <token id="65" string="side" />
          </tokens>
        </chunking>
        <chunking id="11" string="say Lennon used his relationship with Ono as an escape from things in his life that he felt were controlling him" type="VP">
          <tokens>
            <token id="3" string="say" />
            <token id="4" string="Lennon" />
            <token id="5" string="used" />
            <token id="6" string="his" />
            <token id="7" string="relationship" />
            <token id="8" string="with" />
            <token id="9" string="Ono" />
            <token id="10" string="as" />
            <token id="11" string="an" />
            <token id="12" string="escape" />
            <token id="13" string="from" />
            <token id="14" string="things" />
            <token id="15" string="in" />
            <token id="16" string="his" />
            <token id="17" string="life" />
            <token id="18" string="that" />
            <token id="19" string="he" />
            <token id="20" string="felt" />
            <token id="21" string="were" />
            <token id="22" string="controlling" />
            <token id="23" string="him" />
          </tokens>
        </chunking>
        <chunking id="12" string="The White Album" type="NP">
          <tokens>
            <token id="55" string="The" />
            <token id="56" string="White" />
            <token id="57" string="Album" />
          </tokens>
        </chunking>
        <chunking id="13" string="to work on `` The Beatles , '' the two-record set commonly called `` The White Album" type="VP">
          <tokens>
            <token id="41" string="to" />
            <token id="42" string="work" />
            <token id="43" string="on" />
            <token id="44" string="&quot;" />
            <token id="45" string="The" />
            <token id="46" string="Beatles" />
            <token id="47" string="," />
            <token id="48" string="&quot;" />
            <token id="49" string="the" />
            <token id="50" string="two-record" />
            <token id="51" string="set" />
            <token id="52" string="commonly" />
            <token id="53" string="called" />
            <token id="54" string="&quot;" />
            <token id="55" string="The" />
            <token id="56" string="White" />
            <token id="57" string="Album" />
          </tokens>
        </chunking>
        <chunking id="14" string="were controlling him" type="SBAR">
          <tokens>
            <token id="21" string="were" />
            <token id="22" string="controlling" />
            <token id="23" string="him" />
          </tokens>
        </chunking>
        <chunking id="15" string="he" type="NP">
          <tokens>
            <token id="19" string="he" />
          </tokens>
        </chunking>
        <chunking id="16" string="The Beatles" type="NP">
          <tokens>
            <token id="45" string="The" />
            <token id="46" string="Beatles" />
          </tokens>
        </chunking>
        <chunking id="17" string="felt were controlling him" type="VP">
          <tokens>
            <token id="20" string="felt" />
            <token id="21" string="were" />
            <token id="22" string="controlling" />
            <token id="23" string="him" />
          </tokens>
        </chunking>
        <chunking id="18" string="an escape" type="NP">
          <tokens>
            <token id="11" string="an" />
            <token id="12" string="escape" />
          </tokens>
        </chunking>
        <chunking id="19" string="controlling him" type="VP">
          <tokens>
            <token id="22" string="controlling" />
            <token id="23" string="him" />
          </tokens>
        </chunking>
        <chunking id="20" string="things in his life" type="NP">
          <tokens>
            <token id="14" string="things" />
            <token id="15" string="in" />
            <token id="16" string="his" />
            <token id="17" string="life" />
          </tokens>
        </chunking>
        <chunking id="21" string="Lennon" type="NP">
          <tokens>
            <token id="4" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="22" string="him" type="NP">
          <tokens>
            <token id="23" string="him" />
          </tokens>
        </chunking>
        <chunking id="23" string="the Beatles" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="Beatles" />
          </tokens>
        </chunking>
        <chunking id="24" string="work on `` The Beatles , '' the two-record set commonly called `` The White Album" type="VP">
          <tokens>
            <token id="42" string="work" />
            <token id="43" string="on" />
            <token id="44" string="&quot;" />
            <token id="45" string="The" />
            <token id="46" string="Beatles" />
            <token id="47" string="," />
            <token id="48" string="&quot;" />
            <token id="49" string="the" />
            <token id="50" string="two-record" />
            <token id="51" string="set" />
            <token id="52" string="commonly" />
            <token id="53" string="called" />
            <token id="54" string="&quot;" />
            <token id="55" string="The" />
            <token id="56" string="White" />
            <token id="57" string="Album" />
          </tokens>
        </chunking>
        <chunking id="25" string="Lennon 's" type="NP">
          <tokens>
            <token id="63" string="Lennon" />
            <token id="64" string="'s" />
          </tokens>
        </chunking>
        <chunking id="26" string="came together at the studio to work on `` The Beatles , '' the two-record set commonly called `` The White Album" type="VP">
          <tokens>
            <token id="36" string="came" />
            <token id="37" string="together" />
            <token id="38" string="at" />
            <token id="39" string="the" />
            <token id="40" string="studio" />
            <token id="41" string="to" />
            <token id="42" string="work" />
            <token id="43" string="on" />
            <token id="44" string="&quot;" />
            <token id="45" string="The" />
            <token id="46" string="Beatles" />
            <token id="47" string="," />
            <token id="48" string="&quot;" />
            <token id="49" string="the" />
            <token id="50" string="two-record" />
            <token id="51" string="set" />
            <token id="52" string="commonly" />
            <token id="53" string="called" />
            <token id="54" string="&quot;" />
            <token id="55" string="The" />
            <token id="56" string="White" />
            <token id="57" string="Album" />
          </tokens>
        </chunking>
        <chunking id="27" string="Lennon used his relationship with Ono as an escape from things in his life that he felt were controlling him" type="SBAR">
          <tokens>
            <token id="4" string="Lennon" />
            <token id="5" string="used" />
            <token id="6" string="his" />
            <token id="7" string="relationship" />
            <token id="8" string="with" />
            <token id="9" string="Ono" />
            <token id="10" string="as" />
            <token id="11" string="an" />
            <token id="12" string="escape" />
            <token id="13" string="from" />
            <token id="14" string="things" />
            <token id="15" string="in" />
            <token id="16" string="his" />
            <token id="17" string="life" />
            <token id="18" string="that" />
            <token id="19" string="he" />
            <token id="20" string="felt" />
            <token id="21" string="were" />
            <token id="22" string="controlling" />
            <token id="23" string="him" />
          </tokens>
        </chunking>
        <chunking id="28" string="Ono" type="NP">
          <tokens>
            <token id="9" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="29" string="when" type="WHADVP">
          <tokens>
            <token id="33" string="when" />
          </tokens>
        </chunking>
        <chunking id="30" string="that he felt were controlling him" type="SBAR">
          <tokens>
            <token id="18" string="that" />
            <token id="19" string="he" />
            <token id="20" string="felt" />
            <token id="21" string="were" />
            <token id="22" string="controlling" />
            <token id="23" string="him" />
          </tokens>
        </chunking>
        <chunking id="31" string="when the Beatles came together at the studio to work on `` The Beatles , '' the two-record set commonly called `` The White Album" type="SBAR">
          <tokens>
            <token id="33" string="when" />
            <token id="34" string="the" />
            <token id="35" string="Beatles" />
            <token id="36" string="came" />
            <token id="37" string="together" />
            <token id="38" string="at" />
            <token id="39" string="the" />
            <token id="40" string="studio" />
            <token id="41" string="to" />
            <token id="42" string="work" />
            <token id="43" string="on" />
            <token id="44" string="&quot;" />
            <token id="45" string="The" />
            <token id="46" string="Beatles" />
            <token id="47" string="," />
            <token id="48" string="&quot;" />
            <token id="49" string="the" />
            <token id="50" string="two-record" />
            <token id="51" string="set" />
            <token id="52" string="commonly" />
            <token id="53" string="called" />
            <token id="54" string="&quot;" />
            <token id="55" string="The" />
            <token id="56" string="White" />
            <token id="57" string="Album" />
          </tokens>
        </chunking>
        <chunking id="32" string="his life" type="NP">
          <tokens>
            <token id="16" string="his" />
            <token id="17" string="life" />
          </tokens>
        </chunking>
        <chunking id="33" string="things" type="NP">
          <tokens>
            <token id="14" string="things" />
          </tokens>
        </chunking>
        <chunking id="34" string="`` The Beatles , '' the two-record set commonly called `` The White Album" type="NP">
          <tokens>
            <token id="44" string="&quot;" />
            <token id="45" string="The" />
            <token id="46" string="Beatles" />
            <token id="47" string="," />
            <token id="48" string="&quot;" />
            <token id="49" string="the" />
            <token id="50" string="two-record" />
            <token id="51" string="set" />
            <token id="52" string="commonly" />
            <token id="53" string="called" />
            <token id="54" string="&quot;" />
            <token id="55" string="The" />
            <token id="56" string="White" />
            <token id="57" string="Album" />
          </tokens>
        </chunking>
        <chunking id="35" string="was at Lennon 's side" type="VP">
          <tokens>
            <token id="61" string="was" />
            <token id="62" string="at" />
            <token id="63" string="Lennon" />
            <token id="64" string="'s" />
            <token id="65" string="side" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">say</governor>
          <dependent id="2">Others</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">say</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">used</governor>
          <dependent id="4">Lennon</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">say</governor>
          <dependent id="5">used</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">relationship</governor>
          <dependent id="6">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">used</governor>
          <dependent id="7">relationship</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Ono</governor>
          <dependent id="8">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">used</governor>
          <dependent id="9">Ono</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">escape</governor>
          <dependent id="10">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">escape</governor>
          <dependent id="11">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">used</governor>
          <dependent id="12">escape</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">things</governor>
          <dependent id="13">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">escape</governor>
          <dependent id="14">things</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">life</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">life</governor>
          <dependent id="16">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">things</governor>
          <dependent id="17">life</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">felt</governor>
          <dependent id="18">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">felt</governor>
          <dependent id="19">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">used</governor>
          <dependent id="20">felt</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">controlling</governor>
          <dependent id="21">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">felt</governor>
          <dependent id="22">controlling</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">controlling</governor>
          <dependent id="23">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">Beatles</governor>
          <dependent id="25">such</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">Beatles</governor>
          <dependent id="26">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">Beatles</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="65">side</governor>
          <dependent id="28">Beatles</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">May</governor>
          <dependent id="29">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="65">side</governor>
          <dependent id="30">May</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="30">May</governor>
          <dependent id="31">1968</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="36">came</governor>
          <dependent id="33">when</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">Beatles</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">came</governor>
          <dependent id="35">Beatles</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="65">side</governor>
          <dependent id="36">came</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="36">came</governor>
          <dependent id="37">together</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">studio</governor>
          <dependent id="38">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="40">studio</governor>
          <dependent id="39">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">came</governor>
          <dependent id="40">studio</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="42">work</governor>
          <dependent id="41">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="36">came</governor>
          <dependent id="42">work</dependent>
        </dependency>
        <dependency type="case">
          <governor id="46">Beatles</governor>
          <dependent id="43">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="46">Beatles</governor>
          <dependent id="45">The</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="42">work</governor>
          <dependent id="46">Beatles</dependent>
        </dependency>
        <dependency type="det">
          <governor id="51">set</governor>
          <dependent id="49">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="51">set</governor>
          <dependent id="50">two-record</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="46">Beatles</governor>
          <dependent id="51">set</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="53">called</governor>
          <dependent id="52">commonly</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="51">set</governor>
          <dependent id="53">called</dependent>
        </dependency>
        <dependency type="det">
          <governor id="57">Album</governor>
          <dependent id="55">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="57">Album</governor>
          <dependent id="56">White</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="53">called</governor>
          <dependent id="57">Album</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="65">side</governor>
          <dependent id="60">Ono</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="65">side</governor>
          <dependent id="61">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="65">side</governor>
          <dependent id="62">at</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="65">side</governor>
          <dependent id="63">Lennon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="63">Lennon</governor>
          <dependent id="64">'s</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="3">say</governor>
          <dependent id="65">side</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="escape" type="CRIMINAL_CHARGE" score="0.0">
          <tokens>
            <token id="12" string="escape" />
          </tokens>
        </entity>
        <entity id="3" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Ono" />
          </tokens>
        </entity>
        <entity id="4" string="May 1968" type="DATE" score="0.0">
          <tokens>
            <token id="30" string="May" />
            <token id="31" string="1968" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>The two were inseparable.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="3" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="inseparable" lemma="inseparable" stem="insepar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (CD two)) (VP (VBD were) (ADJP (JJ inseparable))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="inseparable" type="ADJP">
          <tokens>
            <token id="4" string="inseparable" />
          </tokens>
        </chunking>
        <chunking id="2" string="were inseparable" type="VP">
          <tokens>
            <token id="3" string="were" />
            <token id="4" string="inseparable" />
          </tokens>
        </chunking>
        <chunking id="3" string="The two" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="two" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">two</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">inseparable</governor>
          <dependent id="2">two</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">inseparable</governor>
          <dependent id="3">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">inseparable</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>According to at least one Beatles biographer, Ono even accompanied Lennon on trips to the bathroom The relationship between the Beatles -- especially Lennon and Paul McCartney -- was already strained.</content>
      <tokens>
        <token id="1" string="According" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="least" lemma="least" stem="least" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="6" string="Beatles" lemma="Beatles" stem="beatl" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="biographer" lemma="biographer" stem="biograph" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="accompanied" lemma="accompany" stem="accompani" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="trips" lemma="trip" stem="trip" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="bathroom" lemma="bathroom" stem="bathroom" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="relationship" lemma="relationship" stem="relationship" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="Beatles" lemma="Beatles" stem="beatl" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="especially" lemma="especially" stem="especi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="Paul" lemma="Paul" stem="paul" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="28" string="McCartney" lemma="McCartney" stem="mccartnei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="29" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="already" lemma="already" stem="alreadi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="strained" lemma="strain" stem="strain" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (VBG According) (PP (TO to) (NP (QP (IN at) (JJS least) (CD one)) (NNP Beatles) (NN biographer)))) (, ,) (NP (NNP Ono)) (ADVP (RB even)) (VP (VBD accompanied) (NP (NP (NNP Lennon)) (PP (IN on) (NP (NNS trips)))) (PP (TO to) (NP (NP (DT the) (NN bathroom)) (SBAR (S (NP (NP (NP (DT The) (NN relationship)) (PP (IN between) (NP (DT the) (NNPS Beatles)))) (PRN (: --) (RRC (ADVP (RB especially)) (NP (NNP Lennon) (CC and) (NNP Paul) (NNP McCartney))) (: --))) (VP (VBD was) (ADJP (RB already) (VBN strained)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the bathroom" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="bathroom" />
          </tokens>
        </chunking>
        <chunking id="2" string="The relationship" type="NP">
          <tokens>
            <token id="18" string="The" />
            <token id="19" string="relationship" />
          </tokens>
        </chunking>
        <chunking id="3" string="Lennon" type="NP">
          <tokens>
            <token id="12" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="4" string="already strained" type="ADJP">
          <tokens>
            <token id="31" string="already" />
            <token id="32" string="strained" />
          </tokens>
        </chunking>
        <chunking id="5" string="accompanied Lennon on trips to the bathroom The relationship between the Beatles -- especially Lennon and Paul McCartney -- was already strained" type="VP">
          <tokens>
            <token id="11" string="accompanied" />
            <token id="12" string="Lennon" />
            <token id="13" string="on" />
            <token id="14" string="trips" />
            <token id="15" string="to" />
            <token id="16" string="the" />
            <token id="17" string="bathroom" />
            <token id="18" string="The" />
            <token id="19" string="relationship" />
            <token id="20" string="between" />
            <token id="21" string="the" />
            <token id="22" string="Beatles" />
            <token id="23" string="--" />
            <token id="24" string="especially" />
            <token id="25" string="Lennon" />
            <token id="26" string="and" />
            <token id="27" string="Paul" />
            <token id="28" string="McCartney" />
            <token id="29" string="--" />
            <token id="30" string="was" />
            <token id="31" string="already" />
            <token id="32" string="strained" />
          </tokens>
        </chunking>
        <chunking id="6" string="at least one Beatles biographer" type="NP">
          <tokens>
            <token id="3" string="at" />
            <token id="4" string="least" />
            <token id="5" string="one" />
            <token id="6" string="Beatles" />
            <token id="7" string="biographer" />
          </tokens>
        </chunking>
        <chunking id="7" string="The relationship between the Beatles" type="NP">
          <tokens>
            <token id="18" string="The" />
            <token id="19" string="relationship" />
            <token id="20" string="between" />
            <token id="21" string="the" />
            <token id="22" string="Beatles" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Beatles" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="Beatles" />
          </tokens>
        </chunking>
        <chunking id="9" string="Ono" type="NP">
          <tokens>
            <token id="9" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="10" string="Lennon and Paul McCartney" type="NP">
          <tokens>
            <token id="25" string="Lennon" />
            <token id="26" string="and" />
            <token id="27" string="Paul" />
            <token id="28" string="McCartney" />
          </tokens>
        </chunking>
        <chunking id="11" string="The relationship between the Beatles -- especially Lennon and Paul McCartney -- was already strained" type="SBAR">
          <tokens>
            <token id="18" string="The" />
            <token id="19" string="relationship" />
            <token id="20" string="between" />
            <token id="21" string="the" />
            <token id="22" string="Beatles" />
            <token id="23" string="--" />
            <token id="24" string="especially" />
            <token id="25" string="Lennon" />
            <token id="26" string="and" />
            <token id="27" string="Paul" />
            <token id="28" string="McCartney" />
            <token id="29" string="--" />
            <token id="30" string="was" />
            <token id="31" string="already" />
            <token id="32" string="strained" />
          </tokens>
        </chunking>
        <chunking id="12" string="trips" type="NP">
          <tokens>
            <token id="14" string="trips" />
          </tokens>
        </chunking>
        <chunking id="13" string="The relationship between the Beatles -- especially Lennon and Paul McCartney --" type="NP">
          <tokens>
            <token id="18" string="The" />
            <token id="19" string="relationship" />
            <token id="20" string="between" />
            <token id="21" string="the" />
            <token id="22" string="Beatles" />
            <token id="23" string="--" />
            <token id="24" string="especially" />
            <token id="25" string="Lennon" />
            <token id="26" string="and" />
            <token id="27" string="Paul" />
            <token id="28" string="McCartney" />
            <token id="29" string="--" />
          </tokens>
        </chunking>
        <chunking id="14" string="Lennon on trips" type="NP">
          <tokens>
            <token id="12" string="Lennon" />
            <token id="13" string="on" />
            <token id="14" string="trips" />
          </tokens>
        </chunking>
        <chunking id="15" string="the bathroom The relationship between the Beatles -- especially Lennon and Paul McCartney -- was already strained" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="bathroom" />
            <token id="18" string="The" />
            <token id="19" string="relationship" />
            <token id="20" string="between" />
            <token id="21" string="the" />
            <token id="22" string="Beatles" />
            <token id="23" string="--" />
            <token id="24" string="especially" />
            <token id="25" string="Lennon" />
            <token id="26" string="and" />
            <token id="27" string="Paul" />
            <token id="28" string="McCartney" />
            <token id="29" string="--" />
            <token id="30" string="was" />
            <token id="31" string="already" />
            <token id="32" string="strained" />
          </tokens>
        </chunking>
        <chunking id="16" string="was already strained" type="VP">
          <tokens>
            <token id="30" string="was" />
            <token id="31" string="already" />
            <token id="32" string="strained" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="7">biographer</governor>
          <dependent id="1">According</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">According</governor>
          <dependent id="2">to</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">least</governor>
          <dependent id="3">at</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="5">one</governor>
          <dependent id="4">least</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">biographer</governor>
          <dependent id="5">one</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">biographer</governor>
          <dependent id="6">Beatles</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">accompanied</governor>
          <dependent id="7">biographer</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">accompanied</governor>
          <dependent id="9">Ono</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">accompanied</governor>
          <dependent id="10">even</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">accompanied</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">accompanied</governor>
          <dependent id="12">Lennon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">trips</governor>
          <dependent id="13">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">Lennon</governor>
          <dependent id="14">trips</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">bathroom</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">bathroom</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">accompanied</governor>
          <dependent id="17">bathroom</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">relationship</governor>
          <dependent id="18">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="32">strained</governor>
          <dependent id="19">relationship</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">Beatles</governor>
          <dependent id="20">between</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">Beatles</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">relationship</governor>
          <dependent id="22">Beatles</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">McCartney</governor>
          <dependent id="24">especially</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">McCartney</governor>
          <dependent id="25">Lennon</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="25">Lennon</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="25">Lennon</governor>
          <dependent id="27">Paul</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="19">relationship</governor>
          <dependent id="28">McCartney</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="32">strained</governor>
          <dependent id="30">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="32">strained</governor>
          <dependent id="31">already</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="17">bathroom</governor>
          <dependent id="32">strained</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Lennon" />
          </tokens>
        </entity>
        <entity id="3" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Ono" />
          </tokens>
        </entity>
        <entity id="4" string="Paul McCartney" type="PERSON" score="0.0">
          <tokens>
            <token id="27" string="Paul" />
            <token id="28" string="McCartney" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>Having Ono in the studio, offering suggestions and backing Lennon up in arguments, didn&amp;apost;t help Still, the group already seemed headed toward a break-up, which finally came when McCartney sued the other Beatles to resolve an argument over the group&amp;apost;s management.</content>
      <tokens>
        <token id="1" string="Having" lemma="have" stem="have" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="studio" lemma="studio" stem="studio" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="offering" lemma="offer" stem="offer" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="suggestions" lemma="suggestion" stem="suggest" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="backing" lemma="back" stem="back" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="arguments" lemma="argument" stem="argument" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="help" lemma="help" stem="help" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="Still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="group" lemma="group" stem="group" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="already" lemma="already" stem="alreadi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="seemed" lemma="seem" stem="seem" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="headed" lemma="head" stem="head" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="toward" lemma="toward" stem="toward" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="break-up" lemma="break-up" stem="break-up" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="finally" lemma="finally" stem="final" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="McCartney" lemma="McCartney" stem="mccartnei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="35" string="sued" lemma="sue" stem="su" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="Beatles" lemma="beatle" stem="beatl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="resolve" lemma="resolve" stem="resolv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="argument" lemma="argument" stem="argument" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="group" lemma="group" stem="group" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="management" lemma="management" stem="manag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VP (VBG Having) (NP (NP (NNP Ono)) (PP (IN in) (NP (DT the) (NN studio))))) (, ,) (VP (VBG offering) (NP (NNS suggestions))) (CC and) (VP (VBG backing) (NP (NNP Lennon)) (PRT (RP up)) (PP (IN in) (NP (NNS arguments))) (, ,) (S (VP (VBD did) (RB n't) (VP (VB help) (ADVP (RB Still)))))))) (, ,) (NP (DT the) (NN group)) (ADVP (RB already)) (VP (VBD seemed) (VP (VBN headed) (PP (IN toward) (NP (NP (DT a) (NN break-up)) (, ,) (SBAR (WHNP (WDT which)) (S (ADVP (RB finally)) (VP (VBD came) (SBAR (WHADVP (WRB when)) (S (NP (NNP McCartney)) (VP (VBD sued) (NP (DT the) (JJ other) (NNS Beatles)) (S (VP (TO to) (VP (VB resolve) (NP (NP (DT an) (NN argument)) (PP (IN over) (NP (NP (DT the) (NN group) (POS 's)) (NN management))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="offering suggestions" type="VP">
          <tokens>
            <token id="7" string="offering" />
            <token id="8" string="suggestions" />
          </tokens>
        </chunking>
        <chunking id="2" string="backing Lennon up in arguments , did n't help Still" type="VP">
          <tokens>
            <token id="10" string="backing" />
            <token id="11" string="Lennon" />
            <token id="12" string="up" />
            <token id="13" string="in" />
            <token id="14" string="arguments" />
            <token id="15" string="," />
            <token id="16" string="did" />
            <token id="17" string="n't" />
            <token id="18" string="help" />
            <token id="19" string="Still" />
          </tokens>
        </chunking>
        <chunking id="3" string="the group 's" type="NP">
          <tokens>
            <token id="44" string="the" />
            <token id="45" string="group" />
            <token id="46" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="seemed headed toward a break-up , which finally came when McCartney sued the other Beatles to resolve an argument over the group 's management" type="VP">
          <tokens>
            <token id="24" string="seemed" />
            <token id="25" string="headed" />
            <token id="26" string="toward" />
            <token id="27" string="a" />
            <token id="28" string="break-up" />
            <token id="29" string="," />
            <token id="30" string="which" />
            <token id="31" string="finally" />
            <token id="32" string="came" />
            <token id="33" string="when" />
            <token id="34" string="McCartney" />
            <token id="35" string="sued" />
            <token id="36" string="the" />
            <token id="37" string="other" />
            <token id="38" string="Beatles" />
            <token id="39" string="to" />
            <token id="40" string="resolve" />
            <token id="41" string="an" />
            <token id="42" string="argument" />
            <token id="43" string="over" />
            <token id="44" string="the" />
            <token id="45" string="group" />
            <token id="46" string="'s" />
            <token id="47" string="management" />
          </tokens>
        </chunking>
        <chunking id="5" string="the studio" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="studio" />
          </tokens>
        </chunking>
        <chunking id="6" string="came when McCartney sued the other Beatles to resolve an argument over the group 's management" type="VP">
          <tokens>
            <token id="32" string="came" />
            <token id="33" string="when" />
            <token id="34" string="McCartney" />
            <token id="35" string="sued" />
            <token id="36" string="the" />
            <token id="37" string="other" />
            <token id="38" string="Beatles" />
            <token id="39" string="to" />
            <token id="40" string="resolve" />
            <token id="41" string="an" />
            <token id="42" string="argument" />
            <token id="43" string="over" />
            <token id="44" string="the" />
            <token id="45" string="group" />
            <token id="46" string="'s" />
            <token id="47" string="management" />
          </tokens>
        </chunking>
        <chunking id="7" string="sued the other Beatles to resolve an argument over the group 's management" type="VP">
          <tokens>
            <token id="35" string="sued" />
            <token id="36" string="the" />
            <token id="37" string="other" />
            <token id="38" string="Beatles" />
            <token id="39" string="to" />
            <token id="40" string="resolve" />
            <token id="41" string="an" />
            <token id="42" string="argument" />
            <token id="43" string="over" />
            <token id="44" string="the" />
            <token id="45" string="group" />
            <token id="46" string="'s" />
            <token id="47" string="management" />
          </tokens>
        </chunking>
        <chunking id="8" string="arguments" type="NP">
          <tokens>
            <token id="14" string="arguments" />
          </tokens>
        </chunking>
        <chunking id="9" string="which finally came when McCartney sued the other Beatles to resolve an argument over the group 's management" type="SBAR">
          <tokens>
            <token id="30" string="which" />
            <token id="31" string="finally" />
            <token id="32" string="came" />
            <token id="33" string="when" />
            <token id="34" string="McCartney" />
            <token id="35" string="sued" />
            <token id="36" string="the" />
            <token id="37" string="other" />
            <token id="38" string="Beatles" />
            <token id="39" string="to" />
            <token id="40" string="resolve" />
            <token id="41" string="an" />
            <token id="42" string="argument" />
            <token id="43" string="over" />
            <token id="44" string="the" />
            <token id="45" string="group" />
            <token id="46" string="'s" />
            <token id="47" string="management" />
          </tokens>
        </chunking>
        <chunking id="10" string="a break-up" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="break-up" />
          </tokens>
        </chunking>
        <chunking id="11" string="suggestions" type="NP">
          <tokens>
            <token id="8" string="suggestions" />
          </tokens>
        </chunking>
        <chunking id="12" string="to resolve an argument over the group 's management" type="VP">
          <tokens>
            <token id="39" string="to" />
            <token id="40" string="resolve" />
            <token id="41" string="an" />
            <token id="42" string="argument" />
            <token id="43" string="over" />
            <token id="44" string="the" />
            <token id="45" string="group" />
            <token id="46" string="'s" />
            <token id="47" string="management" />
          </tokens>
        </chunking>
        <chunking id="13" string="Having Ono in the studio" type="VP">
          <tokens>
            <token id="1" string="Having" />
            <token id="2" string="Ono" />
            <token id="3" string="in" />
            <token id="4" string="the" />
            <token id="5" string="studio" />
          </tokens>
        </chunking>
        <chunking id="14" string="the group" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="group" />
          </tokens>
        </chunking>
        <chunking id="15" string="Lennon" type="NP">
          <tokens>
            <token id="11" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="16" string="McCartney" type="NP">
          <tokens>
            <token id="34" string="McCartney" />
          </tokens>
        </chunking>
        <chunking id="17" string="Ono in the studio" type="NP">
          <tokens>
            <token id="2" string="Ono" />
            <token id="3" string="in" />
            <token id="4" string="the" />
            <token id="5" string="studio" />
          </tokens>
        </chunking>
        <chunking id="18" string="a break-up , which finally came when McCartney sued the other Beatles to resolve an argument over the group 's management" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="break-up" />
            <token id="29" string="," />
            <token id="30" string="which" />
            <token id="31" string="finally" />
            <token id="32" string="came" />
            <token id="33" string="when" />
            <token id="34" string="McCartney" />
            <token id="35" string="sued" />
            <token id="36" string="the" />
            <token id="37" string="other" />
            <token id="38" string="Beatles" />
            <token id="39" string="to" />
            <token id="40" string="resolve" />
            <token id="41" string="an" />
            <token id="42" string="argument" />
            <token id="43" string="over" />
            <token id="44" string="the" />
            <token id="45" string="group" />
            <token id="46" string="'s" />
            <token id="47" string="management" />
          </tokens>
        </chunking>
        <chunking id="19" string="an argument over the group 's management" type="NP">
          <tokens>
            <token id="41" string="an" />
            <token id="42" string="argument" />
            <token id="43" string="over" />
            <token id="44" string="the" />
            <token id="45" string="group" />
            <token id="46" string="'s" />
            <token id="47" string="management" />
          </tokens>
        </chunking>
        <chunking id="20" string="an argument" type="NP">
          <tokens>
            <token id="41" string="an" />
            <token id="42" string="argument" />
          </tokens>
        </chunking>
        <chunking id="21" string="Ono" type="NP">
          <tokens>
            <token id="2" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="22" string="when" type="WHADVP">
          <tokens>
            <token id="33" string="when" />
          </tokens>
        </chunking>
        <chunking id="23" string="resolve an argument over the group 's management" type="VP">
          <tokens>
            <token id="40" string="resolve" />
            <token id="41" string="an" />
            <token id="42" string="argument" />
            <token id="43" string="over" />
            <token id="44" string="the" />
            <token id="45" string="group" />
            <token id="46" string="'s" />
            <token id="47" string="management" />
          </tokens>
        </chunking>
        <chunking id="24" string="Having Ono in the studio , offering suggestions and backing Lennon up in arguments , did n't help Still" type="VP">
          <tokens>
            <token id="1" string="Having" />
            <token id="2" string="Ono" />
            <token id="3" string="in" />
            <token id="4" string="the" />
            <token id="5" string="studio" />
            <token id="6" string="," />
            <token id="7" string="offering" />
            <token id="8" string="suggestions" />
            <token id="9" string="and" />
            <token id="10" string="backing" />
            <token id="11" string="Lennon" />
            <token id="12" string="up" />
            <token id="13" string="in" />
            <token id="14" string="arguments" />
            <token id="15" string="," />
            <token id="16" string="did" />
            <token id="17" string="n't" />
            <token id="18" string="help" />
            <token id="19" string="Still" />
          </tokens>
        </chunking>
        <chunking id="25" string="the other Beatles" type="NP">
          <tokens>
            <token id="36" string="the" />
            <token id="37" string="other" />
            <token id="38" string="Beatles" />
          </tokens>
        </chunking>
        <chunking id="26" string="did n't help Still" type="VP">
          <tokens>
            <token id="16" string="did" />
            <token id="17" string="n't" />
            <token id="18" string="help" />
            <token id="19" string="Still" />
          </tokens>
        </chunking>
        <chunking id="27" string="headed toward a break-up , which finally came when McCartney sued the other Beatles to resolve an argument over the group 's management" type="VP">
          <tokens>
            <token id="25" string="headed" />
            <token id="26" string="toward" />
            <token id="27" string="a" />
            <token id="28" string="break-up" />
            <token id="29" string="," />
            <token id="30" string="which" />
            <token id="31" string="finally" />
            <token id="32" string="came" />
            <token id="33" string="when" />
            <token id="34" string="McCartney" />
            <token id="35" string="sued" />
            <token id="36" string="the" />
            <token id="37" string="other" />
            <token id="38" string="Beatles" />
            <token id="39" string="to" />
            <token id="40" string="resolve" />
            <token id="41" string="an" />
            <token id="42" string="argument" />
            <token id="43" string="over" />
            <token id="44" string="the" />
            <token id="45" string="group" />
            <token id="46" string="'s" />
            <token id="47" string="management" />
          </tokens>
        </chunking>
        <chunking id="28" string="the group 's management" type="NP">
          <tokens>
            <token id="44" string="the" />
            <token id="45" string="group" />
            <token id="46" string="'s" />
            <token id="47" string="management" />
          </tokens>
        </chunking>
        <chunking id="29" string="help Still" type="VP">
          <tokens>
            <token id="18" string="help" />
            <token id="19" string="Still" />
          </tokens>
        </chunking>
        <chunking id="30" string="when McCartney sued the other Beatles to resolve an argument over the group 's management" type="SBAR">
          <tokens>
            <token id="33" string="when" />
            <token id="34" string="McCartney" />
            <token id="35" string="sued" />
            <token id="36" string="the" />
            <token id="37" string="other" />
            <token id="38" string="Beatles" />
            <token id="39" string="to" />
            <token id="40" string="resolve" />
            <token id="41" string="an" />
            <token id="42" string="argument" />
            <token id="43" string="over" />
            <token id="44" string="the" />
            <token id="45" string="group" />
            <token id="46" string="'s" />
            <token id="47" string="management" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="24">seemed</governor>
          <dependent id="1">Having</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Having</governor>
          <dependent id="2">Ono</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">studio</governor>
          <dependent id="3">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">studio</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Ono</governor>
          <dependent id="5">studio</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Having</governor>
          <dependent id="7">offering</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">offering</governor>
          <dependent id="8">suggestions</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Having</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Having</governor>
          <dependent id="10">backing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">backing</governor>
          <dependent id="11">Lennon</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="10">backing</governor>
          <dependent id="12">up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">arguments</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">backing</governor>
          <dependent id="14">arguments</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">help</governor>
          <dependent id="16">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="18">help</governor>
          <dependent id="17">n't</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">backing</governor>
          <dependent id="18">help</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">help</governor>
          <dependent id="19">Still</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">group</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">seemed</governor>
          <dependent id="22">group</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">seemed</governor>
          <dependent id="23">already</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="24">seemed</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="24">seemed</governor>
          <dependent id="25">headed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">break-up</governor>
          <dependent id="26">toward</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">break-up</governor>
          <dependent id="27">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">headed</governor>
          <dependent id="28">break-up</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">came</governor>
          <dependent id="30">which</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="32">came</governor>
          <dependent id="31">finally</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="28">break-up</governor>
          <dependent id="32">came</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="35">sued</governor>
          <dependent id="33">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="35">sued</governor>
          <dependent id="34">McCartney</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="32">came</governor>
          <dependent id="35">sued</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">Beatles</governor>
          <dependent id="36">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">Beatles</governor>
          <dependent id="37">other</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="35">sued</governor>
          <dependent id="38">Beatles</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="40">resolve</governor>
          <dependent id="39">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="35">sued</governor>
          <dependent id="40">resolve</dependent>
        </dependency>
        <dependency type="det">
          <governor id="42">argument</governor>
          <dependent id="41">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="40">resolve</governor>
          <dependent id="42">argument</dependent>
        </dependency>
        <dependency type="case">
          <governor id="47">management</governor>
          <dependent id="43">over</dependent>
        </dependency>
        <dependency type="det">
          <governor id="45">group</governor>
          <dependent id="44">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="47">management</governor>
          <dependent id="45">group</dependent>
        </dependency>
        <dependency type="case">
          <governor id="45">group</governor>
          <dependent id="46">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="42">argument</governor>
          <dependent id="47">management</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="McCartney" type="PERSON" score="0.0">
          <tokens>
            <token id="34" string="McCartney" />
          </tokens>
        </entity>
        <entity id="3" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>So, no, Ono didn&amp;apost;t break up the Beatles.</content>
      <tokens>
        <token id="1" string="So" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="break" lemma="break" stem="break" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="Beatles" lemma="Beatles" stem="beatl" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB So)) (, ,) (ADVP (DT no)) (, ,) (NP (NNP Ono)) (VP (VBD did) (RB n't) (VP (VB break) (PRT (RP up)) (NP (DT the) (NNPS Beatles)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="break up the Beatles" type="VP">
          <tokens>
            <token id="8" string="break" />
            <token id="9" string="up" />
            <token id="10" string="the" />
            <token id="11" string="Beatles" />
          </tokens>
        </chunking>
        <chunking id="2" string="did n't break up the Beatles" type="VP">
          <tokens>
            <token id="6" string="did" />
            <token id="7" string="n't" />
            <token id="8" string="break" />
            <token id="9" string="up" />
            <token id="10" string="the" />
            <token id="11" string="Beatles" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Beatles" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="Beatles" />
          </tokens>
        </chunking>
        <chunking id="4" string="Ono" type="NP">
          <tokens>
            <token id="5" string="Ono" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="8">break</governor>
          <dependent id="1">So</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">break</governor>
          <dependent id="3">no</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">break</governor>
          <dependent id="5">Ono</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">break</governor>
          <dependent id="6">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="8">break</governor>
          <dependent id="7">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">break</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="8">break</governor>
          <dependent id="9">up</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">Beatles</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">break</governor>
          <dependent id="11">Beatles</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>But it&amp;apost;s also true that three of them didn&amp;apost;t like her much Life after John; &amp;quot;I think the very fact that John and I got together hurt them a lot,&amp;quot; she says.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="true" lemma="true" stem="true" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="like" lemma="like" stem="like" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="much" lemma="much" stem="much" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="18" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="fact" lemma="fact" stem="fact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="together" lemma="together" stem="togeth" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="hurt" lemma="hurt" stem="hurt" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (CC But) (NP (PRP it)) (VP (VBZ 's) (ADVP (RB also)) (ADJP (JJ true)) (SBAR (IN that) (S (NP (NP (CD three)) (PP (IN of) (NP (PRP them)))) (VP (VBD did) (RB n't) (VP (VB like) (NP (PRP$ her) (JJ much) (NN Life)) (PP (IN after) (NP (NNP John))))))))) (: ;) (S (`` ``) (S (NP (PRP I)) (VP (VBP think) (NP (NP (DT the) (RB very) (NN fact)) (SBAR (IN that) (S (NP (NNP John) (CC and) (PRP I)) (VP (VBD got) (S (ADVP (RB together)) (VP (VBN hurt) (S (NP (PRP them)) (NP (DT a) (NN lot))))))))))) (, ,) ('' '') (NP (PRP she)) (VP (VBZ says))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="'s also true that three of them did n't like her much Life after John" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="also" />
            <token id="5" string="true" />
            <token id="6" string="that" />
            <token id="7" string="three" />
            <token id="8" string="of" />
            <token id="9" string="them" />
            <token id="10" string="did" />
            <token id="11" string="n't" />
            <token id="12" string="like" />
            <token id="13" string="her" />
            <token id="14" string="much" />
            <token id="15" string="Life" />
            <token id="16" string="after" />
            <token id="17" string="John" />
          </tokens>
        </chunking>
        <chunking id="2" string="that John and I got together hurt them a lot" type="SBAR">
          <tokens>
            <token id="25" string="that" />
            <token id="26" string="John" />
            <token id="27" string="and" />
            <token id="28" string="I" />
            <token id="29" string="got" />
            <token id="30" string="together" />
            <token id="31" string="hurt" />
            <token id="32" string="them" />
            <token id="33" string="a" />
            <token id="34" string="lot" />
          </tokens>
        </chunking>
        <chunking id="3" string="her much Life" type="NP">
          <tokens>
            <token id="13" string="her" />
            <token id="14" string="much" />
            <token id="15" string="Life" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="20" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="John" type="NP">
          <tokens>
            <token id="17" string="John" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="2" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="did n't like her much Life after John" type="VP">
          <tokens>
            <token id="10" string="did" />
            <token id="11" string="n't" />
            <token id="12" string="like" />
            <token id="13" string="her" />
            <token id="14" string="much" />
            <token id="15" string="Life" />
            <token id="16" string="after" />
            <token id="17" string="John" />
          </tokens>
        </chunking>
        <chunking id="8" string="that three of them did n't like her much Life after John" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="three" />
            <token id="8" string="of" />
            <token id="9" string="them" />
            <token id="10" string="did" />
            <token id="11" string="n't" />
            <token id="12" string="like" />
            <token id="13" string="her" />
            <token id="14" string="much" />
            <token id="15" string="Life" />
            <token id="16" string="after" />
            <token id="17" string="John" />
          </tokens>
        </chunking>
        <chunking id="9" string="them" type="NP">
          <tokens>
            <token id="9" string="them" />
          </tokens>
        </chunking>
        <chunking id="10" string="three" type="NP">
          <tokens>
            <token id="7" string="three" />
          </tokens>
        </chunking>
        <chunking id="11" string="the very fact" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="very" />
            <token id="24" string="fact" />
          </tokens>
        </chunking>
        <chunking id="12" string="she" type="NP">
          <tokens>
            <token id="37" string="she" />
          </tokens>
        </chunking>
        <chunking id="13" string="says" type="VP">
          <tokens>
            <token id="38" string="says" />
          </tokens>
        </chunking>
        <chunking id="14" string="got together hurt them a lot" type="VP">
          <tokens>
            <token id="29" string="got" />
            <token id="30" string="together" />
            <token id="31" string="hurt" />
            <token id="32" string="them" />
            <token id="33" string="a" />
            <token id="34" string="lot" />
          </tokens>
        </chunking>
        <chunking id="15" string="a lot" type="NP">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="lot" />
          </tokens>
        </chunking>
        <chunking id="16" string="the very fact that John and I got together hurt them a lot" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="very" />
            <token id="24" string="fact" />
            <token id="25" string="that" />
            <token id="26" string="John" />
            <token id="27" string="and" />
            <token id="28" string="I" />
            <token id="29" string="got" />
            <token id="30" string="together" />
            <token id="31" string="hurt" />
            <token id="32" string="them" />
            <token id="33" string="a" />
            <token id="34" string="lot" />
          </tokens>
        </chunking>
        <chunking id="17" string="John and I" type="NP">
          <tokens>
            <token id="26" string="John" />
            <token id="27" string="and" />
            <token id="28" string="I" />
          </tokens>
        </chunking>
        <chunking id="18" string="like her much Life after John" type="VP">
          <tokens>
            <token id="12" string="like" />
            <token id="13" string="her" />
            <token id="14" string="much" />
            <token id="15" string="Life" />
            <token id="16" string="after" />
            <token id="17" string="John" />
          </tokens>
        </chunking>
        <chunking id="19" string="true" type="ADJP">
          <tokens>
            <token id="5" string="true" />
          </tokens>
        </chunking>
        <chunking id="20" string="hurt them a lot" type="VP">
          <tokens>
            <token id="31" string="hurt" />
            <token id="32" string="them" />
            <token id="33" string="a" />
            <token id="34" string="lot" />
          </tokens>
        </chunking>
        <chunking id="21" string="three of them" type="NP">
          <tokens>
            <token id="7" string="three" />
            <token id="8" string="of" />
            <token id="9" string="them" />
          </tokens>
        </chunking>
        <chunking id="22" string="think the very fact that John and I got together hurt them a lot" type="VP">
          <tokens>
            <token id="21" string="think" />
            <token id="22" string="the" />
            <token id="23" string="very" />
            <token id="24" string="fact" />
            <token id="25" string="that" />
            <token id="26" string="John" />
            <token id="27" string="and" />
            <token id="28" string="I" />
            <token id="29" string="got" />
            <token id="30" string="together" />
            <token id="31" string="hurt" />
            <token id="32" string="them" />
            <token id="33" string="a" />
            <token id="34" string="lot" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="5">true</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">true</governor>
          <dependent id="2">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">true</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">true</governor>
          <dependent id="4">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">true</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">like</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">like</governor>
          <dependent id="7">three</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">them</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">three</governor>
          <dependent id="9">them</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">like</governor>
          <dependent id="10">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="12">like</governor>
          <dependent id="11">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">true</governor>
          <dependent id="12">like</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">Life</governor>
          <dependent id="13">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">Life</governor>
          <dependent id="14">much</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">like</governor>
          <dependent id="15">Life</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">John</governor>
          <dependent id="16">after</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">like</governor>
          <dependent id="17">John</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">think</governor>
          <dependent id="20">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="38">says</governor>
          <dependent id="21">think</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">fact</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">fact</governor>
          <dependent id="23">very</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">think</governor>
          <dependent id="24">fact</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">got</governor>
          <dependent id="25">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">got</governor>
          <dependent id="26">John</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="26">John</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="26">John</governor>
          <dependent id="28">I</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="24">fact</governor>
          <dependent id="29">got</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="31">hurt</governor>
          <dependent id="30">together</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="29">got</governor>
          <dependent id="31">hurt</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">lot</governor>
          <dependent id="32">them</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">lot</governor>
          <dependent id="33">a</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="31">hurt</governor>
          <dependent id="34">lot</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="38">says</governor>
          <dependent id="37">she</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="5">true</governor>
          <dependent id="38">says</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="John" />
          </tokens>
        </entity>
        <entity id="2" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="three" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>&amp;quot;It&amp;apost;s 50/50.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="50/50" lemma="50/50" stem="50/50" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP It)) (VP (VBZ 's) (NP (CD 50/50))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="2" string="'s 50/50" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="50/50" />
          </tokens>
        </chunking>
        <chunking id="3" string="50/50" type="NP">
          <tokens>
            <token id="4" string="50/50" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">50/50</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">50/50</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">50/50</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="50/50" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="50/50" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="45" has_coreference="true">
      <content>We hurt them and they hurt us.</content>
      <tokens>
        <token id="1" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="hurt" lemma="hurt" stem="hurt" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="hurt" lemma="hurt" stem="hurt" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="us" lemma="we" stem="u" pos="PRP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP We)) (VP (VBD hurt) (SBAR (S (NP (PRP them) (CC and) (PRP they)) (VP (VBP hurt) (NP (PRP us)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="them and they" type="NP">
          <tokens>
            <token id="3" string="them" />
            <token id="4" string="and" />
            <token id="5" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="hurt us" type="VP">
          <tokens>
            <token id="6" string="hurt" />
            <token id="7" string="us" />
          </tokens>
        </chunking>
        <chunking id="3" string="them and they hurt us" type="SBAR">
          <tokens>
            <token id="3" string="them" />
            <token id="4" string="and" />
            <token id="5" string="they" />
            <token id="6" string="hurt" />
            <token id="7" string="us" />
          </tokens>
        </chunking>
        <chunking id="4" string="hurt them and they hurt us" type="VP">
          <tokens>
            <token id="2" string="hurt" />
            <token id="3" string="them" />
            <token id="4" string="and" />
            <token id="5" string="they" />
            <token id="6" string="hurt" />
            <token id="7" string="us" />
          </tokens>
        </chunking>
        <chunking id="5" string="We" type="NP">
          <tokens>
            <token id="1" string="We" />
          </tokens>
        </chunking>
        <chunking id="6" string="us" type="NP">
          <tokens>
            <token id="7" string="us" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">hurt</governor>
          <dependent id="1">We</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">hurt</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">hurt</governor>
          <dependent id="3">them</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">them</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">them</governor>
          <dependent id="5">they</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">hurt</governor>
          <dependent id="6">hurt</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">hurt</governor>
          <dependent id="7">us</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="46" has_coreference="true">
      <content>I can&amp;apost;t really say it&amp;apost;s a one-sided situation.&amp;quot;</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="ca" lemma="can" stem="ca" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="one-sided" lemma="one-sided" stem="one-sid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="situation" lemma="situation" stem="situat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (MD ca) (RB n't) (ADVP (RB really)) (VP (VB say) (SBAR (S (NP (PRP it)) (VP (VBZ 's) (NP (DT a) (JJ one-sided) (NN situation))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="ca n't really say it 's a one-sided situation" type="VP">
          <tokens>
            <token id="2" string="ca" />
            <token id="3" string="n't" />
            <token id="4" string="really" />
            <token id="5" string="say" />
            <token id="6" string="it" />
            <token id="7" string="'s" />
            <token id="8" string="a" />
            <token id="9" string="one-sided" />
            <token id="10" string="situation" />
          </tokens>
        </chunking>
        <chunking id="2" string="'s a one-sided situation" type="VP">
          <tokens>
            <token id="7" string="'s" />
            <token id="8" string="a" />
            <token id="9" string="one-sided" />
            <token id="10" string="situation" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="say it 's a one-sided situation" type="VP">
          <tokens>
            <token id="5" string="say" />
            <token id="6" string="it" />
            <token id="7" string="'s" />
            <token id="8" string="a" />
            <token id="9" string="one-sided" />
            <token id="10" string="situation" />
          </tokens>
        </chunking>
        <chunking id="6" string="it 's a one-sided situation" type="SBAR">
          <tokens>
            <token id="6" string="it" />
            <token id="7" string="'s" />
            <token id="8" string="a" />
            <token id="9" string="one-sided" />
            <token id="10" string="situation" />
          </tokens>
        </chunking>
        <chunking id="7" string="a one-sided situation" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="one-sided" />
            <token id="10" string="situation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">say</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">say</governor>
          <dependent id="2">ca</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">say</governor>
          <dependent id="3">n't</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">say</governor>
          <dependent id="4">really</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">say</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">situation</governor>
          <dependent id="6">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">situation</governor>
          <dependent id="7">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">situation</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">situation</governor>
          <dependent id="9">one-sided</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">say</governor>
          <dependent id="10">situation</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="47" has_coreference="true">
      <content>; Ono says she feels no bitterness toward the surviving Beatles &amp;quot;Songwriters in this world are pretty harmless people,&amp;quot; she says.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="feels" lemma="feel" stem="feel" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="bitterness" lemma="bitterness" stem="bitter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="toward" lemma="toward" stem="toward" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="surviving" lemma="survive" stem="surviv" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Beatles" lemma="beatle" stem="beatl" pos="NNS" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Songwriters" lemma="songwriter" stem="songwrit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="pretty" lemma="pretty" stem="pretti" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="harmless" lemma="harmless" stem="harmless" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (NP (NNP Ono)) (VP (VBZ says) (SBAR (S (NP (PRP she)) (VP (VBZ feels) (SBAR (S (NP (NP (DT no) (NN bitterness)) (PP (IN toward) (NP (DT the) (VBG surviving) (NNS Beatles)))) (`` ``) (NP (NP (NNS Songwriters)) (PP (IN in) (NP (DT this) (NN world)))) (VP (VBP are) (ADJP (RB pretty) (JJ harmless) (SBAR (S (NP (NNS people)) (, ,) ('' '') (NP (PRP she)) (VP (VBZ says)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Songwriters" type="NP">
          <tokens>
            <token id="13" string="Songwriters" />
          </tokens>
        </chunking>
        <chunking id="2" string="are pretty harmless people , '' she says" type="VP">
          <tokens>
            <token id="17" string="are" />
            <token id="18" string="pretty" />
            <token id="19" string="harmless" />
            <token id="20" string="people" />
            <token id="21" string="," />
            <token id="22" string="&quot;" />
            <token id="23" string="she" />
            <token id="24" string="says" />
          </tokens>
        </chunking>
        <chunking id="3" string="no bitterness toward the surviving Beatles `` Songwriters in this world are pretty harmless people , '' she says" type="SBAR">
          <tokens>
            <token id="6" string="no" />
            <token id="7" string="bitterness" />
            <token id="8" string="toward" />
            <token id="9" string="the" />
            <token id="10" string="surviving" />
            <token id="11" string="Beatles" />
            <token id="12" string="&quot;" />
            <token id="13" string="Songwriters" />
            <token id="14" string="in" />
            <token id="15" string="this" />
            <token id="16" string="world" />
            <token id="17" string="are" />
            <token id="18" string="pretty" />
            <token id="19" string="harmless" />
            <token id="20" string="people" />
            <token id="21" string="," />
            <token id="22" string="&quot;" />
            <token id="23" string="she" />
            <token id="24" string="says" />
          </tokens>
        </chunking>
        <chunking id="4" string="feels no bitterness toward the surviving Beatles `` Songwriters in this world are pretty harmless people , '' she says" type="VP">
          <tokens>
            <token id="5" string="feels" />
            <token id="6" string="no" />
            <token id="7" string="bitterness" />
            <token id="8" string="toward" />
            <token id="9" string="the" />
            <token id="10" string="surviving" />
            <token id="11" string="Beatles" />
            <token id="12" string="&quot;" />
            <token id="13" string="Songwriters" />
            <token id="14" string="in" />
            <token id="15" string="this" />
            <token id="16" string="world" />
            <token id="17" string="are" />
            <token id="18" string="pretty" />
            <token id="19" string="harmless" />
            <token id="20" string="people" />
            <token id="21" string="," />
            <token id="22" string="&quot;" />
            <token id="23" string="she" />
            <token id="24" string="says" />
          </tokens>
        </chunking>
        <chunking id="5" string="no bitterness toward the surviving Beatles" type="NP">
          <tokens>
            <token id="6" string="no" />
            <token id="7" string="bitterness" />
            <token id="8" string="toward" />
            <token id="9" string="the" />
            <token id="10" string="surviving" />
            <token id="11" string="Beatles" />
          </tokens>
        </chunking>
        <chunking id="6" string="people" type="NP">
          <tokens>
            <token id="20" string="people" />
          </tokens>
        </chunking>
        <chunking id="7" string="Ono" type="NP">
          <tokens>
            <token id="2" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="8" string="she feels no bitterness toward the surviving Beatles `` Songwriters in this world are pretty harmless people , '' she says" type="SBAR">
          <tokens>
            <token id="4" string="she" />
            <token id="5" string="feels" />
            <token id="6" string="no" />
            <token id="7" string="bitterness" />
            <token id="8" string="toward" />
            <token id="9" string="the" />
            <token id="10" string="surviving" />
            <token id="11" string="Beatles" />
            <token id="12" string="&quot;" />
            <token id="13" string="Songwriters" />
            <token id="14" string="in" />
            <token id="15" string="this" />
            <token id="16" string="world" />
            <token id="17" string="are" />
            <token id="18" string="pretty" />
            <token id="19" string="harmless" />
            <token id="20" string="people" />
            <token id="21" string="," />
            <token id="22" string="&quot;" />
            <token id="23" string="she" />
            <token id="24" string="says" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="4" string="she" />
          </tokens>
        </chunking>
        <chunking id="10" string="no bitterness" type="NP">
          <tokens>
            <token id="6" string="no" />
            <token id="7" string="bitterness" />
          </tokens>
        </chunking>
        <chunking id="11" string="people , '' she says" type="SBAR">
          <tokens>
            <token id="20" string="people" />
            <token id="21" string="," />
            <token id="22" string="&quot;" />
            <token id="23" string="she" />
            <token id="24" string="says" />
          </tokens>
        </chunking>
        <chunking id="12" string="says she feels no bitterness toward the surviving Beatles `` Songwriters in this world are pretty harmless people , '' she says" type="VP">
          <tokens>
            <token id="3" string="says" />
            <token id="4" string="she" />
            <token id="5" string="feels" />
            <token id="6" string="no" />
            <token id="7" string="bitterness" />
            <token id="8" string="toward" />
            <token id="9" string="the" />
            <token id="10" string="surviving" />
            <token id="11" string="Beatles" />
            <token id="12" string="&quot;" />
            <token id="13" string="Songwriters" />
            <token id="14" string="in" />
            <token id="15" string="this" />
            <token id="16" string="world" />
            <token id="17" string="are" />
            <token id="18" string="pretty" />
            <token id="19" string="harmless" />
            <token id="20" string="people" />
            <token id="21" string="," />
            <token id="22" string="&quot;" />
            <token id="23" string="she" />
            <token id="24" string="says" />
          </tokens>
        </chunking>
        <chunking id="13" string="says" type="VP">
          <tokens>
            <token id="24" string="says" />
          </tokens>
        </chunking>
        <chunking id="14" string="pretty harmless people , '' she says" type="ADJP">
          <tokens>
            <token id="18" string="pretty" />
            <token id="19" string="harmless" />
            <token id="20" string="people" />
            <token id="21" string="," />
            <token id="22" string="&quot;" />
            <token id="23" string="she" />
            <token id="24" string="says" />
          </tokens>
        </chunking>
        <chunking id="15" string="Songwriters in this world" type="NP">
          <tokens>
            <token id="13" string="Songwriters" />
            <token id="14" string="in" />
            <token id="15" string="this" />
            <token id="16" string="world" />
          </tokens>
        </chunking>
        <chunking id="16" string="this world" type="NP">
          <tokens>
            <token id="15" string="this" />
            <token id="16" string="world" />
          </tokens>
        </chunking>
        <chunking id="17" string="the surviving Beatles" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="surviving" />
            <token id="11" string="Beatles" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">says</governor>
          <dependent id="2">Ono</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">says</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">feels</governor>
          <dependent id="4">she</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">says</governor>
          <dependent id="5">feels</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">bitterness</governor>
          <dependent id="6">no</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">harmless</governor>
          <dependent id="7">bitterness</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Beatles</governor>
          <dependent id="8">toward</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">Beatles</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">Beatles</governor>
          <dependent id="10">surviving</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">bitterness</governor>
          <dependent id="11">Beatles</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">harmless</governor>
          <dependent id="13">Songwriters</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">world</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">world</governor>
          <dependent id="15">this</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">Songwriters</governor>
          <dependent id="16">world</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">harmless</governor>
          <dependent id="17">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">harmless</governor>
          <dependent id="18">pretty</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">feels</governor>
          <dependent id="19">harmless</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">says</governor>
          <dependent id="20">people</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">says</governor>
          <dependent id="23">she</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">harmless</governor>
          <dependent id="24">says</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Beatles" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="11" string="Beatles" />
          </tokens>
        </entity>
        <entity id="2" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="48" has_coreference="true">
      <content>&amp;quot;They&amp;apost;re not doing anything like creating a nuclear bomb or trying to decide whether people should be killed.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="doing" lemma="do" stem="do" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="anything" lemma="anything" stem="anyth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="creating" lemma="create" stem="creat" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="nuclear" lemma="nuclear" stem="nuclear" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="bomb" lemma="bomb" stem="bomb" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="trying" lemma="try" stem="try" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="decide" lemma="decide" stem="decid" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="killed" lemma="kill" stem="kill" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP They)) (VP (VBP 're) (RB not) (VP (VBG doing) (NP (NN anything)) (PP (IN like) (S (VP (VP (VBG creating) (NP (DT a) (JJ nuclear) (NN bomb))) (CC or) (VP (VBG trying) (S (VP (TO to) (VP (VB decide) (SBAR (IN whether) (S (NP (NNS people)) (VP (MD should) (VP (VB be) (VP (VBN killed))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="2" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="should be killed" type="VP">
          <tokens>
            <token id="18" string="should" />
            <token id="19" string="be" />
            <token id="20" string="killed" />
          </tokens>
        </chunking>
        <chunking id="3" string="doing anything like creating a nuclear bomb or trying to decide whether people should be killed" type="VP">
          <tokens>
            <token id="5" string="doing" />
            <token id="6" string="anything" />
            <token id="7" string="like" />
            <token id="8" string="creating" />
            <token id="9" string="a" />
            <token id="10" string="nuclear" />
            <token id="11" string="bomb" />
            <token id="12" string="or" />
            <token id="13" string="trying" />
            <token id="14" string="to" />
            <token id="15" string="decide" />
            <token id="16" string="whether" />
            <token id="17" string="people" />
            <token id="18" string="should" />
            <token id="19" string="be" />
            <token id="20" string="killed" />
          </tokens>
        </chunking>
        <chunking id="4" string="creating a nuclear bomb" type="VP">
          <tokens>
            <token id="8" string="creating" />
            <token id="9" string="a" />
            <token id="10" string="nuclear" />
            <token id="11" string="bomb" />
          </tokens>
        </chunking>
        <chunking id="5" string="trying to decide whether people should be killed" type="VP">
          <tokens>
            <token id="13" string="trying" />
            <token id="14" string="to" />
            <token id="15" string="decide" />
            <token id="16" string="whether" />
            <token id="17" string="people" />
            <token id="18" string="should" />
            <token id="19" string="be" />
            <token id="20" string="killed" />
          </tokens>
        </chunking>
        <chunking id="6" string="to decide whether people should be killed" type="VP">
          <tokens>
            <token id="14" string="to" />
            <token id="15" string="decide" />
            <token id="16" string="whether" />
            <token id="17" string="people" />
            <token id="18" string="should" />
            <token id="19" string="be" />
            <token id="20" string="killed" />
          </tokens>
        </chunking>
        <chunking id="7" string="creating a nuclear bomb or trying to decide whether people should be killed" type="VP">
          <tokens>
            <token id="8" string="creating" />
            <token id="9" string="a" />
            <token id="10" string="nuclear" />
            <token id="11" string="bomb" />
            <token id="12" string="or" />
            <token id="13" string="trying" />
            <token id="14" string="to" />
            <token id="15" string="decide" />
            <token id="16" string="whether" />
            <token id="17" string="people" />
            <token id="18" string="should" />
            <token id="19" string="be" />
            <token id="20" string="killed" />
          </tokens>
        </chunking>
        <chunking id="8" string="anything" type="NP">
          <tokens>
            <token id="6" string="anything" />
          </tokens>
        </chunking>
        <chunking id="9" string="people" type="NP">
          <tokens>
            <token id="17" string="people" />
          </tokens>
        </chunking>
        <chunking id="10" string="killed" type="VP">
          <tokens>
            <token id="20" string="killed" />
          </tokens>
        </chunking>
        <chunking id="11" string="a nuclear bomb" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="nuclear" />
            <token id="11" string="bomb" />
          </tokens>
        </chunking>
        <chunking id="12" string="decide whether people should be killed" type="VP">
          <tokens>
            <token id="15" string="decide" />
            <token id="16" string="whether" />
            <token id="17" string="people" />
            <token id="18" string="should" />
            <token id="19" string="be" />
            <token id="20" string="killed" />
          </tokens>
        </chunking>
        <chunking id="13" string="whether people should be killed" type="SBAR">
          <tokens>
            <token id="16" string="whether" />
            <token id="17" string="people" />
            <token id="18" string="should" />
            <token id="19" string="be" />
            <token id="20" string="killed" />
          </tokens>
        </chunking>
        <chunking id="14" string="'re not doing anything like creating a nuclear bomb or trying to decide whether people should be killed" type="VP">
          <tokens>
            <token id="3" string="'re" />
            <token id="4" string="not" />
            <token id="5" string="doing" />
            <token id="6" string="anything" />
            <token id="7" string="like" />
            <token id="8" string="creating" />
            <token id="9" string="a" />
            <token id="10" string="nuclear" />
            <token id="11" string="bomb" />
            <token id="12" string="or" />
            <token id="13" string="trying" />
            <token id="14" string="to" />
            <token id="15" string="decide" />
            <token id="16" string="whether" />
            <token id="17" string="people" />
            <token id="18" string="should" />
            <token id="19" string="be" />
            <token id="20" string="killed" />
          </tokens>
        </chunking>
        <chunking id="15" string="be killed" type="VP">
          <tokens>
            <token id="19" string="be" />
            <token id="20" string="killed" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">doing</governor>
          <dependent id="2">They</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">doing</governor>
          <dependent id="3">'re</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">doing</governor>
          <dependent id="4">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">doing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">doing</governor>
          <dependent id="6">anything</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">creating</governor>
          <dependent id="7">like</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">doing</governor>
          <dependent id="8">creating</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">bomb</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">bomb</governor>
          <dependent id="10">nuclear</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">creating</governor>
          <dependent id="11">bomb</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">creating</governor>
          <dependent id="12">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">creating</governor>
          <dependent id="13">trying</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">decide</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">trying</governor>
          <dependent id="15">decide</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">killed</governor>
          <dependent id="16">whether</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="20">killed</governor>
          <dependent id="17">people</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">killed</governor>
          <dependent id="18">should</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="20">killed</governor>
          <dependent id="19">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">decide</governor>
          <dependent id="20">killed</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="49" has_coreference="true">
      <content>They&amp;apost;re pretty peaceful people and their songs will hopefully inspire people.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="pretty" lemma="pretty" stem="pretti" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="peaceful" lemma="peaceful" stem="peac" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="songs" lemma="song" stem="song" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="hopefully" lemma="hopefully" stem="hopefulli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="inspire" lemma="inspire" stem="inspir" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBP 're) (ADJP (RB pretty) (JJ peaceful) (SBAR (S (NP (NP (NNS people)) (CC and) (NP (PRP$ their) (NNS songs))) (VP (MD will) (ADVP (RB hopefully)) (VP (VB inspire) (NP (NNS people)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="people and their songs" type="NP">
          <tokens>
            <token id="5" string="people" />
            <token id="6" string="and" />
            <token id="7" string="their" />
            <token id="8" string="songs" />
          </tokens>
        </chunking>
        <chunking id="3" string="'re pretty peaceful people and their songs will hopefully inspire people" type="VP">
          <tokens>
            <token id="2" string="'re" />
            <token id="3" string="pretty" />
            <token id="4" string="peaceful" />
            <token id="5" string="people" />
            <token id="6" string="and" />
            <token id="7" string="their" />
            <token id="8" string="songs" />
            <token id="9" string="will" />
            <token id="10" string="hopefully" />
            <token id="11" string="inspire" />
            <token id="12" string="people" />
          </tokens>
        </chunking>
        <chunking id="4" string="will hopefully inspire people" type="VP">
          <tokens>
            <token id="9" string="will" />
            <token id="10" string="hopefully" />
            <token id="11" string="inspire" />
            <token id="12" string="people" />
          </tokens>
        </chunking>
        <chunking id="5" string="pretty peaceful people and their songs will hopefully inspire people" type="ADJP">
          <tokens>
            <token id="3" string="pretty" />
            <token id="4" string="peaceful" />
            <token id="5" string="people" />
            <token id="6" string="and" />
            <token id="7" string="their" />
            <token id="8" string="songs" />
            <token id="9" string="will" />
            <token id="10" string="hopefully" />
            <token id="11" string="inspire" />
            <token id="12" string="people" />
          </tokens>
        </chunking>
        <chunking id="6" string="people and their songs will hopefully inspire people" type="SBAR">
          <tokens>
            <token id="5" string="people" />
            <token id="6" string="and" />
            <token id="7" string="their" />
            <token id="8" string="songs" />
            <token id="9" string="will" />
            <token id="10" string="hopefully" />
            <token id="11" string="inspire" />
            <token id="12" string="people" />
          </tokens>
        </chunking>
        <chunking id="7" string="their songs" type="NP">
          <tokens>
            <token id="7" string="their" />
            <token id="8" string="songs" />
          </tokens>
        </chunking>
        <chunking id="8" string="people" type="NP">
          <tokens>
            <token id="5" string="people" />
          </tokens>
        </chunking>
        <chunking id="9" string="inspire people" type="VP">
          <tokens>
            <token id="11" string="inspire" />
            <token id="12" string="people" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">peaceful</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">peaceful</governor>
          <dependent id="2">'re</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">peaceful</governor>
          <dependent id="3">pretty</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">peaceful</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">inspire</governor>
          <dependent id="5">people</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">people</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">songs</governor>
          <dependent id="7">their</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">people</governor>
          <dependent id="8">songs</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">inspire</governor>
          <dependent id="9">will</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">inspire</governor>
          <dependent id="10">hopefully</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">peaceful</governor>
          <dependent id="11">inspire</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">inspire</governor>
          <dependent id="12">people</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="50" has_coreference="true">
      <content>I have a lot of respect for them.&amp;quot;</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="respect" lemma="respect" stem="respect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP have) (NP (NP (DT a) (NN lot)) (PP (IN of) (NP (NP (NN respect)) (PP (IN for) (NP (PRP them))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="have a lot of respect for them" type="VP">
          <tokens>
            <token id="2" string="have" />
            <token id="3" string="a" />
            <token id="4" string="lot" />
            <token id="5" string="of" />
            <token id="6" string="respect" />
            <token id="7" string="for" />
            <token id="8" string="them" />
          </tokens>
        </chunking>
        <chunking id="2" string="a lot of respect for them" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="lot" />
            <token id="5" string="of" />
            <token id="6" string="respect" />
            <token id="7" string="for" />
            <token id="8" string="them" />
          </tokens>
        </chunking>
        <chunking id="3" string="a lot" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="lot" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="respect" type="NP">
          <tokens>
            <token id="6" string="respect" />
          </tokens>
        </chunking>
        <chunking id="6" string="them" type="NP">
          <tokens>
            <token id="8" string="them" />
          </tokens>
        </chunking>
        <chunking id="7" string="respect for them" type="NP">
          <tokens>
            <token id="6" string="respect" />
            <token id="7" string="for" />
            <token id="8" string="them" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">have</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">lot</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">have</governor>
          <dependent id="4">lot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">respect</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">lot</governor>
          <dependent id="6">respect</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">them</governor>
          <dependent id="7">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">respect</governor>
          <dependent id="8">them</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="51" has_coreference="true">
      <content>; But how do the Beatles feel toward Ono these days?</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="Beatles" lemma="Beatles" stem="beatl" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="feel" lemma="feel" stem="feel" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="toward" lemma="toward" stem="toward" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="these" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="days" lemma="day" stem="dai" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="12" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (S (CC But) (SBAR (WHADVP (WRB how)) (S (VP (VBP do) (NP (DT the) (NNPS Beatles))))) (VP (VBP feel) (PP (IN toward) (NP (NNP Ono))) (NP-TMP (DT these) (NNS days)))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="how do the Beatles" type="SBAR">
          <tokens>
            <token id="3" string="how" />
            <token id="4" string="do" />
            <token id="5" string="the" />
            <token id="6" string="Beatles" />
          </tokens>
        </chunking>
        <chunking id="2" string="feel toward Ono these days" type="VP">
          <tokens>
            <token id="7" string="feel" />
            <token id="8" string="toward" />
            <token id="9" string="Ono" />
            <token id="10" string="these" />
            <token id="11" string="days" />
          </tokens>
        </chunking>
        <chunking id="3" string="do the Beatles" type="VP">
          <tokens>
            <token id="4" string="do" />
            <token id="5" string="the" />
            <token id="6" string="Beatles" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Beatles" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="Beatles" />
          </tokens>
        </chunking>
        <chunking id="5" string="how" type="WHADVP">
          <tokens>
            <token id="3" string="how" />
          </tokens>
        </chunking>
        <chunking id="6" string="Ono" type="NP">
          <tokens>
            <token id="9" string="Ono" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="7">feel</governor>
          <dependent id="2">But</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">do</governor>
          <dependent id="3">how</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="7">feel</governor>
          <dependent id="4">do</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">Beatles</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">do</governor>
          <dependent id="6">Beatles</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">feel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Ono</governor>
          <dependent id="8">toward</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">feel</governor>
          <dependent id="9">Ono</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">days</governor>
          <dependent id="10">these</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="7">feel</governor>
          <dependent id="11">days</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="days" type="DURATION" score="0.0">
          <tokens>
            <token id="11" string="days" />
          </tokens>
        </entity>
        <entity id="2" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="52" has_coreference="true">
      <content>; &amp;quot;It varies,&amp;quot; she says.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="varies" lemma="vary" stem="vari" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (`` ``) (S (NP (PRP It)) (VP (VBZ varies))) (, ,) ('' '') (NP (PRP she)) (VP (VBZ says)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="says" type="VP">
          <tokens>
            <token id="8" string="says" />
          </tokens>
        </chunking>
        <chunking id="2" string="varies" type="VP">
          <tokens>
            <token id="4" string="varies" />
          </tokens>
        </chunking>
        <chunking id="3" string="It" type="NP">
          <tokens>
            <token id="3" string="It" />
          </tokens>
        </chunking>
        <chunking id="4" string="she" type="NP">
          <tokens>
            <token id="7" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">varies</governor>
          <dependent id="3">It</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">says</governor>
          <dependent id="4">varies</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">says</governor>
          <dependent id="7">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">says</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="53" has_coreference="true">
      <content>&amp;quot;Sometimes they are friendly, sometimes they are not . . . like all relationships with friends.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Sometimes" lemma="sometimes" stem="sometim" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="friendly" lemma="friendly" stem="friendli" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="sometimes" lemma="sometimes" stem="sometim" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="relationships" lemma="relationship" stem="relationship" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="friends" lemma="friend" stem="friend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (S (`` ``) (ADVP (RB Sometimes)) (NP (PRP they)) (VP (VBP are) (ADJP (JJ friendly)))) (, ,) (ADVP (RB sometimes)) (S (NP (PRP they)) (VP (VBP are) (RB not)))) (: ...) (FRAG (PP (IN like) (NP (DT all))) (NP (NP (NNS relationships)) (PP (IN with) (NP (NNS friends))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="relationships" type="NP">
          <tokens>
            <token id="14" string="relationships" />
          </tokens>
        </chunking>
        <chunking id="2" string="they" type="NP">
          <tokens>
            <token id="3" string="they" />
          </tokens>
        </chunking>
        <chunking id="3" string="all" type="NP">
          <tokens>
            <token id="13" string="all" />
          </tokens>
        </chunking>
        <chunking id="4" string="are not" type="VP">
          <tokens>
            <token id="9" string="are" />
            <token id="10" string="not" />
          </tokens>
        </chunking>
        <chunking id="5" string="friendly" type="ADJP">
          <tokens>
            <token id="5" string="friendly" />
          </tokens>
        </chunking>
        <chunking id="6" string="relationships with friends" type="NP">
          <tokens>
            <token id="14" string="relationships" />
            <token id="15" string="with" />
            <token id="16" string="friends" />
          </tokens>
        </chunking>
        <chunking id="7" string="are friendly" type="VP">
          <tokens>
            <token id="4" string="are" />
            <token id="5" string="friendly" />
          </tokens>
        </chunking>
        <chunking id="8" string="friends" type="NP">
          <tokens>
            <token id="16" string="friends" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">friendly</governor>
          <dependent id="2">Sometimes</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">friendly</governor>
          <dependent id="3">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">friendly</governor>
          <dependent id="4">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">friendly</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">are</governor>
          <dependent id="7">sometimes</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">are</governor>
          <dependent id="8">they</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="5">friendly</governor>
          <dependent id="9">are</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="9">are</governor>
          <dependent id="10">not</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">all</governor>
          <dependent id="12">like</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">relationships</governor>
          <dependent id="13">all</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="5">friendly</governor>
          <dependent id="14">relationships</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">friends</governor>
          <dependent id="15">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">relationships</governor>
          <dependent id="16">friends</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="54" has_coreference="true">
      <content>I think that&amp;apost;s natural.&amp;quot;</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="natural" lemma="natural" stem="natur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP think) (SBAR (S (NP (DT that)) (VP (VBZ 's) (ADJP (JJ natural)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="that" type="NP">
          <tokens>
            <token id="3" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="think that 's natural" type="VP">
          <tokens>
            <token id="2" string="think" />
            <token id="3" string="that" />
            <token id="4" string="'s" />
            <token id="5" string="natural" />
          </tokens>
        </chunking>
        <chunking id="3" string="'s natural" type="VP">
          <tokens>
            <token id="4" string="'s" />
            <token id="5" string="natural" />
          </tokens>
        </chunking>
        <chunking id="4" string="natural" type="ADJP">
          <tokens>
            <token id="5" string="natural" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="that 's natural" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="'s" />
            <token id="5" string="natural" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">think</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">think</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">natural</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">natural</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">think</governor>
          <dependent id="5">natural</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="55" has_coreference="true">
      <content>; Many of the books that have been written about Lennon and the Beatles, especially Albert Goldman&amp;apost;s loathing portrait of Lennon, have been painful to Ono.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="written" lemma="write" stem="written" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="14" string="Beatles" lemma="Beatles" stem="beatl" pos="NNPS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="especially" lemma="especially" stem="especi" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="Albert" lemma="Albert" stem="albert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="18" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="19" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="loathing" lemma="loathing" stem="loath" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="portrait" lemma="portrait" stem="portrait" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="painful" lemma="painful" stem="pain" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (NP (NP (NP (JJ Many)) (PP (IN of) (NP (DT the) (NNS books))) (SBAR (WHNP (WDT that)) (S (VP (VBP have) (VP (VBN been) (VP (VBN written) (PP (IN about) (NP (NNP Lennon) (CC and) (DT the) (NNPS Beatles))))))))) (, ,) (RB especially) (NP (NP (NP (NNP Albert) (NNP Goldman) (POS 's)) (NN loathing) (NN portrait)) (PP (IN of) (NP (NNP Lennon)))) (, ,)) (VP (VBP have) (VP (VBN been) (ADJP (JJ painful) (PP (TO to) (NP (NNP Ono)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="written about Lennon and the Beatles" type="VP">
          <tokens>
            <token id="9" string="written" />
            <token id="10" string="about" />
            <token id="11" string="Lennon" />
            <token id="12" string="and" />
            <token id="13" string="the" />
            <token id="14" string="Beatles" />
          </tokens>
        </chunking>
        <chunking id="2" string="Lennon" type="NP">
          <tokens>
            <token id="23" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="3" string="that have been written about Lennon and the Beatles" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="have" />
            <token id="8" string="been" />
            <token id="9" string="written" />
            <token id="10" string="about" />
            <token id="11" string="Lennon" />
            <token id="12" string="and" />
            <token id="13" string="the" />
            <token id="14" string="Beatles" />
          </tokens>
        </chunking>
        <chunking id="4" string="been written about Lennon and the Beatles" type="VP">
          <tokens>
            <token id="8" string="been" />
            <token id="9" string="written" />
            <token id="10" string="about" />
            <token id="11" string="Lennon" />
            <token id="12" string="and" />
            <token id="13" string="the" />
            <token id="14" string="Beatles" />
          </tokens>
        </chunking>
        <chunking id="5" string="Many of the books that have been written about Lennon and the Beatles" type="NP">
          <tokens>
            <token id="2" string="Many" />
            <token id="3" string="of" />
            <token id="4" string="the" />
            <token id="5" string="books" />
            <token id="6" string="that" />
            <token id="7" string="have" />
            <token id="8" string="been" />
            <token id="9" string="written" />
            <token id="10" string="about" />
            <token id="11" string="Lennon" />
            <token id="12" string="and" />
            <token id="13" string="the" />
            <token id="14" string="Beatles" />
          </tokens>
        </chunking>
        <chunking id="6" string="Ono" type="NP">
          <tokens>
            <token id="29" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="7" string="Albert Goldman 's loathing portrait of Lennon" type="NP">
          <tokens>
            <token id="17" string="Albert" />
            <token id="18" string="Goldman" />
            <token id="19" string="'s" />
            <token id="20" string="loathing" />
            <token id="21" string="portrait" />
            <token id="22" string="of" />
            <token id="23" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="8" string="Many of the books that have been written about Lennon and the Beatles , especially Albert Goldman 's loathing portrait of Lennon ," type="NP">
          <tokens>
            <token id="2" string="Many" />
            <token id="3" string="of" />
            <token id="4" string="the" />
            <token id="5" string="books" />
            <token id="6" string="that" />
            <token id="7" string="have" />
            <token id="8" string="been" />
            <token id="9" string="written" />
            <token id="10" string="about" />
            <token id="11" string="Lennon" />
            <token id="12" string="and" />
            <token id="13" string="the" />
            <token id="14" string="Beatles" />
            <token id="15" string="," />
            <token id="16" string="especially" />
            <token id="17" string="Albert" />
            <token id="18" string="Goldman" />
            <token id="19" string="'s" />
            <token id="20" string="loathing" />
            <token id="21" string="portrait" />
            <token id="22" string="of" />
            <token id="23" string="Lennon" />
            <token id="24" string="," />
          </tokens>
        </chunking>
        <chunking id="9" string="been painful to Ono" type="VP">
          <tokens>
            <token id="26" string="been" />
            <token id="27" string="painful" />
            <token id="28" string="to" />
            <token id="29" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="10" string="have been painful to Ono" type="VP">
          <tokens>
            <token id="25" string="have" />
            <token id="26" string="been" />
            <token id="27" string="painful" />
            <token id="28" string="to" />
            <token id="29" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="11" string="Many" type="NP">
          <tokens>
            <token id="2" string="Many" />
          </tokens>
        </chunking>
        <chunking id="12" string="Lennon and the Beatles" type="NP">
          <tokens>
            <token id="11" string="Lennon" />
            <token id="12" string="and" />
            <token id="13" string="the" />
            <token id="14" string="Beatles" />
          </tokens>
        </chunking>
        <chunking id="13" string="Albert Goldman 's" type="NP">
          <tokens>
            <token id="17" string="Albert" />
            <token id="18" string="Goldman" />
            <token id="19" string="'s" />
          </tokens>
        </chunking>
        <chunking id="14" string="the books" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="books" />
          </tokens>
        </chunking>
        <chunking id="15" string="Albert Goldman 's loathing portrait" type="NP">
          <tokens>
            <token id="17" string="Albert" />
            <token id="18" string="Goldman" />
            <token id="19" string="'s" />
            <token id="20" string="loathing" />
            <token id="21" string="portrait" />
          </tokens>
        </chunking>
        <chunking id="16" string="painful to Ono" type="ADJP">
          <tokens>
            <token id="27" string="painful" />
            <token id="28" string="to" />
            <token id="29" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="17" string="have been written about Lennon and the Beatles" type="VP">
          <tokens>
            <token id="7" string="have" />
            <token id="8" string="been" />
            <token id="9" string="written" />
            <token id="10" string="about" />
            <token id="11" string="Lennon" />
            <token id="12" string="and" />
            <token id="13" string="the" />
            <token id="14" string="Beatles" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="27">painful</governor>
          <dependent id="2">Many</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">books</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">books</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Many</governor>
          <dependent id="5">books</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">written</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">written</governor>
          <dependent id="7">have</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">written</governor>
          <dependent id="8">been</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">Many</governor>
          <dependent id="9">written</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Lennon</governor>
          <dependent id="10">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">written</governor>
          <dependent id="11">Lennon</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">Lennon</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">Beatles</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">Lennon</governor>
          <dependent id="14">Beatles</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">Many</governor>
          <dependent id="16">especially</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Goldman</governor>
          <dependent id="17">Albert</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">portrait</governor>
          <dependent id="18">Goldman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Goldman</governor>
          <dependent id="19">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">portrait</governor>
          <dependent id="20">loathing</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">Many</governor>
          <dependent id="21">portrait</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Lennon</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">portrait</governor>
          <dependent id="23">Lennon</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="27">painful</governor>
          <dependent id="25">have</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="27">painful</governor>
          <dependent id="26">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="27">painful</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">Ono</governor>
          <dependent id="28">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">painful</governor>
          <dependent id="29">Ono</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="Albert Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Albert" />
            <token id="18" string="Goldman" />
          </tokens>
        </entity>
        <entity id="3" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="29" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="56" has_coreference="true">
      <content>But she says she isn&amp;apost;t sure about writing her own version &amp;quot;I was hurt very much, and my son, too, by some of the things that were written,&amp;quot; she says.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="sure" lemma="sure" stem="sure" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="writing" lemma="write" stem="write" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="version" lemma="version" stem="version" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="hurt" lemma="hurt" stem="hurt" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="much" lemma="much" stem="much" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="son" lemma="son" stem="son" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="things" lemma="thing" stem="thing" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="32" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="written" lemma="write" stem="written" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="37" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (S (NP (PRP she)) (VP (VBZ says) (SBAR (S (NP (PRP she)) (VP (VBZ is) (RB n't) (ADJP (JJ sure) (PP (IN about) (S (VP (VBG writing) (NP (PRP$ her) (JJ own) (NN version)) (`` ``) (S (NP (PRP I)) (VP (VBD was) (VP (VBN hurt) (ADVP (NP (NP (RB very) (RB much)) (, ,) (CC and) (NP (PRP$ my) (NN son)) (, ,)) (RB too)) (, ,) (PP (IN by) (NP (NP (DT some)) (PP (IN of) (NP (NP (DT the) (NNS things)) (SBAR (WHNP (WDT that)) (S (VP (VBD were) (VP (VBN written))))))))))))))))))))) (, ,) ('' '') (NP (PRP she)) (VP (VBZ says)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that were written" type="SBAR">
          <tokens>
            <token id="31" string="that" />
            <token id="32" string="were" />
            <token id="33" string="written" />
          </tokens>
        </chunking>
        <chunking id="2" string="says she is n't sure about writing her own version `` I was hurt very much , and my son , too , by some of the things that were written" type="VP">
          <tokens>
            <token id="3" string="says" />
            <token id="4" string="she" />
            <token id="5" string="is" />
            <token id="6" string="n't" />
            <token id="7" string="sure" />
            <token id="8" string="about" />
            <token id="9" string="writing" />
            <token id="10" string="her" />
            <token id="11" string="own" />
            <token id="12" string="version" />
            <token id="13" string="&quot;" />
            <token id="14" string="I" />
            <token id="15" string="was" />
            <token id="16" string="hurt" />
            <token id="17" string="very" />
            <token id="18" string="much" />
            <token id="19" string="," />
            <token id="20" string="and" />
            <token id="21" string="my" />
            <token id="22" string="son" />
            <token id="23" string="," />
            <token id="24" string="too" />
            <token id="25" string="," />
            <token id="26" string="by" />
            <token id="27" string="some" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="things" />
            <token id="31" string="that" />
            <token id="32" string="were" />
            <token id="33" string="written" />
          </tokens>
        </chunking>
        <chunking id="3" string="were written" type="VP">
          <tokens>
            <token id="32" string="were" />
            <token id="33" string="written" />
          </tokens>
        </chunking>
        <chunking id="4" string="my son" type="NP">
          <tokens>
            <token id="21" string="my" />
            <token id="22" string="son" />
          </tokens>
        </chunking>
        <chunking id="5" string="some" type="NP">
          <tokens>
            <token id="27" string="some" />
          </tokens>
        </chunking>
        <chunking id="6" string="writing her own version `` I was hurt very much , and my son , too , by some of the things that were written" type="VP">
          <tokens>
            <token id="9" string="writing" />
            <token id="10" string="her" />
            <token id="11" string="own" />
            <token id="12" string="version" />
            <token id="13" string="&quot;" />
            <token id="14" string="I" />
            <token id="15" string="was" />
            <token id="16" string="hurt" />
            <token id="17" string="very" />
            <token id="18" string="much" />
            <token id="19" string="," />
            <token id="20" string="and" />
            <token id="21" string="my" />
            <token id="22" string="son" />
            <token id="23" string="," />
            <token id="24" string="too" />
            <token id="25" string="," />
            <token id="26" string="by" />
            <token id="27" string="some" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="things" />
            <token id="31" string="that" />
            <token id="32" string="were" />
            <token id="33" string="written" />
          </tokens>
        </chunking>
        <chunking id="7" string="I" type="NP">
          <tokens>
            <token id="14" string="I" />
          </tokens>
        </chunking>
        <chunking id="8" string="was hurt very much , and my son , too , by some of the things that were written" type="VP">
          <tokens>
            <token id="15" string="was" />
            <token id="16" string="hurt" />
            <token id="17" string="very" />
            <token id="18" string="much" />
            <token id="19" string="," />
            <token id="20" string="and" />
            <token id="21" string="my" />
            <token id="22" string="son" />
            <token id="23" string="," />
            <token id="24" string="too" />
            <token id="25" string="," />
            <token id="26" string="by" />
            <token id="27" string="some" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="things" />
            <token id="31" string="that" />
            <token id="32" string="were" />
            <token id="33" string="written" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="2" string="she" />
          </tokens>
        </chunking>
        <chunking id="10" string="very much" type="NP">
          <tokens>
            <token id="17" string="very" />
            <token id="18" string="much" />
          </tokens>
        </chunking>
        <chunking id="11" string="is n't sure about writing her own version `` I was hurt very much , and my son , too , by some of the things that were written" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="n't" />
            <token id="7" string="sure" />
            <token id="8" string="about" />
            <token id="9" string="writing" />
            <token id="10" string="her" />
            <token id="11" string="own" />
            <token id="12" string="version" />
            <token id="13" string="&quot;" />
            <token id="14" string="I" />
            <token id="15" string="was" />
            <token id="16" string="hurt" />
            <token id="17" string="very" />
            <token id="18" string="much" />
            <token id="19" string="," />
            <token id="20" string="and" />
            <token id="21" string="my" />
            <token id="22" string="son" />
            <token id="23" string="," />
            <token id="24" string="too" />
            <token id="25" string="," />
            <token id="26" string="by" />
            <token id="27" string="some" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="things" />
            <token id="31" string="that" />
            <token id="32" string="were" />
            <token id="33" string="written" />
          </tokens>
        </chunking>
        <chunking id="12" string="her own version" type="NP">
          <tokens>
            <token id="10" string="her" />
            <token id="11" string="own" />
            <token id="12" string="version" />
          </tokens>
        </chunking>
        <chunking id="13" string="very much , and my son ," type="NP">
          <tokens>
            <token id="17" string="very" />
            <token id="18" string="much" />
            <token id="19" string="," />
            <token id="20" string="and" />
            <token id="21" string="my" />
            <token id="22" string="son" />
            <token id="23" string="," />
          </tokens>
        </chunking>
        <chunking id="14" string="says" type="VP">
          <tokens>
            <token id="37" string="says" />
          </tokens>
        </chunking>
        <chunking id="15" string="she is n't sure about writing her own version `` I was hurt very much , and my son , too , by some of the things that were written" type="SBAR">
          <tokens>
            <token id="4" string="she" />
            <token id="5" string="is" />
            <token id="6" string="n't" />
            <token id="7" string="sure" />
            <token id="8" string="about" />
            <token id="9" string="writing" />
            <token id="10" string="her" />
            <token id="11" string="own" />
            <token id="12" string="version" />
            <token id="13" string="&quot;" />
            <token id="14" string="I" />
            <token id="15" string="was" />
            <token id="16" string="hurt" />
            <token id="17" string="very" />
            <token id="18" string="much" />
            <token id="19" string="," />
            <token id="20" string="and" />
            <token id="21" string="my" />
            <token id="22" string="son" />
            <token id="23" string="," />
            <token id="24" string="too" />
            <token id="25" string="," />
            <token id="26" string="by" />
            <token id="27" string="some" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="things" />
            <token id="31" string="that" />
            <token id="32" string="were" />
            <token id="33" string="written" />
          </tokens>
        </chunking>
        <chunking id="16" string="the things that were written" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="things" />
            <token id="31" string="that" />
            <token id="32" string="were" />
            <token id="33" string="written" />
          </tokens>
        </chunking>
        <chunking id="17" string="some of the things that were written" type="NP">
          <tokens>
            <token id="27" string="some" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="things" />
            <token id="31" string="that" />
            <token id="32" string="were" />
            <token id="33" string="written" />
          </tokens>
        </chunking>
        <chunking id="18" string="written" type="VP">
          <tokens>
            <token id="33" string="written" />
          </tokens>
        </chunking>
        <chunking id="19" string="the things" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="things" />
          </tokens>
        </chunking>
        <chunking id="20" string="sure about writing her own version `` I was hurt very much , and my son , too , by some of the things that were written" type="ADJP">
          <tokens>
            <token id="7" string="sure" />
            <token id="8" string="about" />
            <token id="9" string="writing" />
            <token id="10" string="her" />
            <token id="11" string="own" />
            <token id="12" string="version" />
            <token id="13" string="&quot;" />
            <token id="14" string="I" />
            <token id="15" string="was" />
            <token id="16" string="hurt" />
            <token id="17" string="very" />
            <token id="18" string="much" />
            <token id="19" string="," />
            <token id="20" string="and" />
            <token id="21" string="my" />
            <token id="22" string="son" />
            <token id="23" string="," />
            <token id="24" string="too" />
            <token id="25" string="," />
            <token id="26" string="by" />
            <token id="27" string="some" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="things" />
            <token id="31" string="that" />
            <token id="32" string="were" />
            <token id="33" string="written" />
          </tokens>
        </chunking>
        <chunking id="21" string="hurt very much , and my son , too , by some of the things that were written" type="VP">
          <tokens>
            <token id="16" string="hurt" />
            <token id="17" string="very" />
            <token id="18" string="much" />
            <token id="19" string="," />
            <token id="20" string="and" />
            <token id="21" string="my" />
            <token id="22" string="son" />
            <token id="23" string="," />
            <token id="24" string="too" />
            <token id="25" string="," />
            <token id="26" string="by" />
            <token id="27" string="some" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="things" />
            <token id="31" string="that" />
            <token id="32" string="were" />
            <token id="33" string="written" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="37">says</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">says</governor>
          <dependent id="2">she</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="37">says</governor>
          <dependent id="3">says</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">sure</governor>
          <dependent id="4">she</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">sure</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">sure</governor>
          <dependent id="6">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">says</governor>
          <dependent id="7">sure</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">writing</governor>
          <dependent id="8">about</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">sure</governor>
          <dependent id="9">writing</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">version</governor>
          <dependent id="10">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">version</governor>
          <dependent id="11">own</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">writing</governor>
          <dependent id="12">version</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="16">hurt</governor>
          <dependent id="14">I</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="16">hurt</governor>
          <dependent id="15">was</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">writing</governor>
          <dependent id="16">hurt</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">much</governor>
          <dependent id="17">very</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="24">too</governor>
          <dependent id="18">much</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">much</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">son</governor>
          <dependent id="21">my</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">much</governor>
          <dependent id="22">son</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">hurt</governor>
          <dependent id="24">too</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">some</governor>
          <dependent id="26">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">hurt</governor>
          <dependent id="27">some</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">things</governor>
          <dependent id="28">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">things</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">some</governor>
          <dependent id="30">things</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="33">written</governor>
          <dependent id="31">that</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="33">written</governor>
          <dependent id="32">were</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="30">things</governor>
          <dependent id="33">written</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="37">says</governor>
          <dependent id="36">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="37">says</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="57" has_coreference="true">
      <content>&amp;quot;They were lies and that&amp;apost;s what hurt us &amp;quot;Then again, when I think of writing my true story . . . I could say &amp;apost;this is the truth&amp;apost; and write about things somebody did or whatever, but then I think about their children.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="lies" lemma="lie" stem="li" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="hurt" lemma="hurt" stem="hurt" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="us" lemma="we" stem="u" pos="PRP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="again" lemma="again" stem="again" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="writing" lemma="write" stem="write" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="21" string="true" lemma="true" stem="true" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="truth" lemma="truth" stem="truth" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="write" lemma="write" stem="write" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="things" lemma="thing" stem="thing" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="somebody" lemma="somebody" stem="somebodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="whatever" lemma="whatever" stem="whatev" pos="WDT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="45" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="48" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP They)) (VP (VBD were) (NP (NNS lies)))) (CC and) (S (S (NP (DT that)) (VP (VBZ 's) (SBAR (SBAR (WHNP (WP what)) (S (VP (VBD hurt) (NP (PRP us)) (`` ``) (FRAG (ADVP (RB Then)) (ADVP (RB again))) (, ,) (SBAR (WHADVP (WRB when)) (S (S (NP (PRP I)) (VP (VBP think) (PP (IN of) (S (VP (VBG writing) (NP (PRP$ my) (JJ true) (NN story))))))) (: ...) (S (NP (PRP I)) (VP (MD could) (VP (VP (VB say) (S (`` `) (NP (DT this)) (VP (VBZ is) (NP (DT the) (NN truth))) ('' '))) (CC and) (VP (VB write) (PP (IN about) (NP (NP (NNS things)) (SBAR (S (NP (NN somebody)) (VP (VBD did))))))))))))))) (CC or) (SBAR (WHADVP (WDT whatever)))))) (, ,) (CC but) (S (ADVP (RB then)) (NP (PRP I)) (VP (VBP think) (PP (IN about) (NP (PRP$ their) (NNS children)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="2" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="when I think of writing my true story ... I could say ` this is the truth ' and write about things somebody did" type="SBAR">
          <tokens>
            <token id="15" string="when" />
            <token id="16" string="I" />
            <token id="17" string="think" />
            <token id="18" string="of" />
            <token id="19" string="writing" />
            <token id="20" string="my" />
            <token id="21" string="true" />
            <token id="22" string="story" />
            <token id="23" string=". . ." />
            <token id="24" string="I" />
            <token id="25" string="could" />
            <token id="26" string="say" />
            <token id="27" string="'" />
            <token id="28" string="this" />
            <token id="29" string="is" />
            <token id="30" string="the" />
            <token id="31" string="truth" />
            <token id="32" string="'" />
            <token id="33" string="and" />
            <token id="34" string="write" />
            <token id="35" string="about" />
            <token id="36" string="things" />
            <token id="37" string="somebody" />
            <token id="38" string="did" />
          </tokens>
        </chunking>
        <chunking id="3" string="'s what hurt us `` Then again , when I think of writing my true story ... I could say ` this is the truth ' and write about things somebody did or whatever" type="VP">
          <tokens>
            <token id="7" string="'s" />
            <token id="8" string="what" />
            <token id="9" string="hurt" />
            <token id="10" string="us" />
            <token id="11" string="&quot;" />
            <token id="12" string="Then" />
            <token id="13" string="again" />
            <token id="14" string="," />
            <token id="15" string="when" />
            <token id="16" string="I" />
            <token id="17" string="think" />
            <token id="18" string="of" />
            <token id="19" string="writing" />
            <token id="20" string="my" />
            <token id="21" string="true" />
            <token id="22" string="story" />
            <token id="23" string=". . ." />
            <token id="24" string="I" />
            <token id="25" string="could" />
            <token id="26" string="say" />
            <token id="27" string="'" />
            <token id="28" string="this" />
            <token id="29" string="is" />
            <token id="30" string="the" />
            <token id="31" string="truth" />
            <token id="32" string="'" />
            <token id="33" string="and" />
            <token id="34" string="write" />
            <token id="35" string="about" />
            <token id="36" string="things" />
            <token id="37" string="somebody" />
            <token id="38" string="did" />
            <token id="39" string="or" />
            <token id="40" string="whatever" />
          </tokens>
        </chunking>
        <chunking id="4" string="my true story" type="NP">
          <tokens>
            <token id="20" string="my" />
            <token id="21" string="true" />
            <token id="22" string="story" />
          </tokens>
        </chunking>
        <chunking id="5" string="think about their children" type="VP">
          <tokens>
            <token id="45" string="think" />
            <token id="46" string="about" />
            <token id="47" string="their" />
            <token id="48" string="children" />
          </tokens>
        </chunking>
        <chunking id="6" string="this" type="NP">
          <tokens>
            <token id="28" string="this" />
          </tokens>
        </chunking>
        <chunking id="7" string="writing my true story" type="VP">
          <tokens>
            <token id="19" string="writing" />
            <token id="20" string="my" />
            <token id="21" string="true" />
            <token id="22" string="story" />
          </tokens>
        </chunking>
        <chunking id="8" string="somebody" type="NP">
          <tokens>
            <token id="37" string="somebody" />
          </tokens>
        </chunking>
        <chunking id="9" string="whatever" type="SBAR">
          <tokens>
            <token id="40" string="whatever" />
          </tokens>
        </chunking>
        <chunking id="10" string="what hurt us `` Then again , when I think of writing my true story ... I could say ` this is the truth ' and write about things somebody did or whatever" type="SBAR">
          <tokens>
            <token id="8" string="what" />
            <token id="9" string="hurt" />
            <token id="10" string="us" />
            <token id="11" string="&quot;" />
            <token id="12" string="Then" />
            <token id="13" string="again" />
            <token id="14" string="," />
            <token id="15" string="when" />
            <token id="16" string="I" />
            <token id="17" string="think" />
            <token id="18" string="of" />
            <token id="19" string="writing" />
            <token id="20" string="my" />
            <token id="21" string="true" />
            <token id="22" string="story" />
            <token id="23" string=". . ." />
            <token id="24" string="I" />
            <token id="25" string="could" />
            <token id="26" string="say" />
            <token id="27" string="'" />
            <token id="28" string="this" />
            <token id="29" string="is" />
            <token id="30" string="the" />
            <token id="31" string="truth" />
            <token id="32" string="'" />
            <token id="33" string="and" />
            <token id="34" string="write" />
            <token id="35" string="about" />
            <token id="36" string="things" />
            <token id="37" string="somebody" />
            <token id="38" string="did" />
            <token id="39" string="or" />
            <token id="40" string="whatever" />
          </tokens>
        </chunking>
        <chunking id="11" string="think of writing my true story" type="VP">
          <tokens>
            <token id="17" string="think" />
            <token id="18" string="of" />
            <token id="19" string="writing" />
            <token id="20" string="my" />
            <token id="21" string="true" />
            <token id="22" string="story" />
          </tokens>
        </chunking>
        <chunking id="12" string="say ` this is the truth ' and write about things somebody did" type="VP">
          <tokens>
            <token id="26" string="say" />
            <token id="27" string="'" />
            <token id="28" string="this" />
            <token id="29" string="is" />
            <token id="30" string="the" />
            <token id="31" string="truth" />
            <token id="32" string="'" />
            <token id="33" string="and" />
            <token id="34" string="write" />
            <token id="35" string="about" />
            <token id="36" string="things" />
            <token id="37" string="somebody" />
            <token id="38" string="did" />
          </tokens>
        </chunking>
        <chunking id="13" string="the truth" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="truth" />
          </tokens>
        </chunking>
        <chunking id="14" string="did" type="VP">
          <tokens>
            <token id="38" string="did" />
          </tokens>
        </chunking>
        <chunking id="15" string="hurt us `` Then again , when I think of writing my true story ... I could say ` this is the truth ' and write about things somebody did" type="VP">
          <tokens>
            <token id="9" string="hurt" />
            <token id="10" string="us" />
            <token id="11" string="&quot;" />
            <token id="12" string="Then" />
            <token id="13" string="again" />
            <token id="14" string="," />
            <token id="15" string="when" />
            <token id="16" string="I" />
            <token id="17" string="think" />
            <token id="18" string="of" />
            <token id="19" string="writing" />
            <token id="20" string="my" />
            <token id="21" string="true" />
            <token id="22" string="story" />
            <token id="23" string=". . ." />
            <token id="24" string="I" />
            <token id="25" string="could" />
            <token id="26" string="say" />
            <token id="27" string="'" />
            <token id="28" string="this" />
            <token id="29" string="is" />
            <token id="30" string="the" />
            <token id="31" string="truth" />
            <token id="32" string="'" />
            <token id="33" string="and" />
            <token id="34" string="write" />
            <token id="35" string="about" />
            <token id="36" string="things" />
            <token id="37" string="somebody" />
            <token id="38" string="did" />
          </tokens>
        </chunking>
        <chunking id="16" string="could say ` this is the truth ' and write about things somebody did" type="VP">
          <tokens>
            <token id="25" string="could" />
            <token id="26" string="say" />
            <token id="27" string="'" />
            <token id="28" string="this" />
            <token id="29" string="is" />
            <token id="30" string="the" />
            <token id="31" string="truth" />
            <token id="32" string="'" />
            <token id="33" string="and" />
            <token id="34" string="write" />
            <token id="35" string="about" />
            <token id="36" string="things" />
            <token id="37" string="somebody" />
            <token id="38" string="did" />
          </tokens>
        </chunking>
        <chunking id="17" string="I" type="NP">
          <tokens>
            <token id="16" string="I" />
          </tokens>
        </chunking>
        <chunking id="18" string="is the truth" type="VP">
          <tokens>
            <token id="29" string="is" />
            <token id="30" string="the" />
            <token id="31" string="truth" />
          </tokens>
        </chunking>
        <chunking id="19" string="when" type="WHADVP">
          <tokens>
            <token id="15" string="when" />
          </tokens>
        </chunking>
        <chunking id="20" string="their children" type="NP">
          <tokens>
            <token id="47" string="their" />
            <token id="48" string="children" />
          </tokens>
        </chunking>
        <chunking id="21" string="what hurt us `` Then again , when I think of writing my true story ... I could say ` this is the truth ' and write about things somebody did" type="SBAR">
          <tokens>
            <token id="8" string="what" />
            <token id="9" string="hurt" />
            <token id="10" string="us" />
            <token id="11" string="&quot;" />
            <token id="12" string="Then" />
            <token id="13" string="again" />
            <token id="14" string="," />
            <token id="15" string="when" />
            <token id="16" string="I" />
            <token id="17" string="think" />
            <token id="18" string="of" />
            <token id="19" string="writing" />
            <token id="20" string="my" />
            <token id="21" string="true" />
            <token id="22" string="story" />
            <token id="23" string=". . ." />
            <token id="24" string="I" />
            <token id="25" string="could" />
            <token id="26" string="say" />
            <token id="27" string="'" />
            <token id="28" string="this" />
            <token id="29" string="is" />
            <token id="30" string="the" />
            <token id="31" string="truth" />
            <token id="32" string="'" />
            <token id="33" string="and" />
            <token id="34" string="write" />
            <token id="35" string="about" />
            <token id="36" string="things" />
            <token id="37" string="somebody" />
            <token id="38" string="did" />
          </tokens>
        </chunking>
        <chunking id="22" string="that" type="NP">
          <tokens>
            <token id="6" string="that" />
          </tokens>
        </chunking>
        <chunking id="23" string="say ` this is the truth '" type="VP">
          <tokens>
            <token id="26" string="say" />
            <token id="27" string="'" />
            <token id="28" string="this" />
            <token id="29" string="is" />
            <token id="30" string="the" />
            <token id="31" string="truth" />
            <token id="32" string="'" />
          </tokens>
        </chunking>
        <chunking id="24" string="were lies" type="VP">
          <tokens>
            <token id="3" string="were" />
            <token id="4" string="lies" />
          </tokens>
        </chunking>
        <chunking id="25" string="things somebody did" type="NP">
          <tokens>
            <token id="36" string="things" />
            <token id="37" string="somebody" />
            <token id="38" string="did" />
          </tokens>
        </chunking>
        <chunking id="26" string="somebody did" type="SBAR">
          <tokens>
            <token id="37" string="somebody" />
            <token id="38" string="did" />
          </tokens>
        </chunking>
        <chunking id="27" string="lies" type="NP">
          <tokens>
            <token id="4" string="lies" />
          </tokens>
        </chunking>
        <chunking id="28" string="things" type="NP">
          <tokens>
            <token id="36" string="things" />
          </tokens>
        </chunking>
        <chunking id="29" string="write about things somebody did" type="VP">
          <tokens>
            <token id="34" string="write" />
            <token id="35" string="about" />
            <token id="36" string="things" />
            <token id="37" string="somebody" />
            <token id="38" string="did" />
          </tokens>
        </chunking>
        <chunking id="30" string="us" type="NP">
          <tokens>
            <token id="10" string="us" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">lies</governor>
          <dependent id="2">They</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">lies</governor>
          <dependent id="3">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">lies</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">lies</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">'s</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">lies</governor>
          <dependent id="7">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">hurt</governor>
          <dependent id="8">what</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">'s</governor>
          <dependent id="9">hurt</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">hurt</governor>
          <dependent id="10">us</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">hurt</governor>
          <dependent id="12">Then</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">Then</governor>
          <dependent id="13">again</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">think</governor>
          <dependent id="15">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">think</governor>
          <dependent id="16">I</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">hurt</governor>
          <dependent id="17">think</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">writing</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">think</governor>
          <dependent id="19">writing</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">story</governor>
          <dependent id="20">my</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">story</governor>
          <dependent id="21">true</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">writing</governor>
          <dependent id="22">story</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">say</governor>
          <dependent id="24">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">say</governor>
          <dependent id="25">could</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="17">think</governor>
          <dependent id="26">say</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">truth</governor>
          <dependent id="28">this</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="31">truth</governor>
          <dependent id="29">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">truth</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="26">say</governor>
          <dependent id="31">truth</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="26">say</governor>
          <dependent id="33">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="26">say</governor>
          <dependent id="34">write</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">things</governor>
          <dependent id="35">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">write</governor>
          <dependent id="36">things</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="38">did</governor>
          <dependent id="37">somebody</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="36">things</governor>
          <dependent id="38">did</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">hurt</governor>
          <dependent id="39">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">hurt</governor>
          <dependent id="40">whatever</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">'s</governor>
          <dependent id="42">but</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="45">think</governor>
          <dependent id="43">then</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="45">think</governor>
          <dependent id="44">I</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">'s</governor>
          <dependent id="45">think</dependent>
        </dependency>
        <dependency type="case">
          <governor id="48">children</governor>
          <dependent id="46">about</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="48">children</governor>
          <dependent id="47">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="45">think</governor>
          <dependent id="48">children</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="58" has_coreference="true">
      <content>If you look at it from the big picture, maybe there was not such an incredible crime done to me.&amp;quot;</content>
      <tokens>
        <token id="1" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="look" lemma="look" stem="look" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="big" lemma="big" stem="big" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="picture" lemma="picture" stem="pictur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="maybe" lemma="maybe" stem="mayb" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="incredible" lemma="incredible" stem="incred" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="crime" lemma="crime" stem="crime" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="done" lemma="do" stem="done" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN If) (S (NP (PRP you)) (VP (VBP look) (PP (IN at) (NP (PRP it))) (PP (IN from) (NP (DT the) (JJ big) (NN picture)))))) (, ,) (ADVP (RB maybe)) (NP (EX there)) (VP (VBD was) (RB not) (PP (JJ such) (NP (NP (DT an) (JJ incredible) (NN crime)) (VP (VBN done) (PP (TO to) (NP (PRP me))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="there" type="NP">
          <tokens>
            <token id="12" string="there" />
          </tokens>
        </chunking>
        <chunking id="2" string="an incredible crime" type="NP">
          <tokens>
            <token id="16" string="an" />
            <token id="17" string="incredible" />
            <token id="18" string="crime" />
          </tokens>
        </chunking>
        <chunking id="3" string="look at it from the big picture" type="VP">
          <tokens>
            <token id="3" string="look" />
            <token id="4" string="at" />
            <token id="5" string="it" />
            <token id="6" string="from" />
            <token id="7" string="the" />
            <token id="8" string="big" />
            <token id="9" string="picture" />
          </tokens>
        </chunking>
        <chunking id="4" string="me" type="NP">
          <tokens>
            <token id="21" string="me" />
          </tokens>
        </chunking>
        <chunking id="5" string="the big picture" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="big" />
            <token id="9" string="picture" />
          </tokens>
        </chunking>
        <chunking id="6" string="an incredible crime done to me" type="NP">
          <tokens>
            <token id="16" string="an" />
            <token id="17" string="incredible" />
            <token id="18" string="crime" />
            <token id="19" string="done" />
            <token id="20" string="to" />
            <token id="21" string="me" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="5" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="was not such an incredible crime done to me" type="VP">
          <tokens>
            <token id="13" string="was" />
            <token id="14" string="not" />
            <token id="15" string="such" />
            <token id="16" string="an" />
            <token id="17" string="incredible" />
            <token id="18" string="crime" />
            <token id="19" string="done" />
            <token id="20" string="to" />
            <token id="21" string="me" />
          </tokens>
        </chunking>
        <chunking id="9" string="done to me" type="VP">
          <tokens>
            <token id="19" string="done" />
            <token id="20" string="to" />
            <token id="21" string="me" />
          </tokens>
        </chunking>
        <chunking id="10" string="If you look at it from the big picture" type="SBAR">
          <tokens>
            <token id="1" string="If" />
            <token id="2" string="you" />
            <token id="3" string="look" />
            <token id="4" string="at" />
            <token id="5" string="it" />
            <token id="6" string="from" />
            <token id="7" string="the" />
            <token id="8" string="big" />
            <token id="9" string="picture" />
          </tokens>
        </chunking>
        <chunking id="11" string="you" type="NP">
          <tokens>
            <token id="2" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="3">look</governor>
          <dependent id="1">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">look</governor>
          <dependent id="2">you</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">was</governor>
          <dependent id="3">look</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">it</governor>
          <dependent id="4">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">look</governor>
          <dependent id="5">it</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">picture</governor>
          <dependent id="6">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">picture</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">picture</governor>
          <dependent id="8">big</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">look</governor>
          <dependent id="9">picture</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="13">was</governor>
          <dependent id="11">maybe</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">maybe</governor>
          <dependent id="12">there</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="13">was</governor>
          <dependent id="14">not</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">crime</governor>
          <dependent id="15">such</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">crime</governor>
          <dependent id="16">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">crime</governor>
          <dependent id="17">incredible</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">was</governor>
          <dependent id="18">crime</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="18">crime</governor>
          <dependent id="19">done</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">me</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">done</governor>
          <dependent id="21">me</dependent>
        </dependency>
      </dependencies>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="22-23" string="Yoko Ono" id_sentence="1" />
      <mentions>
        <mention ids_tokens="27-28" string="Ono's" id_sentence="5" />
        <mention ids_tokens="11-12" string="Ono's" id_sentence="6" />
        <mention ids_tokens="23" string="she" id_sentence="6" />
        <mention ids_tokens="38" string="Ono" id_sentence="6" />
        <mention ids_tokens="46" string="her" id_sentence="6" />
        <mention ids_tokens="2-3" string="Ono's" id_sentence="7" />
        <mention ids_tokens="14" string="my" id_sentence="7" />
        <mention ids_tokens="3" string="Ono" id_sentence="8" />
        <mention ids_tokens="1" string="She" id_sentence="9" />
        <mention ids_tokens="7-104" string="her &quot; I'm used to sort of knocking the door rather than having the door opened and having to cope with entering it , &quot; Ono says during a telephone interview She's speaking from the New York office of Bag One Arts , the company Ono founded to promote Lennon's art and image Marketing an icon ; Since his death in 1980 , Ono has steadily kept Lennon products coming out : the albums &quot; Milk and Honey &quot; and &quot; Menlove Avenue &quot; and the 4-CD boxed set &quot; The John Lennon Collection &quot;" id_sentence="10" />
        <mention ids_tokens="39" string="She" id_sentence="10" />
        <mention ids_tokens="1" string="Yoko" id_sentence="28" />
        <mention ids_tokens="7" string="she" id_sentence="28" />
      </mentions>
    </coreference>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="15-16" string="those '70s" id_sentence="1" />
      <mentions>
        <mention ids_tokens="11" string="her" id_sentence="3" />
        <mention ids_tokens="5" string="her" id_sentence="4" />
      </mentions>
    </coreference>
    <coreference id="4" type="PROPER">
      <referenced ids_tokens="17-18" string="John Lennon" id_sentence="2" />
      <mentions>
        <mention ids_tokens="58-59" string="Lennon's" id_sentence="10" />
        <mention ids_tokens="77" string="Lennon" id_sentence="10" />
        <mention ids_tokens="119-120" string="Lennon's" id_sentence="10" />
        <mention ids_tokens="124-125" string="Lennon's" id_sentence="10" />
        <mention ids_tokens="13-14" string="Lennon's" id_sentence="13" />
        <mention ids_tokens="26-27" string="Lennon's" id_sentence="19" />
        <mention ids_tokens="14-15" string="Mr. Lennon" id_sentence="20" />
        <mention ids_tokens="1" string="Lennon" id_sentence="21" />
        <mention ids_tokens="17-18" string="Lennon's" id_sentence="21" />
        <mention ids_tokens="6" string="Lennon" id_sentence="32" />
        <mention ids_tokens="1" string="He" id_sentence="33" />
        <mention ids_tokens="3" string="Lennon" id_sentence="34" />
        <mention ids_tokens="16-17" string="Lennon's" id_sentence="34" />
        <mention ids_tokens="5" string="him" id_sentence="35" />
        <mention ids_tokens="4" string="Lennon" id_sentence="38" />
        <mention ids_tokens="6" string="his" id_sentence="38" />
        <mention ids_tokens="16" string="his" id_sentence="38" />
        <mention ids_tokens="19" string="he" id_sentence="38" />
        <mention ids_tokens="23" string="him" id_sentence="38" />
        <mention ids_tokens="63-64" string="Lennon's" id_sentence="38" />
        <mention ids_tokens="12-14" string="Lennon on trips" id_sentence="40" />
        <mention ids_tokens="25" string="Lennon" id_sentence="40" />
        <mention ids_tokens="11" string="Lennon" id_sentence="41" />
        <mention ids_tokens="11" string="Lennon" id_sentence="55" />
        <mention ids_tokens="23" string="Lennon" id_sentence="55" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="4" string="50/50" id_sentence="44" />
      <mentions>
        <mention ids_tokens="7-8" string="the Beatles" id_sentence="3" />
        <mention ids_tokens="27-28" string="the Beatles" id_sentence="38" />
        <mention ids_tokens="34-35" string="the Beatles" id_sentence="38" />
        <mention ids_tokens="44-57" string="&quot; The Beatles , &quot; the two-record set commonly called &quot; The White Album" id_sentence="38" />
        <mention ids_tokens="45-46" string="The Beatles" id_sentence="38" />
        <mention ids_tokens="49-57" string="the two-record set commonly called &quot; The White Album" id_sentence="38" />
        <mention ids_tokens="21-22" string="the Beatles" id_sentence="40" />
        <mention ids_tokens="10-11" string="the Beatles" id_sentence="42" />
        <mention ids_tokens="2" string="it" id_sentence="43" />
        <mention ids_tokens="20" string="I" id_sentence="43" />
        <mention ids_tokens="28" string="I" id_sentence="43" />
        <mention ids_tokens="1" string="I" id_sentence="46" />
        <mention ids_tokens="5-6" string="the Beatles" id_sentence="51" />
        <mention ids_tokens="3" string="It" id_sentence="52" />
        <mention ids_tokens="3" string="they" id_sentence="53" />
        <mention ids_tokens="8" string="they" id_sentence="53" />
        <mention ids_tokens="3" string="that" id_sentence="54" />
        <mention ids_tokens="11-14" string="Lennon and the Beatles" id_sentence="55" />
        <mention ids_tokens="14" string="Beatles" id_sentence="55" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="5" string="'s" id_sentence="5" />
      <mentions>
        <mention ids_tokens="8" string="they" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="27-28-29-30-31-32" string="Ono 's music as an influence" id_sentence="5" />
      <mentions>
        <mention ids_tokens="22-23" string="her music" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="8" type="PROPER">
      <referenced ids_tokens="14-15" string="last year" id_sentence="6" />
      <mentions>
        <mention ids_tokens="7-9" string="last year's" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="27-28-29-30-31-32-33-34-35-36-37-38-39-40-41-42-43-44-45-46-47-48" string="the world There 's also the American Film Institute , which Ono says is staging an international tour of her experimental films" id_sentence="6" />
      <mentions>
        <mention ids_tokens="15-16" string="this world" id_sentence="47" />
      </mentions>
    </coreference>
    <coreference id="10" type="PROPER">
      <referenced ids_tokens="52-53-54" string="the company Ono" id_sentence="10" />
      <mentions>
        <mention ids_tokens="26" string="Ono" id_sentence="7" />
        <mention ids_tokens="18" string="Ono" id_sentence="11" />
        <mention ids_tokens="4" string="Ono" id_sentence="14" />
        <mention ids_tokens="2-4" string="Ono , 57" id_sentence="15" />
        <mention ids_tokens="2" string="Ono" id_sentence="15" />
        <mention ids_tokens="13-22" string="Iceland Ono began her art career as an abstract impressionist" id_sentence="16" />
        <mention ids_tokens="29" string="Ono" id_sentence="17" />
        <mention ids_tokens="11" string="Ono" id_sentence="19" />
        <mention ids_tokens="49" string="they" id_sentence="19" />
        <mention ids_tokens="68-69" string="Ono's" id_sentence="19" />
        <mention ids_tokens="2" string="they" id_sentence="20" />
        <mention ids_tokens="25" string="Ono" id_sentence="21" />
        <mention ids_tokens="23" string="Ono" id_sentence="22" />
        <mention ids_tokens="2" string="Ono" id_sentence="26" />
        <mention ids_tokens="1" string="Ono" id_sentence="27" />
        <mention ids_tokens="20" string="them" id_sentence="27" />
        <mention ids_tokens="1" string="Ono" id_sentence="30" />
        <mention ids_tokens="4-6" string="Ono and Lennon" id_sentence="32" />
        <mention ids_tokens="4" string="Ono" id_sentence="32" />
        <mention ids_tokens="1-3" string="Ono and Lennon" id_sentence="34" />
        <mention ids_tokens="1" string="Ono" id_sentence="34" />
        <mention ids_tokens="14" string="Ono" id_sentence="34" />
        <mention ids_tokens="10" string="Ono" id_sentence="36" />
        <mention ids_tokens="9" string="Ono" id_sentence="38" />
        <mention ids_tokens="60" string="Ono" id_sentence="38" />
        <mention ids_tokens="9" string="Ono" id_sentence="40" />
        <mention ids_tokens="2-5" string="Ono in the studio" id_sentence="41" />
        <mention ids_tokens="5" string="Ono" id_sentence="42" />
        <mention ids_tokens="1" string="We" id_sentence="45" />
        <mention ids_tokens="7" string="us" id_sentence="45" />
        <mention ids_tokens="2" string="Ono" id_sentence="47" />
        <mention ids_tokens="2" string="They" id_sentence="48" />
        <mention ids_tokens="1" string="They" id_sentence="49" />
        <mention ids_tokens="8" string="them" id_sentence="50" />
        <mention ids_tokens="9" string="Ono" id_sentence="51" />
        <mention ids_tokens="29" string="Ono" id_sentence="55" />
      </mentions>
    </coreference>
    <coreference id="11" type="PROPER">
      <referenced ids_tokens="44-45" string="New York" id_sentence="10" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="19" />
        <mention ids_tokens="20-72" string="New York , the site of Lennon's murder by a crazed fan On Dec. 8 , 1980 , the couple was returning home from the recording studio where they had been remixing &quot; Walking on Thin Ice , &quot; one of the songs that would appear on Ono's most successful album" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="12" type="PROPER">
      <referenced ids_tokens="1" string="Acceptance" id_sentence="10" />
      <mentions>
        <mention ids_tokens="12" string="it" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="17" type="PROPER">
      <referenced ids_tokens="1-2" string="The two" id_sentence="39" />
      <mentions>
        <mention ids_tokens="7" string="two" id_sentence="12" />
        <mention ids_tokens="26" string="two" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="18" type="PROPER">
      <referenced ids_tokens="9" string="three" id_sentence="12" />
      <mentions>
        <mention ids_tokens="7-9" string="three of them" id_sentence="43" />
        <mention ids_tokens="6" string="it" id_sentence="46" />
        <mention ids_tokens="8-10" string="a one-sided situation" id_sentence="46" />
      </mentions>
    </coreference>
    <coreference id="19" type="PROPER">
      <referenced ids_tokens="12" string="John" id_sentence="12" />
      <mentions>
        <mention ids_tokens="4-7" string="an extremely strong person" id_sentence="36" />
        <mention ids_tokens="8" string="him" id_sentence="37" />
        <mention ids_tokens="26-28" string="John and I" id_sentence="43" />
        <mention ids_tokens="32" string="them" id_sentence="43" />
        <mention ids_tokens="3" string="them" id_sentence="45" />
        <mention ids_tokens="5" string="they" id_sentence="45" />
      </mentions>
    </coreference>
    <coreference id="20" type="PROPER">
      <referenced ids_tokens="2" string="1991" id_sentence="14" />
      <mentions>
        <mention ids_tokens="22" string="her" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="21" type="NOMINAL">
      <referenced ids_tokens="18-19-20-21-22-23" string="the proposed boxed-set of her music" id_sentence="15" />
      <mentions>
        <mention ids_tokens="1" string="She" id_sentence="16" />
        <mention ids_tokens="16" string="her" id_sentence="16" />
        <mention ids_tokens="1" string="She" id_sentence="17" />
        <mention ids_tokens="36" string="her" id_sentence="17" />
        <mention ids_tokens="1" string="She" id_sentence="18" />
        <mention ids_tokens="9" string="she" id_sentence="19" />
        <mention ids_tokens="1" string="She" id_sentence="22" />
        <mention ids_tokens="9" string="My" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="22" type="NOMINAL">
      <referenced ids_tokens="4-5" string="performance art" id_sentence="17" />
      <mentions>
        <mention ids_tokens="3" string="that" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="23" type="NOMINAL">
      <referenced ids_tokens="23-24" string="A life" id_sentence="17" />
      <mentions>
        <mention ids_tokens="16-17" string="his life" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="25" type="NOMINAL">
      <referenced ids_tokens="45-46-47-48-49-50-51-52-53-54-55-56-57" string="the recording studio where they had been remixing &quot; Walking on Thin Ice" id_sentence="19" />
      <mentions>
        <mention ids_tokens="39-40" string="the studio" id_sentence="38" />
        <mention ids_tokens="4-5" string="the studio" id_sentence="41" />
      </mentions>
    </coreference>
    <coreference id="29" type="NOMINAL">
      <referenced ids_tokens="9-10" string="My theory" id_sentence="22" />
      <mentions>
        <mention ids_tokens="9" string="me" id_sentence="23" />
        <mention ids_tokens="3" string="my" id_sentence="24" />
        <mention ids_tokens="9" string="I" id_sentence="24" />
        <mention ids_tokens="6" string="I" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="30" type="NOMINAL">
      <referenced ids_tokens="3-4" string="my hometown" id_sentence="24" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="25" />
        <mention ids_tokens="3-10" string="a place where I can work very well" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="34" type="NOMINAL">
      <referenced ids_tokens="16-17-18" string="Lennon 's relationship" id_sentence="34" />
      <mentions>
        <mention ids_tokens="6-7" string="his relationship" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="37" type="PROPER">
      <referenced ids_tokens="34" string="McCartney" id_sentence="41" />
      <mentions>
        <mention ids_tokens="25-28" string="Lennon and Paul McCartney" id_sentence="40" />
      </mentions>
    </coreference>
    <coreference id="40" type="PRONOMINAL">
      <referenced ids_tokens="4" string="she" id_sentence="47" />
      <mentions>
        <mention ids_tokens="1" string="I" id_sentence="50" />
        <mention ids_tokens="1" string="I" id_sentence="54" />
      </mentions>
    </coreference>
    <coreference id="41" type="NOMINAL">
      <referenced ids_tokens="20" string="people" id_sentence="47" />
      <mentions>
        <mention ids_tokens="7" string="their" id_sentence="49" />
      </mentions>
    </coreference>
    <coreference id="42" type="NOMINAL">
      <referenced ids_tokens="2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22-23" string="Many of the books that have been written about Lennon and the Beatles , especially Albert Goldman 's loathing portrait of Lennon" id_sentence="55" />
      <mentions>
        <mention ids_tokens="10" string="us" id_sentence="57" />
        <mention ids_tokens="47" string="their" id_sentence="57" />
      </mentions>
    </coreference>
    <coreference id="43" type="NOMINAL">
      <referenced ids_tokens="2-3-4-5-6-7-8-9-10-11-12-13-14" string="Many of the books that have been written about Lennon and the Beatles" id_sentence="55" />
      <mentions>
        <mention ids_tokens="2" string="she" id_sentence="56" />
        <mention ids_tokens="4" string="she" id_sentence="56" />
        <mention ids_tokens="10" string="her" id_sentence="56" />
        <mention ids_tokens="14" string="I" id_sentence="56" />
        <mention ids_tokens="21" string="my" id_sentence="56" />
        <mention ids_tokens="36" string="she" id_sentence="56" />
        <mention ids_tokens="16" string="I" id_sentence="57" />
        <mention ids_tokens="20" string="my" id_sentence="57" />
        <mention ids_tokens="24" string="I" id_sentence="57" />
        <mention ids_tokens="44" string="I" id_sentence="57" />
        <mention ids_tokens="21" string="me" id_sentence="58" />
      </mentions>
    </coreference>
    <coreference id="44" type="NOMINAL">
      <referenced ids_tokens="27-28-29-30-31-32-33" string="some of the things that were written" id_sentence="56" />
      <mentions>
        <mention ids_tokens="2" string="They" id_sentence="57" />
      </mentions>
    </coreference>
    <coreference id="46" type="NOMINAL">
      <referenced ids_tokens="20-21-22" string="my true story" id_sentence="57" />
      <mentions>
        <mention ids_tokens="5" string="it" id_sentence="58" />
      </mentions>
    </coreference>
  </coreferences>
</document>
