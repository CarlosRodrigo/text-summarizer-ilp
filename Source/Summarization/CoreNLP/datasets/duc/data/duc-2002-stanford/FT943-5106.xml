<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="FT943-5106">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>The shortlist of six for the Pounds 20,000 Booker Prize for fiction, announced yesterday, immediately prompted the question &amp;apost;Who?&amp;apost;</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="shortlist" lemma="shortlist" stem="shortlist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="5" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Pounds" lemma="Pounds" stem="pound" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="20,000" lemma="20,000" stem="20,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="9" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="10" string="Prize" lemma="Prize" stem="prize" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="11" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="fiction" lemma="fiction" stem="fiction" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="announced" lemma="announce" stem="announc" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="yesterday" lemma="yesterday" stem="yesterdai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="immediately" lemma="immediately" stem="immedi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="prompted" lemma="prompt" stem="prompt" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="question" lemma="question" stem="question" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SBARQ (SBAR (WHNP (NP (DT The) (NN shortlist)) (WHPP (IN of) (WHNP (WHNP (CD six)) (PP (IN for) (NP (DT the) (NNPS Pounds)))))) (S (NP (NP (CD 20,000) (NNP Booker) (NNP Prize)) (PP (IN for) (NP (NN fiction)))) (, ,) (VP (VBD announced) (NP-TMP (NN yesterday))))) (, ,) (WHADVP (RB immediately)) (SQ (VBD prompted) (NP (NP (DT the) (NN question)) (`` `) (NP (FRAG (WHNP (WP Who)) (. ?))) ('' ')))))</syntactictree>
      <chunkings>
        <chunking id="1" string="20,000 Booker Prize" type="NP">
          <tokens>
            <token id="8" string="20,000" />
            <token id="9" string="Booker" />
            <token id="10" string="Prize" />
          </tokens>
        </chunking>
        <chunking id="2" string="The shortlist" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="shortlist" />
          </tokens>
        </chunking>
        <chunking id="3" string="fiction" type="NP">
          <tokens>
            <token id="12" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="4" string="20,000 Booker Prize for fiction" type="NP">
          <tokens>
            <token id="8" string="20,000" />
            <token id="9" string="Booker" />
            <token id="10" string="Prize" />
            <token id="11" string="for" />
            <token id="12" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="5" string="The shortlist of six for the Pounds 20,000 Booker Prize for fiction , announced yesterday" type="SBAR">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="shortlist" />
            <token id="3" string="of" />
            <token id="4" string="six" />
            <token id="5" string="for" />
            <token id="6" string="the" />
            <token id="7" string="Pounds" />
            <token id="8" string="20,000" />
            <token id="9" string="Booker" />
            <token id="10" string="Prize" />
            <token id="11" string="for" />
            <token id="12" string="fiction" />
            <token id="13" string="," />
            <token id="14" string="announced" />
            <token id="15" string="yesterday" />
          </tokens>
        </chunking>
        <chunking id="6" string="the question" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="question" />
          </tokens>
        </chunking>
        <chunking id="7" string="the question ` Who ? '" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="question" />
            <token id="21" string="'" />
            <token id="22" string="Who" />
            <token id="23" string="?" />
            <token id="24" string="'" />
          </tokens>
        </chunking>
        <chunking id="8" string="Who ?" type="NP">
          <tokens>
            <token id="22" string="Who" />
            <token id="23" string="?" />
          </tokens>
        </chunking>
        <chunking id="9" string="immediately" type="WHADVP">
          <tokens>
            <token id="17" string="immediately" />
          </tokens>
        </chunking>
        <chunking id="10" string="announced yesterday" type="VP">
          <tokens>
            <token id="14" string="announced" />
            <token id="15" string="yesterday" />
          </tokens>
        </chunking>
        <chunking id="11" string="the Pounds" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="Pounds" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">shortlist</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">announced</governor>
          <dependent id="2">shortlist</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">six</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">shortlist</governor>
          <dependent id="4">six</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Pounds</governor>
          <dependent id="5">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">Pounds</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">six</governor>
          <dependent id="7">Pounds</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">Prize</governor>
          <dependent id="8">20,000</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Prize</governor>
          <dependent id="9">Booker</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">announced</governor>
          <dependent id="10">Prize</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">fiction</governor>
          <dependent id="11">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">Prize</governor>
          <dependent id="12">fiction</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="18">prompted</governor>
          <dependent id="14">announced</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="14">announced</governor>
          <dependent id="15">yesterday</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">prompted</governor>
          <dependent id="17">immediately</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">prompted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">question</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">prompted</governor>
          <dependent id="20">question</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="20">question</governor>
          <dependent id="22">Who</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="six" />
          </tokens>
        </entity>
        <entity id="2" string="yesterday" type="DATE" score="0.0">
          <tokens>
            <token id="15" string="yesterday" />
          </tokens>
        </entity>
        <entity id="3" string="20,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="20,000" />
          </tokens>
        </entity>
        <entity id="4" string="Booker Prize" type="MISC" score="0.0">
          <tokens>
            <token id="9" string="Booker" />
            <token id="10" string="Prize" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="false">
      <content>from many in the publishing industry.</content>
      <tokens>
        <token id="1" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="publishing" lemma="publishing" stem="publish" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="industry" lemma="industry" stem="industri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (PP (IN from) (NP (NP (JJ many)) (PP (IN in) (NP (DT the) (NN publishing) (NN industry))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="many in the publishing industry" type="NP">
          <tokens>
            <token id="2" string="many" />
            <token id="3" string="in" />
            <token id="4" string="the" />
            <token id="5" string="publishing" />
            <token id="6" string="industry" />
          </tokens>
        </chunking>
        <chunking id="2" string="the publishing industry" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="publishing" />
            <token id="6" string="industry" />
          </tokens>
        </chunking>
        <chunking id="3" string="many" type="NP">
          <tokens>
            <token id="2" string="many" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">many</governor>
          <dependent id="1">from</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">many</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">industry</governor>
          <dependent id="3">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">industry</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">industry</governor>
          <dependent id="5">publishing</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">many</governor>
          <dependent id="6">industry</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="3" has_coreference="false">
      <content>According to one insider, some on the list &amp;apost;are B-team writers at best&amp;apost;.</content>
      <tokens>
        <token id="1" string="According" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="insider" lemma="insider" stem="insid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="list" lemma="list" stem="list" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="B-team" lemma="b-team" stem="b-team" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="13" string="writers" lemma="writer" stem="writer" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="best" lemma="best" stem="best" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (VBG According) (PP (TO to) (NP (CD one) (NN insider)))) (, ,) (NP (NP (DT some)) (PP (IN on) (NP (DT the) (NN list)))) (`` `) (VP (VBP are) (NP (JJ B-team) (NNS writers)) (ADVP (IN at)) (ADJP (JJS best)) ('' ')) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the list" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="list" />
          </tokens>
        </chunking>
        <chunking id="2" string="some on the list" type="NP">
          <tokens>
            <token id="6" string="some" />
            <token id="7" string="on" />
            <token id="8" string="the" />
            <token id="9" string="list" />
          </tokens>
        </chunking>
        <chunking id="3" string="some" type="NP">
          <tokens>
            <token id="6" string="some" />
          </tokens>
        </chunking>
        <chunking id="4" string="are B-team writers at best '" type="VP">
          <tokens>
            <token id="11" string="are" />
            <token id="12" string="B-team" />
            <token id="13" string="writers" />
            <token id="14" string="at" />
            <token id="15" string="best" />
            <token id="16" string="'" />
          </tokens>
        </chunking>
        <chunking id="5" string="one insider" type="NP">
          <tokens>
            <token id="3" string="one" />
            <token id="4" string="insider" />
          </tokens>
        </chunking>
        <chunking id="6" string="best" type="ADJP">
          <tokens>
            <token id="15" string="best" />
          </tokens>
        </chunking>
        <chunking id="7" string="B-team writers" type="NP">
          <tokens>
            <token id="12" string="B-team" />
            <token id="13" string="writers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">insider</governor>
          <dependent id="1">According</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">According</governor>
          <dependent id="2">to</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">insider</governor>
          <dependent id="3">one</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">best</governor>
          <dependent id="4">insider</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">best</governor>
          <dependent id="6">some</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">list</governor>
          <dependent id="7">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">list</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">some</governor>
          <dependent id="9">list</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">best</governor>
          <dependent id="11">are</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">writers</governor>
          <dependent id="12">B-team</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="15">best</governor>
          <dependent id="13">writers</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">best</governor>
          <dependent id="14">at</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">best</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="B-team" type="MISC" score="0.0">
          <tokens>
            <token id="12" string="B-team" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>The six include Alan Hollinghurst&amp;apost;s The Folding Star (published by Chatto and Windus), a melancholy study of homosexual obsession which was tipped as a likely candidate from the initial &amp;apost;long list&amp;apost; of 15, The Reef (Granta) by young Sri Lankan writer Romesh Gunesekera and How Late It Was, How Late (Secker and Warburg) by gritty Glasgow realist James Kelman, which was almost universally well-reviewed.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="3" string="include" lemma="include" stem="includ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Alan" lemma="Alan" stem="alan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="5" string="Hollinghurst" lemma="Hollinghurst" stem="hollinghurst" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="6" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Folding" lemma="folding" stem="fold" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Star" lemma="star" stem="star" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="published" lemma="publish" stem="publish" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Chatto" lemma="Chatto" stem="chatto" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="Windus" lemma="Windus" stem="windu" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="16" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="melancholy" lemma="melancholy" stem="melancholi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="study" lemma="study" stem="studi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="homosexual" lemma="homosexual" stem="homosexu" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="obsession" lemma="obsession" stem="obsess" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="tipped" lemma="tip" stem="tip" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="likely" lemma="likely" stem="like" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="candidate" lemma="candidate" stem="candid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="initial" lemma="initial" stem="initi" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="35" string="long" lemma="long" stem="long" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="36" string="list" lemma="list" stem="list" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="37" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="38" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="39" string="15" lemma="15" stem="15" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="40" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="42" string="Reef" lemma="reef" stem="reef" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="43" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="44" string="Granta" lemma="granta" stem="granta" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="45" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="46" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="young" lemma="young" stem="young" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="Sri" lemma="Sri" stem="sri" pos="NNP" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="49" string="Lankan" lemma="Lankan" stem="lankan" pos="NNP" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="50" string="writer" lemma="writer" stem="writer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="51" string="Romesh" lemma="Romesh" stem="romesh" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="52" string="Gunesekera" lemma="Gunesekera" stem="gunesekera" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="53" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="54" string="How" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="55" string="Late" lemma="late" stem="late" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="56" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="57" string="Was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="58" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="59" string="How" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="60" string="Late" lemma="late" stem="late" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="61" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="62" string="Secker" lemma="Secker" stem="secker" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="63" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="64" string="Warburg" lemma="Warburg" stem="warburg" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="65" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="66" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="67" string="gritty" lemma="gritty" stem="gritti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="68" string="Glasgow" lemma="Glasgow" stem="glasgow" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="69" string="realist" lemma="realist" stem="realist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="70" string="James" lemma="James" stem="jame" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="71" string="Kelman" lemma="Kelman" stem="kelman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="72" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="73" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="74" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="75" string="almost" lemma="almost" stem="almost" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="76" string="universally" lemma="universally" stem="univers" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="77" string="well-reviewed" lemma="well-reviewed" stem="well-review" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="78" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (CD six)) (VP (VBP include) (NP (NP (NP (NNP Alan) (NNP Hollinghurst) (POS 's)) (NP (DT The) (JJ Folding) (NN Star))) (PRN (-LRB- -LRB-) (VP (VBN published) (PP (IN by) (NP (NNP Chatto) (CC and) (NNP Windus)))) (-RRB- -RRB-)) (, ,) (NP (NP (DT a) (JJ melancholy) (NN study)) (PP (IN of) (NP (JJ homosexual) (NN obsession))) (SBAR (WHNP (WDT which)) (S (VP (VBD was) (VP (VBN tipped) (PP (IN as) (NP (DT a) (JJ likely) (NN candidate))) (PP (IN from) (NP (NP (DT the) (JJ initial) (`` `) (JJ long) (NN list) ('' ')) (PP (IN of) (NP (CD 15))))))))))))) (, ,) (S (NP (NP (DT The) (NN Reef)) (PRN (-LRB- -LRB-) (NP (NN Granta)) (-RRB- -RRB-))) (PP (IN by) (NP (JJ young) (NNP Sri) (NNP Lankan) (NN writer) (NNP Romesh) (NNP Gunesekera)))) (CC and) (S (SBAR (WHADJP (WRB How) (JJ Late)) (S (NP (PRP It)) (VP (VBD Was)))) (, ,) (SBAR (WHADJP (WRB How) (JJ Late)) (S (VP (PRN (-LRB- -LRB-) (NP (NNP Secker) (CC and) (NNP Warburg)) (-RRB- -RRB-)) (PP (IN by) (NP (JJ gritty) (NNP Glasgow) (NN realist) (NNP James) (NNP Kelman)))))) (, ,) (NP (WDT which)) (VP (VBD was) (ADVP (RB almost)) (ADJP (ADVP (RB universally)) (JJ well-reviewed)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Secker and Warburg" type="NP">
          <tokens>
            <token id="62" string="Secker" />
            <token id="63" string="and" />
            <token id="64" string="Warburg" />
          </tokens>
        </chunking>
        <chunking id="2" string="which" type="NP">
          <tokens>
            <token id="73" string="which" />
          </tokens>
        </chunking>
        <chunking id="3" string="Alan Hollinghurst 's" type="NP">
          <tokens>
            <token id="4" string="Alan" />
            <token id="5" string="Hollinghurst" />
            <token id="6" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="15" type="NP">
          <tokens>
            <token id="39" string="15" />
          </tokens>
        </chunking>
        <chunking id="5" string="tipped as a likely candidate from the initial ` long list ' of 15" type="VP">
          <tokens>
            <token id="26" string="tipped" />
            <token id="27" string="as" />
            <token id="28" string="a" />
            <token id="29" string="likely" />
            <token id="30" string="candidate" />
            <token id="31" string="from" />
            <token id="32" string="the" />
            <token id="33" string="initial" />
            <token id="34" string="'" />
            <token id="35" string="long" />
            <token id="36" string="list" />
            <token id="37" string="'" />
            <token id="38" string="of" />
            <token id="39" string="15" />
          </tokens>
        </chunking>
        <chunking id="6" string="The six" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="six" />
          </tokens>
        </chunking>
        <chunking id="7" string="The Folding Star" type="NP">
          <tokens>
            <token id="7" string="The" />
            <token id="8" string="Folding" />
            <token id="9" string="Star" />
          </tokens>
        </chunking>
        <chunking id="8" string="Granta" type="NP">
          <tokens>
            <token id="44" string="Granta" />
          </tokens>
        </chunking>
        <chunking id="9" string="include Alan Hollinghurst 's The Folding Star -LRB- published by Chatto and Windus -RRB- , a melancholy study of homosexual obsession which was tipped as a likely candidate from the initial ` long list ' of 15" type="VP">
          <tokens>
            <token id="3" string="include" />
            <token id="4" string="Alan" />
            <token id="5" string="Hollinghurst" />
            <token id="6" string="'s" />
            <token id="7" string="The" />
            <token id="8" string="Folding" />
            <token id="9" string="Star" />
            <token id="10" string="(" />
            <token id="11" string="published" />
            <token id="12" string="by" />
            <token id="13" string="Chatto" />
            <token id="14" string="and" />
            <token id="15" string="Windus" />
            <token id="16" string=")" />
            <token id="17" string="," />
            <token id="18" string="a" />
            <token id="19" string="melancholy" />
            <token id="20" string="study" />
            <token id="21" string="of" />
            <token id="22" string="homosexual" />
            <token id="23" string="obsession" />
            <token id="24" string="which" />
            <token id="25" string="was" />
            <token id="26" string="tipped" />
            <token id="27" string="as" />
            <token id="28" string="a" />
            <token id="29" string="likely" />
            <token id="30" string="candidate" />
            <token id="31" string="from" />
            <token id="32" string="the" />
            <token id="33" string="initial" />
            <token id="34" string="'" />
            <token id="35" string="long" />
            <token id="36" string="list" />
            <token id="37" string="'" />
            <token id="38" string="of" />
            <token id="39" string="15" />
          </tokens>
        </chunking>
        <chunking id="10" string="a melancholy study" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="melancholy" />
            <token id="20" string="study" />
          </tokens>
        </chunking>
        <chunking id="11" string="the initial ` long list '" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="initial" />
            <token id="34" string="'" />
            <token id="35" string="long" />
            <token id="36" string="list" />
            <token id="37" string="'" />
          </tokens>
        </chunking>
        <chunking id="12" string="gritty Glasgow realist James Kelman" type="NP">
          <tokens>
            <token id="67" string="gritty" />
            <token id="68" string="Glasgow" />
            <token id="69" string="realist" />
            <token id="70" string="James" />
            <token id="71" string="Kelman" />
          </tokens>
        </chunking>
        <chunking id="13" string="was tipped as a likely candidate from the initial ` long list ' of 15" type="VP">
          <tokens>
            <token id="25" string="was" />
            <token id="26" string="tipped" />
            <token id="27" string="as" />
            <token id="28" string="a" />
            <token id="29" string="likely" />
            <token id="30" string="candidate" />
            <token id="31" string="from" />
            <token id="32" string="the" />
            <token id="33" string="initial" />
            <token id="34" string="'" />
            <token id="35" string="long" />
            <token id="36" string="list" />
            <token id="37" string="'" />
            <token id="38" string="of" />
            <token id="39" string="15" />
          </tokens>
        </chunking>
        <chunking id="14" string="Chatto and Windus" type="NP">
          <tokens>
            <token id="13" string="Chatto" />
            <token id="14" string="and" />
            <token id="15" string="Windus" />
          </tokens>
        </chunking>
        <chunking id="15" string="Alan Hollinghurst 's The Folding Star" type="NP">
          <tokens>
            <token id="4" string="Alan" />
            <token id="5" string="Hollinghurst" />
            <token id="6" string="'s" />
            <token id="7" string="The" />
            <token id="8" string="Folding" />
            <token id="9" string="Star" />
          </tokens>
        </chunking>
        <chunking id="16" string="published by Chatto and Windus" type="VP">
          <tokens>
            <token id="11" string="published" />
            <token id="12" string="by" />
            <token id="13" string="Chatto" />
            <token id="14" string="and" />
            <token id="15" string="Windus" />
          </tokens>
        </chunking>
        <chunking id="17" string="The Reef -LRB- Granta -RRB-" type="NP">
          <tokens>
            <token id="41" string="The" />
            <token id="42" string="Reef" />
            <token id="43" string="(" />
            <token id="44" string="Granta" />
            <token id="45" string=")" />
          </tokens>
        </chunking>
        <chunking id="18" string="How Late It Was" type="SBAR">
          <tokens>
            <token id="54" string="How" />
            <token id="55" string="Late" />
            <token id="56" string="It" />
            <token id="57" string="Was" />
          </tokens>
        </chunking>
        <chunking id="19" string="was almost universally well-reviewed" type="VP">
          <tokens>
            <token id="74" string="was" />
            <token id="75" string="almost" />
            <token id="76" string="universally" />
            <token id="77" string="well-reviewed" />
          </tokens>
        </chunking>
        <chunking id="20" string="Was" type="VP">
          <tokens>
            <token id="57" string="Was" />
          </tokens>
        </chunking>
        <chunking id="21" string="It" type="NP">
          <tokens>
            <token id="56" string="It" />
          </tokens>
        </chunking>
        <chunking id="22" string="a melancholy study of homosexual obsession which was tipped as a likely candidate from the initial ` long list ' of 15" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="melancholy" />
            <token id="20" string="study" />
            <token id="21" string="of" />
            <token id="22" string="homosexual" />
            <token id="23" string="obsession" />
            <token id="24" string="which" />
            <token id="25" string="was" />
            <token id="26" string="tipped" />
            <token id="27" string="as" />
            <token id="28" string="a" />
            <token id="29" string="likely" />
            <token id="30" string="candidate" />
            <token id="31" string="from" />
            <token id="32" string="the" />
            <token id="33" string="initial" />
            <token id="34" string="'" />
            <token id="35" string="long" />
            <token id="36" string="list" />
            <token id="37" string="'" />
            <token id="38" string="of" />
            <token id="39" string="15" />
          </tokens>
        </chunking>
        <chunking id="23" string="The Reef" type="NP">
          <tokens>
            <token id="41" string="The" />
            <token id="42" string="Reef" />
          </tokens>
        </chunking>
        <chunking id="24" string="How Late -LRB- Secker and Warburg -RRB- by gritty Glasgow realist James Kelman" type="SBAR">
          <tokens>
            <token id="59" string="How" />
            <token id="60" string="Late" />
            <token id="61" string="(" />
            <token id="62" string="Secker" />
            <token id="63" string="and" />
            <token id="64" string="Warburg" />
            <token id="65" string=")" />
            <token id="66" string="by" />
            <token id="67" string="gritty" />
            <token id="68" string="Glasgow" />
            <token id="69" string="realist" />
            <token id="70" string="James" />
            <token id="71" string="Kelman" />
          </tokens>
        </chunking>
        <chunking id="25" string="universally well-reviewed" type="ADJP">
          <tokens>
            <token id="76" string="universally" />
            <token id="77" string="well-reviewed" />
          </tokens>
        </chunking>
        <chunking id="26" string="-LRB- Secker and Warburg -RRB- by gritty Glasgow realist James Kelman" type="VP">
          <tokens>
            <token id="61" string="(" />
            <token id="62" string="Secker" />
            <token id="63" string="and" />
            <token id="64" string="Warburg" />
            <token id="65" string=")" />
            <token id="66" string="by" />
            <token id="67" string="gritty" />
            <token id="68" string="Glasgow" />
            <token id="69" string="realist" />
            <token id="70" string="James" />
            <token id="71" string="Kelman" />
          </tokens>
        </chunking>
        <chunking id="27" string="Alan Hollinghurst 's The Folding Star -LRB- published by Chatto and Windus -RRB- , a melancholy study of homosexual obsession which was tipped as a likely candidate from the initial ` long list ' of 15" type="NP">
          <tokens>
            <token id="4" string="Alan" />
            <token id="5" string="Hollinghurst" />
            <token id="6" string="'s" />
            <token id="7" string="The" />
            <token id="8" string="Folding" />
            <token id="9" string="Star" />
            <token id="10" string="(" />
            <token id="11" string="published" />
            <token id="12" string="by" />
            <token id="13" string="Chatto" />
            <token id="14" string="and" />
            <token id="15" string="Windus" />
            <token id="16" string=")" />
            <token id="17" string="," />
            <token id="18" string="a" />
            <token id="19" string="melancholy" />
            <token id="20" string="study" />
            <token id="21" string="of" />
            <token id="22" string="homosexual" />
            <token id="23" string="obsession" />
            <token id="24" string="which" />
            <token id="25" string="was" />
            <token id="26" string="tipped" />
            <token id="27" string="as" />
            <token id="28" string="a" />
            <token id="29" string="likely" />
            <token id="30" string="candidate" />
            <token id="31" string="from" />
            <token id="32" string="the" />
            <token id="33" string="initial" />
            <token id="34" string="'" />
            <token id="35" string="long" />
            <token id="36" string="list" />
            <token id="37" string="'" />
            <token id="38" string="of" />
            <token id="39" string="15" />
          </tokens>
        </chunking>
        <chunking id="28" string="the initial ` long list ' of 15" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="initial" />
            <token id="34" string="'" />
            <token id="35" string="long" />
            <token id="36" string="list" />
            <token id="37" string="'" />
            <token id="38" string="of" />
            <token id="39" string="15" />
          </tokens>
        </chunking>
        <chunking id="29" string="which was tipped as a likely candidate from the initial ` long list ' of 15" type="SBAR">
          <tokens>
            <token id="24" string="which" />
            <token id="25" string="was" />
            <token id="26" string="tipped" />
            <token id="27" string="as" />
            <token id="28" string="a" />
            <token id="29" string="likely" />
            <token id="30" string="candidate" />
            <token id="31" string="from" />
            <token id="32" string="the" />
            <token id="33" string="initial" />
            <token id="34" string="'" />
            <token id="35" string="long" />
            <token id="36" string="list" />
            <token id="37" string="'" />
            <token id="38" string="of" />
            <token id="39" string="15" />
          </tokens>
        </chunking>
        <chunking id="30" string="homosexual obsession" type="NP">
          <tokens>
            <token id="22" string="homosexual" />
            <token id="23" string="obsession" />
          </tokens>
        </chunking>
        <chunking id="31" string="a likely candidate" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="likely" />
            <token id="30" string="candidate" />
          </tokens>
        </chunking>
        <chunking id="32" string="young Sri Lankan writer Romesh Gunesekera" type="NP">
          <tokens>
            <token id="47" string="young" />
            <token id="48" string="Sri" />
            <token id="49" string="Lankan" />
            <token id="50" string="writer" />
            <token id="51" string="Romesh" />
            <token id="52" string="Gunesekera" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">six</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">include</governor>
          <dependent id="2">six</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">include</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Hollinghurst</governor>
          <dependent id="4">Alan</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">include</governor>
          <dependent id="5">Hollinghurst</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Hollinghurst</governor>
          <dependent id="6">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Star</governor>
          <dependent id="7">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">Star</governor>
          <dependent id="8">Folding</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">Hollinghurst</governor>
          <dependent id="9">Star</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">Hollinghurst</governor>
          <dependent id="11">published</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Chatto</governor>
          <dependent id="12">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">published</governor>
          <dependent id="13">Chatto</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">Chatto</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">Chatto</governor>
          <dependent id="15">Windus</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">study</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">study</governor>
          <dependent id="19">melancholy</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">Hollinghurst</governor>
          <dependent id="20">study</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">obsession</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">obsession</governor>
          <dependent id="22">homosexual</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">study</governor>
          <dependent id="23">obsession</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="26">tipped</governor>
          <dependent id="24">which</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="26">tipped</governor>
          <dependent id="25">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="20">study</governor>
          <dependent id="26">tipped</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">candidate</governor>
          <dependent id="27">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">candidate</governor>
          <dependent id="28">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">candidate</governor>
          <dependent id="29">likely</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">tipped</governor>
          <dependent id="30">candidate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">list</governor>
          <dependent id="31">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">list</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="36">list</governor>
          <dependent id="33">initial</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="36">list</governor>
          <dependent id="35">long</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">tipped</governor>
          <dependent id="36">list</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">15</governor>
          <dependent id="38">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">list</governor>
          <dependent id="39">15</dependent>
        </dependency>
        <dependency type="det">
          <governor id="42">Reef</governor>
          <dependent id="41">The</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">include</governor>
          <dependent id="42">Reef</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="42">Reef</governor>
          <dependent id="44">Granta</dependent>
        </dependency>
        <dependency type="case">
          <governor id="52">Gunesekera</governor>
          <dependent id="46">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="52">Gunesekera</governor>
          <dependent id="47">young</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="52">Gunesekera</governor>
          <dependent id="48">Sri</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="52">Gunesekera</governor>
          <dependent id="49">Lankan</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="52">Gunesekera</governor>
          <dependent id="50">writer</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="52">Gunesekera</governor>
          <dependent id="51">Romesh</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="42">Reef</governor>
          <dependent id="52">Gunesekera</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">include</governor>
          <dependent id="53">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="55">Late</governor>
          <dependent id="54">How</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="57">Was</governor>
          <dependent id="55">Late</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="57">Was</governor>
          <dependent id="56">It</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="77">well-reviewed</governor>
          <dependent id="57">Was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="60">Late</governor>
          <dependent id="59">How</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="62">Secker</governor>
          <dependent id="60">Late</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="77">well-reviewed</governor>
          <dependent id="62">Secker</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="62">Secker</governor>
          <dependent id="63">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="62">Secker</governor>
          <dependent id="64">Warburg</dependent>
        </dependency>
        <dependency type="case">
          <governor id="71">Kelman</governor>
          <dependent id="66">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="71">Kelman</governor>
          <dependent id="67">gritty</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="71">Kelman</governor>
          <dependent id="68">Glasgow</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="71">Kelman</governor>
          <dependent id="69">realist</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="71">Kelman</governor>
          <dependent id="70">James</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="62">Secker</governor>
          <dependent id="71">Kelman</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="77">well-reviewed</governor>
          <dependent id="73">which</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="77">well-reviewed</governor>
          <dependent id="74">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="77">well-reviewed</governor>
          <dependent id="75">almost</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="77">well-reviewed</governor>
          <dependent id="76">universally</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">include</governor>
          <dependent id="77">well-reviewed</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="six" />
          </tokens>
        </entity>
        <entity id="2" string="Alan Hollinghurst" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Alan" />
            <token id="5" string="Hollinghurst" />
          </tokens>
        </entity>
        <entity id="3" string="James Kelman" type="PERSON" score="0.0">
          <tokens>
            <token id="70" string="James" />
            <token id="71" string="Kelman" />
          </tokens>
        </entity>
        <entity id="4" string="Sri Lankan" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="48" string="Sri" />
            <token id="49" string="Lankan" />
          </tokens>
        </entity>
        <entity id="5" string="15" type="NUMBER" score="0.0">
          <tokens>
            <token id="39" string="15" />
          </tokens>
        </entity>
        <entity id="6" string="Windus" type="MISC" score="0.0">
          <tokens>
            <token id="15" string="Windus" />
          </tokens>
        </entity>
        <entity id="7" string="Glasgow" type="LOCATION" score="0.0">
          <tokens>
            <token id="68" string="Glasgow" />
          </tokens>
        </entity>
        <entity id="8" string="Secker" type="PERSON" score="0.0">
          <tokens>
            <token id="62" string="Secker" />
          </tokens>
        </entity>
        <entity id="9" string="Warburg" type="LOCATION" score="0.0">
          <tokens>
            <token id="64" string="Warburg" />
          </tokens>
        </entity>
        <entity id="10" string="Granta" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="44" string="Granta" />
          </tokens>
        </entity>
        <entity id="11" string="Romesh Gunesekera" type="PERSON" score="0.0">
          <tokens>
            <token id="51" string="Romesh" />
            <token id="52" string="Gunesekera" />
          </tokens>
        </entity>
        <entity id="12" string="Chatto" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Chatto" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>As for the other three - Knowledge of Angels (Green Bay) a philosophical fable by children&amp;apost;s author Jill Paton Walsh, Paradise (Hamish Hamilton) by Zanzibar-born writer Abdulrazak Gurnah and Beside the Ocean of Time (John Murray) by 72-year-old Orcadian poet George Mackay Brown - &amp;apost;frankly, they don&amp;apost;t make the grade&amp;apost;.</content>
      <tokens>
        <token id="1" string="As" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="6" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Knowledge" lemma="knowledge" stem="knowledg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Angels" lemma="Angels" stem="angel" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Green" lemma="Green" stem="green" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="12" string="Bay" lemma="Bay" stem="bai" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="13" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="philosophical" lemma="philosophical" stem="philosoph" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="fable" lemma="fable" stem="fabl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="author" lemma="author" stem="author" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="Jill" lemma="Jill" stem="jill" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="22" string="Paton" lemma="Paton" stem="paton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="23" string="Walsh" lemma="Walsh" stem="walsh" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Paradise" lemma="Paradise" stem="paradis" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="Hamish" lemma="Hamish" stem="hamish" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="28" string="Hamilton" lemma="Hamilton" stem="hamilton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="29" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="Zanzibar-born" lemma="zanzibar-born" stem="zanzibar-born" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="32" string="writer" lemma="writer" stem="writer" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="Abdulrazak" lemma="Abdulrazak" stem="abdulrazak" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="34" string="Gurnah" lemma="Gurnah" stem="gurnah" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="35" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="36" string="Beside" lemma="beside" stem="besid" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="37" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="38" string="Ocean" lemma="ocean" stem="ocean" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="39" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="40" string="Time" lemma="Time" stem="time" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="41" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="42" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="43" string="Murray" lemma="Murray" stem="murrai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="44" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="45" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="46" string="72-year-old" lemma="72-year-old" stem="72-year-old" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="47" string="Orcadian" lemma="Orcadian" stem="orcadian" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="48" string="poet" lemma="poet" stem="poet" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="49" string="George" lemma="George" stem="georg" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="50" string="Mackay" lemma="Mackay" stem="mackai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="51" string="Brown" lemma="Brown" stem="brown" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="52" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="53" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="54" string="frankly" lemma="frankly" stem="frankli" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="55" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="56" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="57" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="58" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="59" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="60" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="61" string="grade" lemma="grade" stem="grade" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="62" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="63" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (PP (IN As) (PP (IN for) (NP (DT the) (JJ other) (CD three)))) (: -) (NP (NP (NP (NN Knowledge)) (PP (IN of) (NP (NP (NP (NNPS Angels)) (PRN (-LRB- -LRB-) (NP (NNP Green) (NNP Bay)) (-RRB- -RRB-))) (NP (NP (DT a) (JJ philosophical) (NN fable)) (PP (IN by) (NP (NP (NNS children) (POS 's)) (NN author) (NNP Jill) (NNP Paton) (NNP Walsh))))))) (, ,) (NP (NP (NP (NNP Paradise)) (PRN (-LRB- -LRB-) (NP (NNP Hamish) (NNP Hamilton)) (-RRB- -RRB-))) (PP (PP (IN by) (NP (NN Zanzibar-born) (NN writer) (NNP Abdulrazak) (NNP Gurnah))) (CC and) (PP (IN Beside) (NP (NP (DT the) (NN Ocean)) (PP (IN of) (NP (NP (NP (NNP Time)) (PRN (-LRB- -LRB-) (NP (NNP John) (NNP Murray)) (-RRB- -RRB-))) (PP (IN by) (NP (NP (JJ 72-year-old) (NNP Orcadian) (NN poet) (NNP George) (NNP Mackay) (NNP Brown)) (: -) (`` `) (S (ADVP (RB frankly)) (, ,) (NP (PRP they)) (VP (VBP do) (RB n't) (VP (VB make) (NP (DT the) (NN grade))))) ('' ')))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Hamish Hamilton" type="NP">
          <tokens>
            <token id="27" string="Hamish" />
            <token id="28" string="Hamilton" />
          </tokens>
        </chunking>
        <chunking id="2" string="a philosophical fable by children 's author Jill Paton Walsh" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="philosophical" />
            <token id="16" string="fable" />
            <token id="17" string="by" />
            <token id="18" string="children" />
            <token id="19" string="'s" />
            <token id="20" string="author" />
            <token id="21" string="Jill" />
            <token id="22" string="Paton" />
            <token id="23" string="Walsh" />
          </tokens>
        </chunking>
        <chunking id="3" string="Knowledge of Angels -LRB- Green Bay -RRB- a philosophical fable by children 's author Jill Paton Walsh" type="NP">
          <tokens>
            <token id="7" string="Knowledge" />
            <token id="8" string="of" />
            <token id="9" string="Angels" />
            <token id="10" string="(" />
            <token id="11" string="Green" />
            <token id="12" string="Bay" />
            <token id="13" string=")" />
            <token id="14" string="a" />
            <token id="15" string="philosophical" />
            <token id="16" string="fable" />
            <token id="17" string="by" />
            <token id="18" string="children" />
            <token id="19" string="'s" />
            <token id="20" string="author" />
            <token id="21" string="Jill" />
            <token id="22" string="Paton" />
            <token id="23" string="Walsh" />
          </tokens>
        </chunking>
        <chunking id="4" string="Angels -LRB- Green Bay -RRB-" type="NP">
          <tokens>
            <token id="9" string="Angels" />
            <token id="10" string="(" />
            <token id="11" string="Green" />
            <token id="12" string="Bay" />
            <token id="13" string=")" />
          </tokens>
        </chunking>
        <chunking id="5" string="Angels -LRB- Green Bay -RRB- a philosophical fable by children 's author Jill Paton Walsh" type="NP">
          <tokens>
            <token id="9" string="Angels" />
            <token id="10" string="(" />
            <token id="11" string="Green" />
            <token id="12" string="Bay" />
            <token id="13" string=")" />
            <token id="14" string="a" />
            <token id="15" string="philosophical" />
            <token id="16" string="fable" />
            <token id="17" string="by" />
            <token id="18" string="children" />
            <token id="19" string="'s" />
            <token id="20" string="author" />
            <token id="21" string="Jill" />
            <token id="22" string="Paton" />
            <token id="23" string="Walsh" />
          </tokens>
        </chunking>
        <chunking id="6" string="the grade" type="NP">
          <tokens>
            <token id="60" string="the" />
            <token id="61" string="grade" />
          </tokens>
        </chunking>
        <chunking id="7" string="the other three" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="other" />
            <token id="5" string="three" />
          </tokens>
        </chunking>
        <chunking id="8" string="Zanzibar-born writer Abdulrazak Gurnah" type="NP">
          <tokens>
            <token id="31" string="Zanzibar-born" />
            <token id="32" string="writer" />
            <token id="33" string="Abdulrazak" />
            <token id="34" string="Gurnah" />
          </tokens>
        </chunking>
        <chunking id="9" string="Green Bay" type="NP">
          <tokens>
            <token id="11" string="Green" />
            <token id="12" string="Bay" />
          </tokens>
        </chunking>
        <chunking id="10" string="a philosophical fable" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="philosophical" />
            <token id="16" string="fable" />
          </tokens>
        </chunking>
        <chunking id="11" string="children 's" type="NP">
          <tokens>
            <token id="18" string="children" />
            <token id="19" string="'s" />
          </tokens>
        </chunking>
        <chunking id="12" string="Time -LRB- John Murray -RRB- by 72-year-old Orcadian poet George Mackay Brown - ` frankly , they do n't make the grade '" type="NP">
          <tokens>
            <token id="40" string="Time" />
            <token id="41" string="(" />
            <token id="42" string="John" />
            <token id="43" string="Murray" />
            <token id="44" string=")" />
            <token id="45" string="by" />
            <token id="46" string="72-year-old" />
            <token id="47" string="Orcadian" />
            <token id="48" string="poet" />
            <token id="49" string="George" />
            <token id="50" string="Mackay" />
            <token id="51" string="Brown" />
            <token id="52" string="-" />
            <token id="53" string="'" />
            <token id="54" string="frankly" />
            <token id="55" string="," />
            <token id="56" string="they" />
            <token id="57" string="do" />
            <token id="58" string="n't" />
            <token id="59" string="make" />
            <token id="60" string="the" />
            <token id="61" string="grade" />
            <token id="62" string="'" />
          </tokens>
        </chunking>
        <chunking id="13" string="Paradise" type="NP">
          <tokens>
            <token id="25" string="Paradise" />
          </tokens>
        </chunking>
        <chunking id="14" string="make the grade" type="VP">
          <tokens>
            <token id="59" string="make" />
            <token id="60" string="the" />
            <token id="61" string="grade" />
          </tokens>
        </chunking>
        <chunking id="15" string="John Murray" type="NP">
          <tokens>
            <token id="42" string="John" />
            <token id="43" string="Murray" />
          </tokens>
        </chunking>
        <chunking id="16" string="Paradise -LRB- Hamish Hamilton -RRB-" type="NP">
          <tokens>
            <token id="25" string="Paradise" />
            <token id="26" string="(" />
            <token id="27" string="Hamish" />
            <token id="28" string="Hamilton" />
            <token id="29" string=")" />
          </tokens>
        </chunking>
        <chunking id="17" string="Paradise -LRB- Hamish Hamilton -RRB- by Zanzibar-born writer Abdulrazak Gurnah and Beside the Ocean of Time -LRB- John Murray -RRB- by 72-year-old Orcadian poet George Mackay Brown - ` frankly , they do n't make the grade '" type="NP">
          <tokens>
            <token id="25" string="Paradise" />
            <token id="26" string="(" />
            <token id="27" string="Hamish" />
            <token id="28" string="Hamilton" />
            <token id="29" string=")" />
            <token id="30" string="by" />
            <token id="31" string="Zanzibar-born" />
            <token id="32" string="writer" />
            <token id="33" string="Abdulrazak" />
            <token id="34" string="Gurnah" />
            <token id="35" string="and" />
            <token id="36" string="Beside" />
            <token id="37" string="the" />
            <token id="38" string="Ocean" />
            <token id="39" string="of" />
            <token id="40" string="Time" />
            <token id="41" string="(" />
            <token id="42" string="John" />
            <token id="43" string="Murray" />
            <token id="44" string=")" />
            <token id="45" string="by" />
            <token id="46" string="72-year-old" />
            <token id="47" string="Orcadian" />
            <token id="48" string="poet" />
            <token id="49" string="George" />
            <token id="50" string="Mackay" />
            <token id="51" string="Brown" />
            <token id="52" string="-" />
            <token id="53" string="'" />
            <token id="54" string="frankly" />
            <token id="55" string="," />
            <token id="56" string="they" />
            <token id="57" string="do" />
            <token id="58" string="n't" />
            <token id="59" string="make" />
            <token id="60" string="the" />
            <token id="61" string="grade" />
            <token id="62" string="'" />
          </tokens>
        </chunking>
        <chunking id="18" string="the Ocean of Time -LRB- John Murray -RRB- by 72-year-old Orcadian poet George Mackay Brown - ` frankly , they do n't make the grade '" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="Ocean" />
            <token id="39" string="of" />
            <token id="40" string="Time" />
            <token id="41" string="(" />
            <token id="42" string="John" />
            <token id="43" string="Murray" />
            <token id="44" string=")" />
            <token id="45" string="by" />
            <token id="46" string="72-year-old" />
            <token id="47" string="Orcadian" />
            <token id="48" string="poet" />
            <token id="49" string="George" />
            <token id="50" string="Mackay" />
            <token id="51" string="Brown" />
            <token id="52" string="-" />
            <token id="53" string="'" />
            <token id="54" string="frankly" />
            <token id="55" string="," />
            <token id="56" string="they" />
            <token id="57" string="do" />
            <token id="58" string="n't" />
            <token id="59" string="make" />
            <token id="60" string="the" />
            <token id="61" string="grade" />
            <token id="62" string="'" />
          </tokens>
        </chunking>
        <chunking id="19" string="Time -LRB- John Murray -RRB-" type="NP">
          <tokens>
            <token id="40" string="Time" />
            <token id="41" string="(" />
            <token id="42" string="John" />
            <token id="43" string="Murray" />
            <token id="44" string=")" />
          </tokens>
        </chunking>
        <chunking id="20" string="Time" type="NP">
          <tokens>
            <token id="40" string="Time" />
          </tokens>
        </chunking>
        <chunking id="21" string="Knowledge" type="NP">
          <tokens>
            <token id="7" string="Knowledge" />
          </tokens>
        </chunking>
        <chunking id="22" string="Knowledge of Angels -LRB- Green Bay -RRB- a philosophical fable by children 's author Jill Paton Walsh , Paradise -LRB- Hamish Hamilton -RRB- by Zanzibar-born writer Abdulrazak Gurnah and Beside the Ocean of Time -LRB- John Murray -RRB- by 72-year-old Orcadian poet George Mackay Brown - ` frankly , they do n't make the grade '" type="NP">
          <tokens>
            <token id="7" string="Knowledge" />
            <token id="8" string="of" />
            <token id="9" string="Angels" />
            <token id="10" string="(" />
            <token id="11" string="Green" />
            <token id="12" string="Bay" />
            <token id="13" string=")" />
            <token id="14" string="a" />
            <token id="15" string="philosophical" />
            <token id="16" string="fable" />
            <token id="17" string="by" />
            <token id="18" string="children" />
            <token id="19" string="'s" />
            <token id="20" string="author" />
            <token id="21" string="Jill" />
            <token id="22" string="Paton" />
            <token id="23" string="Walsh" />
            <token id="24" string="," />
            <token id="25" string="Paradise" />
            <token id="26" string="(" />
            <token id="27" string="Hamish" />
            <token id="28" string="Hamilton" />
            <token id="29" string=")" />
            <token id="30" string="by" />
            <token id="31" string="Zanzibar-born" />
            <token id="32" string="writer" />
            <token id="33" string="Abdulrazak" />
            <token id="34" string="Gurnah" />
            <token id="35" string="and" />
            <token id="36" string="Beside" />
            <token id="37" string="the" />
            <token id="38" string="Ocean" />
            <token id="39" string="of" />
            <token id="40" string="Time" />
            <token id="41" string="(" />
            <token id="42" string="John" />
            <token id="43" string="Murray" />
            <token id="44" string=")" />
            <token id="45" string="by" />
            <token id="46" string="72-year-old" />
            <token id="47" string="Orcadian" />
            <token id="48" string="poet" />
            <token id="49" string="George" />
            <token id="50" string="Mackay" />
            <token id="51" string="Brown" />
            <token id="52" string="-" />
            <token id="53" string="'" />
            <token id="54" string="frankly" />
            <token id="55" string="," />
            <token id="56" string="they" />
            <token id="57" string="do" />
            <token id="58" string="n't" />
            <token id="59" string="make" />
            <token id="60" string="the" />
            <token id="61" string="grade" />
            <token id="62" string="'" />
          </tokens>
        </chunking>
        <chunking id="23" string="they" type="NP">
          <tokens>
            <token id="56" string="they" />
          </tokens>
        </chunking>
        <chunking id="24" string="children 's author Jill Paton Walsh" type="NP">
          <tokens>
            <token id="18" string="children" />
            <token id="19" string="'s" />
            <token id="20" string="author" />
            <token id="21" string="Jill" />
            <token id="22" string="Paton" />
            <token id="23" string="Walsh" />
          </tokens>
        </chunking>
        <chunking id="25" string="do n't make the grade" type="VP">
          <tokens>
            <token id="57" string="do" />
            <token id="58" string="n't" />
            <token id="59" string="make" />
            <token id="60" string="the" />
            <token id="61" string="grade" />
          </tokens>
        </chunking>
        <chunking id="26" string="Angels" type="NP">
          <tokens>
            <token id="9" string="Angels" />
          </tokens>
        </chunking>
        <chunking id="27" string="72-year-old Orcadian poet George Mackay Brown - ` frankly , they do n't make the grade '" type="NP">
          <tokens>
            <token id="46" string="72-year-old" />
            <token id="47" string="Orcadian" />
            <token id="48" string="poet" />
            <token id="49" string="George" />
            <token id="50" string="Mackay" />
            <token id="51" string="Brown" />
            <token id="52" string="-" />
            <token id="53" string="'" />
            <token id="54" string="frankly" />
            <token id="55" string="," />
            <token id="56" string="they" />
            <token id="57" string="do" />
            <token id="58" string="n't" />
            <token id="59" string="make" />
            <token id="60" string="the" />
            <token id="61" string="grade" />
            <token id="62" string="'" />
          </tokens>
        </chunking>
        <chunking id="28" string="the Ocean" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="Ocean" />
          </tokens>
        </chunking>
        <chunking id="29" string="72-year-old Orcadian poet George Mackay Brown" type="NP">
          <tokens>
            <token id="46" string="72-year-old" />
            <token id="47" string="Orcadian" />
            <token id="48" string="poet" />
            <token id="49" string="George" />
            <token id="50" string="Mackay" />
            <token id="51" string="Brown" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">three</governor>
          <dependent id="1">As</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">As</governor>
          <dependent id="2">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">three</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">three</governor>
          <dependent id="4">other</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">Knowledge</governor>
          <dependent id="5">three</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">Knowledge</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Angels</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">Knowledge</governor>
          <dependent id="9">Angels</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Bay</governor>
          <dependent id="11">Green</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="9">Angels</governor>
          <dependent id="12">Bay</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">fable</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">fable</governor>
          <dependent id="15">philosophical</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">Angels</governor>
          <dependent id="16">fable</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Walsh</governor>
          <dependent id="17">by</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">Walsh</governor>
          <dependent id="18">children</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">children</governor>
          <dependent id="19">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Walsh</governor>
          <dependent id="20">author</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Walsh</governor>
          <dependent id="21">Jill</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Walsh</governor>
          <dependent id="22">Paton</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">fable</governor>
          <dependent id="23">Walsh</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="7">Knowledge</governor>
          <dependent id="25">Paradise</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="25">Paradise</governor>
          <dependent id="25">Paradise</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">Hamilton</governor>
          <dependent id="27">Hamish</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="25">Paradise</governor>
          <dependent id="28">Hamilton</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">Gurnah</governor>
          <dependent id="30">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">Gurnah</governor>
          <dependent id="31">Zanzibar-born</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">Gurnah</governor>
          <dependent id="32">writer</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">Gurnah</governor>
          <dependent id="33">Abdulrazak</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">Paradise</governor>
          <dependent id="34">Gurnah</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="25">Paradise</governor>
          <dependent id="35">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">Ocean</governor>
          <dependent id="36">Beside</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">Ocean</governor>
          <dependent id="37">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">Paradise</governor>
          <dependent id="38">Ocean</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">Time</governor>
          <dependent id="39">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">Ocean</governor>
          <dependent id="40">Time</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="43">Murray</governor>
          <dependent id="42">John</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="40">Time</governor>
          <dependent id="43">Murray</dependent>
        </dependency>
        <dependency type="case">
          <governor id="51">Brown</governor>
          <dependent id="45">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="51">Brown</governor>
          <dependent id="46">72-year-old</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="51">Brown</governor>
          <dependent id="47">Orcadian</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="51">Brown</governor>
          <dependent id="48">poet</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="51">Brown</governor>
          <dependent id="49">George</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="51">Brown</governor>
          <dependent id="50">Mackay</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="40">Time</governor>
          <dependent id="51">Brown</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="59">make</governor>
          <dependent id="54">frankly</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="59">make</governor>
          <dependent id="56">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="59">make</governor>
          <dependent id="57">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="59">make</governor>
          <dependent id="58">n't</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="51">Brown</governor>
          <dependent id="59">make</dependent>
        </dependency>
        <dependency type="det">
          <governor id="61">grade</governor>
          <dependent id="60">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="59">make</governor>
          <dependent id="61">grade</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hamish Hamilton" type="PERSON" score="0.0">
          <tokens>
            <token id="27" string="Hamish" />
            <token id="28" string="Hamilton" />
          </tokens>
        </entity>
        <entity id="2" string="John Murray" type="PERSON" score="0.0">
          <tokens>
            <token id="42" string="John" />
            <token id="43" string="Murray" />
          </tokens>
        </entity>
        <entity id="3" string="72-year-old" type="DURATION" score="0.0">
          <tokens>
            <token id="46" string="72-year-old" />
          </tokens>
        </entity>
        <entity id="4" string="Green Bay" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="Green" />
            <token id="12" string="Bay" />
          </tokens>
        </entity>
        <entity id="5" string="Jill Paton Walsh" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Jill" />
            <token id="22" string="Paton" />
            <token id="23" string="Walsh" />
          </tokens>
        </entity>
        <entity id="6" string="Abdulrazak Gurnah" type="PERSON" score="0.0">
          <tokens>
            <token id="33" string="Abdulrazak" />
            <token id="34" string="Gurnah" />
          </tokens>
        </entity>
        <entity id="7" string="George Mackay Brown" type="PERSON" score="0.0">
          <tokens>
            <token id="49" string="George" />
            <token id="50" string="Mackay" />
            <token id="51" string="Brown" />
          </tokens>
        </entity>
        <entity id="8" string="Ocean of Time" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="38" string="Ocean" />
            <token id="39" string="of" />
            <token id="40" string="Time" />
          </tokens>
        </entity>
        <entity id="9" string="Orcadian" type="MISC" score="0.0">
          <tokens>
            <token id="47" string="Orcadian" />
          </tokens>
        </entity>
        <entity id="10" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="three" />
          </tokens>
        </entity>
        <entity id="11" string="Zanzibar-born" type="MISC" score="0.0">
          <tokens>
            <token id="31" string="Zanzibar-born" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>The shortlist for the Booker, the UK&amp;apost;s most hyped literary prize and one of the most lucrative, is all the more surprising in a bumper year for new fiction fulfilling the criteria - English language and non-American - for consideration for the award.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="shortlist" lemma="shortlist" stem="shortlist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="UK" lemma="UK" stem="uk" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="9" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="hyped" lemma="hyped" stem="hype" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="literary" lemma="literary" stem="literari" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="prize" lemma="prize" stem="prize" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="lucrative" lemma="lucrative" stem="lucr" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="all" lemma="all" stem="all" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="surprising" lemma="surprising" stem="surpris" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="bumper" lemma="bumper" stem="bumper" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="30" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="fiction" lemma="fiction" stem="fiction" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="fulfilling" lemma="fulfil" stem="fulfil" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="criteria" lemma="criterion" stem="criteria" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="English" lemma="english" stem="english" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="38" string="language" lemma="language" stem="languag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="non-American" lemma="non-american" stem="non-american" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="41" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="consideration" lemma="consideration" stem="consider" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="46" string="award" lemma="award" stem="award" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="47" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (DT The) (NN shortlist)) (PP (IN for) (NP (DT the) (NNP Booker)))) (, ,) (NP (NP (NP (DT the) (NNP UK) (POS 's)) (ADJP (RBS most) (JJ hyped)) (JJ literary) (NN prize)) (CC and) (NP (NP (CD one)) (PP (IN of) (NP (DT the) (ADJP (RBS most) (JJ lucrative)))))) (, ,)) (VP (VBZ is) (ADJP (ADVP (PDT all) (DT the) (RBR more)) (JJ surprising) (PP (IN in) (NP (NP (DT a) (NN bumper) (NN year)) (PP (IN for) (NP (JJ new) (NN fiction)))))) (S (VP (VBG fulfilling) (NP (NP (DT the) (NNS criteria)) (: -) (NP (NP (JJ English) (NN language)) (CC and) (NP (JJ non-American))) (: -)) (PP (IN for) (NP (NP (NN consideration)) (PP (IN for) (NP (DT the) (NN award)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="fulfilling the criteria - English language and non-American - for consideration for the award" type="VP">
          <tokens>
            <token id="33" string="fulfilling" />
            <token id="34" string="the" />
            <token id="35" string="criteria" />
            <token id="36" string="-" />
            <token id="37" string="English" />
            <token id="38" string="language" />
            <token id="39" string="and" />
            <token id="40" string="non-American" />
            <token id="41" string="-" />
            <token id="42" string="for" />
            <token id="43" string="consideration" />
            <token id="44" string="for" />
            <token id="45" string="the" />
            <token id="46" string="award" />
          </tokens>
        </chunking>
        <chunking id="2" string="one" type="NP">
          <tokens>
            <token id="15" string="one" />
          </tokens>
        </chunking>
        <chunking id="3" string="the criteria" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="criteria" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Booker" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Booker" />
          </tokens>
        </chunking>
        <chunking id="5" string="the most lucrative" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="most" />
            <token id="19" string="lucrative" />
          </tokens>
        </chunking>
        <chunking id="6" string="non-American" type="NP">
          <tokens>
            <token id="40" string="non-American" />
          </tokens>
        </chunking>
        <chunking id="7" string="the criteria - English language and non-American -" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="criteria" />
            <token id="36" string="-" />
            <token id="37" string="English" />
            <token id="38" string="language" />
            <token id="39" string="and" />
            <token id="40" string="non-American" />
            <token id="41" string="-" />
          </tokens>
        </chunking>
        <chunking id="8" string="is all the more surprising in a bumper year for new fiction fulfilling the criteria - English language and non-American - for consideration for the award" type="VP">
          <tokens>
            <token id="21" string="is" />
            <token id="22" string="all" />
            <token id="23" string="the" />
            <token id="24" string="more" />
            <token id="25" string="surprising" />
            <token id="26" string="in" />
            <token id="27" string="a" />
            <token id="28" string="bumper" />
            <token id="29" string="year" />
            <token id="30" string="for" />
            <token id="31" string="new" />
            <token id="32" string="fiction" />
            <token id="33" string="fulfilling" />
            <token id="34" string="the" />
            <token id="35" string="criteria" />
            <token id="36" string="-" />
            <token id="37" string="English" />
            <token id="38" string="language" />
            <token id="39" string="and" />
            <token id="40" string="non-American" />
            <token id="41" string="-" />
            <token id="42" string="for" />
            <token id="43" string="consideration" />
            <token id="44" string="for" />
            <token id="45" string="the" />
            <token id="46" string="award" />
          </tokens>
        </chunking>
        <chunking id="9" string="most lucrative" type="ADJP">
          <tokens>
            <token id="18" string="most" />
            <token id="19" string="lucrative" />
          </tokens>
        </chunking>
        <chunking id="10" string="a bumper year" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="bumper" />
            <token id="29" string="year" />
          </tokens>
        </chunking>
        <chunking id="11" string="The shortlist" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="shortlist" />
          </tokens>
        </chunking>
        <chunking id="12" string="a bumper year for new fiction" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="bumper" />
            <token id="29" string="year" />
            <token id="30" string="for" />
            <token id="31" string="new" />
            <token id="32" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="13" string="the UK 's most hyped literary prize" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="UK" />
            <token id="9" string="'s" />
            <token id="10" string="most" />
            <token id="11" string="hyped" />
            <token id="12" string="literary" />
            <token id="13" string="prize" />
          </tokens>
        </chunking>
        <chunking id="14" string="the UK 's most hyped literary prize and one of the most lucrative" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="UK" />
            <token id="9" string="'s" />
            <token id="10" string="most" />
            <token id="11" string="hyped" />
            <token id="12" string="literary" />
            <token id="13" string="prize" />
            <token id="14" string="and" />
            <token id="15" string="one" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="most" />
            <token id="19" string="lucrative" />
          </tokens>
        </chunking>
        <chunking id="15" string="one of the most lucrative" type="NP">
          <tokens>
            <token id="15" string="one" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="most" />
            <token id="19" string="lucrative" />
          </tokens>
        </chunking>
        <chunking id="16" string="most hyped" type="ADJP">
          <tokens>
            <token id="10" string="most" />
            <token id="11" string="hyped" />
          </tokens>
        </chunking>
        <chunking id="17" string="the UK 's" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="UK" />
            <token id="9" string="'s" />
          </tokens>
        </chunking>
        <chunking id="18" string="consideration" type="NP">
          <tokens>
            <token id="43" string="consideration" />
          </tokens>
        </chunking>
        <chunking id="19" string="The shortlist for the Booker , the UK 's most hyped literary prize and one of the most lucrative ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="shortlist" />
            <token id="3" string="for" />
            <token id="4" string="the" />
            <token id="5" string="Booker" />
            <token id="6" string="," />
            <token id="7" string="the" />
            <token id="8" string="UK" />
            <token id="9" string="'s" />
            <token id="10" string="most" />
            <token id="11" string="hyped" />
            <token id="12" string="literary" />
            <token id="13" string="prize" />
            <token id="14" string="and" />
            <token id="15" string="one" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="most" />
            <token id="19" string="lucrative" />
            <token id="20" string="," />
          </tokens>
        </chunking>
        <chunking id="20" string="all the more surprising in a bumper year for new fiction" type="ADJP">
          <tokens>
            <token id="22" string="all" />
            <token id="23" string="the" />
            <token id="24" string="more" />
            <token id="25" string="surprising" />
            <token id="26" string="in" />
            <token id="27" string="a" />
            <token id="28" string="bumper" />
            <token id="29" string="year" />
            <token id="30" string="for" />
            <token id="31" string="new" />
            <token id="32" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="21" string="consideration for the award" type="NP">
          <tokens>
            <token id="43" string="consideration" />
            <token id="44" string="for" />
            <token id="45" string="the" />
            <token id="46" string="award" />
          </tokens>
        </chunking>
        <chunking id="22" string="English language" type="NP">
          <tokens>
            <token id="37" string="English" />
            <token id="38" string="language" />
          </tokens>
        </chunking>
        <chunking id="23" string="The shortlist for the Booker" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="shortlist" />
            <token id="3" string="for" />
            <token id="4" string="the" />
            <token id="5" string="Booker" />
          </tokens>
        </chunking>
        <chunking id="24" string="new fiction" type="NP">
          <tokens>
            <token id="31" string="new" />
            <token id="32" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="25" string="the award" type="NP">
          <tokens>
            <token id="45" string="the" />
            <token id="46" string="award" />
          </tokens>
        </chunking>
        <chunking id="26" string="English language and non-American" type="NP">
          <tokens>
            <token id="37" string="English" />
            <token id="38" string="language" />
            <token id="39" string="and" />
            <token id="40" string="non-American" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">shortlist</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">surprising</governor>
          <dependent id="2">shortlist</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Booker</governor>
          <dependent id="3">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">Booker</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">shortlist</governor>
          <dependent id="5">Booker</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">UK</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">prize</governor>
          <dependent id="8">UK</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">UK</governor>
          <dependent id="9">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">hyped</governor>
          <dependent id="10">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">prize</governor>
          <dependent id="11">hyped</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">prize</governor>
          <dependent id="12">literary</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">shortlist</governor>
          <dependent id="13">prize</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">prize</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">prize</governor>
          <dependent id="15">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">lucrative</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">lucrative</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">lucrative</governor>
          <dependent id="18">most</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">one</governor>
          <dependent id="19">lucrative</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="25">surprising</governor>
          <dependent id="21">is</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="24">more</governor>
          <dependent id="22">all</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="24">more</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">surprising</governor>
          <dependent id="24">more</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="25">surprising</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">year</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">year</governor>
          <dependent id="27">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">year</governor>
          <dependent id="28">bumper</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">surprising</governor>
          <dependent id="29">year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">fiction</governor>
          <dependent id="30">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">fiction</governor>
          <dependent id="31">new</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">year</governor>
          <dependent id="32">fiction</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="25">surprising</governor>
          <dependent id="33">fulfilling</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">criteria</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="33">fulfilling</governor>
          <dependent id="35">criteria</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">language</governor>
          <dependent id="37">English</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="35">criteria</governor>
          <dependent id="38">language</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="38">language</governor>
          <dependent id="39">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="38">language</governor>
          <dependent id="40">non-American</dependent>
        </dependency>
        <dependency type="case">
          <governor id="43">consideration</governor>
          <dependent id="42">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">fulfilling</governor>
          <dependent id="43">consideration</dependent>
        </dependency>
        <dependency type="case">
          <governor id="46">award</governor>
          <dependent id="44">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="46">award</governor>
          <dependent id="45">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="43">consideration</governor>
          <dependent id="46">award</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="15" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="year" type="DURATION" score="0.0">
          <tokens>
            <token id="29" string="year" />
          </tokens>
        </entity>
        <entity id="3" string="Booker" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Booker" />
          </tokens>
        </entity>
        <entity id="4" string="UK" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="UK" />
          </tokens>
        </entity>
        <entity id="5" string="non-American" type="MISC" score="0.0">
          <tokens>
            <token id="40" string="non-American" />
          </tokens>
        </entity>
        <entity id="6" string="English" type="MISC" score="0.0">
          <tokens>
            <token id="37" string="English" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="false">
      <content>Margaret Atwood&amp;apost;s The Robber Bride seems an astonishing omission, as do new novels by Peter Ackroyd, Peter Carey, Candia McWilliam, William Trevor and Jim Crace.</content>
      <tokens>
        <token id="1" string="Margaret" lemma="Margaret" stem="margaret" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="Atwood" lemma="Atwood" stem="atwood" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Robber" lemma="Robber" stem="robber" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="6" string="Bride" lemma="bride" stem="bride" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="7" string="seems" lemma="seem" stem="seem" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="astonishing" lemma="astonishing" stem="astonish" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="omission" lemma="omission" stem="omiss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="novels" lemma="novel" stem="novel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Peter" lemma="Peter" stem="peter" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="18" string="Ackroyd" lemma="Ackroyd" stem="ackroyd" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Peter" lemma="Peter" stem="peter" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="21" string="Carey" lemma="Carey" stem="carei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Candia" lemma="Candia" stem="candia" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="24" string="McWilliam" lemma="McWilliam" stem="mcwilliam" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="William" lemma="William" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="27" string="Trevor" lemma="Trevor" stem="trevor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="28" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="Jim" lemma="Jim" stem="jim" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="30" string="Crace" lemma="Crace" stem="crace" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Margaret) (NNP Atwood) (POS 's))) (NP (DT The) (NNP Robber) (NN Bride)) (VP (VBZ seems) (NP (NP (DT an) (JJ astonishing) (NN omission)) (, ,) (SBAR (IN as) (S (VP (VBP do) (NP (JJ new) (NNS novels)) (PP (IN by) (NP (NP (NNP Peter) (NNP Ackroyd)) (, ,) (NP (NNP Peter) (NNP Carey)) (, ,) (NP (NNP Candia) (NNP McWilliam)) (, ,) (NP (NNP William) (NNP Trevor)) (CC and) (NP (NNP Jim) (NNP Crace))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="William Trevor" type="NP">
          <tokens>
            <token id="26" string="William" />
            <token id="27" string="Trevor" />
          </tokens>
        </chunking>
        <chunking id="2" string="The Robber Bride" type="NP">
          <tokens>
            <token id="4" string="The" />
            <token id="5" string="Robber" />
            <token id="6" string="Bride" />
          </tokens>
        </chunking>
        <chunking id="3" string="Peter Ackroyd , Peter Carey , Candia McWilliam , William Trevor and Jim Crace" type="NP">
          <tokens>
            <token id="17" string="Peter" />
            <token id="18" string="Ackroyd" />
            <token id="19" string="," />
            <token id="20" string="Peter" />
            <token id="21" string="Carey" />
            <token id="22" string="," />
            <token id="23" string="Candia" />
            <token id="24" string="McWilliam" />
            <token id="25" string="," />
            <token id="26" string="William" />
            <token id="27" string="Trevor" />
            <token id="28" string="and" />
            <token id="29" string="Jim" />
            <token id="30" string="Crace" />
          </tokens>
        </chunking>
        <chunking id="4" string="an astonishing omission" type="NP">
          <tokens>
            <token id="8" string="an" />
            <token id="9" string="astonishing" />
            <token id="10" string="omission" />
          </tokens>
        </chunking>
        <chunking id="5" string="Jim Crace" type="NP">
          <tokens>
            <token id="29" string="Jim" />
            <token id="30" string="Crace" />
          </tokens>
        </chunking>
        <chunking id="6" string="Candia McWilliam" type="NP">
          <tokens>
            <token id="23" string="Candia" />
            <token id="24" string="McWilliam" />
          </tokens>
        </chunking>
        <chunking id="7" string="Margaret Atwood 's" type="NP">
          <tokens>
            <token id="1" string="Margaret" />
            <token id="2" string="Atwood" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="seems an astonishing omission , as do new novels by Peter Ackroyd , Peter Carey , Candia McWilliam , William Trevor and Jim Crace" type="VP">
          <tokens>
            <token id="7" string="seems" />
            <token id="8" string="an" />
            <token id="9" string="astonishing" />
            <token id="10" string="omission" />
            <token id="11" string="," />
            <token id="12" string="as" />
            <token id="13" string="do" />
            <token id="14" string="new" />
            <token id="15" string="novels" />
            <token id="16" string="by" />
            <token id="17" string="Peter" />
            <token id="18" string="Ackroyd" />
            <token id="19" string="," />
            <token id="20" string="Peter" />
            <token id="21" string="Carey" />
            <token id="22" string="," />
            <token id="23" string="Candia" />
            <token id="24" string="McWilliam" />
            <token id="25" string="," />
            <token id="26" string="William" />
            <token id="27" string="Trevor" />
            <token id="28" string="and" />
            <token id="29" string="Jim" />
            <token id="30" string="Crace" />
          </tokens>
        </chunking>
        <chunking id="9" string="an astonishing omission , as do new novels by Peter Ackroyd , Peter Carey , Candia McWilliam , William Trevor and Jim Crace" type="NP">
          <tokens>
            <token id="8" string="an" />
            <token id="9" string="astonishing" />
            <token id="10" string="omission" />
            <token id="11" string="," />
            <token id="12" string="as" />
            <token id="13" string="do" />
            <token id="14" string="new" />
            <token id="15" string="novels" />
            <token id="16" string="by" />
            <token id="17" string="Peter" />
            <token id="18" string="Ackroyd" />
            <token id="19" string="," />
            <token id="20" string="Peter" />
            <token id="21" string="Carey" />
            <token id="22" string="," />
            <token id="23" string="Candia" />
            <token id="24" string="McWilliam" />
            <token id="25" string="," />
            <token id="26" string="William" />
            <token id="27" string="Trevor" />
            <token id="28" string="and" />
            <token id="29" string="Jim" />
            <token id="30" string="Crace" />
          </tokens>
        </chunking>
        <chunking id="10" string="do new novels by Peter Ackroyd , Peter Carey , Candia McWilliam , William Trevor and Jim Crace" type="VP">
          <tokens>
            <token id="13" string="do" />
            <token id="14" string="new" />
            <token id="15" string="novels" />
            <token id="16" string="by" />
            <token id="17" string="Peter" />
            <token id="18" string="Ackroyd" />
            <token id="19" string="," />
            <token id="20" string="Peter" />
            <token id="21" string="Carey" />
            <token id="22" string="," />
            <token id="23" string="Candia" />
            <token id="24" string="McWilliam" />
            <token id="25" string="," />
            <token id="26" string="William" />
            <token id="27" string="Trevor" />
            <token id="28" string="and" />
            <token id="29" string="Jim" />
            <token id="30" string="Crace" />
          </tokens>
        </chunking>
        <chunking id="11" string="Peter Carey" type="NP">
          <tokens>
            <token id="20" string="Peter" />
            <token id="21" string="Carey" />
          </tokens>
        </chunking>
        <chunking id="12" string="as do new novels by Peter Ackroyd , Peter Carey , Candia McWilliam , William Trevor and Jim Crace" type="SBAR">
          <tokens>
            <token id="12" string="as" />
            <token id="13" string="do" />
            <token id="14" string="new" />
            <token id="15" string="novels" />
            <token id="16" string="by" />
            <token id="17" string="Peter" />
            <token id="18" string="Ackroyd" />
            <token id="19" string="," />
            <token id="20" string="Peter" />
            <token id="21" string="Carey" />
            <token id="22" string="," />
            <token id="23" string="Candia" />
            <token id="24" string="McWilliam" />
            <token id="25" string="," />
            <token id="26" string="William" />
            <token id="27" string="Trevor" />
            <token id="28" string="and" />
            <token id="29" string="Jim" />
            <token id="30" string="Crace" />
          </tokens>
        </chunking>
        <chunking id="13" string="new novels" type="NP">
          <tokens>
            <token id="14" string="new" />
            <token id="15" string="novels" />
          </tokens>
        </chunking>
        <chunking id="14" string="Peter Ackroyd" type="NP">
          <tokens>
            <token id="17" string="Peter" />
            <token id="18" string="Ackroyd" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Atwood</governor>
          <dependent id="1">Margaret</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">seems</governor>
          <dependent id="2">Atwood</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Atwood</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">Bride</governor>
          <dependent id="4">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Bride</governor>
          <dependent id="5">Robber</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">seems</governor>
          <dependent id="6">Bride</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">seems</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">omission</governor>
          <dependent id="8">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">omission</governor>
          <dependent id="9">astonishing</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">seems</governor>
          <dependent id="10">omission</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">do</governor>
          <dependent id="12">as</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">omission</governor>
          <dependent id="13">do</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">novels</governor>
          <dependent id="14">new</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">do</governor>
          <dependent id="15">novels</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Ackroyd</governor>
          <dependent id="16">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Ackroyd</governor>
          <dependent id="17">Peter</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">do</governor>
          <dependent id="18">Ackroyd</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Carey</governor>
          <dependent id="20">Peter</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">Ackroyd</governor>
          <dependent id="21">Carey</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">McWilliam</governor>
          <dependent id="23">Candia</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">Ackroyd</governor>
          <dependent id="24">McWilliam</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Trevor</governor>
          <dependent id="26">William</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">Ackroyd</governor>
          <dependent id="27">Trevor</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">Ackroyd</governor>
          <dependent id="28">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">Crace</governor>
          <dependent id="29">Jim</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">Ackroyd</governor>
          <dependent id="30">Crace</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="William Trevor" type="PERSON" score="0.0">
          <tokens>
            <token id="26" string="William" />
            <token id="27" string="Trevor" />
          </tokens>
        </entity>
        <entity id="2" string="Peter Carey" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Peter" />
            <token id="21" string="Carey" />
          </tokens>
        </entity>
        <entity id="3" string="Jim Crace" type="PERSON" score="0.0">
          <tokens>
            <token id="29" string="Jim" />
            <token id="30" string="Crace" />
          </tokens>
        </entity>
        <entity id="4" string="Robber Bride" type="MISC" score="0.0">
          <tokens>
            <token id="5" string="Robber" />
            <token id="6" string="Bride" />
          </tokens>
        </entity>
        <entity id="5" string="Peter Ackroyd" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Peter" />
            <token id="18" string="Ackroyd" />
          </tokens>
        </entity>
        <entity id="6" string="Margaret Atwood" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Margaret" />
            <token id="2" string="Atwood" />
          </tokens>
        </entity>
        <entity id="7" string="Candia McWilliam" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Candia" />
            <token id="24" string="McWilliam" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>But if the shortlist of the final six candidates for the prize may be disappointing, the traditional controversy surrounding the award is as rife as ever.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="shortlist" lemma="shortlist" stem="shortlist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="final" lemma="final" stem="final" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="9" string="candidates" lemma="candidate" stem="candid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="prize" lemma="prize" stem="prize" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="disappointing" lemma="disappointing" stem="disappoint" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="traditional" lemma="traditional" stem="tradit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="controversy" lemma="controversy" stem="controversi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="surrounding" lemma="surround" stem="surround" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="award" lemma="award" stem="award" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="rife" lemma="rife" stem="rife" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="ever" lemma="ever" stem="ever" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (SBAR (IN if) (S (NP (NP (DT the) (NN shortlist)) (PP (IN of) (NP (NP (DT the) (JJ final) (CD six) (NNS candidates)) (PP (IN for) (NP (DT the) (NN prize)))))) (VP (MD may) (VP (VB be) (ADJP (JJ disappointing)))))) (, ,) (NP (NP (DT the) (JJ traditional) (NN controversy)) (VP (VBG surrounding) (NP (DT the) (NN award)))) (VP (VBZ is) (ADJP (IN as) (JJ rife) (PP (IN as) (ADVP (RB ever))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the traditional controversy surrounding the award" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="traditional" />
            <token id="19" string="controversy" />
            <token id="20" string="surrounding" />
            <token id="21" string="the" />
            <token id="22" string="award" />
          </tokens>
        </chunking>
        <chunking id="2" string="be disappointing" type="VP">
          <tokens>
            <token id="14" string="be" />
            <token id="15" string="disappointing" />
          </tokens>
        </chunking>
        <chunking id="3" string="as rife as ever" type="ADJP">
          <tokens>
            <token id="24" string="as" />
            <token id="25" string="rife" />
            <token id="26" string="as" />
            <token id="27" string="ever" />
          </tokens>
        </chunking>
        <chunking id="4" string="the prize" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="prize" />
          </tokens>
        </chunking>
        <chunking id="5" string="surrounding the award" type="VP">
          <tokens>
            <token id="20" string="surrounding" />
            <token id="21" string="the" />
            <token id="22" string="award" />
          </tokens>
        </chunking>
        <chunking id="6" string="may be disappointing" type="VP">
          <tokens>
            <token id="13" string="may" />
            <token id="14" string="be" />
            <token id="15" string="disappointing" />
          </tokens>
        </chunking>
        <chunking id="7" string="the traditional controversy" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="traditional" />
            <token id="19" string="controversy" />
          </tokens>
        </chunking>
        <chunking id="8" string="the shortlist" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="shortlist" />
          </tokens>
        </chunking>
        <chunking id="9" string="the award" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="award" />
          </tokens>
        </chunking>
        <chunking id="10" string="the shortlist of the final six candidates for the prize" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="shortlist" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="final" />
            <token id="8" string="six" />
            <token id="9" string="candidates" />
            <token id="10" string="for" />
            <token id="11" string="the" />
            <token id="12" string="prize" />
          </tokens>
        </chunking>
        <chunking id="11" string="if the shortlist of the final six candidates for the prize may be disappointing" type="SBAR">
          <tokens>
            <token id="2" string="if" />
            <token id="3" string="the" />
            <token id="4" string="shortlist" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="final" />
            <token id="8" string="six" />
            <token id="9" string="candidates" />
            <token id="10" string="for" />
            <token id="11" string="the" />
            <token id="12" string="prize" />
            <token id="13" string="may" />
            <token id="14" string="be" />
            <token id="15" string="disappointing" />
          </tokens>
        </chunking>
        <chunking id="12" string="the final six candidates for the prize" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="final" />
            <token id="8" string="six" />
            <token id="9" string="candidates" />
            <token id="10" string="for" />
            <token id="11" string="the" />
            <token id="12" string="prize" />
          </tokens>
        </chunking>
        <chunking id="13" string="disappointing" type="ADJP">
          <tokens>
            <token id="15" string="disappointing" />
          </tokens>
        </chunking>
        <chunking id="14" string="is as rife as ever" type="VP">
          <tokens>
            <token id="23" string="is" />
            <token id="24" string="as" />
            <token id="25" string="rife" />
            <token id="26" string="as" />
            <token id="27" string="ever" />
          </tokens>
        </chunking>
        <chunking id="15" string="the final six candidates" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="final" />
            <token id="8" string="six" />
            <token id="9" string="candidates" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="25">rife</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">disappointing</governor>
          <dependent id="2">if</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">shortlist</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">disappointing</governor>
          <dependent id="4">shortlist</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">candidates</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">candidates</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">candidates</governor>
          <dependent id="7">final</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">candidates</governor>
          <dependent id="8">six</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">shortlist</governor>
          <dependent id="9">candidates</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">prize</governor>
          <dependent id="10">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">prize</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">candidates</governor>
          <dependent id="12">prize</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">disappointing</governor>
          <dependent id="13">may</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">disappointing</governor>
          <dependent id="14">be</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="25">rife</governor>
          <dependent id="15">disappointing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">controversy</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">controversy</governor>
          <dependent id="18">traditional</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">rife</governor>
          <dependent id="19">controversy</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="19">controversy</governor>
          <dependent id="20">surrounding</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">award</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">surrounding</governor>
          <dependent id="22">award</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="25">rife</governor>
          <dependent id="23">is</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="25">rife</governor>
          <dependent id="24">as</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="25">rife</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">ever</governor>
          <dependent id="26">as</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="25">rife</governor>
          <dependent id="27">ever</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="six" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>One unsurprising omission from the final selection was When The World Was Steady, a first novel by Claire Messud, which was on the &amp;apost;long list&amp;apost; before it was pointed out that the author was the wife of James Wood, chief literary reviewer of The Guardian newspaper and a Booker judge.</content>
      <tokens>
        <token id="1" string="One" lemma="one" stem="one" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="2" string="unsurprising" lemma="unsurprising" stem="unsurpris" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="omission" lemma="omission" stem="omiss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="final" lemma="final" stem="final" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="selection" lemma="selection" stem="select" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="World" lemma="World" stem="world" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="12" string="Was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="13" string="Steady" lemma="Steady" stem="steadi" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="17" string="novel" lemma="novel" stem="novel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Claire" lemma="Claire" stem="clair" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="20" string="Messud" lemma="Messud" stem="messud" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="long" lemma="long" stem="long" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string="list" lemma="list" stem="list" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="pointed" lemma="point" stem="point" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="author" lemma="author" stem="author" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="wife" lemma="wife" stem="wife" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="James" lemma="James" stem="jame" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="43" string="Wood" lemma="Wood" stem="wood" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="44" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="chief" lemma="chief" stem="chief" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="literary" lemma="literary" stem="literari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="reviewer" lemma="reviewer" stem="review" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="50" string="Guardian" lemma="Guardian" stem="guardian" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="51" string="newspaper" lemma="newspaper" stem="newspap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="52" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="53" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="54" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="55" string="judge" lemma="judge" stem="judg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="56" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (CD One) (JJ unsurprising) (NN omission)) (PP (IN from) (NP (DT the) (JJ final) (NN selection)))) (VP (VBD was) (SBAR (WHADVP (WRB When)) (S (NP (DT The) (NNP World)) (VP (VBD Was) (NP (NP (NNP Steady)) (, ,) (NP (NP (DT a) (JJ first) (NN novel)) (PP (IN by) (NP (NNP Claire) (NNP Messud)))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBD was) (PP (IN on) (NP (DT the) (`` `) (JJ long) (NN list) ('' '))) (SBAR (IN before) (S (NP (PRP it)) (VP (VBD was) (VP (VBN pointed) (PRT (RP out)) (SBAR (IN that) (S (NP (DT the) (NN author)) (VP (VBD was) (NP (NP (DT the) (NN wife)) (PP (IN of) (NP (NP (NNP James) (NNP Wood)) (, ,) (NP (NP (JJ chief) (JJ literary) (NN reviewer)) (PP (IN of) (NP (DT The) (NNP Guardian) (NN newspaper)))) (CC and) (NP (DT a) (NNP Booker) (NN judge)))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The Guardian newspaper" type="NP">
          <tokens>
            <token id="49" string="The" />
            <token id="50" string="Guardian" />
            <token id="51" string="newspaper" />
          </tokens>
        </chunking>
        <chunking id="2" string="was on the ` long list ' before it was pointed out that the author was the wife of James Wood , chief literary reviewer of The Guardian newspaper and a Booker judge" type="VP">
          <tokens>
            <token id="23" string="was" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="'" />
            <token id="27" string="long" />
            <token id="28" string="list" />
            <token id="29" string="'" />
            <token id="30" string="before" />
            <token id="31" string="it" />
            <token id="32" string="was" />
            <token id="33" string="pointed" />
            <token id="34" string="out" />
            <token id="35" string="that" />
            <token id="36" string="the" />
            <token id="37" string="author" />
            <token id="38" string="was" />
            <token id="39" string="the" />
            <token id="40" string="wife" />
            <token id="41" string="of" />
            <token id="42" string="James" />
            <token id="43" string="Wood" />
            <token id="44" string="," />
            <token id="45" string="chief" />
            <token id="46" string="literary" />
            <token id="47" string="reviewer" />
            <token id="48" string="of" />
            <token id="49" string="The" />
            <token id="50" string="Guardian" />
            <token id="51" string="newspaper" />
            <token id="52" string="and" />
            <token id="53" string="a" />
            <token id="54" string="Booker" />
            <token id="55" string="judge" />
          </tokens>
        </chunking>
        <chunking id="3" string="a first novel" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="first" />
            <token id="17" string="novel" />
          </tokens>
        </chunking>
        <chunking id="4" string="that the author was the wife of James Wood , chief literary reviewer of The Guardian newspaper and a Booker judge" type="SBAR">
          <tokens>
            <token id="35" string="that" />
            <token id="36" string="the" />
            <token id="37" string="author" />
            <token id="38" string="was" />
            <token id="39" string="the" />
            <token id="40" string="wife" />
            <token id="41" string="of" />
            <token id="42" string="James" />
            <token id="43" string="Wood" />
            <token id="44" string="," />
            <token id="45" string="chief" />
            <token id="46" string="literary" />
            <token id="47" string="reviewer" />
            <token id="48" string="of" />
            <token id="49" string="The" />
            <token id="50" string="Guardian" />
            <token id="51" string="newspaper" />
            <token id="52" string="and" />
            <token id="53" string="a" />
            <token id="54" string="Booker" />
            <token id="55" string="judge" />
          </tokens>
        </chunking>
        <chunking id="5" string="Claire Messud" type="NP">
          <tokens>
            <token id="19" string="Claire" />
            <token id="20" string="Messud" />
          </tokens>
        </chunking>
        <chunking id="6" string="the final selection" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="final" />
            <token id="7" string="selection" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="31" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="pointed out that the author was the wife of James Wood , chief literary reviewer of The Guardian newspaper and a Booker judge" type="VP">
          <tokens>
            <token id="33" string="pointed" />
            <token id="34" string="out" />
            <token id="35" string="that" />
            <token id="36" string="the" />
            <token id="37" string="author" />
            <token id="38" string="was" />
            <token id="39" string="the" />
            <token id="40" string="wife" />
            <token id="41" string="of" />
            <token id="42" string="James" />
            <token id="43" string="Wood" />
            <token id="44" string="," />
            <token id="45" string="chief" />
            <token id="46" string="literary" />
            <token id="47" string="reviewer" />
            <token id="48" string="of" />
            <token id="49" string="The" />
            <token id="50" string="Guardian" />
            <token id="51" string="newspaper" />
            <token id="52" string="and" />
            <token id="53" string="a" />
            <token id="54" string="Booker" />
            <token id="55" string="judge" />
          </tokens>
        </chunking>
        <chunking id="9" string="Steady , a first novel by Claire Messud , which was on the ` long list ' before it was pointed out that the author was the wife of James Wood , chief literary reviewer of The Guardian newspaper and a Booker judge" type="NP">
          <tokens>
            <token id="13" string="Steady" />
            <token id="14" string="," />
            <token id="15" string="a" />
            <token id="16" string="first" />
            <token id="17" string="novel" />
            <token id="18" string="by" />
            <token id="19" string="Claire" />
            <token id="20" string="Messud" />
            <token id="21" string="," />
            <token id="22" string="which" />
            <token id="23" string="was" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="'" />
            <token id="27" string="long" />
            <token id="28" string="list" />
            <token id="29" string="'" />
            <token id="30" string="before" />
            <token id="31" string="it" />
            <token id="32" string="was" />
            <token id="33" string="pointed" />
            <token id="34" string="out" />
            <token id="35" string="that" />
            <token id="36" string="the" />
            <token id="37" string="author" />
            <token id="38" string="was" />
            <token id="39" string="the" />
            <token id="40" string="wife" />
            <token id="41" string="of" />
            <token id="42" string="James" />
            <token id="43" string="Wood" />
            <token id="44" string="," />
            <token id="45" string="chief" />
            <token id="46" string="literary" />
            <token id="47" string="reviewer" />
            <token id="48" string="of" />
            <token id="49" string="The" />
            <token id="50" string="Guardian" />
            <token id="51" string="newspaper" />
            <token id="52" string="and" />
            <token id="53" string="a" />
            <token id="54" string="Booker" />
            <token id="55" string="judge" />
          </tokens>
        </chunking>
        <chunking id="10" string="When The World Was Steady , a first novel by Claire Messud , which was on the ` long list ' before it was pointed out that the author was the wife of James Wood , chief literary reviewer of The Guardian newspaper and a Booker judge" type="SBAR">
          <tokens>
            <token id="9" string="When" />
            <token id="10" string="The" />
            <token id="11" string="World" />
            <token id="12" string="Was" />
            <token id="13" string="Steady" />
            <token id="14" string="," />
            <token id="15" string="a" />
            <token id="16" string="first" />
            <token id="17" string="novel" />
            <token id="18" string="by" />
            <token id="19" string="Claire" />
            <token id="20" string="Messud" />
            <token id="21" string="," />
            <token id="22" string="which" />
            <token id="23" string="was" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="'" />
            <token id="27" string="long" />
            <token id="28" string="list" />
            <token id="29" string="'" />
            <token id="30" string="before" />
            <token id="31" string="it" />
            <token id="32" string="was" />
            <token id="33" string="pointed" />
            <token id="34" string="out" />
            <token id="35" string="that" />
            <token id="36" string="the" />
            <token id="37" string="author" />
            <token id="38" string="was" />
            <token id="39" string="the" />
            <token id="40" string="wife" />
            <token id="41" string="of" />
            <token id="42" string="James" />
            <token id="43" string="Wood" />
            <token id="44" string="," />
            <token id="45" string="chief" />
            <token id="46" string="literary" />
            <token id="47" string="reviewer" />
            <token id="48" string="of" />
            <token id="49" string="The" />
            <token id="50" string="Guardian" />
            <token id="51" string="newspaper" />
            <token id="52" string="and" />
            <token id="53" string="a" />
            <token id="54" string="Booker" />
            <token id="55" string="judge" />
          </tokens>
        </chunking>
        <chunking id="11" string="When" type="WHADVP">
          <tokens>
            <token id="9" string="When" />
          </tokens>
        </chunking>
        <chunking id="12" string="chief literary reviewer" type="NP">
          <tokens>
            <token id="45" string="chief" />
            <token id="46" string="literary" />
            <token id="47" string="reviewer" />
          </tokens>
        </chunking>
        <chunking id="13" string="was the wife of James Wood , chief literary reviewer of The Guardian newspaper and a Booker judge" type="VP">
          <tokens>
            <token id="38" string="was" />
            <token id="39" string="the" />
            <token id="40" string="wife" />
            <token id="41" string="of" />
            <token id="42" string="James" />
            <token id="43" string="Wood" />
            <token id="44" string="," />
            <token id="45" string="chief" />
            <token id="46" string="literary" />
            <token id="47" string="reviewer" />
            <token id="48" string="of" />
            <token id="49" string="The" />
            <token id="50" string="Guardian" />
            <token id="51" string="newspaper" />
            <token id="52" string="and" />
            <token id="53" string="a" />
            <token id="54" string="Booker" />
            <token id="55" string="judge" />
          </tokens>
        </chunking>
        <chunking id="14" string="which was on the ` long list ' before it was pointed out that the author was the wife of James Wood , chief literary reviewer of The Guardian newspaper and a Booker judge" type="SBAR">
          <tokens>
            <token id="22" string="which" />
            <token id="23" string="was" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="'" />
            <token id="27" string="long" />
            <token id="28" string="list" />
            <token id="29" string="'" />
            <token id="30" string="before" />
            <token id="31" string="it" />
            <token id="32" string="was" />
            <token id="33" string="pointed" />
            <token id="34" string="out" />
            <token id="35" string="that" />
            <token id="36" string="the" />
            <token id="37" string="author" />
            <token id="38" string="was" />
            <token id="39" string="the" />
            <token id="40" string="wife" />
            <token id="41" string="of" />
            <token id="42" string="James" />
            <token id="43" string="Wood" />
            <token id="44" string="," />
            <token id="45" string="chief" />
            <token id="46" string="literary" />
            <token id="47" string="reviewer" />
            <token id="48" string="of" />
            <token id="49" string="The" />
            <token id="50" string="Guardian" />
            <token id="51" string="newspaper" />
            <token id="52" string="and" />
            <token id="53" string="a" />
            <token id="54" string="Booker" />
            <token id="55" string="judge" />
          </tokens>
        </chunking>
        <chunking id="15" string="the wife of James Wood , chief literary reviewer of The Guardian newspaper and a Booker judge" type="NP">
          <tokens>
            <token id="39" string="the" />
            <token id="40" string="wife" />
            <token id="41" string="of" />
            <token id="42" string="James" />
            <token id="43" string="Wood" />
            <token id="44" string="," />
            <token id="45" string="chief" />
            <token id="46" string="literary" />
            <token id="47" string="reviewer" />
            <token id="48" string="of" />
            <token id="49" string="The" />
            <token id="50" string="Guardian" />
            <token id="51" string="newspaper" />
            <token id="52" string="and" />
            <token id="53" string="a" />
            <token id="54" string="Booker" />
            <token id="55" string="judge" />
          </tokens>
        </chunking>
        <chunking id="16" string="the wife" type="NP">
          <tokens>
            <token id="39" string="the" />
            <token id="40" string="wife" />
          </tokens>
        </chunking>
        <chunking id="17" string="The World" type="NP">
          <tokens>
            <token id="10" string="The" />
            <token id="11" string="World" />
          </tokens>
        </chunking>
        <chunking id="18" string="One unsurprising omission" type="NP">
          <tokens>
            <token id="1" string="One" />
            <token id="2" string="unsurprising" />
            <token id="3" string="omission" />
          </tokens>
        </chunking>
        <chunking id="19" string="Steady" type="NP">
          <tokens>
            <token id="13" string="Steady" />
          </tokens>
        </chunking>
        <chunking id="20" string="the author" type="NP">
          <tokens>
            <token id="36" string="the" />
            <token id="37" string="author" />
          </tokens>
        </chunking>
        <chunking id="21" string="chief literary reviewer of The Guardian newspaper" type="NP">
          <tokens>
            <token id="45" string="chief" />
            <token id="46" string="literary" />
            <token id="47" string="reviewer" />
            <token id="48" string="of" />
            <token id="49" string="The" />
            <token id="50" string="Guardian" />
            <token id="51" string="newspaper" />
          </tokens>
        </chunking>
        <chunking id="22" string="before it was pointed out that the author was the wife of James Wood , chief literary reviewer of The Guardian newspaper and a Booker judge" type="SBAR">
          <tokens>
            <token id="30" string="before" />
            <token id="31" string="it" />
            <token id="32" string="was" />
            <token id="33" string="pointed" />
            <token id="34" string="out" />
            <token id="35" string="that" />
            <token id="36" string="the" />
            <token id="37" string="author" />
            <token id="38" string="was" />
            <token id="39" string="the" />
            <token id="40" string="wife" />
            <token id="41" string="of" />
            <token id="42" string="James" />
            <token id="43" string="Wood" />
            <token id="44" string="," />
            <token id="45" string="chief" />
            <token id="46" string="literary" />
            <token id="47" string="reviewer" />
            <token id="48" string="of" />
            <token id="49" string="The" />
            <token id="50" string="Guardian" />
            <token id="51" string="newspaper" />
            <token id="52" string="and" />
            <token id="53" string="a" />
            <token id="54" string="Booker" />
            <token id="55" string="judge" />
          </tokens>
        </chunking>
        <chunking id="23" string="a first novel by Claire Messud" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="first" />
            <token id="17" string="novel" />
            <token id="18" string="by" />
            <token id="19" string="Claire" />
            <token id="20" string="Messud" />
          </tokens>
        </chunking>
        <chunking id="24" string="was When The World Was Steady , a first novel by Claire Messud , which was on the ` long list ' before it was pointed out that the author was the wife of James Wood , chief literary reviewer of The Guardian newspaper and a Booker judge" type="VP">
          <tokens>
            <token id="8" string="was" />
            <token id="9" string="When" />
            <token id="10" string="The" />
            <token id="11" string="World" />
            <token id="12" string="Was" />
            <token id="13" string="Steady" />
            <token id="14" string="," />
            <token id="15" string="a" />
            <token id="16" string="first" />
            <token id="17" string="novel" />
            <token id="18" string="by" />
            <token id="19" string="Claire" />
            <token id="20" string="Messud" />
            <token id="21" string="," />
            <token id="22" string="which" />
            <token id="23" string="was" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="'" />
            <token id="27" string="long" />
            <token id="28" string="list" />
            <token id="29" string="'" />
            <token id="30" string="before" />
            <token id="31" string="it" />
            <token id="32" string="was" />
            <token id="33" string="pointed" />
            <token id="34" string="out" />
            <token id="35" string="that" />
            <token id="36" string="the" />
            <token id="37" string="author" />
            <token id="38" string="was" />
            <token id="39" string="the" />
            <token id="40" string="wife" />
            <token id="41" string="of" />
            <token id="42" string="James" />
            <token id="43" string="Wood" />
            <token id="44" string="," />
            <token id="45" string="chief" />
            <token id="46" string="literary" />
            <token id="47" string="reviewer" />
            <token id="48" string="of" />
            <token id="49" string="The" />
            <token id="50" string="Guardian" />
            <token id="51" string="newspaper" />
            <token id="52" string="and" />
            <token id="53" string="a" />
            <token id="54" string="Booker" />
            <token id="55" string="judge" />
          </tokens>
        </chunking>
        <chunking id="25" string="James Wood" type="NP">
          <tokens>
            <token id="42" string="James" />
            <token id="43" string="Wood" />
          </tokens>
        </chunking>
        <chunking id="26" string="was pointed out that the author was the wife of James Wood , chief literary reviewer of The Guardian newspaper and a Booker judge" type="VP">
          <tokens>
            <token id="32" string="was" />
            <token id="33" string="pointed" />
            <token id="34" string="out" />
            <token id="35" string="that" />
            <token id="36" string="the" />
            <token id="37" string="author" />
            <token id="38" string="was" />
            <token id="39" string="the" />
            <token id="40" string="wife" />
            <token id="41" string="of" />
            <token id="42" string="James" />
            <token id="43" string="Wood" />
            <token id="44" string="," />
            <token id="45" string="chief" />
            <token id="46" string="literary" />
            <token id="47" string="reviewer" />
            <token id="48" string="of" />
            <token id="49" string="The" />
            <token id="50" string="Guardian" />
            <token id="51" string="newspaper" />
            <token id="52" string="and" />
            <token id="53" string="a" />
            <token id="54" string="Booker" />
            <token id="55" string="judge" />
          </tokens>
        </chunking>
        <chunking id="27" string="the ` long list '" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="'" />
            <token id="27" string="long" />
            <token id="28" string="list" />
            <token id="29" string="'" />
          </tokens>
        </chunking>
        <chunking id="28" string="James Wood , chief literary reviewer of The Guardian newspaper and a Booker judge" type="NP">
          <tokens>
            <token id="42" string="James" />
            <token id="43" string="Wood" />
            <token id="44" string="," />
            <token id="45" string="chief" />
            <token id="46" string="literary" />
            <token id="47" string="reviewer" />
            <token id="48" string="of" />
            <token id="49" string="The" />
            <token id="50" string="Guardian" />
            <token id="51" string="newspaper" />
            <token id="52" string="and" />
            <token id="53" string="a" />
            <token id="54" string="Booker" />
            <token id="55" string="judge" />
          </tokens>
        </chunking>
        <chunking id="29" string="a Booker judge" type="NP">
          <tokens>
            <token id="53" string="a" />
            <token id="54" string="Booker" />
            <token id="55" string="judge" />
          </tokens>
        </chunking>
        <chunking id="30" string="One unsurprising omission from the final selection" type="NP">
          <tokens>
            <token id="1" string="One" />
            <token id="2" string="unsurprising" />
            <token id="3" string="omission" />
            <token id="4" string="from" />
            <token id="5" string="the" />
            <token id="6" string="final" />
            <token id="7" string="selection" />
          </tokens>
        </chunking>
        <chunking id="31" string="Was Steady , a first novel by Claire Messud , which was on the ` long list ' before it was pointed out that the author was the wife of James Wood , chief literary reviewer of The Guardian newspaper and a Booker judge" type="VP">
          <tokens>
            <token id="12" string="Was" />
            <token id="13" string="Steady" />
            <token id="14" string="," />
            <token id="15" string="a" />
            <token id="16" string="first" />
            <token id="17" string="novel" />
            <token id="18" string="by" />
            <token id="19" string="Claire" />
            <token id="20" string="Messud" />
            <token id="21" string="," />
            <token id="22" string="which" />
            <token id="23" string="was" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="'" />
            <token id="27" string="long" />
            <token id="28" string="list" />
            <token id="29" string="'" />
            <token id="30" string="before" />
            <token id="31" string="it" />
            <token id="32" string="was" />
            <token id="33" string="pointed" />
            <token id="34" string="out" />
            <token id="35" string="that" />
            <token id="36" string="the" />
            <token id="37" string="author" />
            <token id="38" string="was" />
            <token id="39" string="the" />
            <token id="40" string="wife" />
            <token id="41" string="of" />
            <token id="42" string="James" />
            <token id="43" string="Wood" />
            <token id="44" string="," />
            <token id="45" string="chief" />
            <token id="46" string="literary" />
            <token id="47" string="reviewer" />
            <token id="48" string="of" />
            <token id="49" string="The" />
            <token id="50" string="Guardian" />
            <token id="51" string="newspaper" />
            <token id="52" string="and" />
            <token id="53" string="a" />
            <token id="54" string="Booker" />
            <token id="55" string="judge" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nummod">
          <governor id="3">omission</governor>
          <dependent id="1">One</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">omission</governor>
          <dependent id="2">unsurprising</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">was</governor>
          <dependent id="3">omission</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">selection</governor>
          <dependent id="4">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">selection</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">selection</governor>
          <dependent id="6">final</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">omission</governor>
          <dependent id="7">selection</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">Steady</governor>
          <dependent id="9">When</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">World</governor>
          <dependent id="10">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">Steady</governor>
          <dependent id="11">World</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">Steady</governor>
          <dependent id="12">Was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">was</governor>
          <dependent id="13">Steady</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">novel</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">novel</governor>
          <dependent id="16">first</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="13">Steady</governor>
          <dependent id="17">novel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Messud</governor>
          <dependent id="18">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Messud</governor>
          <dependent id="19">Claire</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">novel</governor>
          <dependent id="20">Messud</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">list</governor>
          <dependent id="22">which</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="28">list</governor>
          <dependent id="23">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">list</governor>
          <dependent id="24">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">list</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">list</governor>
          <dependent id="27">long</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">Steady</governor>
          <dependent id="28">list</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="33">pointed</governor>
          <dependent id="30">before</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="33">pointed</governor>
          <dependent id="31">it</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="33">pointed</governor>
          <dependent id="32">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="28">list</governor>
          <dependent id="33">pointed</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="33">pointed</governor>
          <dependent id="34">out</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="40">wife</governor>
          <dependent id="35">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">author</governor>
          <dependent id="36">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="40">wife</governor>
          <dependent id="37">author</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="40">wife</governor>
          <dependent id="38">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="40">wife</governor>
          <dependent id="39">the</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="33">pointed</governor>
          <dependent id="40">wife</dependent>
        </dependency>
        <dependency type="case">
          <governor id="43">Wood</governor>
          <dependent id="41">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="43">Wood</governor>
          <dependent id="42">James</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="40">wife</governor>
          <dependent id="43">Wood</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="47">reviewer</governor>
          <dependent id="45">chief</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="47">reviewer</governor>
          <dependent id="46">literary</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="43">Wood</governor>
          <dependent id="47">reviewer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="51">newspaper</governor>
          <dependent id="48">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="51">newspaper</governor>
          <dependent id="49">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="51">newspaper</governor>
          <dependent id="50">Guardian</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="47">reviewer</governor>
          <dependent id="51">newspaper</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="43">Wood</governor>
          <dependent id="52">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="55">judge</governor>
          <dependent id="53">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="55">judge</governor>
          <dependent id="54">Booker</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="43">Wood</governor>
          <dependent id="55">judge</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="16" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="One" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="One" />
          </tokens>
        </entity>
        <entity id="3" string="Booker" type="MISC" score="0.0">
          <tokens>
            <token id="54" string="Booker" />
          </tokens>
        </entity>
        <entity id="4" string="World Was Steady" type="MISC" score="0.0">
          <tokens>
            <token id="11" string="World" />
            <token id="12" string="Was" />
            <token id="13" string="Steady" />
          </tokens>
        </entity>
        <entity id="5" string="Claire Messud" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Claire" />
            <token id="20" string="Messud" />
          </tokens>
        </entity>
        <entity id="6" string="The Guardian" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="49" string="The" />
            <token id="50" string="Guardian" />
          </tokens>
        </entity>
        <entity id="7" string="James Wood" type="PERSON" score="0.0">
          <tokens>
            <token id="42" string="James" />
            <token id="43" string="Wood" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Professor John Bayley, chairman of the Booker panel and husband of former Booker Prize winner Dame Iris Murdoch, expressed surprise at Mr Wood&amp;apost;s failure to reveal his relationship with Ms Messud.</content>
      <tokens>
        <token id="1" string="Professor" lemma="Professor" stem="professor" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="2" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Bayley" lemma="Bayley" stem="baylei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="chairman" lemma="chairman" stem="chairman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="9" string="panel" lemma="panel" stem="panel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="husband" lemma="husband" stem="husband" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="15" string="Prize" lemma="Prize" stem="prize" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="16" string="winner" lemma="winner" stem="winner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="Dame" lemma="Dame" stem="dame" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="18" string="Iris" lemma="Iris" stem="iri" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="19" string="Murdoch" lemma="Murdoch" stem="murdoch" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="expressed" lemma="express" stem="express" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="surprise" lemma="surprise" stem="surpris" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Mr" lemma="Mr" stem="mr" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="Wood" lemma="Wood" stem="wood" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="26" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="failure" lemma="failure" stem="failur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="reveal" lemma="reveal" stem="reveal" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="relationship" lemma="relationship" stem="relationship" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="Ms" lemma="Ms" stem="m" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="34" string="Messud" lemma="Messud" stem="messud" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Professor) (NNP John) (NNP Bayley)) (, ,) (NP (NP (NP (NN chairman)) (PP (IN of) (NP (DT the) (NNP Booker) (NN panel)))) (CC and) (NP (NP (NN husband)) (PP (IN of) (NP (JJ former) (NNP Booker) (NNP Prize) (NN winner) (NNP Dame) (NNP Iris) (NNP Murdoch))))) (, ,)) (VP (VBD expressed) (NP (NN surprise)) (PP (IN at) (NP (NP (NNP Mr) (NNP Wood) (POS 's)) (NN failure) (S (VP (TO to) (VP (VB reveal) (NP (PRP$ his) (NN relationship)) (PP (IN with) (NP (NNP Ms) (NNP Messud))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="former Booker Prize winner Dame Iris Murdoch" type="NP">
          <tokens>
            <token id="13" string="former" />
            <token id="14" string="Booker" />
            <token id="15" string="Prize" />
            <token id="16" string="winner" />
            <token id="17" string="Dame" />
            <token id="18" string="Iris" />
            <token id="19" string="Murdoch" />
          </tokens>
        </chunking>
        <chunking id="2" string="surprise" type="NP">
          <tokens>
            <token id="22" string="surprise" />
          </tokens>
        </chunking>
        <chunking id="3" string="Professor John Bayley" type="NP">
          <tokens>
            <token id="1" string="Professor" />
            <token id="2" string="John" />
            <token id="3" string="Bayley" />
          </tokens>
        </chunking>
        <chunking id="4" string="his relationship" type="NP">
          <tokens>
            <token id="30" string="his" />
            <token id="31" string="relationship" />
          </tokens>
        </chunking>
        <chunking id="5" string="expressed surprise at Mr Wood 's failure to reveal his relationship with Ms Messud" type="VP">
          <tokens>
            <token id="21" string="expressed" />
            <token id="22" string="surprise" />
            <token id="23" string="at" />
            <token id="24" string="Mr" />
            <token id="25" string="Wood" />
            <token id="26" string="'s" />
            <token id="27" string="failure" />
            <token id="28" string="to" />
            <token id="29" string="reveal" />
            <token id="30" string="his" />
            <token id="31" string="relationship" />
            <token id="32" string="with" />
            <token id="33" string="Ms" />
            <token id="34" string="Messud" />
          </tokens>
        </chunking>
        <chunking id="6" string="chairman of the Booker panel and husband of former Booker Prize winner Dame Iris Murdoch" type="NP">
          <tokens>
            <token id="5" string="chairman" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="Booker" />
            <token id="9" string="panel" />
            <token id="10" string="and" />
            <token id="11" string="husband" />
            <token id="12" string="of" />
            <token id="13" string="former" />
            <token id="14" string="Booker" />
            <token id="15" string="Prize" />
            <token id="16" string="winner" />
            <token id="17" string="Dame" />
            <token id="18" string="Iris" />
            <token id="19" string="Murdoch" />
          </tokens>
        </chunking>
        <chunking id="7" string="chairman of the Booker panel" type="NP">
          <tokens>
            <token id="5" string="chairman" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="Booker" />
            <token id="9" string="panel" />
          </tokens>
        </chunking>
        <chunking id="8" string="chairman" type="NP">
          <tokens>
            <token id="5" string="chairman" />
          </tokens>
        </chunking>
        <chunking id="9" string="husband" type="NP">
          <tokens>
            <token id="11" string="husband" />
          </tokens>
        </chunking>
        <chunking id="10" string="Mr Wood 's" type="NP">
          <tokens>
            <token id="24" string="Mr" />
            <token id="25" string="Wood" />
            <token id="26" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="Ms Messud" type="NP">
          <tokens>
            <token id="33" string="Ms" />
            <token id="34" string="Messud" />
          </tokens>
        </chunking>
        <chunking id="12" string="Mr Wood 's failure to reveal his relationship with Ms Messud" type="NP">
          <tokens>
            <token id="24" string="Mr" />
            <token id="25" string="Wood" />
            <token id="26" string="'s" />
            <token id="27" string="failure" />
            <token id="28" string="to" />
            <token id="29" string="reveal" />
            <token id="30" string="his" />
            <token id="31" string="relationship" />
            <token id="32" string="with" />
            <token id="33" string="Ms" />
            <token id="34" string="Messud" />
          </tokens>
        </chunking>
        <chunking id="13" string="to reveal his relationship with Ms Messud" type="VP">
          <tokens>
            <token id="28" string="to" />
            <token id="29" string="reveal" />
            <token id="30" string="his" />
            <token id="31" string="relationship" />
            <token id="32" string="with" />
            <token id="33" string="Ms" />
            <token id="34" string="Messud" />
          </tokens>
        </chunking>
        <chunking id="14" string="Professor John Bayley , chairman of the Booker panel and husband of former Booker Prize winner Dame Iris Murdoch ," type="NP">
          <tokens>
            <token id="1" string="Professor" />
            <token id="2" string="John" />
            <token id="3" string="Bayley" />
            <token id="4" string="," />
            <token id="5" string="chairman" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="Booker" />
            <token id="9" string="panel" />
            <token id="10" string="and" />
            <token id="11" string="husband" />
            <token id="12" string="of" />
            <token id="13" string="former" />
            <token id="14" string="Booker" />
            <token id="15" string="Prize" />
            <token id="16" string="winner" />
            <token id="17" string="Dame" />
            <token id="18" string="Iris" />
            <token id="19" string="Murdoch" />
            <token id="20" string="," />
          </tokens>
        </chunking>
        <chunking id="15" string="reveal his relationship with Ms Messud" type="VP">
          <tokens>
            <token id="29" string="reveal" />
            <token id="30" string="his" />
            <token id="31" string="relationship" />
            <token id="32" string="with" />
            <token id="33" string="Ms" />
            <token id="34" string="Messud" />
          </tokens>
        </chunking>
        <chunking id="16" string="the Booker panel" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Booker" />
            <token id="9" string="panel" />
          </tokens>
        </chunking>
        <chunking id="17" string="husband of former Booker Prize winner Dame Iris Murdoch" type="NP">
          <tokens>
            <token id="11" string="husband" />
            <token id="12" string="of" />
            <token id="13" string="former" />
            <token id="14" string="Booker" />
            <token id="15" string="Prize" />
            <token id="16" string="winner" />
            <token id="17" string="Dame" />
            <token id="18" string="Iris" />
            <token id="19" string="Murdoch" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Bayley</governor>
          <dependent id="1">Professor</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Bayley</governor>
          <dependent id="2">John</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">expressed</governor>
          <dependent id="3">Bayley</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">Bayley</governor>
          <dependent id="5">chairman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">panel</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">panel</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">panel</governor>
          <dependent id="8">Booker</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">chairman</governor>
          <dependent id="9">panel</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">chairman</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">chairman</governor>
          <dependent id="11">husband</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Murdoch</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">Murdoch</governor>
          <dependent id="13">former</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Murdoch</governor>
          <dependent id="14">Booker</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Murdoch</governor>
          <dependent id="15">Prize</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Murdoch</governor>
          <dependent id="16">winner</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Murdoch</governor>
          <dependent id="17">Dame</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Murdoch</governor>
          <dependent id="18">Iris</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">husband</governor>
          <dependent id="19">Murdoch</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">expressed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">expressed</governor>
          <dependent id="22">surprise</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">failure</governor>
          <dependent id="23">at</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Wood</governor>
          <dependent id="24">Mr</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="27">failure</governor>
          <dependent id="25">Wood</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Wood</governor>
          <dependent id="26">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">expressed</governor>
          <dependent id="27">failure</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">reveal</governor>
          <dependent id="28">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="27">failure</governor>
          <dependent id="29">reveal</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="31">relationship</governor>
          <dependent id="30">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">reveal</governor>
          <dependent id="31">relationship</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">Messud</governor>
          <dependent id="32">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">Messud</governor>
          <dependent id="33">Ms</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">reveal</governor>
          <dependent id="34">Messud</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Professor" type="TITLE" score="0.0">
          <tokens>
            <token id="1" string="Professor" />
          </tokens>
        </entity>
        <entity id="2" string="John Bayley" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="John" />
            <token id="3" string="Bayley" />
          </tokens>
        </entity>
        <entity id="3" string="Booker" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Booker" />
          </tokens>
        </entity>
        <entity id="4" string="Wood" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Wood" />
          </tokens>
        </entity>
        <entity id="5" string="Dame Iris Murdoch" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Dame" />
            <token id="18" string="Iris" />
            <token id="19" string="Murdoch" />
          </tokens>
        </entity>
        <entity id="6" string="Booker Prize" type="MISC" score="0.0">
          <tokens>
            <token id="14" string="Booker" />
            <token id="15" string="Prize" />
          </tokens>
        </entity>
        <entity id="7" string="Ms Messud" type="PERSON" score="0.0">
          <tokens>
            <token id="33" string="Ms" />
            <token id="34" string="Messud" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>But it is the final list, rather than the controversy, that discredits the award according to some critics.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="final" lemma="final" stem="final" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="list" lemma="list" stem="list" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="rather" lemma="rather" stem="rather" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="controversy" lemma="controversy" stem="controversi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="discredits" lemma="discredit" stem="discredit" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="award" lemma="award" stem="award" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="according" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="critics" lemma="critic" stem="critic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (PRP it)) (VP (VBZ is) (NP (NP (DT the) (JJ final) (NN list)) (, ,) (CONJP (RB rather) (IN than)) (NP (DT the) (NN controversy)) (, ,) (SBAR (WHNP (WDT that)) (S (VP (VBZ discredits) (NP (DT the) (NN award)) (PP (VBG according) (PP (TO to) (NP (DT some) (NNS critics))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="some critics" type="NP">
          <tokens>
            <token id="19" string="some" />
            <token id="20" string="critics" />
          </tokens>
        </chunking>
        <chunking id="2" string="the final list , rather than the controversy , that discredits the award according to some critics" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="final" />
            <token id="6" string="list" />
            <token id="7" string="," />
            <token id="8" string="rather" />
            <token id="9" string="than" />
            <token id="10" string="the" />
            <token id="11" string="controversy" />
            <token id="12" string="," />
            <token id="13" string="that" />
            <token id="14" string="discredits" />
            <token id="15" string="the" />
            <token id="16" string="award" />
            <token id="17" string="according" />
            <token id="18" string="to" />
            <token id="19" string="some" />
            <token id="20" string="critics" />
          </tokens>
        </chunking>
        <chunking id="3" string="discredits the award according to some critics" type="VP">
          <tokens>
            <token id="14" string="discredits" />
            <token id="15" string="the" />
            <token id="16" string="award" />
            <token id="17" string="according" />
            <token id="18" string="to" />
            <token id="19" string="some" />
            <token id="20" string="critics" />
          </tokens>
        </chunking>
        <chunking id="4" string="the award" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="award" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="2" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="is the final list , rather than the controversy , that discredits the award according to some critics" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="the" />
            <token id="5" string="final" />
            <token id="6" string="list" />
            <token id="7" string="," />
            <token id="8" string="rather" />
            <token id="9" string="than" />
            <token id="10" string="the" />
            <token id="11" string="controversy" />
            <token id="12" string="," />
            <token id="13" string="that" />
            <token id="14" string="discredits" />
            <token id="15" string="the" />
            <token id="16" string="award" />
            <token id="17" string="according" />
            <token id="18" string="to" />
            <token id="19" string="some" />
            <token id="20" string="critics" />
          </tokens>
        </chunking>
        <chunking id="7" string="that discredits the award according to some critics" type="SBAR">
          <tokens>
            <token id="13" string="that" />
            <token id="14" string="discredits" />
            <token id="15" string="the" />
            <token id="16" string="award" />
            <token id="17" string="according" />
            <token id="18" string="to" />
            <token id="19" string="some" />
            <token id="20" string="critics" />
          </tokens>
        </chunking>
        <chunking id="8" string="the controversy" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="controversy" />
          </tokens>
        </chunking>
        <chunking id="9" string="the final list" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="final" />
            <token id="6" string="list" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="6">list</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">list</governor>
          <dependent id="2">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">list</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">list</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">list</governor>
          <dependent id="5">final</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">list</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">list</governor>
          <dependent id="8">rather</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="8">rather</governor>
          <dependent id="9">than</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">controversy</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">list</governor>
          <dependent id="11">controversy</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">discredits</governor>
          <dependent id="13">that</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">list</governor>
          <dependent id="14">discredits</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">award</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">discredits</governor>
          <dependent id="16">award</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">critics</governor>
          <dependent id="17">according</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="17">according</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">critics</governor>
          <dependent id="19">some</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">discredits</governor>
          <dependent id="20">critics</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>&amp;apost;This list,&amp;apost; said one man of letters, &amp;apost;must have dealt a final death blow to the Booker.&amp;apost;</content>
      <tokens>
        <token id="1" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="list" lemma="list" stem="list" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="8" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="letters" lemma="letter" stem="letter" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="must" lemma="must" stem="must" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="dealt" lemma="deal" stem="dealt" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="final" lemma="final" stem="final" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="death" lemma="death" stem="death" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="blow" lemma="blow" stem="blow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` `) (NP (DT This) (NN list)) (PRN (, ,) ('' ') (SINV (VP (VBD said)) (NP (NP (CD one) (NN man)) (PP (IN of) (NP (NNS letters))))) (, ,) (`` `)) (VP (MD must) (VP (VB have) (VP (VBN dealt) (NP (DT a) (JJ final) (NN death) (NN blow)) (PP (TO to) (NP (DT the) (NNP Booker)))))) (. .) ('' ')))</syntactictree>
      <chunkings>
        <chunking id="1" string="This list" type="NP">
          <tokens>
            <token id="2" string="This" />
            <token id="3" string="list" />
          </tokens>
        </chunking>
        <chunking id="2" string="a final death blow" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="final" />
            <token id="18" string="death" />
            <token id="19" string="blow" />
          </tokens>
        </chunking>
        <chunking id="3" string="dealt a final death blow to the Booker" type="VP">
          <tokens>
            <token id="15" string="dealt" />
            <token id="16" string="a" />
            <token id="17" string="final" />
            <token id="18" string="death" />
            <token id="19" string="blow" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="Booker" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Booker" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="Booker" />
          </tokens>
        </chunking>
        <chunking id="5" string="one man" type="NP">
          <tokens>
            <token id="7" string="one" />
            <token id="8" string="man" />
          </tokens>
        </chunking>
        <chunking id="6" string="must have dealt a final death blow to the Booker" type="VP">
          <tokens>
            <token id="13" string="must" />
            <token id="14" string="have" />
            <token id="15" string="dealt" />
            <token id="16" string="a" />
            <token id="17" string="final" />
            <token id="18" string="death" />
            <token id="19" string="blow" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="Booker" />
          </tokens>
        </chunking>
        <chunking id="7" string="have dealt a final death blow to the Booker" type="VP">
          <tokens>
            <token id="14" string="have" />
            <token id="15" string="dealt" />
            <token id="16" string="a" />
            <token id="17" string="final" />
            <token id="18" string="death" />
            <token id="19" string="blow" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="Booker" />
          </tokens>
        </chunking>
        <chunking id="8" string="said" type="VP">
          <tokens>
            <token id="6" string="said" />
          </tokens>
        </chunking>
        <chunking id="9" string="one man of letters" type="NP">
          <tokens>
            <token id="7" string="one" />
            <token id="8" string="man" />
            <token id="9" string="of" />
            <token id="10" string="letters" />
          </tokens>
        </chunking>
        <chunking id="10" string="letters" type="NP">
          <tokens>
            <token id="10" string="letters" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">list</governor>
          <dependent id="2">This</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">dealt</governor>
          <dependent id="3">list</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="15">dealt</governor>
          <dependent id="6">said</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">man</governor>
          <dependent id="7">one</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">said</governor>
          <dependent id="8">man</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">letters</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">man</governor>
          <dependent id="10">letters</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">dealt</governor>
          <dependent id="13">must</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">dealt</governor>
          <dependent id="14">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">dealt</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">blow</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">blow</governor>
          <dependent id="17">final</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">blow</governor>
          <dependent id="18">death</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">dealt</governor>
          <dependent id="19">blow</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">Booker</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">Booker</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">dealt</governor>
          <dependent id="22">Booker</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="Booker" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Booker" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="false">
      <content>The winner, selected from an original 130, will be announced on October 11.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="winner" lemma="winner" stem="winner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="selected" lemma="select" stem="select" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="original" lemma="original" stem="origin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="130" lemma="130" stem="130" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="announced" lemma="announce" stem="announc" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="October" lemma="October" stem="october" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="11" lemma="11" stem="11" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN winner)) (, ,) (VP (VBN selected) (PP (IN from) (NP (DT an) (JJ original) (CD 130)))) (, ,)) (VP (MD will) (VP (VB be) (VP (VBN announced) (PP (IN on) (NP (NNP October) (CD 11)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The winner , selected from an original 130 ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="winner" />
            <token id="3" string="," />
            <token id="4" string="selected" />
            <token id="5" string="from" />
            <token id="6" string="an" />
            <token id="7" string="original" />
            <token id="8" string="130" />
            <token id="9" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="October 11" type="NP">
          <tokens>
            <token id="14" string="October" />
            <token id="15" string="11" />
          </tokens>
        </chunking>
        <chunking id="3" string="an original 130" type="NP">
          <tokens>
            <token id="6" string="an" />
            <token id="7" string="original" />
            <token id="8" string="130" />
          </tokens>
        </chunking>
        <chunking id="4" string="be announced on October 11" type="VP">
          <tokens>
            <token id="11" string="be" />
            <token id="12" string="announced" />
            <token id="13" string="on" />
            <token id="14" string="October" />
            <token id="15" string="11" />
          </tokens>
        </chunking>
        <chunking id="5" string="will be announced on October 11" type="VP">
          <tokens>
            <token id="10" string="will" />
            <token id="11" string="be" />
            <token id="12" string="announced" />
            <token id="13" string="on" />
            <token id="14" string="October" />
            <token id="15" string="11" />
          </tokens>
        </chunking>
        <chunking id="6" string="announced on October 11" type="VP">
          <tokens>
            <token id="12" string="announced" />
            <token id="13" string="on" />
            <token id="14" string="October" />
            <token id="15" string="11" />
          </tokens>
        </chunking>
        <chunking id="7" string="The winner" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="winner" />
          </tokens>
        </chunking>
        <chunking id="8" string="selected from an original 130" type="VP">
          <tokens>
            <token id="4" string="selected" />
            <token id="5" string="from" />
            <token id="6" string="an" />
            <token id="7" string="original" />
            <token id="8" string="130" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">winner</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">announced</governor>
          <dependent id="2">winner</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="2">winner</governor>
          <dependent id="4">selected</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">130</governor>
          <dependent id="5">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">130</governor>
          <dependent id="6">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">130</governor>
          <dependent id="7">original</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">selected</governor>
          <dependent id="8">130</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">announced</governor>
          <dependent id="10">will</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">announced</governor>
          <dependent id="11">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">announced</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">October</governor>
          <dependent id="13">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">announced</governor>
          <dependent id="14">October</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">October</governor>
          <dependent id="15">11</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="October 11" type="DATE" score="0.0">
          <tokens>
            <token id="14" string="October" />
            <token id="15" string="11" />
          </tokens>
        </entity>
        <entity id="2" string="130" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="130" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="1-2" string="The six" id_sentence="4" />
      <mentions>
        <mention ids_tokens="4" string="six" id_sentence="1" />
        <mention ids_tokens="8" string="six" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="8-9-10-11-12" string="20,000 Booker Prize for fiction" id_sentence="1" />
      <mentions>
        <mention ids_tokens="14-15" string="Booker Prize" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="4" type="LIST">
      <referenced ids_tokens="13-14-15" string="Chatto and Windus" id_sentence="4" />
      <mentions>
        <mention ids_tokens="56" string="they" id_sentence="5" />
      </mentions>
    </coreference>
    <coreference id="5" type="NOMINAL">
      <referenced ids_tokens="32-33-34-35-36-37-38-39" string="the initial ' long list ' of 15" id_sentence="4" />
      <mentions>
        <mention ids_tokens="25-29" string="the' long list'" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="7-8-9-10-11-12-13" string="the UK 's most hyped literary prize" id_sentence="6" />
      <mentions>
        <mention ids_tokens="11-12" string="the prize" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="14" type="NOMINAL">
      <referenced ids_tokens="4-5-6" string="the final list" id_sentence="11" />
      <mentions>
        <mention ids_tokens="2-3" string="This list" id_sentence="12" />
      </mentions>
    </coreference>
  </coreferences>
</document>
