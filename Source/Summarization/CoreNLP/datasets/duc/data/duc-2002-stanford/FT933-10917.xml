<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="FT933-10917">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>THE revelation that John Major is capable of candid, blunt and salty language when talking off-the- record to friendly journalists has surprised some people.</content>
      <tokens>
        <token id="1" string="THE" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="revelation" lemma="revelation" stem="revel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="Major" lemma="Major" stem="major" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="capable" lemma="capable" stem="capabl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="candid" lemma="candid" stem="candid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="blunt" lemma="blunt" stem="blunt" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="salty" lemma="salty" stem="salti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="language" lemma="language" stem="languag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="talking" lemma="talk" stem="talk" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="off-the" lemma="off-the" stem="off-th" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="record" lemma="record" stem="record" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="friendly" lemma="friendly" stem="friendli" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="journalists" lemma="journalist" stem="journalist" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="surprised" lemma="surprise" stem="surpris" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT THE) (NN revelation)) (SBAR (WHNP (WDT that)) (S (NP (NNP John) (NNP Major)) (VP (VBZ is) (ADJP (JJ capable) (PP (IN of) (NP (ADJP (JJ candid) (, ,) (JJ blunt) (CC and) (JJ salty)) (NN language)))) (SBAR (WHADVP (WRB when)) (S (VP (VBG talking) (UCP (ADJP (JJ off-the)) (: -) (NP (NP (NN record)) (PP (TO to) (NP (JJ friendly) (NNS journalists)))))))))))) (VP (VBZ has) (VP (VBN surprised) (NP (DT some) (NNS people)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="candid , blunt and salty" type="ADJP">
          <tokens>
            <token id="9" string="candid" />
            <token id="10" string="," />
            <token id="11" string="blunt" />
            <token id="12" string="and" />
            <token id="13" string="salty" />
          </tokens>
        </chunking>
        <chunking id="2" string="capable of candid , blunt and salty language" type="ADJP">
          <tokens>
            <token id="7" string="capable" />
            <token id="8" string="of" />
            <token id="9" string="candid" />
            <token id="10" string="," />
            <token id="11" string="blunt" />
            <token id="12" string="and" />
            <token id="13" string="salty" />
            <token id="14" string="language" />
          </tokens>
        </chunking>
        <chunking id="3" string="off-the" type="ADJP">
          <tokens>
            <token id="17" string="off-the" />
          </tokens>
        </chunking>
        <chunking id="4" string="that John Major is capable of candid , blunt and salty language when talking off-the - record to friendly journalists" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="John" />
            <token id="5" string="Major" />
            <token id="6" string="is" />
            <token id="7" string="capable" />
            <token id="8" string="of" />
            <token id="9" string="candid" />
            <token id="10" string="," />
            <token id="11" string="blunt" />
            <token id="12" string="and" />
            <token id="13" string="salty" />
            <token id="14" string="language" />
            <token id="15" string="when" />
            <token id="16" string="talking" />
            <token id="17" string="off-the" />
            <token id="18" string="-" />
            <token id="19" string="record" />
            <token id="20" string="to" />
            <token id="21" string="friendly" />
            <token id="22" string="journalists" />
          </tokens>
        </chunking>
        <chunking id="5" string="candid , blunt and salty language" type="NP">
          <tokens>
            <token id="9" string="candid" />
            <token id="10" string="," />
            <token id="11" string="blunt" />
            <token id="12" string="and" />
            <token id="13" string="salty" />
            <token id="14" string="language" />
          </tokens>
        </chunking>
        <chunking id="6" string="record to friendly journalists" type="NP">
          <tokens>
            <token id="19" string="record" />
            <token id="20" string="to" />
            <token id="21" string="friendly" />
            <token id="22" string="journalists" />
          </tokens>
        </chunking>
        <chunking id="7" string="talking off-the - record to friendly journalists" type="VP">
          <tokens>
            <token id="16" string="talking" />
            <token id="17" string="off-the" />
            <token id="18" string="-" />
            <token id="19" string="record" />
            <token id="20" string="to" />
            <token id="21" string="friendly" />
            <token id="22" string="journalists" />
          </tokens>
        </chunking>
        <chunking id="8" string="some people" type="NP">
          <tokens>
            <token id="25" string="some" />
            <token id="26" string="people" />
          </tokens>
        </chunking>
        <chunking id="9" string="when" type="WHADVP">
          <tokens>
            <token id="15" string="when" />
          </tokens>
        </chunking>
        <chunking id="10" string="is capable of candid , blunt and salty language when talking off-the - record to friendly journalists" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="capable" />
            <token id="8" string="of" />
            <token id="9" string="candid" />
            <token id="10" string="," />
            <token id="11" string="blunt" />
            <token id="12" string="and" />
            <token id="13" string="salty" />
            <token id="14" string="language" />
            <token id="15" string="when" />
            <token id="16" string="talking" />
            <token id="17" string="off-the" />
            <token id="18" string="-" />
            <token id="19" string="record" />
            <token id="20" string="to" />
            <token id="21" string="friendly" />
            <token id="22" string="journalists" />
          </tokens>
        </chunking>
        <chunking id="11" string="THE revelation that John Major is capable of candid , blunt and salty language when talking off-the - record to friendly journalists" type="NP">
          <tokens>
            <token id="1" string="THE" />
            <token id="2" string="revelation" />
            <token id="3" string="that" />
            <token id="4" string="John" />
            <token id="5" string="Major" />
            <token id="6" string="is" />
            <token id="7" string="capable" />
            <token id="8" string="of" />
            <token id="9" string="candid" />
            <token id="10" string="," />
            <token id="11" string="blunt" />
            <token id="12" string="and" />
            <token id="13" string="salty" />
            <token id="14" string="language" />
            <token id="15" string="when" />
            <token id="16" string="talking" />
            <token id="17" string="off-the" />
            <token id="18" string="-" />
            <token id="19" string="record" />
            <token id="20" string="to" />
            <token id="21" string="friendly" />
            <token id="22" string="journalists" />
          </tokens>
        </chunking>
        <chunking id="12" string="surprised some people" type="VP">
          <tokens>
            <token id="24" string="surprised" />
            <token id="25" string="some" />
            <token id="26" string="people" />
          </tokens>
        </chunking>
        <chunking id="13" string="friendly journalists" type="NP">
          <tokens>
            <token id="21" string="friendly" />
            <token id="22" string="journalists" />
          </tokens>
        </chunking>
        <chunking id="14" string="has surprised some people" type="VP">
          <tokens>
            <token id="23" string="has" />
            <token id="24" string="surprised" />
            <token id="25" string="some" />
            <token id="26" string="people" />
          </tokens>
        </chunking>
        <chunking id="15" string="record" type="NP">
          <tokens>
            <token id="19" string="record" />
          </tokens>
        </chunking>
        <chunking id="16" string="John Major" type="NP">
          <tokens>
            <token id="4" string="John" />
            <token id="5" string="Major" />
          </tokens>
        </chunking>
        <chunking id="17" string="when talking off-the - record to friendly journalists" type="SBAR">
          <tokens>
            <token id="15" string="when" />
            <token id="16" string="talking" />
            <token id="17" string="off-the" />
            <token id="18" string="-" />
            <token id="19" string="record" />
            <token id="20" string="to" />
            <token id="21" string="friendly" />
            <token id="22" string="journalists" />
          </tokens>
        </chunking>
        <chunking id="18" string="THE revelation" type="NP">
          <tokens>
            <token id="1" string="THE" />
            <token id="2" string="revelation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">revelation</governor>
          <dependent id="1">THE</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">surprised</governor>
          <dependent id="2">revelation</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">capable</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Major</governor>
          <dependent id="4">John</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">capable</governor>
          <dependent id="5">Major</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">capable</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">revelation</governor>
          <dependent id="7">capable</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">language</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">language</governor>
          <dependent id="9">candid</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">candid</governor>
          <dependent id="11">blunt</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">candid</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">candid</governor>
          <dependent id="13">salty</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">capable</governor>
          <dependent id="14">language</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">talking</governor>
          <dependent id="15">when</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">capable</governor>
          <dependent id="16">talking</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">talking</governor>
          <dependent id="17">off-the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">off-the</governor>
          <dependent id="19">record</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">journalists</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">journalists</governor>
          <dependent id="21">friendly</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">record</governor>
          <dependent id="22">journalists</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">surprised</governor>
          <dependent id="23">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="24">surprised</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">people</governor>
          <dependent id="25">some</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">surprised</governor>
          <dependent id="26">people</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Major" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="John" />
            <token id="5" string="Major" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>It has even been suggested that the recording of the prime minister&amp;apost;s conversation with Michael Brunson, ITN&amp;apost;s political editor, in which Major used a variety of four-, six- and eight-letter words to communicate his lack of fondness for certain colleagues, may do him good.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="suggested" lemma="suggest" stem="suggest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="recording" lemma="recording" stem="record" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="prime" lemma="prime" stem="prime" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="minister" lemma="minister" stem="minist" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="conversation" lemma="conversation" stem="convers" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Michael" lemma="Michael" stem="michael" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="17" string="Brunson" lemma="Brunson" stem="brunson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="ITN" lemma="ITN" stem="itn" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="20" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="editor" lemma="editor" stem="editor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Major" lemma="Major" stem="major" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="27" string="used" lemma="use" stem="us" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="variety" lemma="variety" stem="varieti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="four" lemma="four" stem="four" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="32" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="35" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="eight-letter" lemma="eight-letter" stem="eight-lett" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="38" string="words" lemma="word" stem="word" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="39" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="communicate" lemma="communicate" stem="commun" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="42" string="lack" lemma="lack" stem="lack" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="fondness" lemma="fondness" stem="fond" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="certain" lemma="certain" stem="certain" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="colleagues" lemma="colleague" stem="colleagu" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="51" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="52" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="53" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ has) (ADVP (RB even)) (VP (VBN been) (VP (VBN suggested) (SBAR (IN that) (S (NP (NP (DT the) (NN recording)) (PP (IN of) (NP (NP (NP (DT the) (JJ prime) (NN minister) (POS 's)) (NN conversation)) (PP (IN with) (NP (NP (NNP Michael) (NNP Brunson)) (, ,) (NP (NP (NNP ITN) (POS 's)) (JJ political) (NN editor)))))) (, ,) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (NNP Major)) (VP (VBD used) (NP (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (CD four)) (: -))) (, ,) (NP (CD six)) (: -) (CC and) (NP (JJ eight-letter) (NNS words))) (S (VP (TO to) (VP (VB communicate) (NP (NP (PRP$ his) (NN lack)) (PP (IN of) (NP (NN fondness)))) (PP (IN for) (NP (JJ certain) (NNS colleagues))))))))) (, ,)) (VP (MD may) (VP (VB do) (S (NP (PRP him)) (ADJP (JJ good)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="six" type="NP">
          <tokens>
            <token id="34" string="six" />
          </tokens>
        </chunking>
        <chunking id="2" string="fondness" type="NP">
          <tokens>
            <token id="44" string="fondness" />
          </tokens>
        </chunking>
        <chunking id="3" string="the prime minister 's conversation" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="prime" />
            <token id="12" string="minister" />
            <token id="13" string="'s" />
            <token id="14" string="conversation" />
          </tokens>
        </chunking>
        <chunking id="4" string="a variety of four - , six - and eight-letter words" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="variety" />
            <token id="30" string="of" />
            <token id="31" string="four" />
            <token id="32" string="-" />
            <token id="33" string="," />
            <token id="34" string="six" />
            <token id="35" string="-" />
            <token id="36" string="and" />
            <token id="37" string="eight-letter" />
            <token id="38" string="words" />
          </tokens>
        </chunking>
        <chunking id="5" string="has even been suggested that the recording of the prime minister 's conversation with Michael Brunson , ITN 's political editor , in which Major used a variety of four - , six - and eight-letter words to communicate his lack of fondness for certain colleagues , may do him good" type="VP">
          <tokens>
            <token id="2" string="has" />
            <token id="3" string="even" />
            <token id="4" string="been" />
            <token id="5" string="suggested" />
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="recording" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="prime" />
            <token id="12" string="minister" />
            <token id="13" string="'s" />
            <token id="14" string="conversation" />
            <token id="15" string="with" />
            <token id="16" string="Michael" />
            <token id="17" string="Brunson" />
            <token id="18" string="," />
            <token id="19" string="ITN" />
            <token id="20" string="'s" />
            <token id="21" string="political" />
            <token id="22" string="editor" />
            <token id="23" string="," />
            <token id="24" string="in" />
            <token id="25" string="which" />
            <token id="26" string="Major" />
            <token id="27" string="used" />
            <token id="28" string="a" />
            <token id="29" string="variety" />
            <token id="30" string="of" />
            <token id="31" string="four" />
            <token id="32" string="-" />
            <token id="33" string="," />
            <token id="34" string="six" />
            <token id="35" string="-" />
            <token id="36" string="and" />
            <token id="37" string="eight-letter" />
            <token id="38" string="words" />
            <token id="39" string="to" />
            <token id="40" string="communicate" />
            <token id="41" string="his" />
            <token id="42" string="lack" />
            <token id="43" string="of" />
            <token id="44" string="fondness" />
            <token id="45" string="for" />
            <token id="46" string="certain" />
            <token id="47" string="colleagues" />
            <token id="48" string="," />
            <token id="49" string="may" />
            <token id="50" string="do" />
            <token id="51" string="him" />
            <token id="52" string="good" />
          </tokens>
        </chunking>
        <chunking id="6" string="eight-letter words" type="NP">
          <tokens>
            <token id="37" string="eight-letter" />
            <token id="38" string="words" />
          </tokens>
        </chunking>
        <chunking id="7" string="the recording" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="recording" />
          </tokens>
        </chunking>
        <chunking id="8" string="that the recording of the prime minister 's conversation with Michael Brunson , ITN 's political editor , in which Major used a variety of four - , six - and eight-letter words to communicate his lack of fondness for certain colleagues , may do him good" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="recording" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="prime" />
            <token id="12" string="minister" />
            <token id="13" string="'s" />
            <token id="14" string="conversation" />
            <token id="15" string="with" />
            <token id="16" string="Michael" />
            <token id="17" string="Brunson" />
            <token id="18" string="," />
            <token id="19" string="ITN" />
            <token id="20" string="'s" />
            <token id="21" string="political" />
            <token id="22" string="editor" />
            <token id="23" string="," />
            <token id="24" string="in" />
            <token id="25" string="which" />
            <token id="26" string="Major" />
            <token id="27" string="used" />
            <token id="28" string="a" />
            <token id="29" string="variety" />
            <token id="30" string="of" />
            <token id="31" string="four" />
            <token id="32" string="-" />
            <token id="33" string="," />
            <token id="34" string="six" />
            <token id="35" string="-" />
            <token id="36" string="and" />
            <token id="37" string="eight-letter" />
            <token id="38" string="words" />
            <token id="39" string="to" />
            <token id="40" string="communicate" />
            <token id="41" string="his" />
            <token id="42" string="lack" />
            <token id="43" string="of" />
            <token id="44" string="fondness" />
            <token id="45" string="for" />
            <token id="46" string="certain" />
            <token id="47" string="colleagues" />
            <token id="48" string="," />
            <token id="49" string="may" />
            <token id="50" string="do" />
            <token id="51" string="him" />
            <token id="52" string="good" />
          </tokens>
        </chunking>
        <chunking id="9" string="in which Major used a variety of four - , six - and eight-letter words to communicate his lack of fondness for certain colleagues" type="SBAR">
          <tokens>
            <token id="24" string="in" />
            <token id="25" string="which" />
            <token id="26" string="Major" />
            <token id="27" string="used" />
            <token id="28" string="a" />
            <token id="29" string="variety" />
            <token id="30" string="of" />
            <token id="31" string="four" />
            <token id="32" string="-" />
            <token id="33" string="," />
            <token id="34" string="six" />
            <token id="35" string="-" />
            <token id="36" string="and" />
            <token id="37" string="eight-letter" />
            <token id="38" string="words" />
            <token id="39" string="to" />
            <token id="40" string="communicate" />
            <token id="41" string="his" />
            <token id="42" string="lack" />
            <token id="43" string="of" />
            <token id="44" string="fondness" />
            <token id="45" string="for" />
            <token id="46" string="certain" />
            <token id="47" string="colleagues" />
          </tokens>
        </chunking>
        <chunking id="10" string="his lack" type="NP">
          <tokens>
            <token id="41" string="his" />
            <token id="42" string="lack" />
          </tokens>
        </chunking>
        <chunking id="11" string="the recording of the prime minister 's conversation with Michael Brunson , ITN 's political editor , in which Major used a variety of four - , six - and eight-letter words to communicate his lack of fondness for certain colleagues ," type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="recording" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="prime" />
            <token id="12" string="minister" />
            <token id="13" string="'s" />
            <token id="14" string="conversation" />
            <token id="15" string="with" />
            <token id="16" string="Michael" />
            <token id="17" string="Brunson" />
            <token id="18" string="," />
            <token id="19" string="ITN" />
            <token id="20" string="'s" />
            <token id="21" string="political" />
            <token id="22" string="editor" />
            <token id="23" string="," />
            <token id="24" string="in" />
            <token id="25" string="which" />
            <token id="26" string="Major" />
            <token id="27" string="used" />
            <token id="28" string="a" />
            <token id="29" string="variety" />
            <token id="30" string="of" />
            <token id="31" string="four" />
            <token id="32" string="-" />
            <token id="33" string="," />
            <token id="34" string="six" />
            <token id="35" string="-" />
            <token id="36" string="and" />
            <token id="37" string="eight-letter" />
            <token id="38" string="words" />
            <token id="39" string="to" />
            <token id="40" string="communicate" />
            <token id="41" string="his" />
            <token id="42" string="lack" />
            <token id="43" string="of" />
            <token id="44" string="fondness" />
            <token id="45" string="for" />
            <token id="46" string="certain" />
            <token id="47" string="colleagues" />
            <token id="48" string="," />
          </tokens>
        </chunking>
        <chunking id="12" string="Major" type="NP">
          <tokens>
            <token id="26" string="Major" />
          </tokens>
        </chunking>
        <chunking id="13" string="Michael Brunson" type="NP">
          <tokens>
            <token id="16" string="Michael" />
            <token id="17" string="Brunson" />
          </tokens>
        </chunking>
        <chunking id="14" string="his lack of fondness" type="NP">
          <tokens>
            <token id="41" string="his" />
            <token id="42" string="lack" />
            <token id="43" string="of" />
            <token id="44" string="fondness" />
          </tokens>
        </chunking>
        <chunking id="15" string="the prime minister 's" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="prime" />
            <token id="12" string="minister" />
            <token id="13" string="'s" />
          </tokens>
        </chunking>
        <chunking id="16" string="communicate his lack of fondness for certain colleagues" type="VP">
          <tokens>
            <token id="40" string="communicate" />
            <token id="41" string="his" />
            <token id="42" string="lack" />
            <token id="43" string="of" />
            <token id="44" string="fondness" />
            <token id="45" string="for" />
            <token id="46" string="certain" />
            <token id="47" string="colleagues" />
          </tokens>
        </chunking>
        <chunking id="17" string="certain colleagues" type="NP">
          <tokens>
            <token id="46" string="certain" />
            <token id="47" string="colleagues" />
          </tokens>
        </chunking>
        <chunking id="18" string="a variety" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="variety" />
          </tokens>
        </chunking>
        <chunking id="19" string="may do him good" type="VP">
          <tokens>
            <token id="49" string="may" />
            <token id="50" string="do" />
            <token id="51" string="him" />
            <token id="52" string="good" />
          </tokens>
        </chunking>
        <chunking id="20" string="ITN 's" type="NP">
          <tokens>
            <token id="19" string="ITN" />
            <token id="20" string="'s" />
          </tokens>
        </chunking>
        <chunking id="21" string="used a variety of four - , six - and eight-letter words to communicate his lack of fondness for certain colleagues" type="VP">
          <tokens>
            <token id="27" string="used" />
            <token id="28" string="a" />
            <token id="29" string="variety" />
            <token id="30" string="of" />
            <token id="31" string="four" />
            <token id="32" string="-" />
            <token id="33" string="," />
            <token id="34" string="six" />
            <token id="35" string="-" />
            <token id="36" string="and" />
            <token id="37" string="eight-letter" />
            <token id="38" string="words" />
            <token id="39" string="to" />
            <token id="40" string="communicate" />
            <token id="41" string="his" />
            <token id="42" string="lack" />
            <token id="43" string="of" />
            <token id="44" string="fondness" />
            <token id="45" string="for" />
            <token id="46" string="certain" />
            <token id="47" string="colleagues" />
          </tokens>
        </chunking>
        <chunking id="22" string="to communicate his lack of fondness for certain colleagues" type="VP">
          <tokens>
            <token id="39" string="to" />
            <token id="40" string="communicate" />
            <token id="41" string="his" />
            <token id="42" string="lack" />
            <token id="43" string="of" />
            <token id="44" string="fondness" />
            <token id="45" string="for" />
            <token id="46" string="certain" />
            <token id="47" string="colleagues" />
          </tokens>
        </chunking>
        <chunking id="23" string="suggested that the recording of the prime minister 's conversation with Michael Brunson , ITN 's political editor , in which Major used a variety of four - , six - and eight-letter words to communicate his lack of fondness for certain colleagues , may do him good" type="VP">
          <tokens>
            <token id="5" string="suggested" />
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="recording" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="prime" />
            <token id="12" string="minister" />
            <token id="13" string="'s" />
            <token id="14" string="conversation" />
            <token id="15" string="with" />
            <token id="16" string="Michael" />
            <token id="17" string="Brunson" />
            <token id="18" string="," />
            <token id="19" string="ITN" />
            <token id="20" string="'s" />
            <token id="21" string="political" />
            <token id="22" string="editor" />
            <token id="23" string="," />
            <token id="24" string="in" />
            <token id="25" string="which" />
            <token id="26" string="Major" />
            <token id="27" string="used" />
            <token id="28" string="a" />
            <token id="29" string="variety" />
            <token id="30" string="of" />
            <token id="31" string="four" />
            <token id="32" string="-" />
            <token id="33" string="," />
            <token id="34" string="six" />
            <token id="35" string="-" />
            <token id="36" string="and" />
            <token id="37" string="eight-letter" />
            <token id="38" string="words" />
            <token id="39" string="to" />
            <token id="40" string="communicate" />
            <token id="41" string="his" />
            <token id="42" string="lack" />
            <token id="43" string="of" />
            <token id="44" string="fondness" />
            <token id="45" string="for" />
            <token id="46" string="certain" />
            <token id="47" string="colleagues" />
            <token id="48" string="," />
            <token id="49" string="may" />
            <token id="50" string="do" />
            <token id="51" string="him" />
            <token id="52" string="good" />
          </tokens>
        </chunking>
        <chunking id="24" string="a variety of four -" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="variety" />
            <token id="30" string="of" />
            <token id="31" string="four" />
            <token id="32" string="-" />
          </tokens>
        </chunking>
        <chunking id="25" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="26" string="him" type="NP">
          <tokens>
            <token id="51" string="him" />
          </tokens>
        </chunking>
        <chunking id="27" string="good" type="ADJP">
          <tokens>
            <token id="52" string="good" />
          </tokens>
        </chunking>
        <chunking id="28" string="ITN 's political editor" type="NP">
          <tokens>
            <token id="19" string="ITN" />
            <token id="20" string="'s" />
            <token id="21" string="political" />
            <token id="22" string="editor" />
          </tokens>
        </chunking>
        <chunking id="29" string="the prime minister 's conversation with Michael Brunson , ITN 's political editor" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="prime" />
            <token id="12" string="minister" />
            <token id="13" string="'s" />
            <token id="14" string="conversation" />
            <token id="15" string="with" />
            <token id="16" string="Michael" />
            <token id="17" string="Brunson" />
            <token id="18" string="," />
            <token id="19" string="ITN" />
            <token id="20" string="'s" />
            <token id="21" string="political" />
            <token id="22" string="editor" />
          </tokens>
        </chunking>
        <chunking id="30" string="do him good" type="VP">
          <tokens>
            <token id="50" string="do" />
            <token id="51" string="him" />
            <token id="52" string="good" />
          </tokens>
        </chunking>
        <chunking id="31" string="four" type="NP">
          <tokens>
            <token id="31" string="four" />
          </tokens>
        </chunking>
        <chunking id="32" string="Michael Brunson , ITN 's political editor" type="NP">
          <tokens>
            <token id="16" string="Michael" />
            <token id="17" string="Brunson" />
            <token id="18" string="," />
            <token id="19" string="ITN" />
            <token id="20" string="'s" />
            <token id="21" string="political" />
            <token id="22" string="editor" />
          </tokens>
        </chunking>
        <chunking id="33" string="been suggested that the recording of the prime minister 's conversation with Michael Brunson , ITN 's political editor , in which Major used a variety of four - , six - and eight-letter words to communicate his lack of fondness for certain colleagues , may do him good" type="VP">
          <tokens>
            <token id="4" string="been" />
            <token id="5" string="suggested" />
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="recording" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="prime" />
            <token id="12" string="minister" />
            <token id="13" string="'s" />
            <token id="14" string="conversation" />
            <token id="15" string="with" />
            <token id="16" string="Michael" />
            <token id="17" string="Brunson" />
            <token id="18" string="," />
            <token id="19" string="ITN" />
            <token id="20" string="'s" />
            <token id="21" string="political" />
            <token id="22" string="editor" />
            <token id="23" string="," />
            <token id="24" string="in" />
            <token id="25" string="which" />
            <token id="26" string="Major" />
            <token id="27" string="used" />
            <token id="28" string="a" />
            <token id="29" string="variety" />
            <token id="30" string="of" />
            <token id="31" string="four" />
            <token id="32" string="-" />
            <token id="33" string="," />
            <token id="34" string="six" />
            <token id="35" string="-" />
            <token id="36" string="and" />
            <token id="37" string="eight-letter" />
            <token id="38" string="words" />
            <token id="39" string="to" />
            <token id="40" string="communicate" />
            <token id="41" string="his" />
            <token id="42" string="lack" />
            <token id="43" string="of" />
            <token id="44" string="fondness" />
            <token id="45" string="for" />
            <token id="46" string="certain" />
            <token id="47" string="colleagues" />
            <token id="48" string="," />
            <token id="49" string="may" />
            <token id="50" string="do" />
            <token id="51" string="him" />
            <token id="52" string="good" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="5">suggested</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">suggested</governor>
          <dependent id="2">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">suggested</governor>
          <dependent id="3">even</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">suggested</governor>
          <dependent id="4">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">suggested</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="50">do</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">recording</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="50">do</governor>
          <dependent id="8">recording</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">conversation</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">minister</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">minister</governor>
          <dependent id="11">prime</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">conversation</governor>
          <dependent id="12">minister</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">minister</governor>
          <dependent id="13">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">recording</governor>
          <dependent id="14">conversation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Brunson</governor>
          <dependent id="15">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Brunson</governor>
          <dependent id="16">Michael</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">conversation</governor>
          <dependent id="17">Brunson</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">editor</governor>
          <dependent id="19">ITN</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">ITN</governor>
          <dependent id="20">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">editor</governor>
          <dependent id="21">political</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="17">Brunson</governor>
          <dependent id="22">editor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">which</governor>
          <dependent id="24">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">used</governor>
          <dependent id="25">which</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">used</governor>
          <dependent id="26">Major</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">recording</governor>
          <dependent id="27">used</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">variety</governor>
          <dependent id="28">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">used</governor>
          <dependent id="29">variety</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">four</governor>
          <dependent id="30">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">variety</governor>
          <dependent id="31">four</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="29">variety</governor>
          <dependent id="34">six</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="29">variety</governor>
          <dependent id="36">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">words</governor>
          <dependent id="37">eight-letter</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="29">variety</governor>
          <dependent id="38">words</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="40">communicate</governor>
          <dependent id="39">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="27">used</governor>
          <dependent id="40">communicate</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="42">lack</governor>
          <dependent id="41">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="40">communicate</governor>
          <dependent id="42">lack</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">fondness</governor>
          <dependent id="43">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="42">lack</governor>
          <dependent id="44">fondness</dependent>
        </dependency>
        <dependency type="case">
          <governor id="47">colleagues</governor>
          <dependent id="45">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="47">colleagues</governor>
          <dependent id="46">certain</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="40">communicate</governor>
          <dependent id="47">colleagues</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="50">do</governor>
          <dependent id="49">may</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">suggested</governor>
          <dependent id="50">do</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="52">good</governor>
          <dependent id="51">him</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="50">do</governor>
          <dependent id="52">good</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="34" string="six" />
          </tokens>
        </entity>
        <entity id="2" string="ITN" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="19" string="ITN" />
          </tokens>
        </entity>
        <entity id="3" string="Michael Brunson" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Michael" />
            <token id="17" string="Brunson" />
          </tokens>
        </entity>
        <entity id="4" string="four" type="NUMBER" score="0.0">
          <tokens>
            <token id="31" string="four" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>With luck, it is reckoned, Major&amp;apost;s image as a leaden-tongued wimp may undergo correction.</content>
      <tokens>
        <token id="1" string="With" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="luck" lemma="luck" stem="luck" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="reckoned" lemma="reckon" stem="reckon" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Major" lemma="Major" stem="major" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="image" lemma="image" stem="imag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="leaden-tongued" lemma="leaden-tongued" stem="leaden-tongu" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="wimp" lemma="wimp" stem="wimp" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="undergo" lemma="undergo" stem="undergo" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="correction" lemma="correction" stem="correct" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN With) (NP (NN luck))) (PRN (, ,) (S (NP (PRP it)) (VP (VBZ is) (VP (VBN reckoned)))) (, ,)) (NP (NP (NP (NNP Major) (POS 's)) (NN image)) (PP (IN as) (NP (DT a) (JJ leaden-tongued)))) (VP (VBP wimp) (SBAR (S (VP (MD may) (VP (VB undergo) (NP (NN correction))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="luck" type="NP">
          <tokens>
            <token id="2" string="luck" />
          </tokens>
        </chunking>
        <chunking id="2" string="is reckoned" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="reckoned" />
          </tokens>
        </chunking>
        <chunking id="3" string="undergo correction" type="VP">
          <tokens>
            <token id="16" string="undergo" />
            <token id="17" string="correction" />
          </tokens>
        </chunking>
        <chunking id="4" string="wimp may undergo correction" type="VP">
          <tokens>
            <token id="14" string="wimp" />
            <token id="15" string="may" />
            <token id="16" string="undergo" />
            <token id="17" string="correction" />
          </tokens>
        </chunking>
        <chunking id="5" string="may undergo correction" type="SBAR">
          <tokens>
            <token id="15" string="may" />
            <token id="16" string="undergo" />
            <token id="17" string="correction" />
          </tokens>
        </chunking>
        <chunking id="6" string="Major 's image" type="NP">
          <tokens>
            <token id="8" string="Major" />
            <token id="9" string="'s" />
            <token id="10" string="image" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="4" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="a leaden-tongued" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="leaden-tongued" />
          </tokens>
        </chunking>
        <chunking id="9" string="reckoned" type="VP">
          <tokens>
            <token id="6" string="reckoned" />
          </tokens>
        </chunking>
        <chunking id="10" string="Major 's image as a leaden-tongued" type="NP">
          <tokens>
            <token id="8" string="Major" />
            <token id="9" string="'s" />
            <token id="10" string="image" />
            <token id="11" string="as" />
            <token id="12" string="a" />
            <token id="13" string="leaden-tongued" />
          </tokens>
        </chunking>
        <chunking id="11" string="Major 's" type="NP">
          <tokens>
            <token id="8" string="Major" />
            <token id="9" string="'s" />
          </tokens>
        </chunking>
        <chunking id="12" string="correction" type="NP">
          <tokens>
            <token id="17" string="correction" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">luck</governor>
          <dependent id="1">With</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">wimp</governor>
          <dependent id="2">luck</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">reckoned</governor>
          <dependent id="4">it</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">reckoned</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="14">wimp</governor>
          <dependent id="6">reckoned</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">image</governor>
          <dependent id="8">Major</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Major</governor>
          <dependent id="9">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">wimp</governor>
          <dependent id="10">image</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">leaden-tongued</governor>
          <dependent id="11">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">leaden-tongued</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">image</governor>
          <dependent id="13">leaden-tongued</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">wimp</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">undergo</governor>
          <dependent id="15">may</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">wimp</governor>
          <dependent id="16">undergo</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">undergo</governor>
          <dependent id="17">correction</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="4" has_coreference="false">
      <content>What piffle.</content>
      <tokens>
        <token id="1" string="What" lemma="what" stem="what" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="piffle" lemma="piffle" stem="piffl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (WHNP (WDT What) (NP (NN piffle))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="piffle" type="NP">
          <tokens>
            <token id="2" string="piffle" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">piffle</governor>
          <dependent id="1">What</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">piffle</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>Major is a gonner, especially after this week&amp;apost;s revolt of the wooden-tops in the Christchurch by-election, where a Conservative majority of 23,015 at last year&amp;apost;s general election was converted into a 16,427 majority for the Liberal Democrats.</content>
      <tokens>
        <token id="1" string="Major" lemma="Major" stem="major" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="gonner" lemma="gonner" stem="gonner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="especially" lemma="especially" stem="especi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="true" />
        <token id="9" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="true" />
        <token id="10" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="11" string="revolt" lemma="revolt" stem="revolt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="wooden-tops" lemma="wooden-top" stem="wooden-top" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="Christchurch" lemma="Christchurch" stem="christchurch" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="18" string="by-election" lemma="by-election" stem="by-elect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="Conservative" lemma="conservative" stem="conserv" pos="JJ" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="23" string="majority" lemma="majority" stem="major" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="23,015" lemma="23,015" stem="23,015" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="26" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="28" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="29" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="general" lemma="general" stem="gener" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="31" string="election" lemma="election" stem="elect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="32" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="converted" lemma="convert" stem="convert" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="34" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="16,427" lemma="16,427" stem="16,427" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="37" string="majority" lemma="majority" stem="major" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="38" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="39" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="40" string="Liberal" lemma="liberal" stem="liber" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="true" />
        <token id="41" string="Democrats" lemma="Democrats" stem="democrat" pos="NNPS" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="true" />
        <token id="42" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Major)) (VP (VBZ is) (NP (NP (DT a) (NN gonner)) (, ,) (RRC (ADVP (RB especially)) (PP (IN after) (NP (NP (NP (DT this) (NN week) (POS 's)) (NN revolt)) (PP (IN of) (NP (NP (DT the) (NNS wooden-tops)) (PP (IN in) (NP (DT the) (NNP Christchurch) (NN by-election)))))))) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (NP (DT a) (JJ Conservative) (NN majority)) (PP (IN of) (NP (NP (CD 23,015)) (PP (IN at) (NP (NP (JJ last) (NN year) (POS 's)) (JJ general) (NN election)))))) (VP (VBD was) (VP (VBN converted) (PP (IN into) (NP (DT a) (CD 16,427) (NN majority))) (PP (IN for) (NP (DT the) (JJ Liberal) (NNPS Democrats))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="where a Conservative majority of 23,015 at last year 's general election was converted into a 16,427 majority for the Liberal Democrats" type="SBAR">
          <tokens>
            <token id="20" string="where" />
            <token id="21" string="a" />
            <token id="22" string="Conservative" />
            <token id="23" string="majority" />
            <token id="24" string="of" />
            <token id="25" string="23,015" />
            <token id="26" string="at" />
            <token id="27" string="last" />
            <token id="28" string="year" />
            <token id="29" string="'s" />
            <token id="30" string="general" />
            <token id="31" string="election" />
            <token id="32" string="was" />
            <token id="33" string="converted" />
            <token id="34" string="into" />
            <token id="35" string="a" />
            <token id="36" string="16,427" />
            <token id="37" string="majority" />
            <token id="38" string="for" />
            <token id="39" string="the" />
            <token id="40" string="Liberal" />
            <token id="41" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="2" string="was converted into a 16,427 majority for the Liberal Democrats" type="VP">
          <tokens>
            <token id="32" string="was" />
            <token id="33" string="converted" />
            <token id="34" string="into" />
            <token id="35" string="a" />
            <token id="36" string="16,427" />
            <token id="37" string="majority" />
            <token id="38" string="for" />
            <token id="39" string="the" />
            <token id="40" string="Liberal" />
            <token id="41" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="3" string="is a gonner , especially after this week 's revolt of the wooden-tops in the Christchurch by-election , where a Conservative majority of 23,015 at last year 's general election was converted into a 16,427 majority for the Liberal Democrats" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="a" />
            <token id="4" string="gonner" />
            <token id="5" string="," />
            <token id="6" string="especially" />
            <token id="7" string="after" />
            <token id="8" string="this" />
            <token id="9" string="week" />
            <token id="10" string="'s" />
            <token id="11" string="revolt" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="wooden-tops" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="Christchurch" />
            <token id="18" string="by-election" />
            <token id="19" string="," />
            <token id="20" string="where" />
            <token id="21" string="a" />
            <token id="22" string="Conservative" />
            <token id="23" string="majority" />
            <token id="24" string="of" />
            <token id="25" string="23,015" />
            <token id="26" string="at" />
            <token id="27" string="last" />
            <token id="28" string="year" />
            <token id="29" string="'s" />
            <token id="30" string="general" />
            <token id="31" string="election" />
            <token id="32" string="was" />
            <token id="33" string="converted" />
            <token id="34" string="into" />
            <token id="35" string="a" />
            <token id="36" string="16,427" />
            <token id="37" string="majority" />
            <token id="38" string="for" />
            <token id="39" string="the" />
            <token id="40" string="Liberal" />
            <token id="41" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="4" string="the wooden-tops in the Christchurch by-election" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="wooden-tops" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="Christchurch" />
            <token id="18" string="by-election" />
          </tokens>
        </chunking>
        <chunking id="5" string="a 16,427 majority" type="NP">
          <tokens>
            <token id="35" string="a" />
            <token id="36" string="16,427" />
            <token id="37" string="majority" />
          </tokens>
        </chunking>
        <chunking id="6" string="a Conservative majority of 23,015 at last year 's general election" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="Conservative" />
            <token id="23" string="majority" />
            <token id="24" string="of" />
            <token id="25" string="23,015" />
            <token id="26" string="at" />
            <token id="27" string="last" />
            <token id="28" string="year" />
            <token id="29" string="'s" />
            <token id="30" string="general" />
            <token id="31" string="election" />
          </tokens>
        </chunking>
        <chunking id="7" string="last year 's general election" type="NP">
          <tokens>
            <token id="27" string="last" />
            <token id="28" string="year" />
            <token id="29" string="'s" />
            <token id="30" string="general" />
            <token id="31" string="election" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Liberal Democrats" type="NP">
          <tokens>
            <token id="39" string="the" />
            <token id="40" string="Liberal" />
            <token id="41" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="9" string="a Conservative majority" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="Conservative" />
            <token id="23" string="majority" />
          </tokens>
        </chunking>
        <chunking id="10" string="last year 's" type="NP">
          <tokens>
            <token id="27" string="last" />
            <token id="28" string="year" />
            <token id="29" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="Major" type="NP">
          <tokens>
            <token id="1" string="Major" />
          </tokens>
        </chunking>
        <chunking id="12" string="the Christchurch by-election" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="Christchurch" />
            <token id="18" string="by-election" />
          </tokens>
        </chunking>
        <chunking id="13" string="a gonner , especially after this week 's revolt of the wooden-tops in the Christchurch by-election , where a Conservative majority of 23,015 at last year 's general election was converted into a 16,427 majority for the Liberal Democrats" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="gonner" />
            <token id="5" string="," />
            <token id="6" string="especially" />
            <token id="7" string="after" />
            <token id="8" string="this" />
            <token id="9" string="week" />
            <token id="10" string="'s" />
            <token id="11" string="revolt" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="wooden-tops" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="Christchurch" />
            <token id="18" string="by-election" />
            <token id="19" string="," />
            <token id="20" string="where" />
            <token id="21" string="a" />
            <token id="22" string="Conservative" />
            <token id="23" string="majority" />
            <token id="24" string="of" />
            <token id="25" string="23,015" />
            <token id="26" string="at" />
            <token id="27" string="last" />
            <token id="28" string="year" />
            <token id="29" string="'s" />
            <token id="30" string="general" />
            <token id="31" string="election" />
            <token id="32" string="was" />
            <token id="33" string="converted" />
            <token id="34" string="into" />
            <token id="35" string="a" />
            <token id="36" string="16,427" />
            <token id="37" string="majority" />
            <token id="38" string="for" />
            <token id="39" string="the" />
            <token id="40" string="Liberal" />
            <token id="41" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="14" string="converted into a 16,427 majority for the Liberal Democrats" type="VP">
          <tokens>
            <token id="33" string="converted" />
            <token id="34" string="into" />
            <token id="35" string="a" />
            <token id="36" string="16,427" />
            <token id="37" string="majority" />
            <token id="38" string="for" />
            <token id="39" string="the" />
            <token id="40" string="Liberal" />
            <token id="41" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="15" string="this week 's revolt of the wooden-tops in the Christchurch by-election" type="NP">
          <tokens>
            <token id="8" string="this" />
            <token id="9" string="week" />
            <token id="10" string="'s" />
            <token id="11" string="revolt" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="wooden-tops" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="Christchurch" />
            <token id="18" string="by-election" />
          </tokens>
        </chunking>
        <chunking id="16" string="this week 's revolt" type="NP">
          <tokens>
            <token id="8" string="this" />
            <token id="9" string="week" />
            <token id="10" string="'s" />
            <token id="11" string="revolt" />
          </tokens>
        </chunking>
        <chunking id="17" string="the wooden-tops" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="wooden-tops" />
          </tokens>
        </chunking>
        <chunking id="18" string="23,015 at last year 's general election" type="NP">
          <tokens>
            <token id="25" string="23,015" />
            <token id="26" string="at" />
            <token id="27" string="last" />
            <token id="28" string="year" />
            <token id="29" string="'s" />
            <token id="30" string="general" />
            <token id="31" string="election" />
          </tokens>
        </chunking>
        <chunking id="19" string="where" type="WHADVP">
          <tokens>
            <token id="20" string="where" />
          </tokens>
        </chunking>
        <chunking id="20" string="this week 's" type="NP">
          <tokens>
            <token id="8" string="this" />
            <token id="9" string="week" />
            <token id="10" string="'s" />
          </tokens>
        </chunking>
        <chunking id="21" string="23,015" type="NP">
          <tokens>
            <token id="25" string="23,015" />
          </tokens>
        </chunking>
        <chunking id="22" string="a gonner" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="gonner" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">gonner</governor>
          <dependent id="1">Major</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">gonner</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">gonner</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">gonner</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">revolt</governor>
          <dependent id="6">especially</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">revolt</governor>
          <dependent id="7">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">week</governor>
          <dependent id="8">this</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">revolt</governor>
          <dependent id="9">week</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">week</governor>
          <dependent id="10">'s</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">gonner</governor>
          <dependent id="11">revolt</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">wooden-tops</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">wooden-tops</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">revolt</governor>
          <dependent id="14">wooden-tops</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">by-election</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">by-election</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">by-election</governor>
          <dependent id="17">Christchurch</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">wooden-tops</governor>
          <dependent id="18">by-election</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="33">converted</governor>
          <dependent id="20">where</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">majority</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">majority</governor>
          <dependent id="22">Conservative</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="33">converted</governor>
          <dependent id="23">majority</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">23,015</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">majority</governor>
          <dependent id="25">23,015</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">election</governor>
          <dependent id="26">at</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">year</governor>
          <dependent id="27">last</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="31">election</governor>
          <dependent id="28">year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">year</governor>
          <dependent id="29">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">election</governor>
          <dependent id="30">general</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">23,015</governor>
          <dependent id="31">election</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="33">converted</governor>
          <dependent id="32">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">gonner</governor>
          <dependent id="33">converted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">majority</governor>
          <dependent id="34">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">majority</governor>
          <dependent id="35">a</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="37">majority</governor>
          <dependent id="36">16,427</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">converted</governor>
          <dependent id="37">majority</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">Democrats</governor>
          <dependent id="38">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="41">Democrats</governor>
          <dependent id="39">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="41">Democrats</governor>
          <dependent id="40">Liberal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">converted</governor>
          <dependent id="41">Democrats</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Christchurch" type="LOCATION" score="0.0">
          <tokens>
            <token id="17" string="Christchurch" />
          </tokens>
        </entity>
        <entity id="2" string="Conservative" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="22" string="Conservative" />
          </tokens>
        </entity>
        <entity id="3" string="this week" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="this" />
            <token id="9" string="week" />
          </tokens>
        </entity>
        <entity id="4" string="16,427" type="NUMBER" score="0.0">
          <tokens>
            <token id="36" string="16,427" />
          </tokens>
        </entity>
        <entity id="5" string="Liberal Democrats" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="40" string="Liberal" />
            <token id="41" string="Democrats" />
          </tokens>
        </entity>
        <entity id="6" string="23,015" type="NUMBER" score="0.0">
          <tokens>
            <token id="25" string="23,015" />
          </tokens>
        </entity>
        <entity id="7" string="last year" type="DATE" score="0.0">
          <tokens>
            <token id="27" string="last" />
            <token id="28" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>Fifteen months too late, the voters of Christchurch rounded on the Tories with a malignant and squeaky fury.</content>
      <tokens>
        <token id="1" string="Fifteen" lemma="fifteen" stem="fifteen" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="2" string="months" lemma="month" stem="month" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="3" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="late" lemma="late" stem="late" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="voters" lemma="voter" stem="voter" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="Christchurch" lemma="Christchurch" stem="christchurch" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="10" string="rounded" lemma="round" stem="round" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="Tories" lemma="Tories" stem="tori" pos="NNPS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="malignant" lemma="malignant" stem="malign" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="squeaky" lemma="squeaky" stem="squeaki" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="fury" lemma="fury" stem="furi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (NP (CD Fifteen) (NNS months)) (RB too)) (ADVP (RB late)) (, ,) (NP (NP (DT the) (NNS voters)) (PP (IN of) (NP (NNP Christchurch)))) (VP (VBD rounded) (PP (IN on) (NP (DT the) (NNPS Tories))) (PP (IN with) (NP (DT a) (ADJP (JJ malignant) (CC and) (RB squeaky)) (NN fury)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a malignant and squeaky fury" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="malignant" />
            <token id="17" string="and" />
            <token id="18" string="squeaky" />
            <token id="19" string="fury" />
          </tokens>
        </chunking>
        <chunking id="2" string="Christchurch" type="NP">
          <tokens>
            <token id="9" string="Christchurch" />
          </tokens>
        </chunking>
        <chunking id="3" string="rounded on the Tories with a malignant and squeaky fury" type="VP">
          <tokens>
            <token id="10" string="rounded" />
            <token id="11" string="on" />
            <token id="12" string="the" />
            <token id="13" string="Tories" />
            <token id="14" string="with" />
            <token id="15" string="a" />
            <token id="16" string="malignant" />
            <token id="17" string="and" />
            <token id="18" string="squeaky" />
            <token id="19" string="fury" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Tories" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="Tories" />
          </tokens>
        </chunking>
        <chunking id="5" string="Fifteen months" type="NP">
          <tokens>
            <token id="1" string="Fifteen" />
            <token id="2" string="months" />
          </tokens>
        </chunking>
        <chunking id="6" string="the voters" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="voters" />
          </tokens>
        </chunking>
        <chunking id="7" string="malignant and squeaky" type="ADJP">
          <tokens>
            <token id="16" string="malignant" />
            <token id="17" string="and" />
            <token id="18" string="squeaky" />
          </tokens>
        </chunking>
        <chunking id="8" string="the voters of Christchurch" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="voters" />
            <token id="8" string="of" />
            <token id="9" string="Christchurch" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nummod">
          <governor id="2">months</governor>
          <dependent id="1">Fifteen</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="3">too</governor>
          <dependent id="2">months</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">rounded</governor>
          <dependent id="3">too</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">rounded</governor>
          <dependent id="4">late</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">voters</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">rounded</governor>
          <dependent id="7">voters</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Christchurch</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">voters</governor>
          <dependent id="9">Christchurch</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">rounded</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Tories</governor>
          <dependent id="11">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">Tories</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">rounded</governor>
          <dependent id="13">Tories</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">fury</governor>
          <dependent id="14">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">fury</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">fury</governor>
          <dependent id="16">malignant</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">malignant</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">malignant</governor>
          <dependent id="18">squeaky</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">rounded</governor>
          <dependent id="19">fury</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Christchurch" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Christchurch" />
          </tokens>
        </entity>
        <entity id="2" string="Fifteen months" type="DURATION" score="0.0">
          <tokens>
            <token id="1" string="Fifteen" />
            <token id="2" string="months" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="false">
      <content>In reality, all politicians, not just Major, are far more candid and salty when chatting in private than when speaking in public.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="reality" lemma="reality" stem="realiti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="politicians" lemma="politician" stem="politician" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Major" lemma="major" stem="major" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="far" lemma="far" stem="far" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="candid" lemma="candid" stem="candid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="salty" lemma="salty" stem="salti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="chatting" lemma="chat" stem="chat" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="private" lemma="private" stem="privat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="speaking" lemma="speak" stem="speak" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="public" lemma="public" stem="public" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NN reality))) (, ,) (NP (NP (DT all) (NNS politicians)) (, ,) (NP (RB not) (RB just) (JJ Major)) (, ,)) (VP (VBP are) (ADJP (ADJP (ADVP (RB far) (RBR more)) (JJ candid) (CC and) (JJ salty)) (SBAR (WHADVP (WRB when)) (S (VP (VBG chatting) (PP (IN in) (ADJP (JJ private)))))) (PP (IN than) (SBAR (WHADVP (WRB when)) (S (VP (VBG speaking) (PP (IN in) (NP (NN public))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="private" type="ADJP">
          <tokens>
            <token id="20" string="private" />
          </tokens>
        </chunking>
        <chunking id="2" string="reality" type="NP">
          <tokens>
            <token id="2" string="reality" />
          </tokens>
        </chunking>
        <chunking id="3" string="all politicians , not just Major ," type="NP">
          <tokens>
            <token id="4" string="all" />
            <token id="5" string="politicians" />
            <token id="6" string="," />
            <token id="7" string="not" />
            <token id="8" string="just" />
            <token id="9" string="Major" />
            <token id="10" string="," />
          </tokens>
        </chunking>
        <chunking id="4" string="chatting in private" type="VP">
          <tokens>
            <token id="18" string="chatting" />
            <token id="19" string="in" />
            <token id="20" string="private" />
          </tokens>
        </chunking>
        <chunking id="5" string="speaking in public" type="VP">
          <tokens>
            <token id="23" string="speaking" />
            <token id="24" string="in" />
            <token id="25" string="public" />
          </tokens>
        </chunking>
        <chunking id="6" string="are far more candid and salty when chatting in private than when speaking in public" type="VP">
          <tokens>
            <token id="11" string="are" />
            <token id="12" string="far" />
            <token id="13" string="more" />
            <token id="14" string="candid" />
            <token id="15" string="and" />
            <token id="16" string="salty" />
            <token id="17" string="when" />
            <token id="18" string="chatting" />
            <token id="19" string="in" />
            <token id="20" string="private" />
            <token id="21" string="than" />
            <token id="22" string="when" />
            <token id="23" string="speaking" />
            <token id="24" string="in" />
            <token id="25" string="public" />
          </tokens>
        </chunking>
        <chunking id="7" string="when" type="WHADVP">
          <tokens>
            <token id="17" string="when" />
          </tokens>
        </chunking>
        <chunking id="8" string="not just Major" type="NP">
          <tokens>
            <token id="7" string="not" />
            <token id="8" string="just" />
            <token id="9" string="Major" />
          </tokens>
        </chunking>
        <chunking id="9" string="far more candid and salty when chatting in private than when speaking in public" type="ADJP">
          <tokens>
            <token id="12" string="far" />
            <token id="13" string="more" />
            <token id="14" string="candid" />
            <token id="15" string="and" />
            <token id="16" string="salty" />
            <token id="17" string="when" />
            <token id="18" string="chatting" />
            <token id="19" string="in" />
            <token id="20" string="private" />
            <token id="21" string="than" />
            <token id="22" string="when" />
            <token id="23" string="speaking" />
            <token id="24" string="in" />
            <token id="25" string="public" />
          </tokens>
        </chunking>
        <chunking id="10" string="when speaking in public" type="SBAR">
          <tokens>
            <token id="22" string="when" />
            <token id="23" string="speaking" />
            <token id="24" string="in" />
            <token id="25" string="public" />
          </tokens>
        </chunking>
        <chunking id="11" string="public" type="NP">
          <tokens>
            <token id="25" string="public" />
          </tokens>
        </chunking>
        <chunking id="12" string="far more candid and salty" type="ADJP">
          <tokens>
            <token id="12" string="far" />
            <token id="13" string="more" />
            <token id="14" string="candid" />
            <token id="15" string="and" />
            <token id="16" string="salty" />
          </tokens>
        </chunking>
        <chunking id="13" string="when chatting in private" type="SBAR">
          <tokens>
            <token id="17" string="when" />
            <token id="18" string="chatting" />
            <token id="19" string="in" />
            <token id="20" string="private" />
          </tokens>
        </chunking>
        <chunking id="14" string="all politicians" type="NP">
          <tokens>
            <token id="4" string="all" />
            <token id="5" string="politicians" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">reality</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">candid</governor>
          <dependent id="2">reality</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">politicians</governor>
          <dependent id="4">all</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">candid</governor>
          <dependent id="5">politicians</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="9">Major</governor>
          <dependent id="7">not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">Major</governor>
          <dependent id="8">just</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">politicians</governor>
          <dependent id="9">Major</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">candid</governor>
          <dependent id="11">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">more</governor>
          <dependent id="12">far</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">candid</governor>
          <dependent id="13">more</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">candid</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">candid</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">candid</governor>
          <dependent id="16">salty</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">chatting</governor>
          <dependent id="17">when</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">candid</governor>
          <dependent id="18">chatting</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">private</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="18">chatting</governor>
          <dependent id="20">private</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">speaking</governor>
          <dependent id="21">than</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">speaking</governor>
          <dependent id="22">when</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">candid</governor>
          <dependent id="23">speaking</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">public</governor>
          <dependent id="24">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">speaking</governor>
          <dependent id="25">public</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>In public, they have to be careful of what they say, so their utterances achieve a horrible mattness.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="careful" lemma="careful" stem="care" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="so" lemma="so" stem="so" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="utterances" lemma="utterance" stem="utter" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="achieve" lemma="achieve" stem="achiev" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="horrible" lemma="horrible" stem="horribl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="mattness" lemma="mattness" stem="matt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (ADJP (JJ public))) (, ,) (S (NP (PRP they)) (VP (VBP have) (S (VP (TO to) (VP (VB be) (ADJP (JJ careful) (PP (IN of) (SBAR (WHNP (WP what)) (S (NP (PRP they)) (VP (VBP say))))))))))) (, ,) (IN so) (S (NP (PRP$ their) (NNS utterances)) (VP (VBP achieve) (NP (DT a) (JJ horrible) (NN mattness)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="4" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="be careful of what they say" type="VP">
          <tokens>
            <token id="7" string="be" />
            <token id="8" string="careful" />
            <token id="9" string="of" />
            <token id="10" string="what" />
            <token id="11" string="they" />
            <token id="12" string="say" />
          </tokens>
        </chunking>
        <chunking id="3" string="public" type="ADJP">
          <tokens>
            <token id="2" string="public" />
          </tokens>
        </chunking>
        <chunking id="4" string="to be careful of what they say" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="be" />
            <token id="8" string="careful" />
            <token id="9" string="of" />
            <token id="10" string="what" />
            <token id="11" string="they" />
            <token id="12" string="say" />
          </tokens>
        </chunking>
        <chunking id="5" string="have to be careful of what they say" type="VP">
          <tokens>
            <token id="5" string="have" />
            <token id="6" string="to" />
            <token id="7" string="be" />
            <token id="8" string="careful" />
            <token id="9" string="of" />
            <token id="10" string="what" />
            <token id="11" string="they" />
            <token id="12" string="say" />
          </tokens>
        </chunking>
        <chunking id="6" string="their utterances" type="NP">
          <tokens>
            <token id="15" string="their" />
            <token id="16" string="utterances" />
          </tokens>
        </chunking>
        <chunking id="7" string="achieve a horrible mattness" type="VP">
          <tokens>
            <token id="17" string="achieve" />
            <token id="18" string="a" />
            <token id="19" string="horrible" />
            <token id="20" string="mattness" />
          </tokens>
        </chunking>
        <chunking id="8" string="say" type="VP">
          <tokens>
            <token id="12" string="say" />
          </tokens>
        </chunking>
        <chunking id="9" string="careful of what they say" type="ADJP">
          <tokens>
            <token id="8" string="careful" />
            <token id="9" string="of" />
            <token id="10" string="what" />
            <token id="11" string="they" />
            <token id="12" string="say" />
          </tokens>
        </chunking>
        <chunking id="10" string="what they say" type="SBAR">
          <tokens>
            <token id="10" string="what" />
            <token id="11" string="they" />
            <token id="12" string="say" />
          </tokens>
        </chunking>
        <chunking id="11" string="a horrible mattness" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="horrible" />
            <token id="20" string="mattness" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">public</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">have</governor>
          <dependent id="2">public</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">have</governor>
          <dependent id="4">they</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">have</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">careful</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">careful</governor>
          <dependent id="7">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">have</governor>
          <dependent id="8">careful</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">say</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">say</governor>
          <dependent id="10">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">say</governor>
          <dependent id="11">they</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">careful</governor>
          <dependent id="12">say</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">have</governor>
          <dependent id="14">so</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">utterances</governor>
          <dependent id="15">their</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">achieve</governor>
          <dependent id="16">utterances</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="5">have</governor>
          <dependent id="17">achieve</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">mattness</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">mattness</governor>
          <dependent id="19">horrible</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">achieve</governor>
          <dependent id="20">mattness</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>But in private they relax.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="private" lemma="private" stem="privat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="relax" lemma="relax" stem="relax" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (PP (IN in) (ADJP (JJ private))) (NP (PRP they)) (VP (VBP relax)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="4" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="private" type="ADJP">
          <tokens>
            <token id="3" string="private" />
          </tokens>
        </chunking>
        <chunking id="3" string="relax" type="VP">
          <tokens>
            <token id="5" string="relax" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="5">relax</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">private</governor>
          <dependent id="2">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">relax</governor>
          <dependent id="3">private</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">relax</governor>
          <dependent id="4">they</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">relax</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Their syntax disappears.</content>
      <tokens>
        <token id="1" string="Their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="2" string="syntax" lemma="syntax" stem="syntax" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="disappears" lemma="disappear" stem="disappear" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP$ Their) (NN syntax)) (VP (VBZ disappears)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="disappears" type="VP">
          <tokens>
            <token id="3" string="disappears" />
          </tokens>
        </chunking>
        <chunking id="2" string="Their syntax" type="NP">
          <tokens>
            <token id="1" string="Their" />
            <token id="2" string="syntax" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">syntax</governor>
          <dependent id="1">Their</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">disappears</governor>
          <dependent id="2">syntax</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">disappears</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>Their words become nonsensical.</content>
      <tokens>
        <token id="1" string="Their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="words" lemma="word" stem="word" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="become" lemma="become" stem="becom" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="nonsensical" lemma="nonsensical" stem="nonsens" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP$ Their) (NNS words)) (VP (VBP become) (ADJP (JJ nonsensical))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="nonsensical" type="ADJP">
          <tokens>
            <token id="4" string="nonsensical" />
          </tokens>
        </chunking>
        <chunking id="2" string="become nonsensical" type="VP">
          <tokens>
            <token id="3" string="become" />
            <token id="4" string="nonsensical" />
          </tokens>
        </chunking>
        <chunking id="3" string="Their words" type="NP">
          <tokens>
            <token id="1" string="Their" />
            <token id="2" string="words" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">words</governor>
          <dependent id="1">Their</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">become</governor>
          <dependent id="2">words</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">become</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">become</governor>
          <dependent id="4">nonsensical</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>They swear and joke and shout.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="swear" lemma="swear" stem="swear" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="joke" lemma="joke" stem="joke" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="shout" lemma="shout" stem="shout" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VP (VBP swear)) (CC and) (VP (VP (VBP joke)) (CC and) (VP (VBP shout)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="joke and shout" type="VP">
          <tokens>
            <token id="4" string="joke" />
            <token id="5" string="and" />
            <token id="6" string="shout" />
          </tokens>
        </chunking>
        <chunking id="3" string="swear and joke and shout" type="VP">
          <tokens>
            <token id="2" string="swear" />
            <token id="3" string="and" />
            <token id="4" string="joke" />
            <token id="5" string="and" />
            <token id="6" string="shout" />
          </tokens>
        </chunking>
        <chunking id="4" string="swear" type="VP">
          <tokens>
            <token id="2" string="swear" />
          </tokens>
        </chunking>
        <chunking id="5" string="shout" type="VP">
          <tokens>
            <token id="6" string="shout" />
          </tokens>
        </chunking>
        <chunking id="6" string="joke" type="VP">
          <tokens>
            <token id="4" string="joke" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">swear</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">swear</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">swear</governor>
          <dependent id="3">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">swear</governor>
          <dependent id="4">joke</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">joke</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">joke</governor>
          <dependent id="6">shout</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>It really is a spectacle.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="spectacle" lemma="spectacle" stem="spectacl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (ADVP (RB really)) (VP (VBZ is) (NP (DT a) (NN spectacle))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a spectacle" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="spectacle" />
          </tokens>
        </chunking>
        <chunking id="2" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="3" string="is a spectacle" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="a" />
            <token id="5" string="spectacle" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">spectacle</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">spectacle</governor>
          <dependent id="2">really</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">spectacle</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">spectacle</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">spectacle</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>To show you what I mean, I spoke yesterday to John Major and John Smith.</content>
      <tokens>
        <token id="1" string="To" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="show" lemma="show" stem="show" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="mean" lemma="mean" stem="mean" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="spoke" lemma="speak" stem="spoke" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="yesterday" lemma="yesterday" stem="yesterdai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="Major" lemma="Major" stem="major" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="Smith" lemma="Smith" stem="smith" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (TO To) (VP (VB show) (NP (PRP you)) (SBAR (WHNP (WP what)) (S (NP (PRP I)) (VP (VBP mean))))))) (, ,) (NP (PRP I)) (VP (VBD spoke) (NP-TMP (NN yesterday)) (PP (TO to) (NP (NP (NNP John) (NNP Major)) (CC and) (NP (NNP John) (NNP Smith))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="John Smith" type="NP">
          <tokens>
            <token id="15" string="John" />
            <token id="16" string="Smith" />
          </tokens>
        </chunking>
        <chunking id="2" string="spoke yesterday to John Major and John Smith" type="VP">
          <tokens>
            <token id="9" string="spoke" />
            <token id="10" string="yesterday" />
            <token id="11" string="to" />
            <token id="12" string="John" />
            <token id="13" string="Major" />
            <token id="14" string="and" />
            <token id="15" string="John" />
            <token id="16" string="Smith" />
          </tokens>
        </chunking>
        <chunking id="3" string="To show you what I mean" type="VP">
          <tokens>
            <token id="1" string="To" />
            <token id="2" string="show" />
            <token id="3" string="you" />
            <token id="4" string="what" />
            <token id="5" string="I" />
            <token id="6" string="mean" />
          </tokens>
        </chunking>
        <chunking id="4" string="mean" type="VP">
          <tokens>
            <token id="6" string="mean" />
          </tokens>
        </chunking>
        <chunking id="5" string="John Major" type="NP">
          <tokens>
            <token id="12" string="John" />
            <token id="13" string="Major" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="5" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="John Major and John Smith" type="NP">
          <tokens>
            <token id="12" string="John" />
            <token id="13" string="Major" />
            <token id="14" string="and" />
            <token id="15" string="John" />
            <token id="16" string="Smith" />
          </tokens>
        </chunking>
        <chunking id="8" string="show you what I mean" type="VP">
          <tokens>
            <token id="2" string="show" />
            <token id="3" string="you" />
            <token id="4" string="what" />
            <token id="5" string="I" />
            <token id="6" string="mean" />
          </tokens>
        </chunking>
        <chunking id="9" string="what I mean" type="SBAR">
          <tokens>
            <token id="4" string="what" />
            <token id="5" string="I" />
            <token id="6" string="mean" />
          </tokens>
        </chunking>
        <chunking id="10" string="you" type="NP">
          <tokens>
            <token id="3" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="2">show</governor>
          <dependent id="1">To</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">spoke</governor>
          <dependent id="2">show</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">show</governor>
          <dependent id="3">you</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">mean</governor>
          <dependent id="4">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">mean</governor>
          <dependent id="5">I</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">show</governor>
          <dependent id="6">mean</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">spoke</governor>
          <dependent id="8">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">spoke</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="9">spoke</governor>
          <dependent id="10">yesterday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Major</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Major</governor>
          <dependent id="12">John</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">spoke</governor>
          <dependent id="13">Major</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">Major</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Smith</governor>
          <dependent id="15">John</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">Major</governor>
          <dependent id="16">Smith</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="yesterday" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="yesterday" />
          </tokens>
        </entity>
        <entity id="2" string="John Smith" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="John" />
            <token id="16" string="Smith" />
          </tokens>
        </entity>
        <entity id="3" string="John Major" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="John" />
            <token id="13" string="Major" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>Smith, a Scot, is leader of the Labour Party, though not many people know that.</content>
      <tokens>
        <token id="1" string="Smith" lemma="Smith" stem="smith" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="Scot" lemma="Scot" stem="scot" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="leader" lemma="leader" stem="leader" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="Labour" lemma="Labour" stem="labour" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="11" string="Party" lemma="Party" stem="parti" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="though" lemma="though" stem="though" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="know" lemma="know" stem="know" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Smith)) (, ,) (NP (DT a) (NNP Scot)) (, ,)) (VP (VBZ is) (NP (NP (NN leader)) (PP (IN of) (NP (DT the) (NNP Labour) (NNP Party)))) (, ,) (SBAR (IN though) (S (NP (RB not) (JJ many) (NNS people)) (VP (VBP know) (ADVP (IN that)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="leader" type="NP">
          <tokens>
            <token id="7" string="leader" />
          </tokens>
        </chunking>
        <chunking id="2" string="know that" type="VP">
          <tokens>
            <token id="17" string="know" />
            <token id="18" string="that" />
          </tokens>
        </chunking>
        <chunking id="3" string="a Scot" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="Scot" />
          </tokens>
        </chunking>
        <chunking id="4" string="leader of the Labour Party" type="NP">
          <tokens>
            <token id="7" string="leader" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="Labour" />
            <token id="11" string="Party" />
          </tokens>
        </chunking>
        <chunking id="5" string="is leader of the Labour Party , though not many people know that" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="leader" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="Labour" />
            <token id="11" string="Party" />
            <token id="12" string="," />
            <token id="13" string="though" />
            <token id="14" string="not" />
            <token id="15" string="many" />
            <token id="16" string="people" />
            <token id="17" string="know" />
            <token id="18" string="that" />
          </tokens>
        </chunking>
        <chunking id="6" string="though not many people know that" type="SBAR">
          <tokens>
            <token id="13" string="though" />
            <token id="14" string="not" />
            <token id="15" string="many" />
            <token id="16" string="people" />
            <token id="17" string="know" />
            <token id="18" string="that" />
          </tokens>
        </chunking>
        <chunking id="7" string="Smith" type="NP">
          <tokens>
            <token id="1" string="Smith" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Labour Party" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="Labour" />
            <token id="11" string="Party" />
          </tokens>
        </chunking>
        <chunking id="9" string="not many people" type="NP">
          <tokens>
            <token id="14" string="not" />
            <token id="15" string="many" />
            <token id="16" string="people" />
          </tokens>
        </chunking>
        <chunking id="10" string="Smith , a Scot ," type="NP">
          <tokens>
            <token id="1" string="Smith" />
            <token id="2" string="," />
            <token id="3" string="a" />
            <token id="4" string="Scot" />
            <token id="5" string="," />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">leader</governor>
          <dependent id="1">Smith</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">Scot</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="1">Smith</governor>
          <dependent id="4">Scot</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">leader</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">leader</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Party</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">Party</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Party</governor>
          <dependent id="10">Labour</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">leader</governor>
          <dependent id="11">Party</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">know</governor>
          <dependent id="13">though</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="16">people</governor>
          <dependent id="14">not</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">people</governor>
          <dependent id="15">many</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">know</governor>
          <dependent id="16">people</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">leader</governor>
          <dependent id="17">know</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">know</governor>
          <dependent id="18">that</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Scot" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Scot" />
          </tokens>
        </entity>
        <entity id="2" string="Smith" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Smith" />
          </tokens>
        </entity>
        <entity id="3" string="Labour Party" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="10" string="Labour" />
            <token id="11" string="Party" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="false">
      <content>In the aftermath of Christchurch, where Labour lost its deposit, I wanted to provoke the two Johns into a spot of real soul-searching.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="aftermath" lemma="aftermath" stem="aftermath" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="Christchurch" lemma="Christchurch" stem="christchurch" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Labour" lemma="labour" stem="labour" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="9" string="lost" lemma="lose" stem="lost" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="deposit" lemma="deposit" stem="deposit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="provoke" lemma="provoke" stem="provok" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="19" string="Johns" lemma="Johns" stem="john" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="spot" lemma="spot" stem="spot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="real" lemma="real" stem="real" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="soul-searching" lemma="soul-searching" stem="soul-search" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NP (DT the) (NN aftermath)) (PP (IN of) (NP (NNP Christchurch))))) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (NN Labour)) (VP (VBD lost) (NP (PRP$ its) (NN deposit))))) (, ,) (NP (PRP I)) (VP (VBD wanted) (S (VP (TO to) (VP (VB provoke) (NP (DT the) (CD two) (NNP Johns)) (PP (IN into) (NP (NP (DT a) (NN spot)) (PP (IN of) (NP (JJ real) (NN soul-searching))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the aftermath of Christchurch" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="aftermath" />
            <token id="4" string="of" />
            <token id="5" string="Christchurch" />
          </tokens>
        </chunking>
        <chunking id="2" string="Christchurch" type="NP">
          <tokens>
            <token id="5" string="Christchurch" />
          </tokens>
        </chunking>
        <chunking id="3" string="wanted to provoke the two Johns into a spot of real soul-searching" type="VP">
          <tokens>
            <token id="14" string="wanted" />
            <token id="15" string="to" />
            <token id="16" string="provoke" />
            <token id="17" string="the" />
            <token id="18" string="two" />
            <token id="19" string="Johns" />
            <token id="20" string="into" />
            <token id="21" string="a" />
            <token id="22" string="spot" />
            <token id="23" string="of" />
            <token id="24" string="real" />
            <token id="25" string="soul-searching" />
          </tokens>
        </chunking>
        <chunking id="4" string="real soul-searching" type="NP">
          <tokens>
            <token id="24" string="real" />
            <token id="25" string="soul-searching" />
          </tokens>
        </chunking>
        <chunking id="5" string="lost its deposit" type="VP">
          <tokens>
            <token id="9" string="lost" />
            <token id="10" string="its" />
            <token id="11" string="deposit" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="13" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="the aftermath" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="aftermath" />
          </tokens>
        </chunking>
        <chunking id="8" string="Labour" type="NP">
          <tokens>
            <token id="8" string="Labour" />
          </tokens>
        </chunking>
        <chunking id="9" string="to provoke the two Johns into a spot of real soul-searching" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="provoke" />
            <token id="17" string="the" />
            <token id="18" string="two" />
            <token id="19" string="Johns" />
            <token id="20" string="into" />
            <token id="21" string="a" />
            <token id="22" string="spot" />
            <token id="23" string="of" />
            <token id="24" string="real" />
            <token id="25" string="soul-searching" />
          </tokens>
        </chunking>
        <chunking id="10" string="the two Johns" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="two" />
            <token id="19" string="Johns" />
          </tokens>
        </chunking>
        <chunking id="11" string="where Labour lost its deposit" type="SBAR">
          <tokens>
            <token id="7" string="where" />
            <token id="8" string="Labour" />
            <token id="9" string="lost" />
            <token id="10" string="its" />
            <token id="11" string="deposit" />
          </tokens>
        </chunking>
        <chunking id="12" string="its deposit" type="NP">
          <tokens>
            <token id="10" string="its" />
            <token id="11" string="deposit" />
          </tokens>
        </chunking>
        <chunking id="13" string="where" type="WHADVP">
          <tokens>
            <token id="7" string="where" />
          </tokens>
        </chunking>
        <chunking id="14" string="provoke the two Johns into a spot of real soul-searching" type="VP">
          <tokens>
            <token id="16" string="provoke" />
            <token id="17" string="the" />
            <token id="18" string="two" />
            <token id="19" string="Johns" />
            <token id="20" string="into" />
            <token id="21" string="a" />
            <token id="22" string="spot" />
            <token id="23" string="of" />
            <token id="24" string="real" />
            <token id="25" string="soul-searching" />
          </tokens>
        </chunking>
        <chunking id="15" string="a spot of real soul-searching" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="spot" />
            <token id="23" string="of" />
            <token id="24" string="real" />
            <token id="25" string="soul-searching" />
          </tokens>
        </chunking>
        <chunking id="16" string="a spot" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="spot" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">aftermath</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">aftermath</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">wanted</governor>
          <dependent id="3">aftermath</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Christchurch</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">aftermath</governor>
          <dependent id="5">Christchurch</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">lost</governor>
          <dependent id="7">where</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">lost</governor>
          <dependent id="8">Labour</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">wanted</governor>
          <dependent id="9">lost</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">deposit</governor>
          <dependent id="10">its</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">lost</governor>
          <dependent id="11">deposit</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">wanted</governor>
          <dependent id="13">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">wanted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">provoke</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">wanted</governor>
          <dependent id="16">provoke</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">Johns</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">Johns</governor>
          <dependent id="18">two</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">provoke</governor>
          <dependent id="19">Johns</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">spot</governor>
          <dependent id="20">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">spot</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">provoke</governor>
          <dependent id="22">spot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">soul-searching</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">soul-searching</governor>
          <dependent id="24">real</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">spot</governor>
          <dependent id="25">soul-searching</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Christchurch" type="LOCATION" score="0.0">
          <tokens>
            <token id="5" string="Christchurch" />
          </tokens>
        </entity>
        <entity id="2" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="18" string="two" />
          </tokens>
        </entity>
        <entity id="3" string="Labour" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="Labour" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>To guarantee them privacy, I used a signal-scrambler.</content>
      <tokens>
        <token id="1" string="To" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="guarantee" lemma="guarantee" stem="guarante" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="privacy" lemma="privacy" stem="privaci" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="used" lemma="use" stem="us" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="signal-scrambler" lemma="signal-scrambler" stem="signal-scrambl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (TO To) (VP (VB guarantee) (S (NP (PRP them)) (NP (NN privacy)))))) (, ,) (NP (PRP I)) (VP (VBD used) (NP (DT a) (NN signal-scrambler))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="privacy" type="NP">
          <tokens>
            <token id="4" string="privacy" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="6" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="guarantee them privacy" type="VP">
          <tokens>
            <token id="2" string="guarantee" />
            <token id="3" string="them" />
            <token id="4" string="privacy" />
          </tokens>
        </chunking>
        <chunking id="4" string="To guarantee them privacy" type="VP">
          <tokens>
            <token id="1" string="To" />
            <token id="2" string="guarantee" />
            <token id="3" string="them" />
            <token id="4" string="privacy" />
          </tokens>
        </chunking>
        <chunking id="5" string="them" type="NP">
          <tokens>
            <token id="3" string="them" />
          </tokens>
        </chunking>
        <chunking id="6" string="used a signal-scrambler" type="VP">
          <tokens>
            <token id="7" string="used" />
            <token id="8" string="a" />
            <token id="9" string="signal-scrambler" />
          </tokens>
        </chunking>
        <chunking id="7" string="a signal-scrambler" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="signal-scrambler" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="2">guarantee</governor>
          <dependent id="1">To</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">used</governor>
          <dependent id="2">guarantee</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">privacy</governor>
          <dependent id="3">them</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">guarantee</governor>
          <dependent id="4">privacy</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">used</governor>
          <dependent id="6">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">used</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">signal-scrambler</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">used</governor>
          <dependent id="9">signal-scrambler</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="18" has_coreference="false">
      <content>No one could have eavesdropped.</content>
      <tokens>
        <token id="1" string="No" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="one" lemma="one" stem="on" pos="NN" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="3" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="eavesdropped" lemma="eavesdrop" stem="eavesdrop" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT No) (NN one)) (VP (MD could) (VP (VB have) (VP (VBN eavesdropped)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="No one" type="NP">
          <tokens>
            <token id="1" string="No" />
            <token id="2" string="one" />
          </tokens>
        </chunking>
        <chunking id="2" string="eavesdropped" type="VP">
          <tokens>
            <token id="5" string="eavesdropped" />
          </tokens>
        </chunking>
        <chunking id="3" string="could have eavesdropped" type="VP">
          <tokens>
            <token id="3" string="could" />
            <token id="4" string="have" />
            <token id="5" string="eavesdropped" />
          </tokens>
        </chunking>
        <chunking id="4" string="have eavesdropped" type="VP">
          <tokens>
            <token id="4" string="have" />
            <token id="5" string="eavesdropped" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="neg">
          <governor id="2">one</governor>
          <dependent id="1">No</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">eavesdropped</governor>
          <dependent id="2">one</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">eavesdropped</governor>
          <dependent id="3">could</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">eavesdropped</governor>
          <dependent id="4">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">eavesdropped</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>Their responses were true to form.</content>
      <tokens>
        <token id="1" string="Their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="responses" lemma="response" stem="respons" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="true" lemma="true" stem="true" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="form" lemma="form" stem="form" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP$ Their) (NNS responses)) (VP (VBD were) (ADJP (JJ true) (S (VP (TO to) (VP (VB form)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="were true to form" type="VP">
          <tokens>
            <token id="3" string="were" />
            <token id="4" string="true" />
            <token id="5" string="to" />
            <token id="6" string="form" />
          </tokens>
        </chunking>
        <chunking id="2" string="Their responses" type="NP">
          <tokens>
            <token id="1" string="Their" />
            <token id="2" string="responses" />
          </tokens>
        </chunking>
        <chunking id="3" string="form" type="VP">
          <tokens>
            <token id="6" string="form" />
          </tokens>
        </chunking>
        <chunking id="4" string="to form" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="form" />
          </tokens>
        </chunking>
        <chunking id="5" string="true to form" type="ADJP">
          <tokens>
            <token id="4" string="true" />
            <token id="5" string="to" />
            <token id="6" string="form" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">responses</governor>
          <dependent id="1">Their</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">true</governor>
          <dependent id="2">responses</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">true</governor>
          <dependent id="3">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">true</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">form</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">true</governor>
          <dependent id="6">form</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="20" has_coreference="false">
      <content>But I have left out the swear-words because the new Financial Times Style Guide states that &amp;apost;the gratuitous use of expletives or obscenities is discouraged . . . Four-letter expletives will usually be confined to infrequent use in the review (Arts) pages.&amp;apost;</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="left" lemma="leave" stem="left" pos="VBN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="5" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="swear-words" lemma="swear-word" stem="swear-word" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Financial" lemma="Financial" stem="financi" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="Times" lemma="Times" stem="time" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="Style" lemma="Style" stem="style" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="Guide" lemma="Guide" stem="guid" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="15" string="states" lemma="state" stem="state" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="gratuitous" lemma="gratuitous" stem="gratuit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="use" lemma="use" stem="us" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="expletives" lemma="expletive" stem="explet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="obscenities" lemma="obscenity" stem="obscen" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="discouraged" lemma="discourage" stem="discourag" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Four-letter" lemma="four-letter" stem="four-lett" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="expletives" lemma="expletive" stem="explet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="usually" lemma="usually" stem="usual" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="confined" lemma="confine" stem="confin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="infrequent" lemma="infrequent" stem="infrequ" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="use" lemma="use" stem="us" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="review" lemma="review" stem="review" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="Arts" lemma="art" stem="art" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="pages" lemma="page" stem="page" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (PRP I)) (VP (VBP have) (VP (VBN left) (PRT (RP out)) (NP (DT the) (NNS swear-words)) (SBAR (IN because) (S (NP (DT the) (JJ new) (NNP Financial) (NNP Times) (NNP Style) (NNP Guide)) (VP (VBZ states) (SBAR (IN that) (S (`` `) (S (NP (NP (DT the) (JJ gratuitous) (NN use)) (PP (IN of) (NP (NNS expletives) (CC or) (NNS obscenities)))) (VP (VBZ is) (VP (VBN discouraged)))) (: ...) (S (NP (JJ Four-letter) (NNS expletives)) (VP (MD will) (ADVP (RB usually)) (VP (VB be) (VP (VBN confined) (PP (TO to) (NP (ADJP (JJ infrequent) (NP (NP (NN use)) (PP (IN in) (NP (DT the) (NN review))))) (PRN (-LRB- -LRB-) (NP (NNS Arts)) (-RRB- -RRB-)) (NNS pages)))))))))))))) (. .) ('' ')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the gratuitous use of expletives or obscenities" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="gratuitous" />
            <token id="20" string="use" />
            <token id="21" string="of" />
            <token id="22" string="expletives" />
            <token id="23" string="or" />
            <token id="24" string="obscenities" />
          </tokens>
        </chunking>
        <chunking id="2" string="the new Financial Times Style Guide" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="new" />
            <token id="11" string="Financial" />
            <token id="12" string="Times" />
            <token id="13" string="Style" />
            <token id="14" string="Guide" />
          </tokens>
        </chunking>
        <chunking id="3" string="the gratuitous use" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="gratuitous" />
            <token id="20" string="use" />
          </tokens>
        </chunking>
        <chunking id="4" string="infrequent use in the review" type="ADJP">
          <tokens>
            <token id="35" string="infrequent" />
            <token id="36" string="use" />
            <token id="37" string="in" />
            <token id="38" string="the" />
            <token id="39" string="review" />
          </tokens>
        </chunking>
        <chunking id="5" string="use" type="NP">
          <tokens>
            <token id="36" string="use" />
          </tokens>
        </chunking>
        <chunking id="6" string="the review" type="NP">
          <tokens>
            <token id="38" string="the" />
            <token id="39" string="review" />
          </tokens>
        </chunking>
        <chunking id="7" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="8" string="Four-letter expletives" type="NP">
          <tokens>
            <token id="28" string="Four-letter" />
            <token id="29" string="expletives" />
          </tokens>
        </chunking>
        <chunking id="9" string="discouraged" type="VP">
          <tokens>
            <token id="26" string="discouraged" />
          </tokens>
        </chunking>
        <chunking id="10" string="infrequent use in the review -LRB- Arts -RRB- pages" type="NP">
          <tokens>
            <token id="35" string="infrequent" />
            <token id="36" string="use" />
            <token id="37" string="in" />
            <token id="38" string="the" />
            <token id="39" string="review" />
            <token id="40" string="(" />
            <token id="41" string="Arts" />
            <token id="42" string=")" />
            <token id="43" string="pages" />
          </tokens>
        </chunking>
        <chunking id="11" string="have left out the swear-words because the new Financial Times Style Guide states that ` the gratuitous use of expletives or obscenities is discouraged ... Four-letter expletives will usually be confined to infrequent use in the review -LRB- Arts -RRB- pages" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="left" />
            <token id="5" string="out" />
            <token id="6" string="the" />
            <token id="7" string="swear-words" />
            <token id="8" string="because" />
            <token id="9" string="the" />
            <token id="10" string="new" />
            <token id="11" string="Financial" />
            <token id="12" string="Times" />
            <token id="13" string="Style" />
            <token id="14" string="Guide" />
            <token id="15" string="states" />
            <token id="16" string="that" />
            <token id="17" string="'" />
            <token id="18" string="the" />
            <token id="19" string="gratuitous" />
            <token id="20" string="use" />
            <token id="21" string="of" />
            <token id="22" string="expletives" />
            <token id="23" string="or" />
            <token id="24" string="obscenities" />
            <token id="25" string="is" />
            <token id="26" string="discouraged" />
            <token id="27" string=". . ." />
            <token id="28" string="Four-letter" />
            <token id="29" string="expletives" />
            <token id="30" string="will" />
            <token id="31" string="usually" />
            <token id="32" string="be" />
            <token id="33" string="confined" />
            <token id="34" string="to" />
            <token id="35" string="infrequent" />
            <token id="36" string="use" />
            <token id="37" string="in" />
            <token id="38" string="the" />
            <token id="39" string="review" />
            <token id="40" string="(" />
            <token id="41" string="Arts" />
            <token id="42" string=")" />
            <token id="43" string="pages" />
          </tokens>
        </chunking>
        <chunking id="12" string="expletives or obscenities" type="NP">
          <tokens>
            <token id="22" string="expletives" />
            <token id="23" string="or" />
            <token id="24" string="obscenities" />
          </tokens>
        </chunking>
        <chunking id="13" string="confined to infrequent use in the review -LRB- Arts -RRB- pages" type="VP">
          <tokens>
            <token id="33" string="confined" />
            <token id="34" string="to" />
            <token id="35" string="infrequent" />
            <token id="36" string="use" />
            <token id="37" string="in" />
            <token id="38" string="the" />
            <token id="39" string="review" />
            <token id="40" string="(" />
            <token id="41" string="Arts" />
            <token id="42" string=")" />
            <token id="43" string="pages" />
          </tokens>
        </chunking>
        <chunking id="14" string="Arts" type="NP">
          <tokens>
            <token id="41" string="Arts" />
          </tokens>
        </chunking>
        <chunking id="15" string="the swear-words" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="swear-words" />
          </tokens>
        </chunking>
        <chunking id="16" string="states that ` the gratuitous use of expletives or obscenities is discouraged ... Four-letter expletives will usually be confined to infrequent use in the review -LRB- Arts -RRB- pages" type="VP">
          <tokens>
            <token id="15" string="states" />
            <token id="16" string="that" />
            <token id="17" string="'" />
            <token id="18" string="the" />
            <token id="19" string="gratuitous" />
            <token id="20" string="use" />
            <token id="21" string="of" />
            <token id="22" string="expletives" />
            <token id="23" string="or" />
            <token id="24" string="obscenities" />
            <token id="25" string="is" />
            <token id="26" string="discouraged" />
            <token id="27" string=". . ." />
            <token id="28" string="Four-letter" />
            <token id="29" string="expletives" />
            <token id="30" string="will" />
            <token id="31" string="usually" />
            <token id="32" string="be" />
            <token id="33" string="confined" />
            <token id="34" string="to" />
            <token id="35" string="infrequent" />
            <token id="36" string="use" />
            <token id="37" string="in" />
            <token id="38" string="the" />
            <token id="39" string="review" />
            <token id="40" string="(" />
            <token id="41" string="Arts" />
            <token id="42" string=")" />
            <token id="43" string="pages" />
          </tokens>
        </chunking>
        <chunking id="17" string="because the new Financial Times Style Guide states that ` the gratuitous use of expletives or obscenities is discouraged ... Four-letter expletives will usually be confined to infrequent use in the review -LRB- Arts -RRB- pages" type="SBAR">
          <tokens>
            <token id="8" string="because" />
            <token id="9" string="the" />
            <token id="10" string="new" />
            <token id="11" string="Financial" />
            <token id="12" string="Times" />
            <token id="13" string="Style" />
            <token id="14" string="Guide" />
            <token id="15" string="states" />
            <token id="16" string="that" />
            <token id="17" string="'" />
            <token id="18" string="the" />
            <token id="19" string="gratuitous" />
            <token id="20" string="use" />
            <token id="21" string="of" />
            <token id="22" string="expletives" />
            <token id="23" string="or" />
            <token id="24" string="obscenities" />
            <token id="25" string="is" />
            <token id="26" string="discouraged" />
            <token id="27" string=". . ." />
            <token id="28" string="Four-letter" />
            <token id="29" string="expletives" />
            <token id="30" string="will" />
            <token id="31" string="usually" />
            <token id="32" string="be" />
            <token id="33" string="confined" />
            <token id="34" string="to" />
            <token id="35" string="infrequent" />
            <token id="36" string="use" />
            <token id="37" string="in" />
            <token id="38" string="the" />
            <token id="39" string="review" />
            <token id="40" string="(" />
            <token id="41" string="Arts" />
            <token id="42" string=")" />
            <token id="43" string="pages" />
          </tokens>
        </chunking>
        <chunking id="18" string="that ` the gratuitous use of expletives or obscenities is discouraged ... Four-letter expletives will usually be confined to infrequent use in the review -LRB- Arts -RRB- pages" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="'" />
            <token id="18" string="the" />
            <token id="19" string="gratuitous" />
            <token id="20" string="use" />
            <token id="21" string="of" />
            <token id="22" string="expletives" />
            <token id="23" string="or" />
            <token id="24" string="obscenities" />
            <token id="25" string="is" />
            <token id="26" string="discouraged" />
            <token id="27" string=". . ." />
            <token id="28" string="Four-letter" />
            <token id="29" string="expletives" />
            <token id="30" string="will" />
            <token id="31" string="usually" />
            <token id="32" string="be" />
            <token id="33" string="confined" />
            <token id="34" string="to" />
            <token id="35" string="infrequent" />
            <token id="36" string="use" />
            <token id="37" string="in" />
            <token id="38" string="the" />
            <token id="39" string="review" />
            <token id="40" string="(" />
            <token id="41" string="Arts" />
            <token id="42" string=")" />
            <token id="43" string="pages" />
          </tokens>
        </chunking>
        <chunking id="19" string="use in the review" type="NP">
          <tokens>
            <token id="36" string="use" />
            <token id="37" string="in" />
            <token id="38" string="the" />
            <token id="39" string="review" />
          </tokens>
        </chunking>
        <chunking id="20" string="be confined to infrequent use in the review -LRB- Arts -RRB- pages" type="VP">
          <tokens>
            <token id="32" string="be" />
            <token id="33" string="confined" />
            <token id="34" string="to" />
            <token id="35" string="infrequent" />
            <token id="36" string="use" />
            <token id="37" string="in" />
            <token id="38" string="the" />
            <token id="39" string="review" />
            <token id="40" string="(" />
            <token id="41" string="Arts" />
            <token id="42" string=")" />
            <token id="43" string="pages" />
          </tokens>
        </chunking>
        <chunking id="21" string="will usually be confined to infrequent use in the review -LRB- Arts -RRB- pages" type="VP">
          <tokens>
            <token id="30" string="will" />
            <token id="31" string="usually" />
            <token id="32" string="be" />
            <token id="33" string="confined" />
            <token id="34" string="to" />
            <token id="35" string="infrequent" />
            <token id="36" string="use" />
            <token id="37" string="in" />
            <token id="38" string="the" />
            <token id="39" string="review" />
            <token id="40" string="(" />
            <token id="41" string="Arts" />
            <token id="42" string=")" />
            <token id="43" string="pages" />
          </tokens>
        </chunking>
        <chunking id="22" string="left out the swear-words because the new Financial Times Style Guide states that ` the gratuitous use of expletives or obscenities is discouraged ... Four-letter expletives will usually be confined to infrequent use in the review -LRB- Arts -RRB- pages" type="VP">
          <tokens>
            <token id="4" string="left" />
            <token id="5" string="out" />
            <token id="6" string="the" />
            <token id="7" string="swear-words" />
            <token id="8" string="because" />
            <token id="9" string="the" />
            <token id="10" string="new" />
            <token id="11" string="Financial" />
            <token id="12" string="Times" />
            <token id="13" string="Style" />
            <token id="14" string="Guide" />
            <token id="15" string="states" />
            <token id="16" string="that" />
            <token id="17" string="'" />
            <token id="18" string="the" />
            <token id="19" string="gratuitous" />
            <token id="20" string="use" />
            <token id="21" string="of" />
            <token id="22" string="expletives" />
            <token id="23" string="or" />
            <token id="24" string="obscenities" />
            <token id="25" string="is" />
            <token id="26" string="discouraged" />
            <token id="27" string=". . ." />
            <token id="28" string="Four-letter" />
            <token id="29" string="expletives" />
            <token id="30" string="will" />
            <token id="31" string="usually" />
            <token id="32" string="be" />
            <token id="33" string="confined" />
            <token id="34" string="to" />
            <token id="35" string="infrequent" />
            <token id="36" string="use" />
            <token id="37" string="in" />
            <token id="38" string="the" />
            <token id="39" string="review" />
            <token id="40" string="(" />
            <token id="41" string="Arts" />
            <token id="42" string=")" />
            <token id="43" string="pages" />
          </tokens>
        </chunking>
        <chunking id="23" string="is discouraged" type="VP">
          <tokens>
            <token id="25" string="is" />
            <token id="26" string="discouraged" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">left</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">left</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">left</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">left</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="4">left</governor>
          <dependent id="5">out</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">swear-words</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">left</governor>
          <dependent id="7">swear-words</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">states</governor>
          <dependent id="8">because</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">Guide</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">Guide</governor>
          <dependent id="10">new</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Guide</governor>
          <dependent id="11">Financial</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Guide</governor>
          <dependent id="12">Times</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Guide</governor>
          <dependent id="13">Style</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">states</governor>
          <dependent id="14">Guide</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">left</governor>
          <dependent id="15">states</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">discouraged</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">use</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">use</governor>
          <dependent id="19">gratuitous</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="26">discouraged</governor>
          <dependent id="20">use</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">expletives</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">use</governor>
          <dependent id="22">expletives</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">expletives</governor>
          <dependent id="23">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">expletives</governor>
          <dependent id="24">obscenities</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="26">discouraged</governor>
          <dependent id="25">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">states</governor>
          <dependent id="26">discouraged</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">expletives</governor>
          <dependent id="28">Four-letter</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="33">confined</governor>
          <dependent id="29">expletives</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="33">confined</governor>
          <dependent id="30">will</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="33">confined</governor>
          <dependent id="31">usually</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="33">confined</governor>
          <dependent id="32">be</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="26">discouraged</governor>
          <dependent id="33">confined</dependent>
        </dependency>
        <dependency type="case">
          <governor id="43">pages</governor>
          <dependent id="34">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="43">pages</governor>
          <dependent id="35">infrequent</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="35">infrequent</governor>
          <dependent id="36">use</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">review</governor>
          <dependent id="37">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">review</governor>
          <dependent id="38">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">use</governor>
          <dependent id="39">review</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="43">pages</governor>
          <dependent id="41">Arts</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">confined</governor>
          <dependent id="43">pages</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="left" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="4" string="left" />
          </tokens>
        </entity>
        <entity id="2" string="Guide" type="TITLE" score="0.0">
          <tokens>
            <token id="14" string="Guide" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>I can live with that, though why the artsy-fartsies should receive any dispensation is a puzzle.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="live" lemma="live" stem="live" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="though" lemma="though" stem="though" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="why" lemma="why" stem="why" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="artsy-fartsies" lemma="artsy-fartsy" stem="artsy-fartsi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="receive" lemma="receive" stem="receiv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="dispensation" lemma="dispensation" stem="dispens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="puzzle" lemma="puzzle" stem="puzzl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (MD can) (VP (VB live) (PP (IN with) (NP (NP (DT that)) (, ,) (SBAR (IN though) (S (SBAR (WHADVP (WRB why)) (S (NP (DT the) (NNS artsy-fartsies)) (VP (MD should) (VP (VB receive) (NP (DT any) (NN dispensation)))))) (VP (VBZ is) (NP (DT a) (NN puzzle))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="though why the artsy-fartsies should receive any dispensation is a puzzle" type="SBAR">
          <tokens>
            <token id="7" string="though" />
            <token id="8" string="why" />
            <token id="9" string="the" />
            <token id="10" string="artsy-fartsies" />
            <token id="11" string="should" />
            <token id="12" string="receive" />
            <token id="13" string="any" />
            <token id="14" string="dispensation" />
            <token id="15" string="is" />
            <token id="16" string="a" />
            <token id="17" string="puzzle" />
          </tokens>
        </chunking>
        <chunking id="2" string="why" type="WHADVP">
          <tokens>
            <token id="8" string="why" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="is a puzzle" type="VP">
          <tokens>
            <token id="15" string="is" />
            <token id="16" string="a" />
            <token id="17" string="puzzle" />
          </tokens>
        </chunking>
        <chunking id="5" string="receive any dispensation" type="VP">
          <tokens>
            <token id="12" string="receive" />
            <token id="13" string="any" />
            <token id="14" string="dispensation" />
          </tokens>
        </chunking>
        <chunking id="6" string="can live with that , though why the artsy-fartsies should receive any dispensation is a puzzle" type="VP">
          <tokens>
            <token id="2" string="can" />
            <token id="3" string="live" />
            <token id="4" string="with" />
            <token id="5" string="that" />
            <token id="6" string="," />
            <token id="7" string="though" />
            <token id="8" string="why" />
            <token id="9" string="the" />
            <token id="10" string="artsy-fartsies" />
            <token id="11" string="should" />
            <token id="12" string="receive" />
            <token id="13" string="any" />
            <token id="14" string="dispensation" />
            <token id="15" string="is" />
            <token id="16" string="a" />
            <token id="17" string="puzzle" />
          </tokens>
        </chunking>
        <chunking id="7" string="live with that , though why the artsy-fartsies should receive any dispensation is a puzzle" type="VP">
          <tokens>
            <token id="3" string="live" />
            <token id="4" string="with" />
            <token id="5" string="that" />
            <token id="6" string="," />
            <token id="7" string="though" />
            <token id="8" string="why" />
            <token id="9" string="the" />
            <token id="10" string="artsy-fartsies" />
            <token id="11" string="should" />
            <token id="12" string="receive" />
            <token id="13" string="any" />
            <token id="14" string="dispensation" />
            <token id="15" string="is" />
            <token id="16" string="a" />
            <token id="17" string="puzzle" />
          </tokens>
        </chunking>
        <chunking id="8" string="that" type="NP">
          <tokens>
            <token id="5" string="that" />
          </tokens>
        </chunking>
        <chunking id="9" string="any dispensation" type="NP">
          <tokens>
            <token id="13" string="any" />
            <token id="14" string="dispensation" />
          </tokens>
        </chunking>
        <chunking id="10" string="the artsy-fartsies" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="artsy-fartsies" />
          </tokens>
        </chunking>
        <chunking id="11" string="should receive any dispensation" type="VP">
          <tokens>
            <token id="11" string="should" />
            <token id="12" string="receive" />
            <token id="13" string="any" />
            <token id="14" string="dispensation" />
          </tokens>
        </chunking>
        <chunking id="12" string="that , though why the artsy-fartsies should receive any dispensation is a puzzle" type="NP">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="," />
            <token id="7" string="though" />
            <token id="8" string="why" />
            <token id="9" string="the" />
            <token id="10" string="artsy-fartsies" />
            <token id="11" string="should" />
            <token id="12" string="receive" />
            <token id="13" string="any" />
            <token id="14" string="dispensation" />
            <token id="15" string="is" />
            <token id="16" string="a" />
            <token id="17" string="puzzle" />
          </tokens>
        </chunking>
        <chunking id="13" string="why the artsy-fartsies should receive any dispensation" type="SBAR">
          <tokens>
            <token id="8" string="why" />
            <token id="9" string="the" />
            <token id="10" string="artsy-fartsies" />
            <token id="11" string="should" />
            <token id="12" string="receive" />
            <token id="13" string="any" />
            <token id="14" string="dispensation" />
          </tokens>
        </chunking>
        <chunking id="14" string="a puzzle" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="puzzle" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">live</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">live</governor>
          <dependent id="2">can</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">live</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">that</governor>
          <dependent id="4">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">live</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">puzzle</governor>
          <dependent id="7">though</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">receive</governor>
          <dependent id="8">why</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">artsy-fartsies</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">receive</governor>
          <dependent id="10">artsy-fartsies</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">receive</governor>
          <dependent id="11">should</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">puzzle</governor>
          <dependent id="12">receive</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">dispensation</governor>
          <dependent id="13">any</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">receive</governor>
          <dependent id="14">dispensation</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">puzzle</governor>
          <dependent id="15">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">puzzle</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">that</governor>
          <dependent id="17">puzzle</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>First, I tackled Major.</content>
      <tokens>
        <token id="1" string="First" lemma="first" stem="first" pos="RB" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="tackled" lemma="tackle" stem="tackl" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="Major" lemma="Major" stem="major" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB First)) (, ,) (NP (PRP I)) (VP (VBD tackled) (NP (NNP Major))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="tackled Major" type="VP">
          <tokens>
            <token id="4" string="tackled" />
            <token id="5" string="Major" />
          </tokens>
        </chunking>
        <chunking id="2" string="Major" type="NP">
          <tokens>
            <token id="5" string="Major" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="3" string="I" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">tackled</governor>
          <dependent id="1">First</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">tackled</governor>
          <dependent id="3">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">tackled</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">tackled</governor>
          <dependent id="5">Major</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="First" type="ORDINAL" score="0.0">
          <tokens>
            <token id="1" string="First" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>I said: &amp;apost;Did you read, John, what Olivier Blanchard, Rudiger Dornbusch, Stanley Fischer, Franco Modigliani, Paul A Samuelson and Robert Solow wrote, in just one article, in the FT this week?</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="read" lemma="read" stem="read" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="what" lemma="what" stem="what" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="Olivier" lemma="Olivier" stem="olivier" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="Blanchard" lemma="Blanchard" stem="blanchard" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="Rudiger" lemma="Rudiger" stem="rudig" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="Dornbusch" lemma="Dornbusch" stem="dornbusch" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="Stanley" lemma="Stanley" stem="stanlei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="19" string="Fischer" lemma="Fischer" stem="fischer" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="Franco" lemma="Franco" stem="franco" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="22" string="Modigliani" lemma="Modigliani" stem="modigliani" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="Paul" lemma="Paul" stem="paul" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="25" string="A" lemma="A" stem="a" pos="NNP" type="Word" isStopWord="true" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="26" string="Samuelson" lemma="Samuelson" stem="samuelson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="Robert" lemma="Robert" stem="robert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="29" string="Solow" lemma="Solow" stem="solow" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="30" string="wrote" lemma="write" stem="wrote" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="32" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="34" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="35" string="article" lemma="article" stem="articl" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="36" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="37" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="38" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="39" string="FT" lemma="FT" stem="ft" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="40" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="true" />
        <token id="41" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="true" />
        <token id="42" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VP (VBD said) (: :) (`` `) (SQ (VBD Did) (NP (PRP you)) (VP (VB read)))) (, ,) (NP (NP (NNP John)) (, ,) (SBAR (WHNP (WDT what)) (S (NP (NP (NNP Olivier) (NNP Blanchard)) (, ,) (NP (NNP Rudiger) (NNP Dornbusch)) (, ,) (NP (NNP Stanley) (NNP Fischer)) (, ,) (NP (NNP Franco) (NNP Modigliani)) (, ,) (NP (NNP Paul) (NNP A) (NNP Samuelson)) (CC and) (NP (NNP Robert) (NNP Solow))) (VP (VBD wrote) (, ,) (PP (IN in) (NP (RB just) (CD one) (NN article))) (, ,) (PP (IN in) (NP (DT the) (NNP FT))) (NP-TMP (DT this) (NN week))))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="read" type="VP">
          <tokens>
            <token id="7" string="read" />
          </tokens>
        </chunking>
        <chunking id="2" string="said : ` Did you read , John , what Olivier Blanchard , Rudiger Dornbusch , Stanley Fischer , Franco Modigliani , Paul A Samuelson and Robert Solow wrote , in just one article , in the FT this week" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string=":" />
            <token id="4" string="'" />
            <token id="5" string="Did" />
            <token id="6" string="you" />
            <token id="7" string="read" />
            <token id="8" string="," />
            <token id="9" string="John" />
            <token id="10" string="," />
            <token id="11" string="what" />
            <token id="12" string="Olivier" />
            <token id="13" string="Blanchard" />
            <token id="14" string="," />
            <token id="15" string="Rudiger" />
            <token id="16" string="Dornbusch" />
            <token id="17" string="," />
            <token id="18" string="Stanley" />
            <token id="19" string="Fischer" />
            <token id="20" string="," />
            <token id="21" string="Franco" />
            <token id="22" string="Modigliani" />
            <token id="23" string="," />
            <token id="24" string="Paul" />
            <token id="25" string="A" />
            <token id="26" string="Samuelson" />
            <token id="27" string="and" />
            <token id="28" string="Robert" />
            <token id="29" string="Solow" />
            <token id="30" string="wrote" />
            <token id="31" string="," />
            <token id="32" string="in" />
            <token id="33" string="just" />
            <token id="34" string="one" />
            <token id="35" string="article" />
            <token id="36" string="," />
            <token id="37" string="in" />
            <token id="38" string="the" />
            <token id="39" string="FT" />
            <token id="40" string="this" />
            <token id="41" string="week" />
          </tokens>
        </chunking>
        <chunking id="3" string="Olivier Blanchard" type="NP">
          <tokens>
            <token id="12" string="Olivier" />
            <token id="13" string="Blanchard" />
          </tokens>
        </chunking>
        <chunking id="4" string="wrote , in just one article , in the FT this week" type="VP">
          <tokens>
            <token id="30" string="wrote" />
            <token id="31" string="," />
            <token id="32" string="in" />
            <token id="33" string="just" />
            <token id="34" string="one" />
            <token id="35" string="article" />
            <token id="36" string="," />
            <token id="37" string="in" />
            <token id="38" string="the" />
            <token id="39" string="FT" />
            <token id="40" string="this" />
            <token id="41" string="week" />
          </tokens>
        </chunking>
        <chunking id="5" string="Olivier Blanchard , Rudiger Dornbusch , Stanley Fischer , Franco Modigliani , Paul A Samuelson and Robert Solow" type="NP">
          <tokens>
            <token id="12" string="Olivier" />
            <token id="13" string="Blanchard" />
            <token id="14" string="," />
            <token id="15" string="Rudiger" />
            <token id="16" string="Dornbusch" />
            <token id="17" string="," />
            <token id="18" string="Stanley" />
            <token id="19" string="Fischer" />
            <token id="20" string="," />
            <token id="21" string="Franco" />
            <token id="22" string="Modigliani" />
            <token id="23" string="," />
            <token id="24" string="Paul" />
            <token id="25" string="A" />
            <token id="26" string="Samuelson" />
            <token id="27" string="and" />
            <token id="28" string="Robert" />
            <token id="29" string="Solow" />
          </tokens>
        </chunking>
        <chunking id="6" string="the FT" type="NP">
          <tokens>
            <token id="38" string="the" />
            <token id="39" string="FT" />
          </tokens>
        </chunking>
        <chunking id="7" string="Stanley Fischer" type="NP">
          <tokens>
            <token id="18" string="Stanley" />
            <token id="19" string="Fischer" />
          </tokens>
        </chunking>
        <chunking id="8" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="9" string="John" type="NP">
          <tokens>
            <token id="9" string="John" />
          </tokens>
        </chunking>
        <chunking id="10" string="John , what Olivier Blanchard , Rudiger Dornbusch , Stanley Fischer , Franco Modigliani , Paul A Samuelson and Robert Solow wrote , in just one article , in the FT this week" type="NP">
          <tokens>
            <token id="9" string="John" />
            <token id="10" string="," />
            <token id="11" string="what" />
            <token id="12" string="Olivier" />
            <token id="13" string="Blanchard" />
            <token id="14" string="," />
            <token id="15" string="Rudiger" />
            <token id="16" string="Dornbusch" />
            <token id="17" string="," />
            <token id="18" string="Stanley" />
            <token id="19" string="Fischer" />
            <token id="20" string="," />
            <token id="21" string="Franco" />
            <token id="22" string="Modigliani" />
            <token id="23" string="," />
            <token id="24" string="Paul" />
            <token id="25" string="A" />
            <token id="26" string="Samuelson" />
            <token id="27" string="and" />
            <token id="28" string="Robert" />
            <token id="29" string="Solow" />
            <token id="30" string="wrote" />
            <token id="31" string="," />
            <token id="32" string="in" />
            <token id="33" string="just" />
            <token id="34" string="one" />
            <token id="35" string="article" />
            <token id="36" string="," />
            <token id="37" string="in" />
            <token id="38" string="the" />
            <token id="39" string="FT" />
            <token id="40" string="this" />
            <token id="41" string="week" />
          </tokens>
        </chunking>
        <chunking id="11" string="said : ` Did you read" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string=":" />
            <token id="4" string="'" />
            <token id="5" string="Did" />
            <token id="6" string="you" />
            <token id="7" string="read" />
          </tokens>
        </chunking>
        <chunking id="12" string="what Olivier Blanchard , Rudiger Dornbusch , Stanley Fischer , Franco Modigliani , Paul A Samuelson and Robert Solow wrote , in just one article , in the FT this week" type="SBAR">
          <tokens>
            <token id="11" string="what" />
            <token id="12" string="Olivier" />
            <token id="13" string="Blanchard" />
            <token id="14" string="," />
            <token id="15" string="Rudiger" />
            <token id="16" string="Dornbusch" />
            <token id="17" string="," />
            <token id="18" string="Stanley" />
            <token id="19" string="Fischer" />
            <token id="20" string="," />
            <token id="21" string="Franco" />
            <token id="22" string="Modigliani" />
            <token id="23" string="," />
            <token id="24" string="Paul" />
            <token id="25" string="A" />
            <token id="26" string="Samuelson" />
            <token id="27" string="and" />
            <token id="28" string="Robert" />
            <token id="29" string="Solow" />
            <token id="30" string="wrote" />
            <token id="31" string="," />
            <token id="32" string="in" />
            <token id="33" string="just" />
            <token id="34" string="one" />
            <token id="35" string="article" />
            <token id="36" string="," />
            <token id="37" string="in" />
            <token id="38" string="the" />
            <token id="39" string="FT" />
            <token id="40" string="this" />
            <token id="41" string="week" />
          </tokens>
        </chunking>
        <chunking id="13" string="Rudiger Dornbusch" type="NP">
          <tokens>
            <token id="15" string="Rudiger" />
            <token id="16" string="Dornbusch" />
          </tokens>
        </chunking>
        <chunking id="14" string="Franco Modigliani" type="NP">
          <tokens>
            <token id="21" string="Franco" />
            <token id="22" string="Modigliani" />
          </tokens>
        </chunking>
        <chunking id="15" string="Paul A Samuelson" type="NP">
          <tokens>
            <token id="24" string="Paul" />
            <token id="25" string="A" />
            <token id="26" string="Samuelson" />
          </tokens>
        </chunking>
        <chunking id="16" string="Robert Solow" type="NP">
          <tokens>
            <token id="28" string="Robert" />
            <token id="29" string="Solow" />
          </tokens>
        </chunking>
        <chunking id="17" string="you" type="NP">
          <tokens>
            <token id="6" string="you" />
          </tokens>
        </chunking>
        <chunking id="18" string="just one article" type="NP">
          <tokens>
            <token id="33" string="just" />
            <token id="34" string="one" />
            <token id="35" string="article" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">read</governor>
          <dependent id="5">Did</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">read</governor>
          <dependent id="6">you</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">said</governor>
          <dependent id="7">read</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">said</governor>
          <dependent id="9">John</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">wrote</governor>
          <dependent id="11">what</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Blanchard</governor>
          <dependent id="12">Olivier</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">wrote</governor>
          <dependent id="13">Blanchard</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Dornbusch</governor>
          <dependent id="15">Rudiger</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">Blanchard</governor>
          <dependent id="16">Dornbusch</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Fischer</governor>
          <dependent id="18">Stanley</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">Blanchard</governor>
          <dependent id="19">Fischer</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Modigliani</governor>
          <dependent id="21">Franco</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">Blanchard</governor>
          <dependent id="22">Modigliani</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Samuelson</governor>
          <dependent id="24">Paul</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Samuelson</governor>
          <dependent id="25">A</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">Blanchard</governor>
          <dependent id="26">Samuelson</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">Blanchard</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Solow</governor>
          <dependent id="28">Robert</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">Blanchard</governor>
          <dependent id="29">Solow</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">John</governor>
          <dependent id="30">wrote</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">article</governor>
          <dependent id="32">in</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="35">article</governor>
          <dependent id="33">just</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="35">article</governor>
          <dependent id="34">one</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">wrote</governor>
          <dependent id="35">article</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">FT</governor>
          <dependent id="37">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">FT</governor>
          <dependent id="38">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">wrote</governor>
          <dependent id="39">FT</dependent>
        </dependency>
        <dependency type="det">
          <governor id="41">week</governor>
          <dependent id="40">this</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="30">wrote</governor>
          <dependent id="41">week</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Rudiger Dornbusch" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Rudiger" />
            <token id="16" string="Dornbusch" />
          </tokens>
        </entity>
        <entity id="2" string="Olivier Blanchard" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Olivier" />
            <token id="13" string="Blanchard" />
          </tokens>
        </entity>
        <entity id="3" string="Franco Modigliani" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Franco" />
            <token id="22" string="Modigliani" />
          </tokens>
        </entity>
        <entity id="4" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="34" string="one" />
          </tokens>
        </entity>
        <entity id="5" string="Stanley Fischer" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Stanley" />
            <token id="19" string="Fischer" />
          </tokens>
        </entity>
        <entity id="6" string="this week" type="DATE" score="0.0">
          <tokens>
            <token id="40" string="this" />
            <token id="41" string="week" />
          </tokens>
        </entity>
        <entity id="7" string="John" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="John" />
          </tokens>
        </entity>
        <entity id="8" string="Paul A Samuelson" type="PERSON" score="0.0">
          <tokens>
            <token id="24" string="Paul" />
            <token id="25" string="A" />
            <token id="26" string="Samuelson" />
          </tokens>
        </entity>
        <entity id="9" string="Robert Solow" type="PERSON" score="0.0">
          <tokens>
            <token id="28" string="Robert" />
            <token id="29" string="Solow" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>They were describing Europe&amp;apost;s lunatic monetary policies and exchange rate arrangements.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="describing" lemma="describe" stem="describ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Europe" lemma="Europe" stem="europ" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="5" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="lunatic" lemma="lunatic" stem="lunat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="monetary" lemma="monetary" stem="monetari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="policies" lemma="policy" stem="polici" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="exchange" lemma="exchange" stem="exchang" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="rate" lemma="rate" stem="rate" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="arrangements" lemma="arrangement" stem="arrang" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBD were) (VP (VBG describing) (NP (NP (NP (NNP Europe) (POS 's)) (JJ lunatic) (JJ monetary) (NNS policies)) (CC and) (NP (NN exchange) (NN rate) (NNS arrangements))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="were describing Europe 's lunatic monetary policies and exchange rate arrangements" type="VP">
          <tokens>
            <token id="2" string="were" />
            <token id="3" string="describing" />
            <token id="4" string="Europe" />
            <token id="5" string="'s" />
            <token id="6" string="lunatic" />
            <token id="7" string="monetary" />
            <token id="8" string="policies" />
            <token id="9" string="and" />
            <token id="10" string="exchange" />
            <token id="11" string="rate" />
            <token id="12" string="arrangements" />
          </tokens>
        </chunking>
        <chunking id="3" string="Europe 's lunatic monetary policies" type="NP">
          <tokens>
            <token id="4" string="Europe" />
            <token id="5" string="'s" />
            <token id="6" string="lunatic" />
            <token id="7" string="monetary" />
            <token id="8" string="policies" />
          </tokens>
        </chunking>
        <chunking id="4" string="Europe 's lunatic monetary policies and exchange rate arrangements" type="NP">
          <tokens>
            <token id="4" string="Europe" />
            <token id="5" string="'s" />
            <token id="6" string="lunatic" />
            <token id="7" string="monetary" />
            <token id="8" string="policies" />
            <token id="9" string="and" />
            <token id="10" string="exchange" />
            <token id="11" string="rate" />
            <token id="12" string="arrangements" />
          </tokens>
        </chunking>
        <chunking id="5" string="describing Europe 's lunatic monetary policies and exchange rate arrangements" type="VP">
          <tokens>
            <token id="3" string="describing" />
            <token id="4" string="Europe" />
            <token id="5" string="'s" />
            <token id="6" string="lunatic" />
            <token id="7" string="monetary" />
            <token id="8" string="policies" />
            <token id="9" string="and" />
            <token id="10" string="exchange" />
            <token id="11" string="rate" />
            <token id="12" string="arrangements" />
          </tokens>
        </chunking>
        <chunking id="6" string="Europe 's" type="NP">
          <tokens>
            <token id="4" string="Europe" />
            <token id="5" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="exchange rate arrangements" type="NP">
          <tokens>
            <token id="10" string="exchange" />
            <token id="11" string="rate" />
            <token id="12" string="arrangements" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">describing</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">describing</governor>
          <dependent id="2">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">describing</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">policies</governor>
          <dependent id="4">Europe</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Europe</governor>
          <dependent id="5">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">policies</governor>
          <dependent id="6">lunatic</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">policies</governor>
          <dependent id="7">monetary</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">describing</governor>
          <dependent id="8">policies</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">policies</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">arrangements</governor>
          <dependent id="10">exchange</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">arrangements</governor>
          <dependent id="11">rate</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">policies</governor>
          <dependent id="12">arrangements</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Europe" type="LOCATION" score="0.0">
          <tokens>
            <token id="4" string="Europe" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>They did not pull their punches.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="pull" lemma="pull" stem="pull" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="punches" lemma="punch" stem="punch" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBD did) (RB not) (VP (VB pull) (NP (PRP$ their) (NNS punches)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="pull their punches" type="VP">
          <tokens>
            <token id="4" string="pull" />
            <token id="5" string="their" />
            <token id="6" string="punches" />
          </tokens>
        </chunking>
        <chunking id="3" string="their punches" type="NP">
          <tokens>
            <token id="5" string="their" />
            <token id="6" string="punches" />
          </tokens>
        </chunking>
        <chunking id="4" string="did not pull their punches" type="VP">
          <tokens>
            <token id="2" string="did" />
            <token id="3" string="not" />
            <token id="4" string="pull" />
            <token id="5" string="their" />
            <token id="6" string="punches" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">pull</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">pull</governor>
          <dependent id="2">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">pull</governor>
          <dependent id="3">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">pull</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">punches</governor>
          <dependent id="5">their</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">pull</governor>
          <dependent id="6">punches</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="26" has_coreference="false">
      <content>I bet you went chalk-white.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="bet" lemma="bet" stem="bet" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="chalk-white" lemma="chalk-white" stem="chalk-whit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP bet) (SBAR (S (NP (PRP you)) (VP (VBD went) (ADJP (JJ chalk-white)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="chalk-white" type="ADJP">
          <tokens>
            <token id="5" string="chalk-white" />
          </tokens>
        </chunking>
        <chunking id="2" string="bet you went chalk-white" type="VP">
          <tokens>
            <token id="2" string="bet" />
            <token id="3" string="you" />
            <token id="4" string="went" />
            <token id="5" string="chalk-white" />
          </tokens>
        </chunking>
        <chunking id="3" string="you went chalk-white" type="SBAR">
          <tokens>
            <token id="3" string="you" />
            <token id="4" string="went" />
            <token id="5" string="chalk-white" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="went chalk-white" type="VP">
          <tokens>
            <token id="4" string="went" />
            <token id="5" string="chalk-white" />
          </tokens>
        </chunking>
        <chunking id="6" string="you" type="NP">
          <tokens>
            <token id="3" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">bet</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">bet</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">went</governor>
          <dependent id="3">you</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">bet</governor>
          <dependent id="4">went</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">went</governor>
          <dependent id="5">chalk-white</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>&amp;apost;So why not walk the plank, John?</content>
      <tokens>
        <token id="1" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="So" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="why" lemma="why" stem="why" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="walk" lemma="walk" stem="walk" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="plank" lemma="plank" stem="plank" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SBARQ (`` `) (WHADVP (ADVP (RB So)) (WRB why)) (SQ (RB not) (VP (VB walk) (NP (NP (DT the) (NN plank)) (, ,) (NP (NNP John))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the plank , John" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="plank" />
            <token id="8" string="," />
            <token id="9" string="John" />
          </tokens>
        </chunking>
        <chunking id="2" string="John" type="NP">
          <tokens>
            <token id="9" string="John" />
          </tokens>
        </chunking>
        <chunking id="3" string="the plank" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="plank" />
          </tokens>
        </chunking>
        <chunking id="4" string="So why" type="WHADVP">
          <tokens>
            <token id="2" string="So" />
            <token id="3" string="why" />
          </tokens>
        </chunking>
        <chunking id="5" string="walk the plank , John" type="VP">
          <tokens>
            <token id="5" string="walk" />
            <token id="6" string="the" />
            <token id="7" string="plank" />
            <token id="8" string="," />
            <token id="9" string="John" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">why</governor>
          <dependent id="2">So</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">walk</governor>
          <dependent id="3">why</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">walk</governor>
          <dependent id="4">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">walk</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">plank</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">walk</governor>
          <dependent id="7">plank</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="7">plank</governor>
          <dependent id="9">John</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="John" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="false">
      <content>You are the most unpopular prime minister since the start of the fourth century.</content>
      <tokens>
        <token id="1" string="You" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="unpopular" lemma="unpopular" stem="unpopular" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="prime" lemma="prime" stem="prime" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="minister" lemma="minister" stem="minist" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="10" string="start" lemma="start" stem="start" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="13" string="fourth" lemma="fourth" stem="fourth" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="14" string="century" lemma="century" stem="centuri" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP You)) (VP (VBP are) (NP (NP (DT the) (ADJP (RBS most) (JJ unpopular)) (JJ prime) (NN minister)) (PP (IN since) (NP (NP (DT the) (NN start)) (PP (IN of) (NP (DT the) (JJ fourth) (NN century))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the most unpopular prime minister" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="most" />
            <token id="5" string="unpopular" />
            <token id="6" string="prime" />
            <token id="7" string="minister" />
          </tokens>
        </chunking>
        <chunking id="2" string="the fourth century" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="fourth" />
            <token id="14" string="century" />
          </tokens>
        </chunking>
        <chunking id="3" string="the start" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="start" />
          </tokens>
        </chunking>
        <chunking id="4" string="most unpopular" type="ADJP">
          <tokens>
            <token id="4" string="most" />
            <token id="5" string="unpopular" />
          </tokens>
        </chunking>
        <chunking id="5" string="the start of the fourth century" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="start" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="fourth" />
            <token id="14" string="century" />
          </tokens>
        </chunking>
        <chunking id="6" string="are the most unpopular prime minister since the start of the fourth century" type="VP">
          <tokens>
            <token id="2" string="are" />
            <token id="3" string="the" />
            <token id="4" string="most" />
            <token id="5" string="unpopular" />
            <token id="6" string="prime" />
            <token id="7" string="minister" />
            <token id="8" string="since" />
            <token id="9" string="the" />
            <token id="10" string="start" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="fourth" />
            <token id="14" string="century" />
          </tokens>
        </chunking>
        <chunking id="7" string="the most unpopular prime minister since the start of the fourth century" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="most" />
            <token id="5" string="unpopular" />
            <token id="6" string="prime" />
            <token id="7" string="minister" />
            <token id="8" string="since" />
            <token id="9" string="the" />
            <token id="10" string="start" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="fourth" />
            <token id="14" string="century" />
          </tokens>
        </chunking>
        <chunking id="8" string="You" type="NP">
          <tokens>
            <token id="1" string="You" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">minister</governor>
          <dependent id="1">You</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">minister</governor>
          <dependent id="2">are</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">minister</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">unpopular</governor>
          <dependent id="4">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">minister</governor>
          <dependent id="5">unpopular</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">minister</governor>
          <dependent id="6">prime</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">minister</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">start</governor>
          <dependent id="8">since</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">start</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">minister</governor>
          <dependent id="10">start</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">century</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">century</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">century</governor>
          <dependent id="13">fourth</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">start</governor>
          <dependent id="14">century</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the start of the fourth century" type="DATE" score="0.0">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="start" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="fourth" />
            <token id="14" string="century" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="false">
      <content>Why invite more punishment?</content>
      <tokens>
        <token id="1" string="Why" lemma="why" stem="why" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="invite" lemma="invite" stem="invit" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="punishment" lemma="punishment" stem="punish" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SBARQ (WHADVP (WRB Why)) (SQ (VP (VBP invite) (NP (JJR more) (NN punishment)))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="invite more punishment" type="VP">
          <tokens>
            <token id="2" string="invite" />
            <token id="3" string="more" />
            <token id="4" string="punishment" />
          </tokens>
        </chunking>
        <chunking id="2" string="more punishment" type="NP">
          <tokens>
            <token id="3" string="more" />
            <token id="4" string="punishment" />
          </tokens>
        </chunking>
        <chunking id="3" string="Why" type="WHADVP">
          <tokens>
            <token id="1" string="Why" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="2">invite</governor>
          <dependent id="1">Why</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">invite</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">punishment</governor>
          <dependent id="3">more</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">invite</governor>
          <dependent id="4">punishment</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>Unfairly or not, you are drawing the blame for all life&amp;apost;s unpleasantnesses, let alone the cock-ups.&amp;apost;</content>
      <tokens>
        <token id="1" string="Unfairly" lemma="unfairly" stem="unfairli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="drawing" lemma="draw" stem="draw" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="blame" lemma="blame" stem="blame" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="unpleasantnesses" lemma="unpleasantness" stem="unpleas" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="let" lemma="let" stem="let" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="alone" lemma="alone" stem="alon" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="cock-ups" lemma="cock-up" stem="cock-up" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (ADVP (RB Unfairly)) (CC or) (ADVP (RB not))) (, ,) (NP (PRP you)) (VP (VBP are) (VP (VBG drawing) (NP (DT the) (NN blame)) (PP (IN for) (NP (NP (DT all) (NN life) (POS 's)) (NNS unpleasantnesses))) (, ,) (S (VP (VB let) (S (ADJP (RB alone)) (NP (DT the) (NNS cock-ups))))))) (. .) ('' ')))</syntactictree>
      <chunkings>
        <chunking id="1" string="are drawing the blame for all life 's unpleasantnesses , let alone the cock-ups" type="VP">
          <tokens>
            <token id="6" string="are" />
            <token id="7" string="drawing" />
            <token id="8" string="the" />
            <token id="9" string="blame" />
            <token id="10" string="for" />
            <token id="11" string="all" />
            <token id="12" string="life" />
            <token id="13" string="'s" />
            <token id="14" string="unpleasantnesses" />
            <token id="15" string="," />
            <token id="16" string="let" />
            <token id="17" string="alone" />
            <token id="18" string="the" />
            <token id="19" string="cock-ups" />
          </tokens>
        </chunking>
        <chunking id="2" string="all life 's" type="NP">
          <tokens>
            <token id="11" string="all" />
            <token id="12" string="life" />
            <token id="13" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="drawing the blame for all life 's unpleasantnesses , let alone the cock-ups" type="VP">
          <tokens>
            <token id="7" string="drawing" />
            <token id="8" string="the" />
            <token id="9" string="blame" />
            <token id="10" string="for" />
            <token id="11" string="all" />
            <token id="12" string="life" />
            <token id="13" string="'s" />
            <token id="14" string="unpleasantnesses" />
            <token id="15" string="," />
            <token id="16" string="let" />
            <token id="17" string="alone" />
            <token id="18" string="the" />
            <token id="19" string="cock-ups" />
          </tokens>
        </chunking>
        <chunking id="4" string="alone" type="ADJP">
          <tokens>
            <token id="17" string="alone" />
          </tokens>
        </chunking>
        <chunking id="5" string="all life 's unpleasantnesses" type="NP">
          <tokens>
            <token id="11" string="all" />
            <token id="12" string="life" />
            <token id="13" string="'s" />
            <token id="14" string="unpleasantnesses" />
          </tokens>
        </chunking>
        <chunking id="6" string="let alone the cock-ups" type="VP">
          <tokens>
            <token id="16" string="let" />
            <token id="17" string="alone" />
            <token id="18" string="the" />
            <token id="19" string="cock-ups" />
          </tokens>
        </chunking>
        <chunking id="7" string="the blame" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="blame" />
          </tokens>
        </chunking>
        <chunking id="8" string="the cock-ups" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="cock-ups" />
          </tokens>
        </chunking>
        <chunking id="9" string="you" type="NP">
          <tokens>
            <token id="5" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="2">or</governor>
          <dependent id="1">Unfairly</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">drawing</governor>
          <dependent id="2">or</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">or</governor>
          <dependent id="3">not</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">drawing</governor>
          <dependent id="5">you</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">drawing</governor>
          <dependent id="6">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">drawing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">blame</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">drawing</governor>
          <dependent id="9">blame</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">unpleasantnesses</governor>
          <dependent id="10">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">life</governor>
          <dependent id="11">all</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">unpleasantnesses</governor>
          <dependent id="12">life</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">life</governor>
          <dependent id="13">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">drawing</governor>
          <dependent id="14">unpleasantnesses</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">drawing</governor>
          <dependent id="16">let</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">let</governor>
          <dependent id="17">alone</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">cock-ups</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">alone</governor>
          <dependent id="19">cock-ups</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>&amp;apost;Are you sure?&amp;apost;</content>
      <tokens>
        <token id="1" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Are" lemma="be" stem="are" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="sure" lemma="sure" stem="sure" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (VP (`` `) (VBP Are) (NP (PRP you) (JJ sure))) (. ?) ('' ')))</syntactictree>
      <chunkings>
        <chunking id="1" string="you sure" type="NP">
          <tokens>
            <token id="3" string="you" />
            <token id="4" string="sure" />
          </tokens>
        </chunking>
        <chunking id="2" string="` Are you sure" type="VP">
          <tokens>
            <token id="1" string="'" />
            <token id="2" string="Are" />
            <token id="3" string="you" />
            <token id="4" string="sure" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cop">
          <governor id="3">you</governor>
          <dependent id="2">Are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">you</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">you</governor>
          <dependent id="4">sure</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>the prime minister replied. &amp;apost;</content>
      <tokens>
        <token id="1" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="prime" lemma="prime" stem="prime" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="minister" lemma="minister" stem="minist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="replied" lemma="reply" stem="repli" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT the) (JJ prime) (NN minister)) (VP (VBD replied)) (. .) ('' ')))</syntactictree>
      <chunkings>
        <chunking id="1" string="replied" type="VP">
          <tokens>
            <token id="4" string="replied" />
          </tokens>
        </chunking>
        <chunking id="2" string="the prime minister" type="NP">
          <tokens>
            <token id="1" string="the" />
            <token id="2" string="prime" />
            <token id="3" string="minister" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">minister</governor>
          <dependent id="1">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">minister</governor>
          <dependent id="2">prime</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">replied</governor>
          <dependent id="3">minister</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">replied</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>I mean . . . how did it come about, Michael . . . like, Christchurch, y&amp;apost;know - load of . . . let me put it to you - the economy, of course . . . I mean, wimpy guy like me.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="mean" lemma="mean" stem="mean" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="come" lemma="come" stem="come" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="about" lemma="about" stem="about" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Michael" lemma="Michael" stem="michael" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Christchurch" lemma="Christchurch" stem="christchurch" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="y'" lemma="y'" stem="y'" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="know" lemma="know" stem="know" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="load" lemma="load" stem="load" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="let" lemma="let" stem="let" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="put" lemma="put" stem="put" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="economy" lemma="economy" stem="economi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="course" lemma="course" stem="cours" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="mean" lemma="mean" stem="mean" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="wimpy" lemma="wimpy" stem="wimpi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="guy" lemma="guy" stem="gui" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="42" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP I)) (VP (VBP mean))) (: ...) (S (SBAR (WHADVP (WRB how)) (S (VP (VBD did) (S (NP (PRP it)) (VP (VB come) (ADVP (RB about)))) (, ,) (FRAG (NP (NNP Michael)) (: ...) (PP (IN like))) (, ,) (S (NP (NNP Christchurch)))))) (, ,) (NP (NN y')) (VP (VBP know) (: -) (NP (NP (NN load)) (PP (IN of) (: ...) (NP (NP (VP (VB let) (S (NP (PRP me)) (VP (VB put) (NP (PRP it))))) (PP (TO to) (NP (PRP you)))) (: -) (NP (NP (DT the) (NN economy)) (, ,) (PP (IN of) (NP (NN course))))))))) (: ...) (S (NP (PRP I)) (VP (VBP mean) (, ,) (NP (JJ wimpy) (NN guy)) (PP (IN like) (NP (PRP me))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Christchurch" type="NP">
          <tokens>
            <token id="14" string="Christchurch" />
          </tokens>
        </chunking>
        <chunking id="2" string="wimpy guy" type="NP">
          <tokens>
            <token id="38" string="wimpy" />
            <token id="39" string="guy" />
          </tokens>
        </chunking>
        <chunking id="3" string="the economy , of course" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="economy" />
            <token id="31" string="," />
            <token id="32" string="of" />
            <token id="33" string="course" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="how did it come about , Michael ... like , Christchurch" type="SBAR">
          <tokens>
            <token id="4" string="how" />
            <token id="5" string="did" />
            <token id="6" string="it" />
            <token id="7" string="come" />
            <token id="8" string="about" />
            <token id="9" string="," />
            <token id="10" string="Michael" />
            <token id="11" string=". . ." />
            <token id="12" string="like" />
            <token id="13" string="," />
            <token id="14" string="Christchurch" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="load of ... let me put it to you - the economy , of course" type="NP">
          <tokens>
            <token id="19" string="load" />
            <token id="20" string="of" />
            <token id="21" string=". . ." />
            <token id="22" string="let" />
            <token id="23" string="me" />
            <token id="24" string="put" />
            <token id="25" string="it" />
            <token id="26" string="to" />
            <token id="27" string="you" />
            <token id="28" string="-" />
            <token id="29" string="the" />
            <token id="30" string="economy" />
            <token id="31" string="," />
            <token id="32" string="of" />
            <token id="33" string="course" />
          </tokens>
        </chunking>
        <chunking id="8" string="let me put it" type="VP">
          <tokens>
            <token id="22" string="let" />
            <token id="23" string="me" />
            <token id="24" string="put" />
            <token id="25" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="y'" type="NP">
          <tokens>
            <token id="16" string="y'" />
          </tokens>
        </chunking>
        <chunking id="10" string="how" type="WHADVP">
          <tokens>
            <token id="4" string="how" />
          </tokens>
        </chunking>
        <chunking id="11" string="know - load of ... let me put it to you - the economy , of course" type="VP">
          <tokens>
            <token id="17" string="know" />
            <token id="18" string="-" />
            <token id="19" string="load" />
            <token id="20" string="of" />
            <token id="21" string=". . ." />
            <token id="22" string="let" />
            <token id="23" string="me" />
            <token id="24" string="put" />
            <token id="25" string="it" />
            <token id="26" string="to" />
            <token id="27" string="you" />
            <token id="28" string="-" />
            <token id="29" string="the" />
            <token id="30" string="economy" />
            <token id="31" string="," />
            <token id="32" string="of" />
            <token id="33" string="course" />
          </tokens>
        </chunking>
        <chunking id="12" string="did it come about , Michael ... like , Christchurch" type="VP">
          <tokens>
            <token id="5" string="did" />
            <token id="6" string="it" />
            <token id="7" string="come" />
            <token id="8" string="about" />
            <token id="9" string="," />
            <token id="10" string="Michael" />
            <token id="11" string=". . ." />
            <token id="12" string="like" />
            <token id="13" string="," />
            <token id="14" string="Christchurch" />
          </tokens>
        </chunking>
        <chunking id="13" string="mean , wimpy guy like me" type="VP">
          <tokens>
            <token id="36" string="mean" />
            <token id="37" string="," />
            <token id="38" string="wimpy" />
            <token id="39" string="guy" />
            <token id="40" string="like" />
            <token id="41" string="me" />
          </tokens>
        </chunking>
        <chunking id="14" string="Michael" type="NP">
          <tokens>
            <token id="10" string="Michael" />
          </tokens>
        </chunking>
        <chunking id="15" string="mean" type="VP">
          <tokens>
            <token id="2" string="mean" />
          </tokens>
        </chunking>
        <chunking id="16" string="load" type="NP">
          <tokens>
            <token id="19" string="load" />
          </tokens>
        </chunking>
        <chunking id="17" string="let me put it to you" type="NP">
          <tokens>
            <token id="22" string="let" />
            <token id="23" string="me" />
            <token id="24" string="put" />
            <token id="25" string="it" />
            <token id="26" string="to" />
            <token id="27" string="you" />
          </tokens>
        </chunking>
        <chunking id="18" string="me" type="NP">
          <tokens>
            <token id="23" string="me" />
          </tokens>
        </chunking>
        <chunking id="19" string="come about" type="VP">
          <tokens>
            <token id="7" string="come" />
            <token id="8" string="about" />
          </tokens>
        </chunking>
        <chunking id="20" string="course" type="NP">
          <tokens>
            <token id="33" string="course" />
          </tokens>
        </chunking>
        <chunking id="21" string="let me put it to you - the economy , of course" type="NP">
          <tokens>
            <token id="22" string="let" />
            <token id="23" string="me" />
            <token id="24" string="put" />
            <token id="25" string="it" />
            <token id="26" string="to" />
            <token id="27" string="you" />
            <token id="28" string="-" />
            <token id="29" string="the" />
            <token id="30" string="economy" />
            <token id="31" string="," />
            <token id="32" string="of" />
            <token id="33" string="course" />
          </tokens>
        </chunking>
        <chunking id="22" string="put it" type="VP">
          <tokens>
            <token id="24" string="put" />
            <token id="25" string="it" />
          </tokens>
        </chunking>
        <chunking id="23" string="you" type="NP">
          <tokens>
            <token id="27" string="you" />
          </tokens>
        </chunking>
        <chunking id="24" string="the economy" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="economy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">mean</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">mean</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">did</governor>
          <dependent id="4">how</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">know</governor>
          <dependent id="5">did</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">come</governor>
          <dependent id="6">it</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">did</governor>
          <dependent id="7">come</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">come</governor>
          <dependent id="8">about</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">did</governor>
          <dependent id="10">Michael</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">Michael</governor>
          <dependent id="12">like</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">did</governor>
          <dependent id="14">Christchurch</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">know</governor>
          <dependent id="16">y'</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="2">mean</governor>
          <dependent id="17">know</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">know</governor>
          <dependent id="19">load</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">let</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">load</governor>
          <dependent id="22">let</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">put</governor>
          <dependent id="23">me</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">let</governor>
          <dependent id="24">put</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">put</governor>
          <dependent id="25">it</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">you</governor>
          <dependent id="26">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">let</governor>
          <dependent id="27">you</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">economy</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="22">let</governor>
          <dependent id="30">economy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">course</governor>
          <dependent id="32">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">economy</governor>
          <dependent id="33">course</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">mean</governor>
          <dependent id="35">I</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="2">mean</governor>
          <dependent id="36">mean</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="39">guy</governor>
          <dependent id="38">wimpy</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="36">mean</governor>
          <dependent id="39">guy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">me</governor>
          <dependent id="40">like</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">mean</governor>
          <dependent id="41">me</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Christchurch" type="LOCATION" score="0.0">
          <tokens>
            <token id="14" string="Christchurch" />
          </tokens>
        </entity>
        <entity id="2" string="Michael" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Michael" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>But I&amp;apost;m not giving in like that, like . . .&amp;apost; On and on it went.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="giving" lemma="give" stem="give" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="On" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (S (NP (PRP I)) (VP (VBP 'm) (RB not) (VP (VBG giving) (PRT (RP in)) (PP (IN like) (NP (DT that))) (, ,) (PP (IN like))))) (: ...) ('' ') (PP (PP (IN On)) (CC and) (PP (IN on) (S (NP (PRP it)) (VP (VBD went))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="'m not giving in like that , like" type="VP">
          <tokens>
            <token id="3" string="'m" />
            <token id="4" string="not" />
            <token id="5" string="giving" />
            <token id="6" string="in" />
            <token id="7" string="like" />
            <token id="8" string="that" />
            <token id="9" string="," />
            <token id="10" string="like" />
          </tokens>
        </chunking>
        <chunking id="2" string="that" type="NP">
          <tokens>
            <token id="8" string="that" />
          </tokens>
        </chunking>
        <chunking id="3" string="went" type="VP">
          <tokens>
            <token id="17" string="went" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="giving in like that , like" type="VP">
          <tokens>
            <token id="5" string="giving" />
            <token id="6" string="in" />
            <token id="7" string="like" />
            <token id="8" string="that" />
            <token id="9" string="," />
            <token id="10" string="like" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="16" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="5">giving</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">giving</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">giving</governor>
          <dependent id="3">'m</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">giving</governor>
          <dependent id="4">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">giving</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="5">giving</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">that</governor>
          <dependent id="7">like</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">giving</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">that</governor>
          <dependent id="10">like</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">giving</governor>
          <dependent id="13">On</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">On</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">went</governor>
          <dependent id="15">on</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">went</governor>
          <dependent id="16">it</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">On</governor>
          <dependent id="17">went</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="35" has_coreference="false">
      <content>Then I rang John Smith.</content>
      <tokens>
        <token id="1" string="Then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="rang" lemma="ring" stem="rang" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="5" string="Smith" lemma="Smith" stem="smith" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (RB Then) (NP (PRP I)) (VP (VBD rang) (NP (NNP John) (NNP Smith))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="John Smith" type="NP">
          <tokens>
            <token id="4" string="John" />
            <token id="5" string="Smith" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="rang John Smith" type="VP">
          <tokens>
            <token id="3" string="rang" />
            <token id="4" string="John" />
            <token id="5" string="Smith" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">rang</governor>
          <dependent id="1">Then</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">rang</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">rang</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Smith</governor>
          <dependent id="4">John</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">rang</governor>
          <dependent id="5">Smith</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Smith" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="John" />
            <token id="5" string="Smith" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>I told him I had been impressed with his interview with Andrew Marr in The Independent on Thursday, in which he sharpened up his promise to introduce meaty political reforms (if he ever gets elected), including a referendum on proportional representation.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="impressed" lemma="impress" stem="impress" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="interview" lemma="interview" stem="interview" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Andrew" lemma="Andrew" stem="andrew" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="13" string="Marr" lemma="Marr" stem="marr" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Independent" lemma="Independent" stem="independ" pos="NNP" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="17" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Thursday" lemma="Thursday" stem="thursdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="sharpened" lemma="sharpen" stem="sharpen" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="promise" lemma="promise" stem="promis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="introduce" lemma="introduce" stem="introduc" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="meaty" lemma="meaty" stem="meati" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="reforms" lemma="reform" stem="reform" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="ever" lemma="ever" stem="ever" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="gets" lemma="get" stem="get" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="elected" lemma="elect" stem="elect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="referendum" lemma="referendum" stem="referendum" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="proportional" lemma="proportional" stem="proport" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="representation" lemma="representation" stem="represent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBD told) (NP (PRP him)) (SBAR (S (NP (PRP I)) (VP (VBD had) (VP (VBN been) (VP (VBN impressed) (PP (IN with) (NP (PRP$ his) (NN interview))) (PP (IN with) (NP (NP (NNP Andrew) (NNP Marr)) (PP (IN in) (NP (DT The) (NNP Independent))))) (PP (IN on) (NP (NP (NNP Thursday)) (, ,) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (PRP he)) (VP (VBD sharpened) (PRT (RP up)) (NP (PRP$ his) (NN promise) (S (VP (TO to) (VP (VB introduce) (NP (NP (JJ meaty) (JJ political) (NNS reforms)) (PRN (-LRB- -LRB-) (SBAR (IN if) (S (NP (PRP he)) (ADVP (RB ever)) (VP (VBZ gets) (VP (VBN elected))))) (-RRB- -RRB-)))))))))))) (, ,) (PP (VBG including) (NP (NP (DT a) (NN referendum)) (PP (IN on) (NP (JJ proportional) (NN representation))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="told him I had been impressed with his interview with Andrew Marr in The Independent on Thursday , in which he sharpened up his promise to introduce meaty political reforms -LRB- if he ever gets elected -RRB- , including a referendum on proportional representation" type="VP">
          <tokens>
            <token id="2" string="told" />
            <token id="3" string="him" />
            <token id="4" string="I" />
            <token id="5" string="had" />
            <token id="6" string="been" />
            <token id="7" string="impressed" />
            <token id="8" string="with" />
            <token id="9" string="his" />
            <token id="10" string="interview" />
            <token id="11" string="with" />
            <token id="12" string="Andrew" />
            <token id="13" string="Marr" />
            <token id="14" string="in" />
            <token id="15" string="The" />
            <token id="16" string="Independent" />
            <token id="17" string="on" />
            <token id="18" string="Thursday" />
            <token id="19" string="," />
            <token id="20" string="in" />
            <token id="21" string="which" />
            <token id="22" string="he" />
            <token id="23" string="sharpened" />
            <token id="24" string="up" />
            <token id="25" string="his" />
            <token id="26" string="promise" />
            <token id="27" string="to" />
            <token id="28" string="introduce" />
            <token id="29" string="meaty" />
            <token id="30" string="political" />
            <token id="31" string="reforms" />
            <token id="32" string="(" />
            <token id="33" string="if" />
            <token id="34" string="he" />
            <token id="35" string="ever" />
            <token id="36" string="gets" />
            <token id="37" string="elected" />
            <token id="38" string=")" />
            <token id="39" string="," />
            <token id="40" string="including" />
            <token id="41" string="a" />
            <token id="42" string="referendum" />
            <token id="43" string="on" />
            <token id="44" string="proportional" />
            <token id="45" string="representation" />
          </tokens>
        </chunking>
        <chunking id="2" string="a referendum" type="NP">
          <tokens>
            <token id="41" string="a" />
            <token id="42" string="referendum" />
          </tokens>
        </chunking>
        <chunking id="3" string="Thursday , in which he sharpened up his promise to introduce meaty political reforms -LRB- if he ever gets elected -RRB-" type="NP">
          <tokens>
            <token id="18" string="Thursday" />
            <token id="19" string="," />
            <token id="20" string="in" />
            <token id="21" string="which" />
            <token id="22" string="he" />
            <token id="23" string="sharpened" />
            <token id="24" string="up" />
            <token id="25" string="his" />
            <token id="26" string="promise" />
            <token id="27" string="to" />
            <token id="28" string="introduce" />
            <token id="29" string="meaty" />
            <token id="30" string="political" />
            <token id="31" string="reforms" />
            <token id="32" string="(" />
            <token id="33" string="if" />
            <token id="34" string="he" />
            <token id="35" string="ever" />
            <token id="36" string="gets" />
            <token id="37" string="elected" />
            <token id="38" string=")" />
          </tokens>
        </chunking>
        <chunking id="4" string="meaty political reforms -LRB- if he ever gets elected -RRB-" type="NP">
          <tokens>
            <token id="29" string="meaty" />
            <token id="30" string="political" />
            <token id="31" string="reforms" />
            <token id="32" string="(" />
            <token id="33" string="if" />
            <token id="34" string="he" />
            <token id="35" string="ever" />
            <token id="36" string="gets" />
            <token id="37" string="elected" />
            <token id="38" string=")" />
          </tokens>
        </chunking>
        <chunking id="5" string="been impressed with his interview with Andrew Marr in The Independent on Thursday , in which he sharpened up his promise to introduce meaty political reforms -LRB- if he ever gets elected -RRB- , including a referendum on proportional representation" type="VP">
          <tokens>
            <token id="6" string="been" />
            <token id="7" string="impressed" />
            <token id="8" string="with" />
            <token id="9" string="his" />
            <token id="10" string="interview" />
            <token id="11" string="with" />
            <token id="12" string="Andrew" />
            <token id="13" string="Marr" />
            <token id="14" string="in" />
            <token id="15" string="The" />
            <token id="16" string="Independent" />
            <token id="17" string="on" />
            <token id="18" string="Thursday" />
            <token id="19" string="," />
            <token id="20" string="in" />
            <token id="21" string="which" />
            <token id="22" string="he" />
            <token id="23" string="sharpened" />
            <token id="24" string="up" />
            <token id="25" string="his" />
            <token id="26" string="promise" />
            <token id="27" string="to" />
            <token id="28" string="introduce" />
            <token id="29" string="meaty" />
            <token id="30" string="political" />
            <token id="31" string="reforms" />
            <token id="32" string="(" />
            <token id="33" string="if" />
            <token id="34" string="he" />
            <token id="35" string="ever" />
            <token id="36" string="gets" />
            <token id="37" string="elected" />
            <token id="38" string=")" />
            <token id="39" string="," />
            <token id="40" string="including" />
            <token id="41" string="a" />
            <token id="42" string="referendum" />
            <token id="43" string="on" />
            <token id="44" string="proportional" />
            <token id="45" string="representation" />
          </tokens>
        </chunking>
        <chunking id="6" string="The Independent" type="NP">
          <tokens>
            <token id="15" string="The" />
            <token id="16" string="Independent" />
          </tokens>
        </chunking>
        <chunking id="7" string="elected" type="VP">
          <tokens>
            <token id="37" string="elected" />
          </tokens>
        </chunking>
        <chunking id="8" string="I had been impressed with his interview with Andrew Marr in The Independent on Thursday , in which he sharpened up his promise to introduce meaty political reforms -LRB- if he ever gets elected -RRB- , including a referendum on proportional representation" type="SBAR">
          <tokens>
            <token id="4" string="I" />
            <token id="5" string="had" />
            <token id="6" string="been" />
            <token id="7" string="impressed" />
            <token id="8" string="with" />
            <token id="9" string="his" />
            <token id="10" string="interview" />
            <token id="11" string="with" />
            <token id="12" string="Andrew" />
            <token id="13" string="Marr" />
            <token id="14" string="in" />
            <token id="15" string="The" />
            <token id="16" string="Independent" />
            <token id="17" string="on" />
            <token id="18" string="Thursday" />
            <token id="19" string="," />
            <token id="20" string="in" />
            <token id="21" string="which" />
            <token id="22" string="he" />
            <token id="23" string="sharpened" />
            <token id="24" string="up" />
            <token id="25" string="his" />
            <token id="26" string="promise" />
            <token id="27" string="to" />
            <token id="28" string="introduce" />
            <token id="29" string="meaty" />
            <token id="30" string="political" />
            <token id="31" string="reforms" />
            <token id="32" string="(" />
            <token id="33" string="if" />
            <token id="34" string="he" />
            <token id="35" string="ever" />
            <token id="36" string="gets" />
            <token id="37" string="elected" />
            <token id="38" string=")" />
            <token id="39" string="," />
            <token id="40" string="including" />
            <token id="41" string="a" />
            <token id="42" string="referendum" />
            <token id="43" string="on" />
            <token id="44" string="proportional" />
            <token id="45" string="representation" />
          </tokens>
        </chunking>
        <chunking id="9" string="sharpened up his promise to introduce meaty political reforms -LRB- if he ever gets elected -RRB-" type="VP">
          <tokens>
            <token id="23" string="sharpened" />
            <token id="24" string="up" />
            <token id="25" string="his" />
            <token id="26" string="promise" />
            <token id="27" string="to" />
            <token id="28" string="introduce" />
            <token id="29" string="meaty" />
            <token id="30" string="political" />
            <token id="31" string="reforms" />
            <token id="32" string="(" />
            <token id="33" string="if" />
            <token id="34" string="he" />
            <token id="35" string="ever" />
            <token id="36" string="gets" />
            <token id="37" string="elected" />
            <token id="38" string=")" />
          </tokens>
        </chunking>
        <chunking id="10" string="Thursday" type="NP">
          <tokens>
            <token id="18" string="Thursday" />
          </tokens>
        </chunking>
        <chunking id="11" string="had been impressed with his interview with Andrew Marr in The Independent on Thursday , in which he sharpened up his promise to introduce meaty political reforms -LRB- if he ever gets elected -RRB- , including a referendum on proportional representation" type="VP">
          <tokens>
            <token id="5" string="had" />
            <token id="6" string="been" />
            <token id="7" string="impressed" />
            <token id="8" string="with" />
            <token id="9" string="his" />
            <token id="10" string="interview" />
            <token id="11" string="with" />
            <token id="12" string="Andrew" />
            <token id="13" string="Marr" />
            <token id="14" string="in" />
            <token id="15" string="The" />
            <token id="16" string="Independent" />
            <token id="17" string="on" />
            <token id="18" string="Thursday" />
            <token id="19" string="," />
            <token id="20" string="in" />
            <token id="21" string="which" />
            <token id="22" string="he" />
            <token id="23" string="sharpened" />
            <token id="24" string="up" />
            <token id="25" string="his" />
            <token id="26" string="promise" />
            <token id="27" string="to" />
            <token id="28" string="introduce" />
            <token id="29" string="meaty" />
            <token id="30" string="political" />
            <token id="31" string="reforms" />
            <token id="32" string="(" />
            <token id="33" string="if" />
            <token id="34" string="he" />
            <token id="35" string="ever" />
            <token id="36" string="gets" />
            <token id="37" string="elected" />
            <token id="38" string=")" />
            <token id="39" string="," />
            <token id="40" string="including" />
            <token id="41" string="a" />
            <token id="42" string="referendum" />
            <token id="43" string="on" />
            <token id="44" string="proportional" />
            <token id="45" string="representation" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="22" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="to introduce meaty political reforms -LRB- if he ever gets elected -RRB-" type="VP">
          <tokens>
            <token id="27" string="to" />
            <token id="28" string="introduce" />
            <token id="29" string="meaty" />
            <token id="30" string="political" />
            <token id="31" string="reforms" />
            <token id="32" string="(" />
            <token id="33" string="if" />
            <token id="34" string="he" />
            <token id="35" string="ever" />
            <token id="36" string="gets" />
            <token id="37" string="elected" />
            <token id="38" string=")" />
          </tokens>
        </chunking>
        <chunking id="14" string="Andrew Marr in The Independent" type="NP">
          <tokens>
            <token id="12" string="Andrew" />
            <token id="13" string="Marr" />
            <token id="14" string="in" />
            <token id="15" string="The" />
            <token id="16" string="Independent" />
          </tokens>
        </chunking>
        <chunking id="15" string="proportional representation" type="NP">
          <tokens>
            <token id="44" string="proportional" />
            <token id="45" string="representation" />
          </tokens>
        </chunking>
        <chunking id="16" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="17" string="Andrew Marr" type="NP">
          <tokens>
            <token id="12" string="Andrew" />
            <token id="13" string="Marr" />
          </tokens>
        </chunking>
        <chunking id="18" string="him" type="NP">
          <tokens>
            <token id="3" string="him" />
          </tokens>
        </chunking>
        <chunking id="19" string="if he ever gets elected" type="SBAR">
          <tokens>
            <token id="33" string="if" />
            <token id="34" string="he" />
            <token id="35" string="ever" />
            <token id="36" string="gets" />
            <token id="37" string="elected" />
          </tokens>
        </chunking>
        <chunking id="20" string="his interview" type="NP">
          <tokens>
            <token id="9" string="his" />
            <token id="10" string="interview" />
          </tokens>
        </chunking>
        <chunking id="21" string="introduce meaty political reforms -LRB- if he ever gets elected -RRB-" type="VP">
          <tokens>
            <token id="28" string="introduce" />
            <token id="29" string="meaty" />
            <token id="30" string="political" />
            <token id="31" string="reforms" />
            <token id="32" string="(" />
            <token id="33" string="if" />
            <token id="34" string="he" />
            <token id="35" string="ever" />
            <token id="36" string="gets" />
            <token id="37" string="elected" />
            <token id="38" string=")" />
          </tokens>
        </chunking>
        <chunking id="22" string="a referendum on proportional representation" type="NP">
          <tokens>
            <token id="41" string="a" />
            <token id="42" string="referendum" />
            <token id="43" string="on" />
            <token id="44" string="proportional" />
            <token id="45" string="representation" />
          </tokens>
        </chunking>
        <chunking id="23" string="impressed with his interview with Andrew Marr in The Independent on Thursday , in which he sharpened up his promise to introduce meaty political reforms -LRB- if he ever gets elected -RRB- , including a referendum on proportional representation" type="VP">
          <tokens>
            <token id="7" string="impressed" />
            <token id="8" string="with" />
            <token id="9" string="his" />
            <token id="10" string="interview" />
            <token id="11" string="with" />
            <token id="12" string="Andrew" />
            <token id="13" string="Marr" />
            <token id="14" string="in" />
            <token id="15" string="The" />
            <token id="16" string="Independent" />
            <token id="17" string="on" />
            <token id="18" string="Thursday" />
            <token id="19" string="," />
            <token id="20" string="in" />
            <token id="21" string="which" />
            <token id="22" string="he" />
            <token id="23" string="sharpened" />
            <token id="24" string="up" />
            <token id="25" string="his" />
            <token id="26" string="promise" />
            <token id="27" string="to" />
            <token id="28" string="introduce" />
            <token id="29" string="meaty" />
            <token id="30" string="political" />
            <token id="31" string="reforms" />
            <token id="32" string="(" />
            <token id="33" string="if" />
            <token id="34" string="he" />
            <token id="35" string="ever" />
            <token id="36" string="gets" />
            <token id="37" string="elected" />
            <token id="38" string=")" />
            <token id="39" string="," />
            <token id="40" string="including" />
            <token id="41" string="a" />
            <token id="42" string="referendum" />
            <token id="43" string="on" />
            <token id="44" string="proportional" />
            <token id="45" string="representation" />
          </tokens>
        </chunking>
        <chunking id="24" string="his promise to introduce meaty political reforms -LRB- if he ever gets elected -RRB-" type="NP">
          <tokens>
            <token id="25" string="his" />
            <token id="26" string="promise" />
            <token id="27" string="to" />
            <token id="28" string="introduce" />
            <token id="29" string="meaty" />
            <token id="30" string="political" />
            <token id="31" string="reforms" />
            <token id="32" string="(" />
            <token id="33" string="if" />
            <token id="34" string="he" />
            <token id="35" string="ever" />
            <token id="36" string="gets" />
            <token id="37" string="elected" />
            <token id="38" string=")" />
          </tokens>
        </chunking>
        <chunking id="25" string="in which he sharpened up his promise to introduce meaty political reforms -LRB- if he ever gets elected -RRB-" type="SBAR">
          <tokens>
            <token id="20" string="in" />
            <token id="21" string="which" />
            <token id="22" string="he" />
            <token id="23" string="sharpened" />
            <token id="24" string="up" />
            <token id="25" string="his" />
            <token id="26" string="promise" />
            <token id="27" string="to" />
            <token id="28" string="introduce" />
            <token id="29" string="meaty" />
            <token id="30" string="political" />
            <token id="31" string="reforms" />
            <token id="32" string="(" />
            <token id="33" string="if" />
            <token id="34" string="he" />
            <token id="35" string="ever" />
            <token id="36" string="gets" />
            <token id="37" string="elected" />
            <token id="38" string=")" />
          </tokens>
        </chunking>
        <chunking id="26" string="gets elected" type="VP">
          <tokens>
            <token id="36" string="gets" />
            <token id="37" string="elected" />
          </tokens>
        </chunking>
        <chunking id="27" string="meaty political reforms" type="NP">
          <tokens>
            <token id="29" string="meaty" />
            <token id="30" string="political" />
            <token id="31" string="reforms" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">told</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">told</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">told</governor>
          <dependent id="3">him</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">impressed</governor>
          <dependent id="4">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">impressed</governor>
          <dependent id="5">had</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">impressed</governor>
          <dependent id="6">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">told</governor>
          <dependent id="7">impressed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">interview</governor>
          <dependent id="8">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">interview</governor>
          <dependent id="9">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">impressed</governor>
          <dependent id="10">interview</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Marr</governor>
          <dependent id="11">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Marr</governor>
          <dependent id="12">Andrew</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">impressed</governor>
          <dependent id="13">Marr</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Independent</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">Independent</governor>
          <dependent id="15">The</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">Marr</governor>
          <dependent id="16">Independent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Thursday</governor>
          <dependent id="17">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">impressed</governor>
          <dependent id="18">Thursday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">which</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">sharpened</governor>
          <dependent id="21">which</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">sharpened</governor>
          <dependent id="22">he</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="18">Thursday</governor>
          <dependent id="23">sharpened</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="23">sharpened</governor>
          <dependent id="24">up</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="26">promise</governor>
          <dependent id="25">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">sharpened</governor>
          <dependent id="26">promise</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">introduce</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="26">promise</governor>
          <dependent id="28">introduce</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">reforms</governor>
          <dependent id="29">meaty</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">reforms</governor>
          <dependent id="30">political</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">introduce</governor>
          <dependent id="31">reforms</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="37">elected</governor>
          <dependent id="33">if</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="37">elected</governor>
          <dependent id="34">he</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="37">elected</governor>
          <dependent id="35">ever</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="37">elected</governor>
          <dependent id="36">gets</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="31">reforms</governor>
          <dependent id="37">elected</dependent>
        </dependency>
        <dependency type="case">
          <governor id="42">referendum</governor>
          <dependent id="40">including</dependent>
        </dependency>
        <dependency type="det">
          <governor id="42">referendum</governor>
          <dependent id="41">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">impressed</governor>
          <dependent id="42">referendum</dependent>
        </dependency>
        <dependency type="case">
          <governor id="45">representation</governor>
          <dependent id="43">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="45">representation</governor>
          <dependent id="44">proportional</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="42">referendum</governor>
          <dependent id="45">representation</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Independent" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="16" string="Independent" />
          </tokens>
        </entity>
        <entity id="2" string="Thursday" type="DATE" score="0.0">
          <tokens>
            <token id="18" string="Thursday" />
          </tokens>
        </entity>
        <entity id="3" string="Andrew Marr" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Andrew" />
            <token id="13" string="Marr" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>I said: &amp;apost;You are starting to raise your game, John.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="You" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="starting" lemma="start" stem="start" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="raise" lemma="raise" stem="rais" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="your" lemma="you" stem="your" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="game" lemma="game" stem="game" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBD said) (: :) (`` `) (S (NP (PRP You)) (VP (VBP are) (VP (VBG starting) (S (VP (TO to) (VP (VB raise) (NP (NP (PRP$ your) (NN game)) (, ,) (NP (NNP John)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="are starting to raise your game , John" type="VP">
          <tokens>
            <token id="6" string="are" />
            <token id="7" string="starting" />
            <token id="8" string="to" />
            <token id="9" string="raise" />
            <token id="10" string="your" />
            <token id="11" string="game" />
            <token id="12" string="," />
            <token id="13" string="John" />
          </tokens>
        </chunking>
        <chunking id="2" string="your game" type="NP">
          <tokens>
            <token id="10" string="your" />
            <token id="11" string="game" />
          </tokens>
        </chunking>
        <chunking id="3" string="to raise your game , John" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="raise" />
            <token id="10" string="your" />
            <token id="11" string="game" />
            <token id="12" string="," />
            <token id="13" string="John" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="said : ` You are starting to raise your game , John" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string=":" />
            <token id="4" string="'" />
            <token id="5" string="You" />
            <token id="6" string="are" />
            <token id="7" string="starting" />
            <token id="8" string="to" />
            <token id="9" string="raise" />
            <token id="10" string="your" />
            <token id="11" string="game" />
            <token id="12" string="," />
            <token id="13" string="John" />
          </tokens>
        </chunking>
        <chunking id="6" string="raise your game , John" type="VP">
          <tokens>
            <token id="9" string="raise" />
            <token id="10" string="your" />
            <token id="11" string="game" />
            <token id="12" string="," />
            <token id="13" string="John" />
          </tokens>
        </chunking>
        <chunking id="7" string="starting to raise your game , John" type="VP">
          <tokens>
            <token id="7" string="starting" />
            <token id="8" string="to" />
            <token id="9" string="raise" />
            <token id="10" string="your" />
            <token id="11" string="game" />
            <token id="12" string="," />
            <token id="13" string="John" />
          </tokens>
        </chunking>
        <chunking id="8" string="John" type="NP">
          <tokens>
            <token id="13" string="John" />
          </tokens>
        </chunking>
        <chunking id="9" string="your game , John" type="NP">
          <tokens>
            <token id="10" string="your" />
            <token id="11" string="game" />
            <token id="12" string="," />
            <token id="13" string="John" />
          </tokens>
        </chunking>
        <chunking id="10" string="You" type="NP">
          <tokens>
            <token id="5" string="You" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">starting</governor>
          <dependent id="5">You</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">starting</governor>
          <dependent id="6">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="7">starting</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">raise</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">starting</governor>
          <dependent id="9">raise</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">game</governor>
          <dependent id="10">your</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">raise</governor>
          <dependent id="11">game</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="11">game</governor>
          <dependent id="13">John</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="John" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="false">
      <content>Many people will have agreed with your assertion that democracy in Britain is decaying, and that the Tories must be roasted for their arrogance, incompetence, complacency and sharp practices - especially their &amp;apost;centralisation of power and the elimination of opposition&amp;apost;.</content>
      <tokens>
        <token id="1" string="Many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="agreed" lemma="agree" stem="agre" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="your" lemma="you" stem="your" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="assertion" lemma="assertion" stem="assert" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="democracy" lemma="democracy" stem="democraci" pos="NN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Britain" lemma="Britain" stem="britain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="13" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="decaying" lemma="decay" stem="decai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Tories" lemma="Tories" stem="tori" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="must" lemma="must" stem="must" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="roasted" lemma="roasted" stem="roast" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="arrogance" lemma="arrogance" stem="arrog" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="incompetence" lemma="incompetence" stem="incompet" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="complacency" lemma="complacency" stem="complac" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="sharp" lemma="sharp" stem="sharp" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="practices" lemma="practice" stem="practic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="especially" lemma="especially" stem="especi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="centralisation" lemma="centralisation" stem="centralis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="power" lemma="power" stem="power" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="elimination" lemma="elimination" stem="elimin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="opposition" lemma="opposition" stem="opposit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NP (JJ Many) (NNS people)) (SBAR (S (VP (MD will) (VP (VB have) (VP (VBN agreed) (PP (IN with) (NP (PRP$ your) (NN assertion))) (SBAR (SBAR (IN that) (S (NP (NP (NN democracy)) (PP (IN in) (NP (NNP Britain)))) (VP (VBZ is) (VP (VBG decaying))))) (, ,) (CC and) (SBAR (IN that) (S (NP (DT the) (NNPS Tories)) (VP (MD must) (VP (VB be) (ADJP (JJ roasted) (PP (IN for) (NP (PRP$ their) (NN arrogance) (, ,) (NN incompetence) (, ,) (NN complacency) (CC and) (JJ sharp) (NNS practices))))))))))))))) (: -) (RB especially) (NP (NP (PRP$ their) (`` `) (NN centralisation)) (PP (IN of) (NP (NP (NN power)) (CC and) (NP (NP (DT the) (NN elimination)) (PP (IN of) (NP (NN opposition)))) ('' ')))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="your assertion" type="NP">
          <tokens>
            <token id="7" string="your" />
            <token id="8" string="assertion" />
          </tokens>
        </chunking>
        <chunking id="2" string="have agreed with your assertion that democracy in Britain is decaying , and that the Tories must be roasted for their arrogance , incompetence , complacency and sharp practices" type="VP">
          <tokens>
            <token id="4" string="have" />
            <token id="5" string="agreed" />
            <token id="6" string="with" />
            <token id="7" string="your" />
            <token id="8" string="assertion" />
            <token id="9" string="that" />
            <token id="10" string="democracy" />
            <token id="11" string="in" />
            <token id="12" string="Britain" />
            <token id="13" string="is" />
            <token id="14" string="decaying" />
            <token id="15" string="," />
            <token id="16" string="and" />
            <token id="17" string="that" />
            <token id="18" string="the" />
            <token id="19" string="Tories" />
            <token id="20" string="must" />
            <token id="21" string="be" />
            <token id="22" string="roasted" />
            <token id="23" string="for" />
            <token id="24" string="their" />
            <token id="25" string="arrogance" />
            <token id="26" string="," />
            <token id="27" string="incompetence" />
            <token id="28" string="," />
            <token id="29" string="complacency" />
            <token id="30" string="and" />
            <token id="31" string="sharp" />
            <token id="32" string="practices" />
          </tokens>
        </chunking>
        <chunking id="3" string="democracy in Britain" type="NP">
          <tokens>
            <token id="10" string="democracy" />
            <token id="11" string="in" />
            <token id="12" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="4" string="their ` centralisation" type="NP">
          <tokens>
            <token id="35" string="their" />
            <token id="36" string="'" />
            <token id="37" string="centralisation" />
          </tokens>
        </chunking>
        <chunking id="5" string="Britain" type="NP">
          <tokens>
            <token id="12" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="6" string="decaying" type="VP">
          <tokens>
            <token id="14" string="decaying" />
          </tokens>
        </chunking>
        <chunking id="7" string="democracy" type="NP">
          <tokens>
            <token id="10" string="democracy" />
          </tokens>
        </chunking>
        <chunking id="8" string="must be roasted for their arrogance , incompetence , complacency and sharp practices" type="VP">
          <tokens>
            <token id="20" string="must" />
            <token id="21" string="be" />
            <token id="22" string="roasted" />
            <token id="23" string="for" />
            <token id="24" string="their" />
            <token id="25" string="arrogance" />
            <token id="26" string="," />
            <token id="27" string="incompetence" />
            <token id="28" string="," />
            <token id="29" string="complacency" />
            <token id="30" string="and" />
            <token id="31" string="sharp" />
            <token id="32" string="practices" />
          </tokens>
        </chunking>
        <chunking id="9" string="their ` centralisation of power and the elimination of opposition '" type="NP">
          <tokens>
            <token id="35" string="their" />
            <token id="36" string="'" />
            <token id="37" string="centralisation" />
            <token id="38" string="of" />
            <token id="39" string="power" />
            <token id="40" string="and" />
            <token id="41" string="the" />
            <token id="42" string="elimination" />
            <token id="43" string="of" />
            <token id="44" string="opposition" />
            <token id="45" string="'" />
          </tokens>
        </chunking>
        <chunking id="10" string="Many people will have agreed with your assertion that democracy in Britain is decaying , and that the Tories must be roasted for their arrogance , incompetence , complacency and sharp practices" type="NP">
          <tokens>
            <token id="1" string="Many" />
            <token id="2" string="people" />
            <token id="3" string="will" />
            <token id="4" string="have" />
            <token id="5" string="agreed" />
            <token id="6" string="with" />
            <token id="7" string="your" />
            <token id="8" string="assertion" />
            <token id="9" string="that" />
            <token id="10" string="democracy" />
            <token id="11" string="in" />
            <token id="12" string="Britain" />
            <token id="13" string="is" />
            <token id="14" string="decaying" />
            <token id="15" string="," />
            <token id="16" string="and" />
            <token id="17" string="that" />
            <token id="18" string="the" />
            <token id="19" string="Tories" />
            <token id="20" string="must" />
            <token id="21" string="be" />
            <token id="22" string="roasted" />
            <token id="23" string="for" />
            <token id="24" string="their" />
            <token id="25" string="arrogance" />
            <token id="26" string="," />
            <token id="27" string="incompetence" />
            <token id="28" string="," />
            <token id="29" string="complacency" />
            <token id="30" string="and" />
            <token id="31" string="sharp" />
            <token id="32" string="practices" />
          </tokens>
        </chunking>
        <chunking id="11" string="power and the elimination of opposition '" type="NP">
          <tokens>
            <token id="39" string="power" />
            <token id="40" string="and" />
            <token id="41" string="the" />
            <token id="42" string="elimination" />
            <token id="43" string="of" />
            <token id="44" string="opposition" />
            <token id="45" string="'" />
          </tokens>
        </chunking>
        <chunking id="12" string="is decaying" type="VP">
          <tokens>
            <token id="13" string="is" />
            <token id="14" string="decaying" />
          </tokens>
        </chunking>
        <chunking id="13" string="the elimination of opposition" type="NP">
          <tokens>
            <token id="41" string="the" />
            <token id="42" string="elimination" />
            <token id="43" string="of" />
            <token id="44" string="opposition" />
          </tokens>
        </chunking>
        <chunking id="14" string="that the Tories must be roasted for their arrogance , incompetence , complacency and sharp practices" type="SBAR">
          <tokens>
            <token id="17" string="that" />
            <token id="18" string="the" />
            <token id="19" string="Tories" />
            <token id="20" string="must" />
            <token id="21" string="be" />
            <token id="22" string="roasted" />
            <token id="23" string="for" />
            <token id="24" string="their" />
            <token id="25" string="arrogance" />
            <token id="26" string="," />
            <token id="27" string="incompetence" />
            <token id="28" string="," />
            <token id="29" string="complacency" />
            <token id="30" string="and" />
            <token id="31" string="sharp" />
            <token id="32" string="practices" />
          </tokens>
        </chunking>
        <chunking id="15" string="roasted for their arrogance , incompetence , complacency and sharp practices" type="ADJP">
          <tokens>
            <token id="22" string="roasted" />
            <token id="23" string="for" />
            <token id="24" string="their" />
            <token id="25" string="arrogance" />
            <token id="26" string="," />
            <token id="27" string="incompetence" />
            <token id="28" string="," />
            <token id="29" string="complacency" />
            <token id="30" string="and" />
            <token id="31" string="sharp" />
            <token id="32" string="practices" />
          </tokens>
        </chunking>
        <chunking id="16" string="be roasted for their arrogance , incompetence , complacency and sharp practices" type="VP">
          <tokens>
            <token id="21" string="be" />
            <token id="22" string="roasted" />
            <token id="23" string="for" />
            <token id="24" string="their" />
            <token id="25" string="arrogance" />
            <token id="26" string="," />
            <token id="27" string="incompetence" />
            <token id="28" string="," />
            <token id="29" string="complacency" />
            <token id="30" string="and" />
            <token id="31" string="sharp" />
            <token id="32" string="practices" />
          </tokens>
        </chunking>
        <chunking id="17" string="Many people will have agreed with your assertion that democracy in Britain is decaying , and that the Tories must be roasted for their arrogance , incompetence , complacency and sharp practices - especially their ` centralisation of power and the elimination of opposition ' ." type="NP">
          <tokens>
            <token id="1" string="Many" />
            <token id="2" string="people" />
            <token id="3" string="will" />
            <token id="4" string="have" />
            <token id="5" string="agreed" />
            <token id="6" string="with" />
            <token id="7" string="your" />
            <token id="8" string="assertion" />
            <token id="9" string="that" />
            <token id="10" string="democracy" />
            <token id="11" string="in" />
            <token id="12" string="Britain" />
            <token id="13" string="is" />
            <token id="14" string="decaying" />
            <token id="15" string="," />
            <token id="16" string="and" />
            <token id="17" string="that" />
            <token id="18" string="the" />
            <token id="19" string="Tories" />
            <token id="20" string="must" />
            <token id="21" string="be" />
            <token id="22" string="roasted" />
            <token id="23" string="for" />
            <token id="24" string="their" />
            <token id="25" string="arrogance" />
            <token id="26" string="," />
            <token id="27" string="incompetence" />
            <token id="28" string="," />
            <token id="29" string="complacency" />
            <token id="30" string="and" />
            <token id="31" string="sharp" />
            <token id="32" string="practices" />
            <token id="33" string="-" />
            <token id="34" string="especially" />
            <token id="35" string="their" />
            <token id="36" string="'" />
            <token id="37" string="centralisation" />
            <token id="38" string="of" />
            <token id="39" string="power" />
            <token id="40" string="and" />
            <token id="41" string="the" />
            <token id="42" string="elimination" />
            <token id="43" string="of" />
            <token id="44" string="opposition" />
            <token id="45" string="'" />
            <token id="46" string="." />
          </tokens>
        </chunking>
        <chunking id="18" string="that democracy in Britain is decaying" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="democracy" />
            <token id="11" string="in" />
            <token id="12" string="Britain" />
            <token id="13" string="is" />
            <token id="14" string="decaying" />
          </tokens>
        </chunking>
        <chunking id="19" string="the elimination" type="NP">
          <tokens>
            <token id="41" string="the" />
            <token id="42" string="elimination" />
          </tokens>
        </chunking>
        <chunking id="20" string="Many people" type="NP">
          <tokens>
            <token id="1" string="Many" />
            <token id="2" string="people" />
          </tokens>
        </chunking>
        <chunking id="21" string="opposition" type="NP">
          <tokens>
            <token id="44" string="opposition" />
          </tokens>
        </chunking>
        <chunking id="22" string="agreed with your assertion that democracy in Britain is decaying , and that the Tories must be roasted for their arrogance , incompetence , complacency and sharp practices" type="VP">
          <tokens>
            <token id="5" string="agreed" />
            <token id="6" string="with" />
            <token id="7" string="your" />
            <token id="8" string="assertion" />
            <token id="9" string="that" />
            <token id="10" string="democracy" />
            <token id="11" string="in" />
            <token id="12" string="Britain" />
            <token id="13" string="is" />
            <token id="14" string="decaying" />
            <token id="15" string="," />
            <token id="16" string="and" />
            <token id="17" string="that" />
            <token id="18" string="the" />
            <token id="19" string="Tories" />
            <token id="20" string="must" />
            <token id="21" string="be" />
            <token id="22" string="roasted" />
            <token id="23" string="for" />
            <token id="24" string="their" />
            <token id="25" string="arrogance" />
            <token id="26" string="," />
            <token id="27" string="incompetence" />
            <token id="28" string="," />
            <token id="29" string="complacency" />
            <token id="30" string="and" />
            <token id="31" string="sharp" />
            <token id="32" string="practices" />
          </tokens>
        </chunking>
        <chunking id="23" string="the Tories" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="Tories" />
          </tokens>
        </chunking>
        <chunking id="24" string="will have agreed with your assertion that democracy in Britain is decaying , and that the Tories must be roasted for their arrogance , incompetence , complacency and sharp practices" type="SBAR">
          <tokens>
            <token id="3" string="will" />
            <token id="4" string="have" />
            <token id="5" string="agreed" />
            <token id="6" string="with" />
            <token id="7" string="your" />
            <token id="8" string="assertion" />
            <token id="9" string="that" />
            <token id="10" string="democracy" />
            <token id="11" string="in" />
            <token id="12" string="Britain" />
            <token id="13" string="is" />
            <token id="14" string="decaying" />
            <token id="15" string="," />
            <token id="16" string="and" />
            <token id="17" string="that" />
            <token id="18" string="the" />
            <token id="19" string="Tories" />
            <token id="20" string="must" />
            <token id="21" string="be" />
            <token id="22" string="roasted" />
            <token id="23" string="for" />
            <token id="24" string="their" />
            <token id="25" string="arrogance" />
            <token id="26" string="," />
            <token id="27" string="incompetence" />
            <token id="28" string="," />
            <token id="29" string="complacency" />
            <token id="30" string="and" />
            <token id="31" string="sharp" />
            <token id="32" string="practices" />
          </tokens>
        </chunking>
        <chunking id="25" string="power" type="NP">
          <tokens>
            <token id="39" string="power" />
          </tokens>
        </chunking>
        <chunking id="26" string="their arrogance , incompetence , complacency and sharp practices" type="NP">
          <tokens>
            <token id="24" string="their" />
            <token id="25" string="arrogance" />
            <token id="26" string="," />
            <token id="27" string="incompetence" />
            <token id="28" string="," />
            <token id="29" string="complacency" />
            <token id="30" string="and" />
            <token id="31" string="sharp" />
            <token id="32" string="practices" />
          </tokens>
        </chunking>
        <chunking id="27" string="that democracy in Britain is decaying , and that the Tories must be roasted for their arrogance , incompetence , complacency and sharp practices" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="democracy" />
            <token id="11" string="in" />
            <token id="12" string="Britain" />
            <token id="13" string="is" />
            <token id="14" string="decaying" />
            <token id="15" string="," />
            <token id="16" string="and" />
            <token id="17" string="that" />
            <token id="18" string="the" />
            <token id="19" string="Tories" />
            <token id="20" string="must" />
            <token id="21" string="be" />
            <token id="22" string="roasted" />
            <token id="23" string="for" />
            <token id="24" string="their" />
            <token id="25" string="arrogance" />
            <token id="26" string="," />
            <token id="27" string="incompetence" />
            <token id="28" string="," />
            <token id="29" string="complacency" />
            <token id="30" string="and" />
            <token id="31" string="sharp" />
            <token id="32" string="practices" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">people</governor>
          <dependent id="1">Many</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">people</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">agreed</governor>
          <dependent id="3">will</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">agreed</governor>
          <dependent id="4">have</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">people</governor>
          <dependent id="5">agreed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">assertion</governor>
          <dependent id="6">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">assertion</governor>
          <dependent id="7">your</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">agreed</governor>
          <dependent id="8">assertion</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">decaying</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">decaying</governor>
          <dependent id="10">democracy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Britain</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">democracy</governor>
          <dependent id="12">Britain</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">decaying</governor>
          <dependent id="13">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">agreed</governor>
          <dependent id="14">decaying</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">decaying</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">roasted</governor>
          <dependent id="17">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">Tories</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">roasted</governor>
          <dependent id="19">Tories</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">roasted</governor>
          <dependent id="20">must</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="22">roasted</governor>
          <dependent id="21">be</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">decaying</governor>
          <dependent id="22">roasted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">practices</governor>
          <dependent id="23">for</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="32">practices</governor>
          <dependent id="24">their</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">complacency</governor>
          <dependent id="25">arrogance</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="29">complacency</governor>
          <dependent id="27">incompetence</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">practices</governor>
          <dependent id="29">complacency</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="29">complacency</governor>
          <dependent id="30">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="29">complacency</governor>
          <dependent id="31">sharp</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">roasted</governor>
          <dependent id="32">practices</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">people</governor>
          <dependent id="34">especially</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="37">centralisation</governor>
          <dependent id="35">their</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">people</governor>
          <dependent id="37">centralisation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">power</governor>
          <dependent id="38">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="37">centralisation</governor>
          <dependent id="39">power</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="39">power</governor>
          <dependent id="40">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="42">elimination</governor>
          <dependent id="41">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="39">power</governor>
          <dependent id="42">elimination</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">opposition</governor>
          <dependent id="43">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="42">elimination</governor>
          <dependent id="44">opposition</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Britain" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="Britain" />
          </tokens>
        </entity>
        <entity id="2" string="democracy" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="10" string="democracy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>But some of your critics still accuse you, John, of laziness and ineffectualness.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="your" lemma="you" stem="your" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="critics" lemma="critic" stem="critic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="accuse" lemma="accuse" stem="accus" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="laziness" lemma="laziness" stem="lazi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="ineffectualness" lemma="ineffectualness" stem="ineffectu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NP (DT some)) (PP (IN of) (NP (PRP$ your) (NNS critics)))) (ADVP (RB still)) (VP (VBP accuse) (NP (NP (NP (PRP you)) (, ,) (NP (NNP John)) (, ,)) (PP (IN of) (NP (NN laziness) (CC and) (NN ineffectualness))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="accuse you , John , of laziness and ineffectualness" type="VP">
          <tokens>
            <token id="7" string="accuse" />
            <token id="8" string="you" />
            <token id="9" string="," />
            <token id="10" string="John" />
            <token id="11" string="," />
            <token id="12" string="of" />
            <token id="13" string="laziness" />
            <token id="14" string="and" />
            <token id="15" string="ineffectualness" />
          </tokens>
        </chunking>
        <chunking id="2" string="you , John ," type="NP">
          <tokens>
            <token id="8" string="you" />
            <token id="9" string="," />
            <token id="10" string="John" />
            <token id="11" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="some" type="NP">
          <tokens>
            <token id="2" string="some" />
          </tokens>
        </chunking>
        <chunking id="4" string="John" type="NP">
          <tokens>
            <token id="10" string="John" />
          </tokens>
        </chunking>
        <chunking id="5" string="laziness and ineffectualness" type="NP">
          <tokens>
            <token id="13" string="laziness" />
            <token id="14" string="and" />
            <token id="15" string="ineffectualness" />
          </tokens>
        </chunking>
        <chunking id="6" string="some of your critics" type="NP">
          <tokens>
            <token id="2" string="some" />
            <token id="3" string="of" />
            <token id="4" string="your" />
            <token id="5" string="critics" />
          </tokens>
        </chunking>
        <chunking id="7" string="you , John , of laziness and ineffectualness" type="NP">
          <tokens>
            <token id="8" string="you" />
            <token id="9" string="," />
            <token id="10" string="John" />
            <token id="11" string="," />
            <token id="12" string="of" />
            <token id="13" string="laziness" />
            <token id="14" string="and" />
            <token id="15" string="ineffectualness" />
          </tokens>
        </chunking>
        <chunking id="8" string="your critics" type="NP">
          <tokens>
            <token id="4" string="your" />
            <token id="5" string="critics" />
          </tokens>
        </chunking>
        <chunking id="9" string="you" type="NP">
          <tokens>
            <token id="8" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="7">accuse</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">accuse</governor>
          <dependent id="2">some</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">critics</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">critics</governor>
          <dependent id="4">your</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">some</governor>
          <dependent id="5">critics</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">accuse</governor>
          <dependent id="6">still</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">accuse</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">accuse</governor>
          <dependent id="8">you</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">you</governor>
          <dependent id="10">John</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">laziness</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">you</governor>
          <dependent id="13">laziness</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">laziness</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">laziness</governor>
          <dependent id="15">ineffectualness</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="John" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>What do you say to that?&amp;apost;</content>
      <tokens>
        <token id="1" string="What" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SBARQ (WHNP (WP What)) (SQ (VBP do) (NP (PRP you)) (VP (VB say) (S (VP (TO to) (VP (VB that)))))) (. ?) ('' ')))</syntactictree>
      <chunkings>
        <chunking id="1" string="that" type="VP">
          <tokens>
            <token id="6" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="say to that" type="VP">
          <tokens>
            <token id="4" string="say" />
            <token id="5" string="to" />
            <token id="6" string="that" />
          </tokens>
        </chunking>
        <chunking id="3" string="to that" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="that" />
          </tokens>
        </chunking>
        <chunking id="4" string="you" type="NP">
          <tokens>
            <token id="3" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="4">say</governor>
          <dependent id="1">What</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">say</governor>
          <dependent id="2">do</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">say</governor>
          <dependent id="3">you</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">say</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">that</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">say</governor>
          <dependent id="6">that</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>&amp;apost;Away, ye thowless jad,&amp;apost; shouted the Labour leader.</content>
      <tokens>
        <token id="1" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Away" lemma="away" stem="awai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="ye" lemma="ye" stem="ye" pos="PRP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="thowless" lemma="thowless" stem="thowless" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="jad" lemma="jad" stem="jad" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="shouted" lemma="shout" stem="shout" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="Labour" lemma="Labour" stem="labour" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="12" string="leader" lemma="leader" stem="leader" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` `) (ADVP (RB Away)) (, ,) (NP (NP (PRP ye)) (NP (JJ thowless) (NN jad)) (, ,) ('' ')) (VP (VBD shouted) (NP (DT the) (NNP Labour) (NN leader))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="ye thowless jad , '" type="NP">
          <tokens>
            <token id="4" string="ye" />
            <token id="5" string="thowless" />
            <token id="6" string="jad" />
            <token id="7" string="," />
            <token id="8" string="'" />
          </tokens>
        </chunking>
        <chunking id="2" string="shouted the Labour leader" type="VP">
          <tokens>
            <token id="9" string="shouted" />
            <token id="10" string="the" />
            <token id="11" string="Labour" />
            <token id="12" string="leader" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Labour leader" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="Labour" />
            <token id="12" string="leader" />
          </tokens>
        </chunking>
        <chunking id="4" string="thowless jad" type="NP">
          <tokens>
            <token id="5" string="thowless" />
            <token id="6" string="jad" />
          </tokens>
        </chunking>
        <chunking id="5" string="ye" type="NP">
          <tokens>
            <token id="4" string="ye" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="9">shouted</governor>
          <dependent id="2">Away</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">shouted</governor>
          <dependent id="4">ye</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">jad</governor>
          <dependent id="5">thowless</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">ye</governor>
          <dependent id="6">jad</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">shouted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">leader</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">leader</governor>
          <dependent id="11">Labour</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">shouted</governor>
          <dependent id="12">leader</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Labour" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="11" string="Labour" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>&amp;apost;Gie me o&amp;apost;wit an&amp;apost; sense a life, behint a kist to lie an&amp;apost; sklent.</content>
      <tokens>
        <token id="1" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Gie" lemma="Gie" stem="gie" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="o'wit" lemma="o'wit" stem="o'wit" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="sense" lemma="sense" stem="sens" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="behint" lemma="behint" stem="behint" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="kist" lemma="kist" stem="kist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="lie" lemma="lie" stem="lie" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="sklent" lemma="sklent" stem="sklent" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` `) (S (NP (NNP Gie) (PRP me)) (VP (VBP o'wit) (NP (DT an)))) ('' ') (VP (VBP sense) (NP (NP (DT a) (NN life)) (, ,) (NP (NP (NN behint)) (SBAR (S (NP (DT a) (NN kist)) (VP (TO to) (VP (VB lie) (NP (DT an))))))) ('' '))) (NP (JJ sklent)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="behint a kist to lie an" type="NP">
          <tokens>
            <token id="11" string="behint" />
            <token id="12" string="a" />
            <token id="13" string="kist" />
            <token id="14" string="to" />
            <token id="15" string="lie" />
            <token id="16" string="an" />
          </tokens>
        </chunking>
        <chunking id="2" string="o'wit an" type="VP">
          <tokens>
            <token id="4" string="o'wit" />
            <token id="5" string="an" />
          </tokens>
        </chunking>
        <chunking id="3" string="a life" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="life" />
          </tokens>
        </chunking>
        <chunking id="4" string="to lie an" type="VP">
          <tokens>
            <token id="14" string="to" />
            <token id="15" string="lie" />
            <token id="16" string="an" />
          </tokens>
        </chunking>
        <chunking id="5" string="lie an" type="VP">
          <tokens>
            <token id="15" string="lie" />
            <token id="16" string="an" />
          </tokens>
        </chunking>
        <chunking id="6" string="sklent" type="NP">
          <tokens>
            <token id="18" string="sklent" />
          </tokens>
        </chunking>
        <chunking id="7" string="a kist" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="kist" />
          </tokens>
        </chunking>
        <chunking id="8" string="a life , behint a kist to lie an '" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="life" />
            <token id="10" string="," />
            <token id="11" string="behint" />
            <token id="12" string="a" />
            <token id="13" string="kist" />
            <token id="14" string="to" />
            <token id="15" string="lie" />
            <token id="16" string="an" />
            <token id="17" string="'" />
          </tokens>
        </chunking>
        <chunking id="9" string="Gie me" type="NP">
          <tokens>
            <token id="2" string="Gie" />
            <token id="3" string="me" />
          </tokens>
        </chunking>
        <chunking id="10" string="a kist to lie an" type="SBAR">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="kist" />
            <token id="14" string="to" />
            <token id="15" string="lie" />
            <token id="16" string="an" />
          </tokens>
        </chunking>
        <chunking id="11" string="an" type="NP">
          <tokens>
            <token id="5" string="an" />
          </tokens>
        </chunking>
        <chunking id="12" string="behint" type="NP">
          <tokens>
            <token id="11" string="behint" />
          </tokens>
        </chunking>
        <chunking id="13" string="sense a life , behint a kist to lie an '" type="VP">
          <tokens>
            <token id="7" string="sense" />
            <token id="8" string="a" />
            <token id="9" string="life" />
            <token id="10" string="," />
            <token id="11" string="behint" />
            <token id="12" string="a" />
            <token id="13" string="kist" />
            <token id="14" string="to" />
            <token id="15" string="lie" />
            <token id="16" string="an" />
            <token id="17" string="'" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">o'wit</governor>
          <dependent id="2">Gie</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">Gie</governor>
          <dependent id="3">me</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">sense</governor>
          <dependent id="4">o'wit</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">o'wit</governor>
          <dependent id="5">an</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">sense</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">life</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">sense</governor>
          <dependent id="9">life</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="9">life</governor>
          <dependent id="11">behint</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">kist</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">lie</governor>
          <dependent id="13">kist</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">lie</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="11">behint</governor>
          <dependent id="15">lie</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">lie</governor>
          <dependent id="16">an</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">sense</governor>
          <dependent id="18">sklent</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gie" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Gie" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="43" has_coreference="false">
      <content>Our Stibble-rig was Rab M&amp;apost;Graen, a clever, sturdy fellow, but then he was sae fley&amp;apost;d by his showther gae a keek, an&amp;apost; tumbl&amp;apost;d wi&amp;apost; a wintle.</content>
      <tokens>
        <token id="1" string="Our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Stibble-rig" lemma="stibble-rig" stem="stibble-rig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Rab" lemma="Rab" stem="rab" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="M'Graen" lemma="M'Graen" stem="m'graen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="clever" lemma="clever" stem="clever" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="sturdy" lemma="sturdy" stem="sturdi" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="fellow" lemma="fellow" stem="fellow" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="sae" lemma="sae" stem="sae" pos="FW" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="fley" lemma="fley" stem="flei" pos="FW" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="'d" lemma="would" stem="'d" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="showther" lemma="showther" stem="showther" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="gae" lemma="gae" stem="gae" pos="FW" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="keek" lemma="keek" stem="keek" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="tumbl" lemma="tumbl" stem="tumbl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="'d" lemma="would" stem="'d" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="wi" lemma="wi" stem="wi" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="wintle" lemma="wintle" stem="wintl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP$ Our) (NN Stibble-rig)) (VP (VBD was) (NP (NP (NNP Rab) (NNP M'Graen)) (, ,) (NP (DT a) (JJ clever) (, ,) (JJ sturdy) (NN fellow))))) (, ,) (CC but) (S (ADVP (RB then)) (NP (PRP he)) (VP (VBD was) (NP (NP (FW sae) (FW fley)) (SBAR (S (VP (MD 'd) (PP (IN by) (NP (NP (PRP$ his) (NN showther)) (NP (NP (FW gae)) (NP (DT a) (NN keek))))))))) (, ,) (NP (NP (DT an)) ('' ') (SBAR (S (NP (NN tumbl)) (VP (MD 'd) (VP (VB wi) ('' ') (NP (DT a) (NN wintle))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Rab M'Graen" type="NP">
          <tokens>
            <token id="4" string="Rab" />
            <token id="5" string="M'Graen" />
          </tokens>
        </chunking>
        <chunking id="2" string="gae a keek" type="NP">
          <tokens>
            <token id="23" string="gae" />
            <token id="24" string="a" />
            <token id="25" string="keek" />
          </tokens>
        </chunking>
        <chunking id="3" string="a clever , sturdy fellow" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="clever" />
            <token id="9" string="," />
            <token id="10" string="sturdy" />
            <token id="11" string="fellow" />
          </tokens>
        </chunking>
        <chunking id="4" string="a keek" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="keek" />
          </tokens>
        </chunking>
        <chunking id="5" string="wi ' a wintle" type="VP">
          <tokens>
            <token id="31" string="wi" />
            <token id="32" string="'" />
            <token id="33" string="a" />
            <token id="34" string="wintle" />
          </tokens>
        </chunking>
        <chunking id="6" string="Our Stibble-rig" type="NP">
          <tokens>
            <token id="1" string="Our" />
            <token id="2" string="Stibble-rig" />
          </tokens>
        </chunking>
        <chunking id="7" string="a wintle" type="NP">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="wintle" />
          </tokens>
        </chunking>
        <chunking id="8" string="his showther" type="NP">
          <tokens>
            <token id="21" string="his" />
            <token id="22" string="showther" />
          </tokens>
        </chunking>
        <chunking id="9" string="gae" type="NP">
          <tokens>
            <token id="23" string="gae" />
          </tokens>
        </chunking>
        <chunking id="10" string="an ' tumbl 'd wi ' a wintle" type="NP">
          <tokens>
            <token id="27" string="an" />
            <token id="28" string="'" />
            <token id="29" string="tumbl" />
            <token id="30" string="'d" />
            <token id="31" string="wi" />
            <token id="32" string="'" />
            <token id="33" string="a" />
            <token id="34" string="wintle" />
          </tokens>
        </chunking>
        <chunking id="11" string="an" type="NP">
          <tokens>
            <token id="27" string="an" />
          </tokens>
        </chunking>
        <chunking id="12" string="tumbl" type="NP">
          <tokens>
            <token id="29" string="tumbl" />
          </tokens>
        </chunking>
        <chunking id="13" string="sae fley 'd by his showther gae a keek" type="NP">
          <tokens>
            <token id="17" string="sae" />
            <token id="18" string="fley" />
            <token id="19" string="'d" />
            <token id="20" string="by" />
            <token id="21" string="his" />
            <token id="22" string="showther" />
            <token id="23" string="gae" />
            <token id="24" string="a" />
            <token id="25" string="keek" />
          </tokens>
        </chunking>
        <chunking id="14" string="sae fley" type="NP">
          <tokens>
            <token id="17" string="sae" />
            <token id="18" string="fley" />
          </tokens>
        </chunking>
        <chunking id="15" string="tumbl 'd wi ' a wintle" type="SBAR">
          <tokens>
            <token id="29" string="tumbl" />
            <token id="30" string="'d" />
            <token id="31" string="wi" />
            <token id="32" string="'" />
            <token id="33" string="a" />
            <token id="34" string="wintle" />
          </tokens>
        </chunking>
        <chunking id="16" string="'d wi ' a wintle" type="VP">
          <tokens>
            <token id="30" string="'d" />
            <token id="31" string="wi" />
            <token id="32" string="'" />
            <token id="33" string="a" />
            <token id="34" string="wintle" />
          </tokens>
        </chunking>
        <chunking id="17" string="his showther gae a keek" type="NP">
          <tokens>
            <token id="21" string="his" />
            <token id="22" string="showther" />
            <token id="23" string="gae" />
            <token id="24" string="a" />
            <token id="25" string="keek" />
          </tokens>
        </chunking>
        <chunking id="18" string="Rab M'Graen , a clever , sturdy fellow" type="NP">
          <tokens>
            <token id="4" string="Rab" />
            <token id="5" string="M'Graen" />
            <token id="6" string="," />
            <token id="7" string="a" />
            <token id="8" string="clever" />
            <token id="9" string="," />
            <token id="10" string="sturdy" />
            <token id="11" string="fellow" />
          </tokens>
        </chunking>
        <chunking id="19" string="he" type="NP">
          <tokens>
            <token id="15" string="he" />
          </tokens>
        </chunking>
        <chunking id="20" string="was sae fley 'd by his showther gae a keek , an ' tumbl 'd wi ' a wintle" type="VP">
          <tokens>
            <token id="16" string="was" />
            <token id="17" string="sae" />
            <token id="18" string="fley" />
            <token id="19" string="'d" />
            <token id="20" string="by" />
            <token id="21" string="his" />
            <token id="22" string="showther" />
            <token id="23" string="gae" />
            <token id="24" string="a" />
            <token id="25" string="keek" />
            <token id="26" string="," />
            <token id="27" string="an" />
            <token id="28" string="'" />
            <token id="29" string="tumbl" />
            <token id="30" string="'d" />
            <token id="31" string="wi" />
            <token id="32" string="'" />
            <token id="33" string="a" />
            <token id="34" string="wintle" />
          </tokens>
        </chunking>
        <chunking id="21" string="was Rab M'Graen , a clever , sturdy fellow" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="Rab" />
            <token id="5" string="M'Graen" />
            <token id="6" string="," />
            <token id="7" string="a" />
            <token id="8" string="clever" />
            <token id="9" string="," />
            <token id="10" string="sturdy" />
            <token id="11" string="fellow" />
          </tokens>
        </chunking>
        <chunking id="22" string="'d by his showther gae a keek" type="SBAR">
          <tokens>
            <token id="19" string="'d" />
            <token id="20" string="by" />
            <token id="21" string="his" />
            <token id="22" string="showther" />
            <token id="23" string="gae" />
            <token id="24" string="a" />
            <token id="25" string="keek" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">Stibble-rig</governor>
          <dependent id="1">Our</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">M'Graen</governor>
          <dependent id="2">Stibble-rig</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">M'Graen</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">M'Graen</governor>
          <dependent id="4">Rab</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">M'Graen</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">fellow</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">fellow</governor>
          <dependent id="8">clever</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">fellow</governor>
          <dependent id="10">sturdy</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">M'Graen</governor>
          <dependent id="11">fellow</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">M'Graen</governor>
          <dependent id="13">but</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">fley</governor>
          <dependent id="14">then</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">fley</governor>
          <dependent id="15">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="18">fley</governor>
          <dependent id="16">was</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">fley</governor>
          <dependent id="17">sae</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">M'Graen</governor>
          <dependent id="18">fley</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="18">fley</governor>
          <dependent id="19">'d</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">showther</governor>
          <dependent id="20">by</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">showther</governor>
          <dependent id="21">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">'d</governor>
          <dependent id="22">showther</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="22">showther</governor>
          <dependent id="23">gae</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">keek</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="23">gae</governor>
          <dependent id="25">keek</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="18">fley</governor>
          <dependent id="27">an</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">wi</governor>
          <dependent id="29">tumbl</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="31">wi</governor>
          <dependent id="30">'d</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="27">an</governor>
          <dependent id="31">wi</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">wintle</governor>
          <dependent id="33">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="31">wi</governor>
          <dependent id="34">wintle</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Rab M'Graen" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Rab" />
            <token id="5" string="M'Graen" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>Likewise with political and constitutional reform, Michael, for by the L - - d, tho&amp;apost; I should beg wi&amp;apost;lyart pow, I&amp;apost;ll laugh, an&amp;apost; sing, an&amp;apost; shake my leg, as lang&amp;apost;s I dow]&amp;apost; After that, I thought of telephoning Wing-Commander Paddy Ashdown, leader of the Liberal Democrats, to solicit his views on Christchurch.</content>
      <tokens>
        <token id="1" string="Likewise" lemma="likewise" stem="likewis" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="constitutional" lemma="constitutional" stem="constitut" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="reform" lemma="reform" stem="reform" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Michael" lemma="Michael" stem="michael" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="L" lemma="l" stem="l" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="d" lemma="d" stem="d" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="tho" lemma="tho" stem="tho" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="beg" lemma="beg" stem="beg" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="wi" lemma="wi" stem="wi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="lyart" lemma="lyart" stem="lyart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="pow" lemma="pow" stem="pow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="'ll" lemma="will" stem="'ll" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="laugh" lemma="laugh" stem="laugh" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="sing" lemma="sing" stem="sing" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="shake" lemma="shake" stem="shake" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="40" string="leg" lemma="leg" stem="leg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="lang" lemma="lang" stem="lang" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="dow" lemma="dow" stem="dow" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="]" lemma="-rsb-" stem="]" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="After" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="51" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="52" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="53" string="thought" lemma="think" stem="thought" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="54" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="55" string="telephoning" lemma="telephone" stem="telephon" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="56" string="Wing-Commander" lemma="Wing-Commander" stem="wing-command" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="57" string="Paddy" lemma="Paddy" stem="paddi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="58" string="Ashdown" lemma="Ashdown" stem="ashdown" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="59" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="60" string="leader" lemma="leader" stem="leader" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="61" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="62" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="63" string="Liberal" lemma="liberal" stem="liber" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="true" />
        <token id="64" string="Democrats" lemma="Democrats" stem="democrat" pos="NNPS" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="true" />
        <token id="65" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="66" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="67" string="solicit" lemma="solicit" stem="solicit" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="68" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="69" string="views" lemma="view" stem="view" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="70" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="71" string="Christchurch" lemma="Christchurch" stem="christchurch" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="72" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (ADVP (RB Likewise)) (IN with) (NP (JJ political) (CC and) (JJ constitutional) (NN reform))) (, ,) (S (FRAG (X (NP (NNP Michael)) (, ,) (PP (IN for) (PP (IN by) (NP (DT the) (NN L)))) (: -)) (: -) (NP (NN d))) (, ,) (NP (NP (NN tho) ('' ')) (NP (PRP I))) (VP (MD should) (VP (VB beg) (NP (NP (NN wi)) (`` `) (NP (NN lyart) (NN pow)))))) (, ,) (S (NP (PRP I)) (VP (MD 'll) (VP (NN laugh)))) (, ,) (S (NP (DT an)) ('' ') (VP (VB sing))) (, ,) (S (NP (DT an)) ('' ') (VP (VB shake) (NP (PRP$ my) (NN leg)))) (, ,) (S (PP (IN as) (NP (NN lang) (POS 's))) (NP (PRP I)) (VP (VBP dow))) (-RRB- -RSB-) ('' ') (S (PP (IN After) (NP (DT that))) (, ,) (NP (PRP I)) (VP (VBD thought) (PP (IN of) (S (VP (VBG telephoning) (S (NP (NP (NNP Wing-Commander) (NNP Paddy) (NNP Ashdown)) (, ,) (NP (NP (NN leader)) (PP (IN of) (NP (DT the) (JJ Liberal) (NNPS Democrats)))) (, ,)) (VP (TO to) (VP (VB solicit) (NP (PRP$ his) (NNS views)) (PP (IN on) (NP (NNP Christchurch))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="my leg" type="NP">
          <tokens>
            <token id="39" string="my" />
            <token id="40" string="leg" />
          </tokens>
        </chunking>
        <chunking id="2" string="Wing-Commander Paddy Ashdown" type="NP">
          <tokens>
            <token id="56" string="Wing-Commander" />
            <token id="57" string="Paddy" />
            <token id="58" string="Ashdown" />
          </tokens>
        </chunking>
        <chunking id="3" string="leader of the Liberal Democrats" type="NP">
          <tokens>
            <token id="60" string="leader" />
            <token id="61" string="of" />
            <token id="62" string="the" />
            <token id="63" string="Liberal" />
            <token id="64" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="4" string="d" type="NP">
          <tokens>
            <token id="16" string="d" />
          </tokens>
        </chunking>
        <chunking id="5" string="lyart pow" type="NP">
          <tokens>
            <token id="25" string="lyart" />
            <token id="26" string="pow" />
          </tokens>
        </chunking>
        <chunking id="6" string="solicit his views on Christchurch" type="VP">
          <tokens>
            <token id="67" string="solicit" />
            <token id="68" string="his" />
            <token id="69" string="views" />
            <token id="70" string="on" />
            <token id="71" string="Christchurch" />
          </tokens>
        </chunking>
        <chunking id="7" string="an" type="NP">
          <tokens>
            <token id="32" string="an" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Liberal Democrats" type="NP">
          <tokens>
            <token id="62" string="the" />
            <token id="63" string="Liberal" />
            <token id="64" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="9" string="should beg wi ` lyart pow" type="VP">
          <tokens>
            <token id="21" string="should" />
            <token id="22" string="beg" />
            <token id="23" string="wi" />
            <token id="24" string="'" />
            <token id="25" string="lyart" />
            <token id="26" string="pow" />
          </tokens>
        </chunking>
        <chunking id="10" string="lang 's" type="NP">
          <tokens>
            <token id="43" string="lang" />
            <token id="44" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="thought of telephoning Wing-Commander Paddy Ashdown , leader of the Liberal Democrats , to solicit his views on Christchurch" type="VP">
          <tokens>
            <token id="53" string="thought" />
            <token id="54" string="of" />
            <token id="55" string="telephoning" />
            <token id="56" string="Wing-Commander" />
            <token id="57" string="Paddy" />
            <token id="58" string="Ashdown" />
            <token id="59" string="," />
            <token id="60" string="leader" />
            <token id="61" string="of" />
            <token id="62" string="the" />
            <token id="63" string="Liberal" />
            <token id="64" string="Democrats" />
            <token id="65" string="," />
            <token id="66" string="to" />
            <token id="67" string="solicit" />
            <token id="68" string="his" />
            <token id="69" string="views" />
            <token id="70" string="on" />
            <token id="71" string="Christchurch" />
          </tokens>
        </chunking>
        <chunking id="12" string="sing" type="VP">
          <tokens>
            <token id="34" string="sing" />
          </tokens>
        </chunking>
        <chunking id="13" string="to solicit his views on Christchurch" type="VP">
          <tokens>
            <token id="66" string="to" />
            <token id="67" string="solicit" />
            <token id="68" string="his" />
            <token id="69" string="views" />
            <token id="70" string="on" />
            <token id="71" string="Christchurch" />
          </tokens>
        </chunking>
        <chunking id="14" string="his views" type="NP">
          <tokens>
            <token id="68" string="his" />
            <token id="69" string="views" />
          </tokens>
        </chunking>
        <chunking id="15" string="beg wi ` lyart pow" type="VP">
          <tokens>
            <token id="22" string="beg" />
            <token id="23" string="wi" />
            <token id="24" string="'" />
            <token id="25" string="lyart" />
            <token id="26" string="pow" />
          </tokens>
        </chunking>
        <chunking id="16" string="'ll laugh" type="VP">
          <tokens>
            <token id="29" string="'ll" />
            <token id="30" string="laugh" />
          </tokens>
        </chunking>
        <chunking id="17" string="telephoning Wing-Commander Paddy Ashdown , leader of the Liberal Democrats , to solicit his views on Christchurch" type="VP">
          <tokens>
            <token id="55" string="telephoning" />
            <token id="56" string="Wing-Commander" />
            <token id="57" string="Paddy" />
            <token id="58" string="Ashdown" />
            <token id="59" string="," />
            <token id="60" string="leader" />
            <token id="61" string="of" />
            <token id="62" string="the" />
            <token id="63" string="Liberal" />
            <token id="64" string="Democrats" />
            <token id="65" string="," />
            <token id="66" string="to" />
            <token id="67" string="solicit" />
            <token id="68" string="his" />
            <token id="69" string="views" />
            <token id="70" string="on" />
            <token id="71" string="Christchurch" />
          </tokens>
        </chunking>
        <chunking id="18" string="leader" type="NP">
          <tokens>
            <token id="60" string="leader" />
          </tokens>
        </chunking>
        <chunking id="19" string="Wing-Commander Paddy Ashdown , leader of the Liberal Democrats ," type="NP">
          <tokens>
            <token id="56" string="Wing-Commander" />
            <token id="57" string="Paddy" />
            <token id="58" string="Ashdown" />
            <token id="59" string="," />
            <token id="60" string="leader" />
            <token id="61" string="of" />
            <token id="62" string="the" />
            <token id="63" string="Liberal" />
            <token id="64" string="Democrats" />
            <token id="65" string="," />
          </tokens>
        </chunking>
        <chunking id="20" string="Christchurch" type="NP">
          <tokens>
            <token id="71" string="Christchurch" />
          </tokens>
        </chunking>
        <chunking id="21" string="I" type="NP">
          <tokens>
            <token id="20" string="I" />
          </tokens>
        </chunking>
        <chunking id="22" string="shake my leg" type="VP">
          <tokens>
            <token id="38" string="shake" />
            <token id="39" string="my" />
            <token id="40" string="leg" />
          </tokens>
        </chunking>
        <chunking id="23" string="dow" type="VP">
          <tokens>
            <token id="46" string="dow" />
          </tokens>
        </chunking>
        <chunking id="24" string="the L" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="L" />
          </tokens>
        </chunking>
        <chunking id="25" string="that" type="NP">
          <tokens>
            <token id="50" string="that" />
          </tokens>
        </chunking>
        <chunking id="26" string="wi" type="NP">
          <tokens>
            <token id="23" string="wi" />
          </tokens>
        </chunking>
        <chunking id="27" string="tho '" type="NP">
          <tokens>
            <token id="18" string="tho" />
            <token id="19" string="'" />
          </tokens>
        </chunking>
        <chunking id="28" string="political and constitutional reform" type="NP">
          <tokens>
            <token id="3" string="political" />
            <token id="4" string="and" />
            <token id="5" string="constitutional" />
            <token id="6" string="reform" />
          </tokens>
        </chunking>
        <chunking id="29" string="Michael" type="NP">
          <tokens>
            <token id="8" string="Michael" />
          </tokens>
        </chunking>
        <chunking id="30" string="tho ' I" type="NP">
          <tokens>
            <token id="18" string="tho" />
            <token id="19" string="'" />
            <token id="20" string="I" />
          </tokens>
        </chunking>
        <chunking id="31" string="wi ` lyart pow" type="NP">
          <tokens>
            <token id="23" string="wi" />
            <token id="24" string="'" />
            <token id="25" string="lyart" />
            <token id="26" string="pow" />
          </tokens>
        </chunking>
        <chunking id="32" string="laugh" type="VP">
          <tokens>
            <token id="30" string="laugh" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="6">reform</governor>
          <dependent id="1">Likewise</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">reform</governor>
          <dependent id="2">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">reform</governor>
          <dependent id="3">political</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">political</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">political</governor>
          <dependent id="5">constitutional</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">beg</governor>
          <dependent id="6">reform</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">d</governor>
          <dependent id="8">Michael</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">L</governor>
          <dependent id="10">for</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">L</governor>
          <dependent id="11">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">L</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">Michael</governor>
          <dependent id="13">L</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="22">beg</governor>
          <dependent id="16">d</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">beg</governor>
          <dependent id="18">tho</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="18">tho</governor>
          <dependent id="20">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">beg</governor>
          <dependent id="21">should</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="22">beg</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">beg</governor>
          <dependent id="23">wi</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">pow</governor>
          <dependent id="25">lyart</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="23">wi</governor>
          <dependent id="26">pow</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">laugh</governor>
          <dependent id="28">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="30">laugh</governor>
          <dependent id="29">'ll</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="22">beg</governor>
          <dependent id="30">laugh</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">sing</governor>
          <dependent id="32">an</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="22">beg</governor>
          <dependent id="34">sing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="38">shake</governor>
          <dependent id="36">an</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="22">beg</governor>
          <dependent id="38">shake</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="40">leg</governor>
          <dependent id="39">my</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="38">shake</governor>
          <dependent id="40">leg</dependent>
        </dependency>
        <dependency type="case">
          <governor id="43">lang</governor>
          <dependent id="42">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="46">dow</governor>
          <dependent id="43">lang</dependent>
        </dependency>
        <dependency type="case">
          <governor id="43">lang</governor>
          <dependent id="44">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="46">dow</governor>
          <dependent id="45">I</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="22">beg</governor>
          <dependent id="46">dow</dependent>
        </dependency>
        <dependency type="case">
          <governor id="50">that</governor>
          <dependent id="49">After</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="53">thought</governor>
          <dependent id="50">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="53">thought</governor>
          <dependent id="52">I</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="22">beg</governor>
          <dependent id="53">thought</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="55">telephoning</governor>
          <dependent id="54">of</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="53">thought</governor>
          <dependent id="55">telephoning</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="58">Ashdown</governor>
          <dependent id="56">Wing-Commander</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="58">Ashdown</governor>
          <dependent id="57">Paddy</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="55">telephoning</governor>
          <dependent id="58">Ashdown</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="58">Ashdown</governor>
          <dependent id="60">leader</dependent>
        </dependency>
        <dependency type="case">
          <governor id="64">Democrats</governor>
          <dependent id="61">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="64">Democrats</governor>
          <dependent id="62">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="64">Democrats</governor>
          <dependent id="63">Liberal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="60">leader</governor>
          <dependent id="64">Democrats</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="67">solicit</governor>
          <dependent id="66">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="55">telephoning</governor>
          <dependent id="67">solicit</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="69">views</governor>
          <dependent id="68">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="67">solicit</governor>
          <dependent id="69">views</dependent>
        </dependency>
        <dependency type="case">
          <governor id="71">Christchurch</governor>
          <dependent id="70">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="67">solicit</governor>
          <dependent id="71">Christchurch</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Wing-Commander Paddy Ashdown" type="PERSON" score="0.0">
          <tokens>
            <token id="56" string="Wing-Commander" />
            <token id="57" string="Paddy" />
            <token id="58" string="Ashdown" />
          </tokens>
        </entity>
        <entity id="2" string="Christchurch" type="LOCATION" score="0.0">
          <tokens>
            <token id="71" string="Christchurch" />
          </tokens>
        </entity>
        <entity id="3" string="Michael" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Michael" />
          </tokens>
        </entity>
        <entity id="4" string="Liberal Democrats" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="63" string="Liberal" />
            <token id="64" string="Democrats" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="45" has_coreference="false">
      <content>But I couldn&amp;apost;t raise the energy.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="raise" lemma="raise" stem="rais" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="energy" lemma="energy" stem="energi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (PRP I)) (VP (MD could) (RB n't) (VP (VB raise) (NP (DT the) (NN energy)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="2" string="raise the energy" type="VP">
          <tokens>
            <token id="5" string="raise" />
            <token id="6" string="the" />
            <token id="7" string="energy" />
          </tokens>
        </chunking>
        <chunking id="3" string="could n't raise the energy" type="VP">
          <tokens>
            <token id="3" string="could" />
            <token id="4" string="n't" />
            <token id="5" string="raise" />
            <token id="6" string="the" />
            <token id="7" string="energy" />
          </tokens>
        </chunking>
        <chunking id="4" string="the energy" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="energy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="5">raise</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">raise</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">raise</governor>
          <dependent id="3">could</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">raise</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">raise</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">energy</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">raise</governor>
          <dependent id="7">energy</dependent>
        </dependency>
      </dependencies>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="4-5" string="John Major" id_sentence="1" />
      <mentions>
        <mention ids_tokens="26" string="Major" id_sentence="2" />
        <mention ids_tokens="41" string="his" id_sentence="2" />
        <mention ids_tokens="8-9" string="Major's" id_sentence="3" />
        <mention ids_tokens="1" string="Major" id_sentence="5" />
        <mention ids_tokens="3-41" string="a gonner , especially after this week's revolt of the wooden-tops in the Christchurch by-election , where a Conservative majority of 23,015 at last year's general election was converted into a 16,427 majority for the Liberal Democrats" id_sentence="5" />
        <mention ids_tokens="3-4" string="a gonner" id_sentence="5" />
        <mention ids_tokens="5" string="Major" id_sentence="22" />
        <mention ids_tokens="9" string="John" id_sentence="23" />
        <mention ids_tokens="9" string="John" id_sentence="27" />
        <mention ids_tokens="13" string="John" id_sentence="37" />
        <mention ids_tokens="10" string="John" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="2" type="NOMINAL">
      <referenced ids_tokens="19-20-21-22" string="record to friendly journalists" id_sentence="1" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="2" />
        <mention ids_tokens="4" string="it" id_sentence="3" />
      </mentions>
    </coreference>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="16-17" string="Michael Brunson" id_sentence="2" />
      <mentions>
        <mention ids_tokens="10" string="Michael" id_sentence="33" />
        <mention ids_tokens="8" string="Michael" id_sentence="44" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="10-11-12-13" string="the prime minister 's" id_sentence="2" />
      <mentions>
        <mention ids_tokens="1-3" string="the prime minister" id_sentence="32" />
      </mentions>
    </coreference>
    <coreference id="5" type="NOMINAL">
      <referenced ids_tokens="37-38" string="eight-letter words" id_sentence="2" />
      <mentions>
        <mention ids_tokens="1-2" string="Their words" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="7" type="PROPER">
      <referenced ids_tokens="8-9-10" string="this week 's" id_sentence="5" />
      <mentions>
        <mention ids_tokens="40-41" string="this week" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="8" type="PROPER">
      <referenced ids_tokens="39-40-41" string="the Liberal Democrats" id_sentence="5" />
      <mentions>
        <mention ids_tokens="63-64" string="Liberal Democrats" id_sentence="44" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="6-7-8-9" string="the voters of Christchurch" id_sentence="6" />
      <mentions>
        <mention ids_tokens="4" string="they" id_sentence="8" />
        <mention ids_tokens="11" string="they" id_sentence="8" />
        <mention ids_tokens="15" string="their" id_sentence="8" />
        <mention ids_tokens="4" string="they" id_sentence="9" />
        <mention ids_tokens="1" string="Their" id_sentence="10" />
        <mention ids_tokens="1" string="Their" id_sentence="11" />
        <mention ids_tokens="1" string="They" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="1-2" string="Their syntax" id_sentence="10" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="13" />
        <mention ids_tokens="4-5" string="a spectacle" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="12" type="PROPER">
      <referenced ids_tokens="15-16" string="John Smith" id_sentence="14" />
      <mentions>
        <mention ids_tokens="1-4" string="Smith , a Scot" id_sentence="15" />
        <mention ids_tokens="1" string="Smith" id_sentence="15" />
        <mention ids_tokens="7-11" string="leader of the Labour Party" id_sentence="15" />
        <mention ids_tokens="3" string="him" id_sentence="36" />
        <mention ids_tokens="9" string="his" id_sentence="36" />
        <mention ids_tokens="22" string="he" id_sentence="36" />
        <mention ids_tokens="25" string="his" id_sentence="36" />
        <mention ids_tokens="34" string="he" id_sentence="36" />
        <mention ids_tokens="10-12" string="the Labour leader" id_sentence="41" />
      </mentions>
    </coreference>
    <coreference id="13" type="PRONOMINAL">
      <referenced ids_tokens="5" string="I" id_sentence="14" />
      <mentions>
        <mention ids_tokens="5" string="that" id_sentence="21" />
        <mention ids_tokens="23" string="me" id_sentence="33" />
        <mention ids_tokens="41" string="me" id_sentence="33" />
        <mention ids_tokens="8" string="that" id_sentence="34" />
        <mention ids_tokens="3" string="me" id_sentence="42" />
        <mention ids_tokens="39" string="my" id_sentence="44" />
        <mention ids_tokens="50" string="that" id_sentence="44" />
      </mentions>
    </coreference>
    <coreference id="14" type="LIST">
      <referenced ids_tokens="12-13-14-15-16" string="John Major and John Smith" id_sentence="14" />
      <mentions>
        <mention ids_tokens="3" string="them" id_sentence="17" />
        <mention ids_tokens="1" string="Their" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="15" type="PROPER">
      <referenced ids_tokens="10-11" string="Labour Party" id_sentence="15" />
      <mentions>
        <mention ids_tokens="11" string="Labour" id_sentence="41" />
      </mentions>
    </coreference>
    <coreference id="17" type="LIST">
      <referenced ids_tokens="9-10-11-12-13-14-15-16-17-18-19-20-21-22-23-24-25-26-27-28-29-30-31-32-33-34-35-36-37-38-39-40-41" string="John , what Olivier Blanchard , Rudiger Dornbusch , Stanley Fischer , Franco Modigliani , Paul A Samuelson and Robert Solow wrote , in just one article , in the FT this week" id_sentence="23" />
      <mentions>
        <mention ids_tokens="1" string="They" id_sentence="24" />
        <mention ids_tokens="1" string="They" id_sentence="25" />
        <mention ids_tokens="5" string="their" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="19" type="PRONOMINAL">
      <referenced ids_tokens="5" string="you" id_sentence="30" />
      <mentions>
        <mention ids_tokens="3-4" string="you sure" id_sentence="31" />
      </mentions>
    </coreference>
    <coreference id="20" type="NOMINAL">
      <referenced ids_tokens="8-9" string="the blame" id_sentence="30" />
      <mentions>
        <mention ids_tokens="6" string="it" id_sentence="33" />
        <mention ids_tokens="25" string="it" id_sentence="33" />
        <mention ids_tokens="16" string="it" id_sentence="34" />
      </mentions>
    </coreference>
    <coreference id="22" type="PRONOMINAL">
      <referenced ids_tokens="3" string="you" id_sentence="40" />
      <mentions>
        <mention ids_tokens="4-8" string="ye thowless jad ,'" id_sentence="41" />
      </mentions>
    </coreference>
  </coreferences>
</document>
