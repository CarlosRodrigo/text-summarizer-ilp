<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP901016-0112">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Critic and novelist A.S. Byatt on Tuesday won the Booker Prize, Britain&amp;apost;s most prestigious literary award, for her tale of two young scholars investigating the lives of a pair of imaginary Victorian poets.</content>
      <tokens>
        <token id="1" string="Critic" lemma="critic" stem="critic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="novelist" lemma="novelist" stem="novelist" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="A.S." lemma="A.S." stem="a.s." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="Byatt" lemma="Byatt" stem="byatt" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="Tuesday" lemma="Tuesday" stem="tuesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="8" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="11" string="Prize" lemma="Prize" stem="prize" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Britain" lemma="Britain" stem="britain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="14" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="most" lemma="most" stem="most" pos="JJS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="prestigious" lemma="prestigious" stem="prestigi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="literary" lemma="literary" stem="literari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="award" lemma="award" stem="award" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="tale" lemma="tale" stem="tale" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="25" string="young" lemma="young" stem="young" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="scholars" lemma="scholar" stem="scholar" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="investigating" lemma="investigate" stem="investig" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="lives" lemma="life" stem="live" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="pair" lemma="pair" stem="pair" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="imaginary" lemma="imaginary" stem="imaginari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="Victorian" lemma="victorian" stem="victorian" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="36" string="poets" lemma="poet" stem="poet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NN Critic)) (CC and) (NP (NP (NN novelist) (NNP A.S.) (NNP Byatt)) (PP (IN on) (NP (NNP Tuesday))))) (VP (VBD won) (NP (NP (DT the) (NNP Booker) (NNP Prize)) (, ,) (NP (NP (NNP Britain) (POS 's)) (ADJP (JJS most) (JJ prestigious)) (JJ literary) (NN award))) (, ,) (PP (IN for) (NP (NP (PRP$ her) (NN tale)) (PP (IN of) (NP (NP (CD two) (JJ young) (NNS scholars)) (VP (VBG investigating) (NP (NP (DT the) (NNS lives)) (PP (IN of) (NP (NP (DT a) (NN pair)) (PP (IN of) (NP (JJ imaginary) (JJ Victorian) (NNS poets)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="her tale" type="NP">
          <tokens>
            <token id="21" string="her" />
            <token id="22" string="tale" />
          </tokens>
        </chunking>
        <chunking id="2" string="Britain 's most prestigious literary award" type="NP">
          <tokens>
            <token id="13" string="Britain" />
            <token id="14" string="'s" />
            <token id="15" string="most" />
            <token id="16" string="prestigious" />
            <token id="17" string="literary" />
            <token id="18" string="award" />
          </tokens>
        </chunking>
        <chunking id="3" string="a pair" type="NP">
          <tokens>
            <token id="31" string="a" />
            <token id="32" string="pair" />
          </tokens>
        </chunking>
        <chunking id="4" string="her tale of two young scholars investigating the lives of a pair of imaginary Victorian poets" type="NP">
          <tokens>
            <token id="21" string="her" />
            <token id="22" string="tale" />
            <token id="23" string="of" />
            <token id="24" string="two" />
            <token id="25" string="young" />
            <token id="26" string="scholars" />
            <token id="27" string="investigating" />
            <token id="28" string="the" />
            <token id="29" string="lives" />
            <token id="30" string="of" />
            <token id="31" string="a" />
            <token id="32" string="pair" />
            <token id="33" string="of" />
            <token id="34" string="imaginary" />
            <token id="35" string="Victorian" />
            <token id="36" string="poets" />
          </tokens>
        </chunking>
        <chunking id="5" string="the lives" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="lives" />
          </tokens>
        </chunking>
        <chunking id="6" string="imaginary Victorian poets" type="NP">
          <tokens>
            <token id="34" string="imaginary" />
            <token id="35" string="Victorian" />
            <token id="36" string="poets" />
          </tokens>
        </chunking>
        <chunking id="7" string="won the Booker Prize , Britain 's most prestigious literary award , for her tale of two young scholars investigating the lives of a pair of imaginary Victorian poets" type="VP">
          <tokens>
            <token id="8" string="won" />
            <token id="9" string="the" />
            <token id="10" string="Booker" />
            <token id="11" string="Prize" />
            <token id="12" string="," />
            <token id="13" string="Britain" />
            <token id="14" string="'s" />
            <token id="15" string="most" />
            <token id="16" string="prestigious" />
            <token id="17" string="literary" />
            <token id="18" string="award" />
            <token id="19" string="," />
            <token id="20" string="for" />
            <token id="21" string="her" />
            <token id="22" string="tale" />
            <token id="23" string="of" />
            <token id="24" string="two" />
            <token id="25" string="young" />
            <token id="26" string="scholars" />
            <token id="27" string="investigating" />
            <token id="28" string="the" />
            <token id="29" string="lives" />
            <token id="30" string="of" />
            <token id="31" string="a" />
            <token id="32" string="pair" />
            <token id="33" string="of" />
            <token id="34" string="imaginary" />
            <token id="35" string="Victorian" />
            <token id="36" string="poets" />
          </tokens>
        </chunking>
        <chunking id="8" string="Critic and novelist A.S. Byatt on Tuesday" type="NP">
          <tokens>
            <token id="1" string="Critic" />
            <token id="2" string="and" />
            <token id="3" string="novelist" />
            <token id="4" string="A.S." />
            <token id="5" string="Byatt" />
            <token id="6" string="on" />
            <token id="7" string="Tuesday" />
          </tokens>
        </chunking>
        <chunking id="9" string="investigating the lives of a pair of imaginary Victorian poets" type="VP">
          <tokens>
            <token id="27" string="investigating" />
            <token id="28" string="the" />
            <token id="29" string="lives" />
            <token id="30" string="of" />
            <token id="31" string="a" />
            <token id="32" string="pair" />
            <token id="33" string="of" />
            <token id="34" string="imaginary" />
            <token id="35" string="Victorian" />
            <token id="36" string="poets" />
          </tokens>
        </chunking>
        <chunking id="10" string="the Booker Prize" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="Booker" />
            <token id="11" string="Prize" />
          </tokens>
        </chunking>
        <chunking id="11" string="the lives of a pair of imaginary Victorian poets" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="lives" />
            <token id="30" string="of" />
            <token id="31" string="a" />
            <token id="32" string="pair" />
            <token id="33" string="of" />
            <token id="34" string="imaginary" />
            <token id="35" string="Victorian" />
            <token id="36" string="poets" />
          </tokens>
        </chunking>
        <chunking id="12" string="two young scholars" type="NP">
          <tokens>
            <token id="24" string="two" />
            <token id="25" string="young" />
            <token id="26" string="scholars" />
          </tokens>
        </chunking>
        <chunking id="13" string="most prestigious" type="ADJP">
          <tokens>
            <token id="15" string="most" />
            <token id="16" string="prestigious" />
          </tokens>
        </chunking>
        <chunking id="14" string="novelist A.S. Byatt" type="NP">
          <tokens>
            <token id="3" string="novelist" />
            <token id="4" string="A.S." />
            <token id="5" string="Byatt" />
          </tokens>
        </chunking>
        <chunking id="15" string="novelist A.S. Byatt on Tuesday" type="NP">
          <tokens>
            <token id="3" string="novelist" />
            <token id="4" string="A.S." />
            <token id="5" string="Byatt" />
            <token id="6" string="on" />
            <token id="7" string="Tuesday" />
          </tokens>
        </chunking>
        <chunking id="16" string="a pair of imaginary Victorian poets" type="NP">
          <tokens>
            <token id="31" string="a" />
            <token id="32" string="pair" />
            <token id="33" string="of" />
            <token id="34" string="imaginary" />
            <token id="35" string="Victorian" />
            <token id="36" string="poets" />
          </tokens>
        </chunking>
        <chunking id="17" string="Britain 's" type="NP">
          <tokens>
            <token id="13" string="Britain" />
            <token id="14" string="'s" />
          </tokens>
        </chunking>
        <chunking id="18" string="Tuesday" type="NP">
          <tokens>
            <token id="7" string="Tuesday" />
          </tokens>
        </chunking>
        <chunking id="19" string="the Booker Prize , Britain 's most prestigious literary award" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="Booker" />
            <token id="11" string="Prize" />
            <token id="12" string="," />
            <token id="13" string="Britain" />
            <token id="14" string="'s" />
            <token id="15" string="most" />
            <token id="16" string="prestigious" />
            <token id="17" string="literary" />
            <token id="18" string="award" />
          </tokens>
        </chunking>
        <chunking id="20" string="Critic" type="NP">
          <tokens>
            <token id="1" string="Critic" />
          </tokens>
        </chunking>
        <chunking id="21" string="two young scholars investigating the lives of a pair of imaginary Victorian poets" type="NP">
          <tokens>
            <token id="24" string="two" />
            <token id="25" string="young" />
            <token id="26" string="scholars" />
            <token id="27" string="investigating" />
            <token id="28" string="the" />
            <token id="29" string="lives" />
            <token id="30" string="of" />
            <token id="31" string="a" />
            <token id="32" string="pair" />
            <token id="33" string="of" />
            <token id="34" string="imaginary" />
            <token id="35" string="Victorian" />
            <token id="36" string="poets" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="8">won</governor>
          <dependent id="1">Critic</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Critic</governor>
          <dependent id="2">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Byatt</governor>
          <dependent id="3">novelist</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Byatt</governor>
          <dependent id="4">A.S.</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Critic</governor>
          <dependent id="5">Byatt</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Tuesday</governor>
          <dependent id="6">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">Byatt</governor>
          <dependent id="7">Tuesday</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">won</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">Prize</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Prize</governor>
          <dependent id="10">Booker</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">won</governor>
          <dependent id="11">Prize</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">award</governor>
          <dependent id="13">Britain</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Britain</governor>
          <dependent id="14">'s</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">prestigious</governor>
          <dependent id="15">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">award</governor>
          <dependent id="16">prestigious</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">award</governor>
          <dependent id="17">literary</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="11">Prize</governor>
          <dependent id="18">award</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">tale</governor>
          <dependent id="20">for</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">tale</governor>
          <dependent id="21">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">won</governor>
          <dependent id="22">tale</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">scholars</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="26">scholars</governor>
          <dependent id="24">two</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">scholars</governor>
          <dependent id="25">young</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">tale</governor>
          <dependent id="26">scholars</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="26">scholars</governor>
          <dependent id="27">investigating</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">lives</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">investigating</governor>
          <dependent id="29">lives</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">pair</governor>
          <dependent id="30">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">pair</governor>
          <dependent id="31">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">lives</governor>
          <dependent id="32">pair</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">poets</governor>
          <dependent id="33">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="36">poets</governor>
          <dependent id="34">imaginary</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="36">poets</governor>
          <dependent id="35">Victorian</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">pair</governor>
          <dependent id="36">poets</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="A.S. Byatt" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="A.S." />
            <token id="5" string="Byatt" />
          </tokens>
        </entity>
        <entity id="2" string="Booker Prize" type="MISC" score="0.0">
          <tokens>
            <token id="10" string="Booker" />
            <token id="11" string="Prize" />
          </tokens>
        </entity>
        <entity id="3" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="24" string="two" />
          </tokens>
        </entity>
        <entity id="4" string="Tuesday" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="Tuesday" />
          </tokens>
        </entity>
        <entity id="5" string="Britain" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Britain" />
          </tokens>
        </entity>
        <entity id="6" string="Victorian" type="MISC" score="0.0">
          <tokens>
            <token id="35" string="Victorian" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>The five judges deliberated two hours before awarding the $39,000 prize to Antonia Byatt for ``Possession,&amp;apost;&amp;apost; one of six finalists in the 21-year-old competition.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="3" string="judges" lemma="judge" stem="judg" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="deliberated" lemma="deliberate" stem="deliber" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="6" string="hours" lemma="hour" stem="hour" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="7" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="awarding" lemma="award" stem="award" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="true" is_refers="false" />
        <token id="11" string="39,000" lemma="39,000" stem="39,000" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="true" is_refers="false" />
        <token id="12" string="prize" lemma="prize" stem="prize" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Antonia" lemma="Antonia" stem="antonia" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="15" string="Byatt" lemma="Byatt" stem="byatt" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="16" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Possession" lemma="Possession" stem="possess" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="24" string="finalists" lemma="finalist" stem="finalist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="21-year-old" lemma="21-year-old" stem="21-year-old" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="28" string="competition" lemma="competition" stem="competit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (CD five) (NNS judges)) (VP (VBD deliberated) (NP (CD two) (NNS hours)) (PP (IN before) (S (VP (VBG awarding) (NP (DT the) (ADJP (QP ($ $) (CD 39,000))) (NN prize)) (PP (TO to) (NP (NP (NNP Antonia) (NNP Byatt)) (PP (IN for) (NP (`` ``) (NP (NNP Possession)) (, ,) ('' '') (NP (NP (CD one)) (PP (IN of) (NP (NP (CD six) (NNS finalists)) (PP (IN in) (NP (DT the) (JJ 21-year-old) (NN competition)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Antonia Byatt" type="NP">
          <tokens>
            <token id="14" string="Antonia" />
            <token id="15" string="Byatt" />
          </tokens>
        </chunking>
        <chunking id="2" string="`` Possession , '' one of six finalists in the 21-year-old competition" type="NP">
          <tokens>
            <token id="17" string="``" />
            <token id="18" string="Possession" />
            <token id="19" string="," />
            <token id="20" string="''" />
            <token id="21" string="one" />
            <token id="22" string="of" />
            <token id="23" string="six" />
            <token id="24" string="finalists" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="21-year-old" />
            <token id="28" string="competition" />
          </tokens>
        </chunking>
        <chunking id="3" string="one" type="NP">
          <tokens>
            <token id="21" string="one" />
          </tokens>
        </chunking>
        <chunking id="4" string="six finalists in the 21-year-old competition" type="NP">
          <tokens>
            <token id="23" string="six" />
            <token id="24" string="finalists" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="21-year-old" />
            <token id="28" string="competition" />
          </tokens>
        </chunking>
        <chunking id="5" string="the $ 39,000 prize" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="$" />
            <token id="11" string="39,000" />
            <token id="12" string="prize" />
          </tokens>
        </chunking>
        <chunking id="6" string="two hours" type="NP">
          <tokens>
            <token id="5" string="two" />
            <token id="6" string="hours" />
          </tokens>
        </chunking>
        <chunking id="7" string="the 21-year-old competition" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="21-year-old" />
            <token id="28" string="competition" />
          </tokens>
        </chunking>
        <chunking id="8" string="six finalists" type="NP">
          <tokens>
            <token id="23" string="six" />
            <token id="24" string="finalists" />
          </tokens>
        </chunking>
        <chunking id="9" string="The five judges" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="five" />
            <token id="3" string="judges" />
          </tokens>
        </chunking>
        <chunking id="10" string="awarding the $ 39,000 prize to Antonia Byatt for `` Possession , '' one of six finalists in the 21-year-old competition" type="VP">
          <tokens>
            <token id="8" string="awarding" />
            <token id="9" string="the" />
            <token id="10" string="$" />
            <token id="11" string="39,000" />
            <token id="12" string="prize" />
            <token id="13" string="to" />
            <token id="14" string="Antonia" />
            <token id="15" string="Byatt" />
            <token id="16" string="for" />
            <token id="17" string="``" />
            <token id="18" string="Possession" />
            <token id="19" string="," />
            <token id="20" string="''" />
            <token id="21" string="one" />
            <token id="22" string="of" />
            <token id="23" string="six" />
            <token id="24" string="finalists" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="21-year-old" />
            <token id="28" string="competition" />
          </tokens>
        </chunking>
        <chunking id="11" string="$ 39,000" type="ADJP">
          <tokens>
            <token id="10" string="$" />
            <token id="11" string="39,000" />
          </tokens>
        </chunking>
        <chunking id="12" string="Possession" type="NP">
          <tokens>
            <token id="18" string="Possession" />
          </tokens>
        </chunking>
        <chunking id="13" string="one of six finalists in the 21-year-old competition" type="NP">
          <tokens>
            <token id="21" string="one" />
            <token id="22" string="of" />
            <token id="23" string="six" />
            <token id="24" string="finalists" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="21-year-old" />
            <token id="28" string="competition" />
          </tokens>
        </chunking>
        <chunking id="14" string="deliberated two hours before awarding the $ 39,000 prize to Antonia Byatt for `` Possession , '' one of six finalists in the 21-year-old competition" type="VP">
          <tokens>
            <token id="4" string="deliberated" />
            <token id="5" string="two" />
            <token id="6" string="hours" />
            <token id="7" string="before" />
            <token id="8" string="awarding" />
            <token id="9" string="the" />
            <token id="10" string="$" />
            <token id="11" string="39,000" />
            <token id="12" string="prize" />
            <token id="13" string="to" />
            <token id="14" string="Antonia" />
            <token id="15" string="Byatt" />
            <token id="16" string="for" />
            <token id="17" string="``" />
            <token id="18" string="Possession" />
            <token id="19" string="," />
            <token id="20" string="''" />
            <token id="21" string="one" />
            <token id="22" string="of" />
            <token id="23" string="six" />
            <token id="24" string="finalists" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="21-year-old" />
            <token id="28" string="competition" />
          </tokens>
        </chunking>
        <chunking id="15" string="Antonia Byatt for `` Possession , '' one of six finalists in the 21-year-old competition" type="NP">
          <tokens>
            <token id="14" string="Antonia" />
            <token id="15" string="Byatt" />
            <token id="16" string="for" />
            <token id="17" string="``" />
            <token id="18" string="Possession" />
            <token id="19" string="," />
            <token id="20" string="''" />
            <token id="21" string="one" />
            <token id="22" string="of" />
            <token id="23" string="six" />
            <token id="24" string="finalists" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="21-year-old" />
            <token id="28" string="competition" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">judges</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="3">judges</governor>
          <dependent id="2">five</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">deliberated</governor>
          <dependent id="3">judges</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">deliberated</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">hours</governor>
          <dependent id="5">two</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">deliberated</governor>
          <dependent id="6">hours</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">awarding</governor>
          <dependent id="7">before</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">deliberated</governor>
          <dependent id="8">awarding</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">prize</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">prize</governor>
          <dependent id="10">$</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">$</governor>
          <dependent id="11">39,000</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">awarding</governor>
          <dependent id="12">prize</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Byatt</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Byatt</governor>
          <dependent id="14">Antonia</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">awarding</governor>
          <dependent id="15">Byatt</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Possession</governor>
          <dependent id="16">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">Byatt</governor>
          <dependent id="18">Possession</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="18">Possession</governor>
          <dependent id="21">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">finalists</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="24">finalists</governor>
          <dependent id="23">six</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">one</governor>
          <dependent id="24">finalists</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">competition</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">competition</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">competition</governor>
          <dependent id="27">21-year-old</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">finalists</governor>
          <dependent id="28">competition</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="two hours" type="DURATION" score="0.0">
          <tokens>
            <token id="5" string="two" />
            <token id="6" string="hours" />
          </tokens>
        </entity>
        <entity id="2" string="Antonia Byatt" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Antonia" />
            <token id="15" string="Byatt" />
          </tokens>
        </entity>
        <entity id="3" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="23" string="six" />
          </tokens>
        </entity>
        <entity id="4" string="21-year-old" type="DURATION" score="0.0">
          <tokens>
            <token id="27" string="21-year-old" />
          </tokens>
        </entity>
        <entity id="5" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="21" string="one" />
          </tokens>
        </entity>
        <entity id="6" string="$ 39,000" type="MONEY" score="0.0">
          <tokens>
            <token id="10" string="$" />
            <token id="11" string="39,000" />
          </tokens>
        </entity>
        <entity id="7" string="five" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="five" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>Last year&amp;apost;s Booker winner was Kazuo Ishiguro for his novel, ``The Remains of the Day.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="Last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="2" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="winner" lemma="winner" stem="winner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Kazuo" lemma="Kazuo" stem="kazuo" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="Ishiguro" lemma="Ishiguro" stem="ishiguro" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="9" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="novel" lemma="novel" stem="novel" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="Remains" lemma="remains" stem="remain" pos="NNS" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="18" string="Day" lemma="day" stem="dai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (JJ Last) (NN year) (POS 's)) (NNP Booker) (NN winner)) (VP (VBD was) (NP (NP (NNP Kazuo) (NNP Ishiguro)) (PP (IN for) (NP (NP (PRP$ his) (JJ novel)) (, ,) (`` ``) (NP (NP (DT The) (NNS Remains)) (PP (IN of) (NP (DT the) (NN Day)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Kazuo Ishiguro" type="NP">
          <tokens>
            <token id="7" string="Kazuo" />
            <token id="8" string="Ishiguro" />
          </tokens>
        </chunking>
        <chunking id="2" string="Kazuo Ishiguro for his novel , `` The Remains of the Day" type="NP">
          <tokens>
            <token id="7" string="Kazuo" />
            <token id="8" string="Ishiguro" />
            <token id="9" string="for" />
            <token id="10" string="his" />
            <token id="11" string="novel" />
            <token id="12" string="," />
            <token id="13" string="``" />
            <token id="14" string="The" />
            <token id="15" string="Remains" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="Day" />
          </tokens>
        </chunking>
        <chunking id="3" string="Last year 's" type="NP">
          <tokens>
            <token id="1" string="Last" />
            <token id="2" string="year" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Day" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="Day" />
          </tokens>
        </chunking>
        <chunking id="5" string="was Kazuo Ishiguro for his novel , `` The Remains of the Day" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="Kazuo" />
            <token id="8" string="Ishiguro" />
            <token id="9" string="for" />
            <token id="10" string="his" />
            <token id="11" string="novel" />
            <token id="12" string="," />
            <token id="13" string="``" />
            <token id="14" string="The" />
            <token id="15" string="Remains" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="Day" />
          </tokens>
        </chunking>
        <chunking id="6" string="The Remains of the Day" type="NP">
          <tokens>
            <token id="14" string="The" />
            <token id="15" string="Remains" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="Day" />
          </tokens>
        </chunking>
        <chunking id="7" string="his novel , `` The Remains of the Day" type="NP">
          <tokens>
            <token id="10" string="his" />
            <token id="11" string="novel" />
            <token id="12" string="," />
            <token id="13" string="``" />
            <token id="14" string="The" />
            <token id="15" string="Remains" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="Day" />
          </tokens>
        </chunking>
        <chunking id="8" string="The Remains" type="NP">
          <tokens>
            <token id="14" string="The" />
            <token id="15" string="Remains" />
          </tokens>
        </chunking>
        <chunking id="9" string="Last year 's Booker winner" type="NP">
          <tokens>
            <token id="1" string="Last" />
            <token id="2" string="year" />
            <token id="3" string="'s" />
            <token id="4" string="Booker" />
            <token id="5" string="winner" />
          </tokens>
        </chunking>
        <chunking id="10" string="his novel" type="NP">
          <tokens>
            <token id="10" string="his" />
            <token id="11" string="novel" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">year</governor>
          <dependent id="1">Last</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">winner</governor>
          <dependent id="2">year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">year</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">winner</governor>
          <dependent id="4">Booker</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">Ishiguro</governor>
          <dependent id="5">winner</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">Ishiguro</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Ishiguro</governor>
          <dependent id="7">Kazuo</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">Ishiguro</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">novel</governor>
          <dependent id="9">for</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">novel</governor>
          <dependent id="10">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">Ishiguro</governor>
          <dependent id="11">novel</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">Remains</governor>
          <dependent id="14">The</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">novel</governor>
          <dependent id="15">Remains</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Day</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">Day</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">Remains</governor>
          <dependent id="18">Day</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Kazuo Ishiguro" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Kazuo" />
            <token id="8" string="Ishiguro" />
          </tokens>
        </entity>
        <entity id="2" string="Booker" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Booker" />
          </tokens>
        </entity>
        <entity id="3" string="the Day" type="DATE" score="0.0">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="Day" />
          </tokens>
        </entity>
        <entity id="4" string="Last year" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Last" />
            <token id="2" string="year" />
          </tokens>
        </entity>
        <entity id="5" string="Remains of" type="MISC" score="0.0">
          <tokens>
            <token id="15" string="Remains" />
            <token id="16" string="of" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>Television executive Sir Denis Forman, chairman of the judge&amp;apost;s panel, announced the prize at a banquet in London&amp;apost;s Elizabethan Guildhall, seat of the city&amp;apost;s Lord Mayor.</content>
      <tokens>
        <token id="1" string="Television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="executive" lemma="executive" stem="execut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Sir" lemma="Sir" stem="sir" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Denis" lemma="Denis" stem="deni" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="Forman" lemma="Forman" stem="forman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="chairman" lemma="chairman" stem="chairman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="judge" lemma="judge" stem="judg" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="panel" lemma="panel" stem="panel" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="announced" lemma="announce" stem="announc" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="prize" lemma="prize" stem="prize" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="banquet" lemma="banquet" stem="banquet" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="London" lemma="London" stem="london" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="22" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="Elizabethan" lemma="Elizabethan" stem="elizabethan" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="24" string="Guildhall" lemma="Guildhall" stem="guildhal" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="seat" lemma="seat" stem="seat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="Lord" lemma="Lord" stem="lord" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="Mayor" lemma="Mayor" stem="mayor" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NN Television) (NN executive) (NNP Sir) (NNP Denis) (NNP Forman)) (, ,) (NP (NP (NN chairman)) (PP (IN of) (NP (NP (DT the) (NN judge) (POS 's)) (NN panel)))) (, ,)) (VP (VBD announced) (NP (DT the) (NN prize)) (PP (IN at) (NP (DT a) (NN banquet))) (PP (IN in) (NP (NP (NP (NNP London) (POS 's)) (NNP Elizabethan) (NNP Guildhall)) (, ,) (NP (NP (NN seat)) (PP (IN of) (NP (NP (DT the) (NN city) (POS 's)) (NNP Lord) (NNP Mayor))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the judge 's" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="judge" />
            <token id="11" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="the city 's Lord Mayor" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="city" />
            <token id="30" string="'s" />
            <token id="31" string="Lord" />
            <token id="32" string="Mayor" />
          </tokens>
        </chunking>
        <chunking id="3" string="London 's" type="NP">
          <tokens>
            <token id="21" string="London" />
            <token id="22" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="Television executive Sir Denis Forman , chairman of the judge 's panel ," type="NP">
          <tokens>
            <token id="1" string="Television" />
            <token id="2" string="executive" />
            <token id="3" string="Sir" />
            <token id="4" string="Denis" />
            <token id="5" string="Forman" />
            <token id="6" string="," />
            <token id="7" string="chairman" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="judge" />
            <token id="11" string="'s" />
            <token id="12" string="panel" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="chairman" type="NP">
          <tokens>
            <token id="7" string="chairman" />
          </tokens>
        </chunking>
        <chunking id="6" string="the judge 's panel" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="judge" />
            <token id="11" string="'s" />
            <token id="12" string="panel" />
          </tokens>
        </chunking>
        <chunking id="7" string="London 's Elizabethan Guildhall , seat of the city 's Lord Mayor" type="NP">
          <tokens>
            <token id="21" string="London" />
            <token id="22" string="'s" />
            <token id="23" string="Elizabethan" />
            <token id="24" string="Guildhall" />
            <token id="25" string="," />
            <token id="26" string="seat" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="city" />
            <token id="30" string="'s" />
            <token id="31" string="Lord" />
            <token id="32" string="Mayor" />
          </tokens>
        </chunking>
        <chunking id="8" string="Television executive Sir Denis Forman" type="NP">
          <tokens>
            <token id="1" string="Television" />
            <token id="2" string="executive" />
            <token id="3" string="Sir" />
            <token id="4" string="Denis" />
            <token id="5" string="Forman" />
          </tokens>
        </chunking>
        <chunking id="9" string="the prize" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="prize" />
          </tokens>
        </chunking>
        <chunking id="10" string="chairman of the judge 's panel" type="NP">
          <tokens>
            <token id="7" string="chairman" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="judge" />
            <token id="11" string="'s" />
            <token id="12" string="panel" />
          </tokens>
        </chunking>
        <chunking id="11" string="London 's Elizabethan Guildhall" type="NP">
          <tokens>
            <token id="21" string="London" />
            <token id="22" string="'s" />
            <token id="23" string="Elizabethan" />
            <token id="24" string="Guildhall" />
          </tokens>
        </chunking>
        <chunking id="12" string="seat" type="NP">
          <tokens>
            <token id="26" string="seat" />
          </tokens>
        </chunking>
        <chunking id="13" string="seat of the city 's Lord Mayor" type="NP">
          <tokens>
            <token id="26" string="seat" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="city" />
            <token id="30" string="'s" />
            <token id="31" string="Lord" />
            <token id="32" string="Mayor" />
          </tokens>
        </chunking>
        <chunking id="14" string="announced the prize at a banquet in London 's Elizabethan Guildhall , seat of the city 's Lord Mayor" type="VP">
          <tokens>
            <token id="14" string="announced" />
            <token id="15" string="the" />
            <token id="16" string="prize" />
            <token id="17" string="at" />
            <token id="18" string="a" />
            <token id="19" string="banquet" />
            <token id="20" string="in" />
            <token id="21" string="London" />
            <token id="22" string="'s" />
            <token id="23" string="Elizabethan" />
            <token id="24" string="Guildhall" />
            <token id="25" string="," />
            <token id="26" string="seat" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="city" />
            <token id="30" string="'s" />
            <token id="31" string="Lord" />
            <token id="32" string="Mayor" />
          </tokens>
        </chunking>
        <chunking id="15" string="a banquet" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="banquet" />
          </tokens>
        </chunking>
        <chunking id="16" string="the city 's" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="city" />
            <token id="30" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="5">Forman</governor>
          <dependent id="1">Television</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Forman</governor>
          <dependent id="2">executive</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Forman</governor>
          <dependent id="3">Sir</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Forman</governor>
          <dependent id="4">Denis</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">announced</governor>
          <dependent id="5">Forman</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">Forman</governor>
          <dependent id="7">chairman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">panel</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">judge</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">panel</governor>
          <dependent id="10">judge</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">judge</governor>
          <dependent id="11">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">chairman</governor>
          <dependent id="12">panel</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">announced</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">prize</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">announced</governor>
          <dependent id="16">prize</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">banquet</governor>
          <dependent id="17">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">banquet</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">announced</governor>
          <dependent id="19">banquet</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">Guildhall</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">Guildhall</governor>
          <dependent id="21">London</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">London</governor>
          <dependent id="22">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Guildhall</governor>
          <dependent id="23">Elizabethan</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">announced</governor>
          <dependent id="24">Guildhall</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="24">Guildhall</governor>
          <dependent id="26">seat</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">Mayor</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">city</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="32">Mayor</governor>
          <dependent id="29">city</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">city</governor>
          <dependent id="30">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">Mayor</governor>
          <dependent id="31">Lord</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">seat</governor>
          <dependent id="32">Mayor</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Elizabethan Guildhall" type="LOCATION" score="0.0">
          <tokens>
            <token id="23" string="Elizabethan" />
            <token id="24" string="Guildhall" />
          </tokens>
        </entity>
        <entity id="2" string="Denis Forman" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Denis" />
            <token id="5" string="Forman" />
          </tokens>
        </entity>
        <entity id="3" string="London" type="LOCATION" score="0.0">
          <tokens>
            <token id="21" string="London" />
          </tokens>
        </entity>
        <entity id="4" string="Mayor" type="TITLE" score="0.0">
          <tokens>
            <token id="32" string="Mayor" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>``There was very strong individual support for several books on the short list and finally `Possession&amp;apost; by A.S. Byatt was the winner by a majority vote,&amp;apost;&amp;apost; said the judges.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="strong" lemma="strong" stem="strong" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="individual" lemma="individual" stem="individu" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="support" lemma="support" stem="support" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="several" lemma="several" stem="sever" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="short" lemma="short" stem="short" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="list" lemma="list" stem="list" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="finally" lemma="finally" stem="final" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="`" lemma="`" stem="`" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Possession" lemma="possession" stem="possess" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="A.S." lemma="A.S." stem="a.s." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="22" string="Byatt" lemma="Byatt" stem="byatt" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="23" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="winner" lemma="winner" stem="winner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="majority" lemma="majority" stem="major" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="vote" lemma="vote" stem="vote" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="judges" lemma="judge" stem="judg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (EX There)) (VP (VBD was) (ADJP (RB very) (JJ strong) (SBAR (S (NP (NP (NP (JJ individual) (NN support)) (PP (IN for) (NP (NP (JJ several) (NNS books)) (PP (IN on) (NP (DT the) (JJ short) (NN list)))))) (CC and) (ADVP (RB finally)) (NP (`` `) (NP (NN Possession)) ('' ') (PP (IN by) (NP (NNP A.S.) (NNP Byatt))))) (VP (VBD was) (NP (NP (DT the) (NN winner)) (PP (IN by) (NP (DT a) (NN majority) (NN vote)))))))))) (, ,) ('' '') (VP (VBD said)) (NP (DT the) (NNS judges)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="` Possession ' by A.S. Byatt" type="NP">
          <tokens>
            <token id="17" string="`" />
            <token id="18" string="Possession" />
            <token id="19" string="'" />
            <token id="20" string="by" />
            <token id="21" string="A.S." />
            <token id="22" string="Byatt" />
          </tokens>
        </chunking>
        <chunking id="2" string="individual support for several books on the short list and finally ` Possession ' by A.S. Byatt was the winner by a majority vote" type="SBAR">
          <tokens>
            <token id="6" string="individual" />
            <token id="7" string="support" />
            <token id="8" string="for" />
            <token id="9" string="several" />
            <token id="10" string="books" />
            <token id="11" string="on" />
            <token id="12" string="the" />
            <token id="13" string="short" />
            <token id="14" string="list" />
            <token id="15" string="and" />
            <token id="16" string="finally" />
            <token id="17" string="`" />
            <token id="18" string="Possession" />
            <token id="19" string="'" />
            <token id="20" string="by" />
            <token id="21" string="A.S." />
            <token id="22" string="Byatt" />
            <token id="23" string="was" />
            <token id="24" string="the" />
            <token id="25" string="winner" />
            <token id="26" string="by" />
            <token id="27" string="a" />
            <token id="28" string="majority" />
            <token id="29" string="vote" />
          </tokens>
        </chunking>
        <chunking id="3" string="very strong individual support for several books on the short list and finally ` Possession ' by A.S. Byatt was the winner by a majority vote" type="ADJP">
          <tokens>
            <token id="4" string="very" />
            <token id="5" string="strong" />
            <token id="6" string="individual" />
            <token id="7" string="support" />
            <token id="8" string="for" />
            <token id="9" string="several" />
            <token id="10" string="books" />
            <token id="11" string="on" />
            <token id="12" string="the" />
            <token id="13" string="short" />
            <token id="14" string="list" />
            <token id="15" string="and" />
            <token id="16" string="finally" />
            <token id="17" string="`" />
            <token id="18" string="Possession" />
            <token id="19" string="'" />
            <token id="20" string="by" />
            <token id="21" string="A.S." />
            <token id="22" string="Byatt" />
            <token id="23" string="was" />
            <token id="24" string="the" />
            <token id="25" string="winner" />
            <token id="26" string="by" />
            <token id="27" string="a" />
            <token id="28" string="majority" />
            <token id="29" string="vote" />
          </tokens>
        </chunking>
        <chunking id="4" string="was very strong individual support for several books on the short list and finally ` Possession ' by A.S. Byatt was the winner by a majority vote" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="very" />
            <token id="5" string="strong" />
            <token id="6" string="individual" />
            <token id="7" string="support" />
            <token id="8" string="for" />
            <token id="9" string="several" />
            <token id="10" string="books" />
            <token id="11" string="on" />
            <token id="12" string="the" />
            <token id="13" string="short" />
            <token id="14" string="list" />
            <token id="15" string="and" />
            <token id="16" string="finally" />
            <token id="17" string="`" />
            <token id="18" string="Possession" />
            <token id="19" string="'" />
            <token id="20" string="by" />
            <token id="21" string="A.S." />
            <token id="22" string="Byatt" />
            <token id="23" string="was" />
            <token id="24" string="the" />
            <token id="25" string="winner" />
            <token id="26" string="by" />
            <token id="27" string="a" />
            <token id="28" string="majority" />
            <token id="29" string="vote" />
          </tokens>
        </chunking>
        <chunking id="5" string="a majority vote" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="majority" />
            <token id="29" string="vote" />
          </tokens>
        </chunking>
        <chunking id="6" string="several books on the short list" type="NP">
          <tokens>
            <token id="9" string="several" />
            <token id="10" string="books" />
            <token id="11" string="on" />
            <token id="12" string="the" />
            <token id="13" string="short" />
            <token id="14" string="list" />
          </tokens>
        </chunking>
        <chunking id="7" string="was the winner by a majority vote" type="VP">
          <tokens>
            <token id="23" string="was" />
            <token id="24" string="the" />
            <token id="25" string="winner" />
            <token id="26" string="by" />
            <token id="27" string="a" />
            <token id="28" string="majority" />
            <token id="29" string="vote" />
          </tokens>
        </chunking>
        <chunking id="8" string="individual support for several books on the short list" type="NP">
          <tokens>
            <token id="6" string="individual" />
            <token id="7" string="support" />
            <token id="8" string="for" />
            <token id="9" string="several" />
            <token id="10" string="books" />
            <token id="11" string="on" />
            <token id="12" string="the" />
            <token id="13" string="short" />
            <token id="14" string="list" />
          </tokens>
        </chunking>
        <chunking id="9" string="the winner by a majority vote" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="winner" />
            <token id="26" string="by" />
            <token id="27" string="a" />
            <token id="28" string="majority" />
            <token id="29" string="vote" />
          </tokens>
        </chunking>
        <chunking id="10" string="individual support for several books on the short list and finally ` Possession ' by A.S. Byatt" type="NP">
          <tokens>
            <token id="6" string="individual" />
            <token id="7" string="support" />
            <token id="8" string="for" />
            <token id="9" string="several" />
            <token id="10" string="books" />
            <token id="11" string="on" />
            <token id="12" string="the" />
            <token id="13" string="short" />
            <token id="14" string="list" />
            <token id="15" string="and" />
            <token id="16" string="finally" />
            <token id="17" string="`" />
            <token id="18" string="Possession" />
            <token id="19" string="'" />
            <token id="20" string="by" />
            <token id="21" string="A.S." />
            <token id="22" string="Byatt" />
          </tokens>
        </chunking>
        <chunking id="11" string="the short list" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="short" />
            <token id="14" string="list" />
          </tokens>
        </chunking>
        <chunking id="12" string="There" type="NP">
          <tokens>
            <token id="2" string="There" />
          </tokens>
        </chunking>
        <chunking id="13" string="several books" type="NP">
          <tokens>
            <token id="9" string="several" />
            <token id="10" string="books" />
          </tokens>
        </chunking>
        <chunking id="14" string="the winner" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="winner" />
          </tokens>
        </chunking>
        <chunking id="15" string="Possession" type="NP">
          <tokens>
            <token id="18" string="Possession" />
          </tokens>
        </chunking>
        <chunking id="16" string="A.S. Byatt" type="NP">
          <tokens>
            <token id="21" string="A.S." />
            <token id="22" string="Byatt" />
          </tokens>
        </chunking>
        <chunking id="17" string="the judges" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="judges" />
          </tokens>
        </chunking>
        <chunking id="18" string="individual support" type="NP">
          <tokens>
            <token id="6" string="individual" />
            <token id="7" string="support" />
          </tokens>
        </chunking>
        <chunking id="19" string="said" type="VP">
          <tokens>
            <token id="32" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="3">was</governor>
          <dependent id="2">There</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="32">said</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">strong</governor>
          <dependent id="4">very</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">was</governor>
          <dependent id="5">strong</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">support</governor>
          <dependent id="6">individual</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">winner</governor>
          <dependent id="7">support</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">books</governor>
          <dependent id="8">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">books</governor>
          <dependent id="9">several</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">support</governor>
          <dependent id="10">books</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">list</governor>
          <dependent id="11">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">list</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">list</governor>
          <dependent id="13">short</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">books</governor>
          <dependent id="14">list</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">support</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">Possession</governor>
          <dependent id="16">finally</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">support</governor>
          <dependent id="18">Possession</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">Byatt</governor>
          <dependent id="20">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Byatt</governor>
          <dependent id="21">A.S.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">Possession</governor>
          <dependent id="22">Byatt</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="25">winner</governor>
          <dependent id="23">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">winner</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">strong</governor>
          <dependent id="25">winner</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">vote</governor>
          <dependent id="26">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">vote</governor>
          <dependent id="27">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">vote</governor>
          <dependent id="28">majority</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">winner</governor>
          <dependent id="29">vote</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="32">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">judges</governor>
          <dependent id="33">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">said</governor>
          <dependent id="34">judges</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="A.S. Byatt" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="A.S." />
            <token id="22" string="Byatt" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>``The panel was unanimous, however, in agreeing that the standard of the other five novels was exceptionally high and this made their decision unusually interesting and unusually difficult.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="panel" lemma="panel" stem="panel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="unanimous" lemma="unanimous" stem="unanim" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="however" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="agreeing" lemma="agree" stem="agre" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="standard" lemma="standard" stem="standard" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="18" string="novels" lemma="novel" stem="novel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="exceptionally" lemma="exceptionally" stem="exception" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="high" lemma="high" stem="high" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="decision" lemma="decision" stem="decis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="unusually" lemma="unusually" stem="unusu" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="interesting" lemma="interesting" stem="interest" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="unusually" lemma="unusually" stem="unusu" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="difficult" lemma="difficult" stem="difficult" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (DT The) (NN panel)) (VP (VBD was) (ADJP (ADJP (ADJP (JJ unanimous)) (PRN (, ,) (ADVP (RB however)) (, ,))) (PP (IN in) (S (VP (VBG agreeing) (SBAR (IN that) (S (NP (NP (DT the) (NN standard)) (PP (IN of) (NP (DT the) (JJ other) (CD five) (NNS novels)))) (VP (VBD was) (ADJP (RB exceptionally) (JJ high))))))))))) (CC and) (S (NP (DT this)) (VP (VBD made) (S (NP (PRP$ their) (NN decision)) (ADJP (ADJP (RB unusually) (JJ interesting)) (CC and) (ADJP (RB unusually) (JJ difficult)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="was unanimous , however , in agreeing that the standard of the other five novels was exceptionally high" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="unanimous" />
            <token id="6" string="," />
            <token id="7" string="however" />
            <token id="8" string="," />
            <token id="9" string="in" />
            <token id="10" string="agreeing" />
            <token id="11" string="that" />
            <token id="12" string="the" />
            <token id="13" string="standard" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="other" />
            <token id="17" string="five" />
            <token id="18" string="novels" />
            <token id="19" string="was" />
            <token id="20" string="exceptionally" />
            <token id="21" string="high" />
          </tokens>
        </chunking>
        <chunking id="2" string="agreeing that the standard of the other five novels was exceptionally high" type="VP">
          <tokens>
            <token id="10" string="agreeing" />
            <token id="11" string="that" />
            <token id="12" string="the" />
            <token id="13" string="standard" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="other" />
            <token id="17" string="five" />
            <token id="18" string="novels" />
            <token id="19" string="was" />
            <token id="20" string="exceptionally" />
            <token id="21" string="high" />
          </tokens>
        </chunking>
        <chunking id="3" string="the other five novels" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="other" />
            <token id="17" string="five" />
            <token id="18" string="novels" />
          </tokens>
        </chunking>
        <chunking id="4" string="The panel" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="panel" />
          </tokens>
        </chunking>
        <chunking id="5" string="the standard" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="standard" />
          </tokens>
        </chunking>
        <chunking id="6" string="unusually interesting" type="ADJP">
          <tokens>
            <token id="27" string="unusually" />
            <token id="28" string="interesting" />
          </tokens>
        </chunking>
        <chunking id="7" string="unanimous , however ," type="ADJP">
          <tokens>
            <token id="5" string="unanimous" />
            <token id="6" string="," />
            <token id="7" string="however" />
            <token id="8" string="," />
          </tokens>
        </chunking>
        <chunking id="8" string="this" type="NP">
          <tokens>
            <token id="23" string="this" />
          </tokens>
        </chunking>
        <chunking id="9" string="unusually difficult" type="ADJP">
          <tokens>
            <token id="30" string="unusually" />
            <token id="31" string="difficult" />
          </tokens>
        </chunking>
        <chunking id="10" string="the standard of the other five novels" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="standard" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="other" />
            <token id="17" string="five" />
            <token id="18" string="novels" />
          </tokens>
        </chunking>
        <chunking id="11" string="was exceptionally high" type="VP">
          <tokens>
            <token id="19" string="was" />
            <token id="20" string="exceptionally" />
            <token id="21" string="high" />
          </tokens>
        </chunking>
        <chunking id="12" string="made their decision unusually interesting and unusually difficult" type="VP">
          <tokens>
            <token id="24" string="made" />
            <token id="25" string="their" />
            <token id="26" string="decision" />
            <token id="27" string="unusually" />
            <token id="28" string="interesting" />
            <token id="29" string="and" />
            <token id="30" string="unusually" />
            <token id="31" string="difficult" />
          </tokens>
        </chunking>
        <chunking id="13" string="that the standard of the other five novels was exceptionally high" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="the" />
            <token id="13" string="standard" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="other" />
            <token id="17" string="five" />
            <token id="18" string="novels" />
            <token id="19" string="was" />
            <token id="20" string="exceptionally" />
            <token id="21" string="high" />
          </tokens>
        </chunking>
        <chunking id="14" string="unusually interesting and unusually difficult" type="ADJP">
          <tokens>
            <token id="27" string="unusually" />
            <token id="28" string="interesting" />
            <token id="29" string="and" />
            <token id="30" string="unusually" />
            <token id="31" string="difficult" />
          </tokens>
        </chunking>
        <chunking id="15" string="unanimous" type="ADJP">
          <tokens>
            <token id="5" string="unanimous" />
          </tokens>
        </chunking>
        <chunking id="16" string="their decision" type="NP">
          <tokens>
            <token id="25" string="their" />
            <token id="26" string="decision" />
          </tokens>
        </chunking>
        <chunking id="17" string="exceptionally high" type="ADJP">
          <tokens>
            <token id="20" string="exceptionally" />
            <token id="21" string="high" />
          </tokens>
        </chunking>
        <chunking id="18" string="unanimous , however , in agreeing that the standard of the other five novels was exceptionally high" type="ADJP">
          <tokens>
            <token id="5" string="unanimous" />
            <token id="6" string="," />
            <token id="7" string="however" />
            <token id="8" string="," />
            <token id="9" string="in" />
            <token id="10" string="agreeing" />
            <token id="11" string="that" />
            <token id="12" string="the" />
            <token id="13" string="standard" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="other" />
            <token id="17" string="five" />
            <token id="18" string="novels" />
            <token id="19" string="was" />
            <token id="20" string="exceptionally" />
            <token id="21" string="high" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">panel</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">unanimous</governor>
          <dependent id="3">panel</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">unanimous</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">unanimous</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">unanimous</governor>
          <dependent id="7">however</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">agreeing</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">unanimous</governor>
          <dependent id="10">agreeing</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">high</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">standard</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">high</governor>
          <dependent id="13">standard</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">novels</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">novels</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">novels</governor>
          <dependent id="16">other</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="18">novels</governor>
          <dependent id="17">five</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">standard</governor>
          <dependent id="18">novels</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">high</governor>
          <dependent id="19">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">high</governor>
          <dependent id="20">exceptionally</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">agreeing</governor>
          <dependent id="21">high</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">unanimous</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">made</governor>
          <dependent id="23">this</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">unanimous</governor>
          <dependent id="24">made</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="26">decision</governor>
          <dependent id="25">their</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">interesting</governor>
          <dependent id="26">decision</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">interesting</governor>
          <dependent id="27">unusually</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="24">made</governor>
          <dependent id="28">interesting</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="28">interesting</governor>
          <dependent id="29">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="31">difficult</governor>
          <dependent id="30">unusually</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="28">interesting</governor>
          <dependent id="31">difficult</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="five" type="NUMBER" score="0.0">
          <tokens>
            <token id="17" string="five" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>Ms. Byatt, who earlier this month won the $43,000 Irish Times-Aer Lingus prize for international fiction for the same work, has published five novels since 1964.</content>
      <tokens>
        <token id="1" string="Ms." lemma="Ms." stem="ms." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="Byatt" lemma="Byatt" stem="byatt" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="earlier" lemma="earlier" stem="earlier" pos="RBR" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="6" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="7" string="month" lemma="month" stem="month" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="8" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="true" />
        <token id="11" string="43,000" lemma="43,000" stem="43,000" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="true" />
        <token id="12" string="Irish" lemma="irish" stem="irish" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="true" />
        <token id="13" string="Times-Aer" lemma="Times-Aer" stem="times-a" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="14" string="Lingus" lemma="Lingus" stem="lingu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="15" string="prize" lemma="prize" stem="prize" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="international" lemma="international" stem="intern" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="fiction" lemma="fiction" stem="fiction" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="same" lemma="same" stem="same" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="work" lemma="work" stem="work" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="published" lemma="publish" stem="publish" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="27" string="novels" lemma="novel" stem="novel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="1964" lemma="1964" stem="1964" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Ms.) (NNP Byatt)) (, ,) (SBAR (WHNP (WP who)) (S (NP-TMP (RBR earlier) (DT this) (NN month)) (VP (VBD won) (NP (NP (DT the) (ADJP (QP ($ $) (CD 43,000))) (JJ Irish) (NNP Times-Aer) (NNP Lingus) (NN prize)) (PP (IN for) (NP (JJ international) (NN fiction)))) (PP (IN for) (NP (DT the) (JJ same) (NN work)))))) (, ,)) (VP (VBZ has) (VP (VBN published) (NP (NP (CD five) (NNS novels)) (PP (IN since) (NP (CD 1964)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Ms. Byatt" type="NP">
          <tokens>
            <token id="1" string="Ms." />
            <token id="2" string="Byatt" />
          </tokens>
        </chunking>
        <chunking id="2" string="the same work" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="same" />
            <token id="22" string="work" />
          </tokens>
        </chunking>
        <chunking id="3" string="won the $ 43,000 Irish Times-Aer Lingus prize for international fiction for the same work" type="VP">
          <tokens>
            <token id="8" string="won" />
            <token id="9" string="the" />
            <token id="10" string="$" />
            <token id="11" string="43,000" />
            <token id="12" string="Irish" />
            <token id="13" string="Times-Aer" />
            <token id="14" string="Lingus" />
            <token id="15" string="prize" />
            <token id="16" string="for" />
            <token id="17" string="international" />
            <token id="18" string="fiction" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="same" />
            <token id="22" string="work" />
          </tokens>
        </chunking>
        <chunking id="4" string="five novels since 1964" type="NP">
          <tokens>
            <token id="26" string="five" />
            <token id="27" string="novels" />
            <token id="28" string="since" />
            <token id="29" string="1964" />
          </tokens>
        </chunking>
        <chunking id="5" string="who earlier this month won the $ 43,000 Irish Times-Aer Lingus prize for international fiction for the same work" type="SBAR">
          <tokens>
            <token id="4" string="who" />
            <token id="5" string="earlier" />
            <token id="6" string="this" />
            <token id="7" string="month" />
            <token id="8" string="won" />
            <token id="9" string="the" />
            <token id="10" string="$" />
            <token id="11" string="43,000" />
            <token id="12" string="Irish" />
            <token id="13" string="Times-Aer" />
            <token id="14" string="Lingus" />
            <token id="15" string="prize" />
            <token id="16" string="for" />
            <token id="17" string="international" />
            <token id="18" string="fiction" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="same" />
            <token id="22" string="work" />
          </tokens>
        </chunking>
        <chunking id="6" string="$ 43,000" type="ADJP">
          <tokens>
            <token id="10" string="$" />
            <token id="11" string="43,000" />
          </tokens>
        </chunking>
        <chunking id="7" string="has published five novels since 1964" type="VP">
          <tokens>
            <token id="24" string="has" />
            <token id="25" string="published" />
            <token id="26" string="five" />
            <token id="27" string="novels" />
            <token id="28" string="since" />
            <token id="29" string="1964" />
          </tokens>
        </chunking>
        <chunking id="8" string="international fiction" type="NP">
          <tokens>
            <token id="17" string="international" />
            <token id="18" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="9" string="1964" type="NP">
          <tokens>
            <token id="29" string="1964" />
          </tokens>
        </chunking>
        <chunking id="10" string="five novels" type="NP">
          <tokens>
            <token id="26" string="five" />
            <token id="27" string="novels" />
          </tokens>
        </chunking>
        <chunking id="11" string="the $ 43,000 Irish Times-Aer Lingus prize for international fiction" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="$" />
            <token id="11" string="43,000" />
            <token id="12" string="Irish" />
            <token id="13" string="Times-Aer" />
            <token id="14" string="Lingus" />
            <token id="15" string="prize" />
            <token id="16" string="for" />
            <token id="17" string="international" />
            <token id="18" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="12" string="Ms. Byatt , who earlier this month won the $ 43,000 Irish Times-Aer Lingus prize for international fiction for the same work ," type="NP">
          <tokens>
            <token id="1" string="Ms." />
            <token id="2" string="Byatt" />
            <token id="3" string="," />
            <token id="4" string="who" />
            <token id="5" string="earlier" />
            <token id="6" string="this" />
            <token id="7" string="month" />
            <token id="8" string="won" />
            <token id="9" string="the" />
            <token id="10" string="$" />
            <token id="11" string="43,000" />
            <token id="12" string="Irish" />
            <token id="13" string="Times-Aer" />
            <token id="14" string="Lingus" />
            <token id="15" string="prize" />
            <token id="16" string="for" />
            <token id="17" string="international" />
            <token id="18" string="fiction" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="same" />
            <token id="22" string="work" />
            <token id="23" string="," />
          </tokens>
        </chunking>
        <chunking id="13" string="published five novels since 1964" type="VP">
          <tokens>
            <token id="25" string="published" />
            <token id="26" string="five" />
            <token id="27" string="novels" />
            <token id="28" string="since" />
            <token id="29" string="1964" />
          </tokens>
        </chunking>
        <chunking id="14" string="the $ 43,000 Irish Times-Aer Lingus prize" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="$" />
            <token id="11" string="43,000" />
            <token id="12" string="Irish" />
            <token id="13" string="Times-Aer" />
            <token id="14" string="Lingus" />
            <token id="15" string="prize" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Byatt</governor>
          <dependent id="1">Ms.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">published</governor>
          <dependent id="2">Byatt</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">won</governor>
          <dependent id="4">who</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">month</governor>
          <dependent id="5">earlier</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">month</governor>
          <dependent id="6">this</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">won</governor>
          <dependent id="7">month</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">Byatt</governor>
          <dependent id="8">won</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">prize</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">prize</governor>
          <dependent id="10">$</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">$</governor>
          <dependent id="11">43,000</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">prize</governor>
          <dependent id="12">Irish</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">prize</governor>
          <dependent id="13">Times-Aer</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">prize</governor>
          <dependent id="14">Lingus</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">won</governor>
          <dependent id="15">prize</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">fiction</governor>
          <dependent id="16">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">fiction</governor>
          <dependent id="17">international</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">prize</governor>
          <dependent id="18">fiction</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">work</governor>
          <dependent id="19">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">work</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">work</governor>
          <dependent id="21">same</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">won</governor>
          <dependent id="22">work</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="25">published</governor>
          <dependent id="24">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="25">published</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="27">novels</governor>
          <dependent id="26">five</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">published</governor>
          <dependent id="27">novels</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">1964</governor>
          <dependent id="28">since</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">novels</governor>
          <dependent id="29">1964</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1964" type="DATE" score="0.0">
          <tokens>
            <token id="29" string="1964" />
          </tokens>
        </entity>
        <entity id="2" string="Byatt" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Byatt" />
          </tokens>
        </entity>
        <entity id="3" string="Times-Aer Lingus" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="13" string="Times-Aer" />
            <token id="14" string="Lingus" />
          </tokens>
        </entity>
        <entity id="4" string="earlier this month" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="earlier" />
            <token id="6" string="this" />
            <token id="7" string="month" />
          </tokens>
        </entity>
        <entity id="5" string="Irish" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="12" string="Irish" />
          </tokens>
        </entity>
        <entity id="6" string="five" type="NUMBER" score="0.0">
          <tokens>
            <token id="26" string="five" />
          </tokens>
        </entity>
        <entity id="7" string="$ 43,000" type="MONEY" score="0.0">
          <tokens>
            <token id="10" string="$" />
            <token id="11" string="43,000" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>In ``Possession,&amp;apost;&amp;apost; she tells how two graduate students piece together the relationship and lives of two imaginary Victorian poets from fragments of their letters and by retracing the poets&amp;apost; journeys across England and to France.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Possession" lemma="Possession" stem="possess" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="tells" lemma="tell" stem="tell" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="10" string="graduate" lemma="graduate" stem="graduat" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="students" lemma="student" stem="student" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="piece" lemma="piece" stem="piec" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="together" lemma="together" stem="togeth" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="relationship" lemma="relationship" stem="relationship" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="lives" lemma="life" stem="live" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="20" string="imaginary" lemma="imaginary" stem="imaginari" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="Victorian" lemma="victorian" stem="victorian" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="22" string="poets" lemma="poet" stem="poet" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="fragments" lemma="fragment" stem="fragment" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="letters" lemma="letter" stem="letter" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="retracing" lemma="retrace" stem="retrac" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="poets" lemma="poet" stem="poet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="journeys" lemma="journey" stem="journei" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="across" lemma="across" stem="across" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="England" lemma="England" stem="england" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="37" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="France" lemma="France" stem="franc" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (`` ``) (NP (NNP Possession))) (, ,) ('' '') (NP (PRP she)) (VP (VBZ tells) (SBAR (WHADVP (WRB how)) (S (NP (CD two) (JJ graduate) (NNS students)) (VP (VBP piece) (PRT (RB together)) (NP (NP (DT the) (NN relationship) (CC and) (NNS lives)) (PP (IN of) (NP (CD two) (JJ imaginary) (JJ Victorian) (NNS poets)))) (PP (PP (IN from) (NP (NP (NNS fragments)) (PP (IN of) (NP (PRP$ their) (NNS letters))))) (CC and) (PP (IN by) (S (VP (VBG retracing) (NP (NP (DT the) (NNS poets) (POS ')) (NNS journeys)) (PP (PP (IN across) (NP (NNP England))) (CC and) (PP (TO to) (NP (NNP France)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the relationship and lives" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="relationship" />
            <token id="16" string="and" />
            <token id="17" string="lives" />
          </tokens>
        </chunking>
        <chunking id="2" string="retracing the poets ' journeys across England and to France" type="VP">
          <tokens>
            <token id="30" string="retracing" />
            <token id="31" string="the" />
            <token id="32" string="poets" />
            <token id="33" string="'" />
            <token id="34" string="journeys" />
            <token id="35" string="across" />
            <token id="36" string="England" />
            <token id="37" string="and" />
            <token id="38" string="to" />
            <token id="39" string="France" />
          </tokens>
        </chunking>
        <chunking id="3" string="piece together the relationship and lives of two imaginary Victorian poets from fragments of their letters and by retracing the poets ' journeys across England and to France" type="VP">
          <tokens>
            <token id="12" string="piece" />
            <token id="13" string="together" />
            <token id="14" string="the" />
            <token id="15" string="relationship" />
            <token id="16" string="and" />
            <token id="17" string="lives" />
            <token id="18" string="of" />
            <token id="19" string="two" />
            <token id="20" string="imaginary" />
            <token id="21" string="Victorian" />
            <token id="22" string="poets" />
            <token id="23" string="from" />
            <token id="24" string="fragments" />
            <token id="25" string="of" />
            <token id="26" string="their" />
            <token id="27" string="letters" />
            <token id="28" string="and" />
            <token id="29" string="by" />
            <token id="30" string="retracing" />
            <token id="31" string="the" />
            <token id="32" string="poets" />
            <token id="33" string="'" />
            <token id="34" string="journeys" />
            <token id="35" string="across" />
            <token id="36" string="England" />
            <token id="37" string="and" />
            <token id="38" string="to" />
            <token id="39" string="France" />
          </tokens>
        </chunking>
        <chunking id="4" string="the poets ' journeys" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="poets" />
            <token id="33" string="'" />
            <token id="34" string="journeys" />
          </tokens>
        </chunking>
        <chunking id="5" string="England" type="NP">
          <tokens>
            <token id="36" string="England" />
          </tokens>
        </chunking>
        <chunking id="6" string="two imaginary Victorian poets" type="NP">
          <tokens>
            <token id="19" string="two" />
            <token id="20" string="imaginary" />
            <token id="21" string="Victorian" />
            <token id="22" string="poets" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="6" string="she" />
          </tokens>
        </chunking>
        <chunking id="8" string="how" type="WHADVP">
          <tokens>
            <token id="8" string="how" />
          </tokens>
        </chunking>
        <chunking id="9" string="their letters" type="NP">
          <tokens>
            <token id="26" string="their" />
            <token id="27" string="letters" />
          </tokens>
        </chunking>
        <chunking id="10" string="the relationship and lives of two imaginary Victorian poets" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="relationship" />
            <token id="16" string="and" />
            <token id="17" string="lives" />
            <token id="18" string="of" />
            <token id="19" string="two" />
            <token id="20" string="imaginary" />
            <token id="21" string="Victorian" />
            <token id="22" string="poets" />
          </tokens>
        </chunking>
        <chunking id="11" string="Possession" type="NP">
          <tokens>
            <token id="3" string="Possession" />
          </tokens>
        </chunking>
        <chunking id="12" string="fragments of their letters" type="NP">
          <tokens>
            <token id="24" string="fragments" />
            <token id="25" string="of" />
            <token id="26" string="their" />
            <token id="27" string="letters" />
          </tokens>
        </chunking>
        <chunking id="13" string="the poets '" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="poets" />
            <token id="33" string="'" />
          </tokens>
        </chunking>
        <chunking id="14" string="tells how two graduate students piece together the relationship and lives of two imaginary Victorian poets from fragments of their letters and by retracing the poets ' journeys across England and to France" type="VP">
          <tokens>
            <token id="7" string="tells" />
            <token id="8" string="how" />
            <token id="9" string="two" />
            <token id="10" string="graduate" />
            <token id="11" string="students" />
            <token id="12" string="piece" />
            <token id="13" string="together" />
            <token id="14" string="the" />
            <token id="15" string="relationship" />
            <token id="16" string="and" />
            <token id="17" string="lives" />
            <token id="18" string="of" />
            <token id="19" string="two" />
            <token id="20" string="imaginary" />
            <token id="21" string="Victorian" />
            <token id="22" string="poets" />
            <token id="23" string="from" />
            <token id="24" string="fragments" />
            <token id="25" string="of" />
            <token id="26" string="their" />
            <token id="27" string="letters" />
            <token id="28" string="and" />
            <token id="29" string="by" />
            <token id="30" string="retracing" />
            <token id="31" string="the" />
            <token id="32" string="poets" />
            <token id="33" string="'" />
            <token id="34" string="journeys" />
            <token id="35" string="across" />
            <token id="36" string="England" />
            <token id="37" string="and" />
            <token id="38" string="to" />
            <token id="39" string="France" />
          </tokens>
        </chunking>
        <chunking id="15" string="fragments" type="NP">
          <tokens>
            <token id="24" string="fragments" />
          </tokens>
        </chunking>
        <chunking id="16" string="how two graduate students piece together the relationship and lives of two imaginary Victorian poets from fragments of their letters and by retracing the poets ' journeys across England and to France" type="SBAR">
          <tokens>
            <token id="8" string="how" />
            <token id="9" string="two" />
            <token id="10" string="graduate" />
            <token id="11" string="students" />
            <token id="12" string="piece" />
            <token id="13" string="together" />
            <token id="14" string="the" />
            <token id="15" string="relationship" />
            <token id="16" string="and" />
            <token id="17" string="lives" />
            <token id="18" string="of" />
            <token id="19" string="two" />
            <token id="20" string="imaginary" />
            <token id="21" string="Victorian" />
            <token id="22" string="poets" />
            <token id="23" string="from" />
            <token id="24" string="fragments" />
            <token id="25" string="of" />
            <token id="26" string="their" />
            <token id="27" string="letters" />
            <token id="28" string="and" />
            <token id="29" string="by" />
            <token id="30" string="retracing" />
            <token id="31" string="the" />
            <token id="32" string="poets" />
            <token id="33" string="'" />
            <token id="34" string="journeys" />
            <token id="35" string="across" />
            <token id="36" string="England" />
            <token id="37" string="and" />
            <token id="38" string="to" />
            <token id="39" string="France" />
          </tokens>
        </chunking>
        <chunking id="17" string="two graduate students" type="NP">
          <tokens>
            <token id="9" string="two" />
            <token id="10" string="graduate" />
            <token id="11" string="students" />
          </tokens>
        </chunking>
        <chunking id="18" string="France" type="NP">
          <tokens>
            <token id="39" string="France" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">Possession</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">tells</governor>
          <dependent id="3">Possession</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">tells</governor>
          <dependent id="6">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">tells</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">piece</governor>
          <dependent id="8">how</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">students</governor>
          <dependent id="9">two</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">students</governor>
          <dependent id="10">graduate</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">piece</governor>
          <dependent id="11">students</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">tells</governor>
          <dependent id="12">piece</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="12">piece</governor>
          <dependent id="13">together</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">relationship</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">piece</governor>
          <dependent id="15">relationship</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">relationship</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">relationship</governor>
          <dependent id="17">lives</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">poets</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="22">poets</governor>
          <dependent id="19">two</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">poets</governor>
          <dependent id="20">imaginary</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">poets</governor>
          <dependent id="21">Victorian</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">relationship</governor>
          <dependent id="22">poets</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">fragments</governor>
          <dependent id="23">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">piece</governor>
          <dependent id="24">fragments</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">letters</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="27">letters</governor>
          <dependent id="26">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">fragments</governor>
          <dependent id="27">letters</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">fragments</governor>
          <dependent id="28">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="30">retracing</governor>
          <dependent id="29">by</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">fragments</governor>
          <dependent id="30">retracing</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="30">retracing</governor>
          <dependent id="30">retracing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">poets</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="34">journeys</governor>
          <dependent id="32">poets</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">poets</governor>
          <dependent id="33">'</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">retracing</governor>
          <dependent id="34">journeys</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">England</governor>
          <dependent id="35">across</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">retracing</governor>
          <dependent id="36">England</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="30">retracing</governor>
          <dependent id="37">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">France</governor>
          <dependent id="38">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">retracing</governor>
          <dependent id="39">France</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="England" type="LOCATION" score="0.0">
          <tokens>
            <token id="36" string="England" />
          </tokens>
        </entity>
        <entity id="2" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="two" />
          </tokens>
        </entity>
        <entity id="3" string="Victorian" type="MISC" score="0.0">
          <tokens>
            <token id="21" string="Victorian" />
          </tokens>
        </entity>
        <entity id="4" string="France" type="LOCATION" score="0.0">
          <tokens>
            <token id="39" string="France" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="false">
      <content>The influence of the past on the living is a theme throughout the book.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="influence" lemma="influence" stem="influenc" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="5" string="past" lemma="past" stem="past" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="6" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="living" lemma="living" stem="live" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="theme" lemma="theme" stem="theme" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="throughout" lemma="throughout" stem="throughout" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN influence)) (PP (IN of) (NP (NP (DT the) (NN past)) (PP (IN on) (NP (DT the) (NN living)))))) (VP (VBZ is) (NP (NP (DT a) (NN theme)) (PP (IN throughout) (NP (DT the) (NN book))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the past" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="past" />
          </tokens>
        </chunking>
        <chunking id="2" string="a theme" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="theme" />
          </tokens>
        </chunking>
        <chunking id="3" string="is a theme throughout the book" type="VP">
          <tokens>
            <token id="9" string="is" />
            <token id="10" string="a" />
            <token id="11" string="theme" />
            <token id="12" string="throughout" />
            <token id="13" string="the" />
            <token id="14" string="book" />
          </tokens>
        </chunking>
        <chunking id="4" string="The influence" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="influence" />
          </tokens>
        </chunking>
        <chunking id="5" string="the living" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="living" />
          </tokens>
        </chunking>
        <chunking id="6" string="a theme throughout the book" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="theme" />
            <token id="12" string="throughout" />
            <token id="13" string="the" />
            <token id="14" string="book" />
          </tokens>
        </chunking>
        <chunking id="7" string="the book" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="book" />
          </tokens>
        </chunking>
        <chunking id="8" string="The influence of the past on the living" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="influence" />
            <token id="3" string="of" />
            <token id="4" string="the" />
            <token id="5" string="past" />
            <token id="6" string="on" />
            <token id="7" string="the" />
            <token id="8" string="living" />
          </tokens>
        </chunking>
        <chunking id="9" string="the past on the living" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="past" />
            <token id="6" string="on" />
            <token id="7" string="the" />
            <token id="8" string="living" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">influence</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">theme</governor>
          <dependent id="2">influence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">past</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">past</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">influence</governor>
          <dependent id="5">past</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">living</governor>
          <dependent id="6">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">living</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">past</governor>
          <dependent id="8">living</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">theme</governor>
          <dependent id="9">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">theme</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">theme</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">book</governor>
          <dependent id="12">throughout</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">book</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">theme</governor>
          <dependent id="14">book</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the past" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="past" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Ms. Byatt, born in 1936, is the daughter of a lawyer and sister of novelist Margaret Drabble.</content>
      <tokens>
        <token id="1" string="Ms." lemma="Ms." stem="ms." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="Byatt" lemma="Byatt" stem="byatt" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="born" lemma="bear" stem="born" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="1936" lemma="1936" stem="1936" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="daughter" lemma="daughter" stem="daughter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="lawyer" lemma="lawyer" stem="lawyer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="sister" lemma="sister" stem="sister" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="novelist" lemma="novelist" stem="novelist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="Margaret" lemma="Margaret" stem="margaret" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="Drabble" lemma="Drabble" stem="drabbl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Ms.) (NNP Byatt)) (, ,) (VP (VBN born) (PP (IN in) (NP (CD 1936)))) (, ,)) (VP (VBZ is) (NP (NP (DT the) (NN daughter)) (PP (IN of) (NP (NP (DT a) (NN lawyer) (CC and) (NN sister)) (PP (IN of) (NP (NN novelist) (NNP Margaret) (NNP Drabble))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Ms. Byatt" type="NP">
          <tokens>
            <token id="1" string="Ms." />
            <token id="2" string="Byatt" />
          </tokens>
        </chunking>
        <chunking id="2" string="the daughter" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="daughter" />
          </tokens>
        </chunking>
        <chunking id="3" string="the daughter of a lawyer and sister of novelist Margaret Drabble" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="daughter" />
            <token id="11" string="of" />
            <token id="12" string="a" />
            <token id="13" string="lawyer" />
            <token id="14" string="and" />
            <token id="15" string="sister" />
            <token id="16" string="of" />
            <token id="17" string="novelist" />
            <token id="18" string="Margaret" />
            <token id="19" string="Drabble" />
          </tokens>
        </chunking>
        <chunking id="4" string="novelist Margaret Drabble" type="NP">
          <tokens>
            <token id="17" string="novelist" />
            <token id="18" string="Margaret" />
            <token id="19" string="Drabble" />
          </tokens>
        </chunking>
        <chunking id="5" string="born in 1936" type="VP">
          <tokens>
            <token id="4" string="born" />
            <token id="5" string="in" />
            <token id="6" string="1936" />
          </tokens>
        </chunking>
        <chunking id="6" string="Ms. Byatt , born in 1936 ," type="NP">
          <tokens>
            <token id="1" string="Ms." />
            <token id="2" string="Byatt" />
            <token id="3" string="," />
            <token id="4" string="born" />
            <token id="5" string="in" />
            <token id="6" string="1936" />
            <token id="7" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="a lawyer and sister of novelist Margaret Drabble" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="lawyer" />
            <token id="14" string="and" />
            <token id="15" string="sister" />
            <token id="16" string="of" />
            <token id="17" string="novelist" />
            <token id="18" string="Margaret" />
            <token id="19" string="Drabble" />
          </tokens>
        </chunking>
        <chunking id="8" string="a lawyer and sister" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="lawyer" />
            <token id="14" string="and" />
            <token id="15" string="sister" />
          </tokens>
        </chunking>
        <chunking id="9" string="is the daughter of a lawyer and sister of novelist Margaret Drabble" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="the" />
            <token id="10" string="daughter" />
            <token id="11" string="of" />
            <token id="12" string="a" />
            <token id="13" string="lawyer" />
            <token id="14" string="and" />
            <token id="15" string="sister" />
            <token id="16" string="of" />
            <token id="17" string="novelist" />
            <token id="18" string="Margaret" />
            <token id="19" string="Drabble" />
          </tokens>
        </chunking>
        <chunking id="10" string="1936" type="NP">
          <tokens>
            <token id="6" string="1936" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Byatt</governor>
          <dependent id="1">Ms.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">daughter</governor>
          <dependent id="2">Byatt</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="2">Byatt</governor>
          <dependent id="4">born</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">1936</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">born</governor>
          <dependent id="6">1936</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">daughter</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">daughter</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">daughter</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">lawyer</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">lawyer</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">daughter</governor>
          <dependent id="13">lawyer</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">lawyer</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">lawyer</governor>
          <dependent id="15">sister</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Drabble</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Drabble</governor>
          <dependent id="17">novelist</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Drabble</governor>
          <dependent id="18">Margaret</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">lawyer</governor>
          <dependent id="19">Drabble</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Byatt" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Byatt" />
          </tokens>
        </entity>
        <entity id="2" string="Margaret Drabble" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Margaret" />
            <token id="19" string="Drabble" />
          </tokens>
        </entity>
        <entity id="3" string="1936" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="1936" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>Her first novel, ``Shadow of a Sun,&amp;apost;&amp;apost; concerned the efforts of a woman to escape the shadow of her novelist father.</content>
      <tokens>
        <token id="1" string="Her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="3" string="novel" lemma="novel" stem="novel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Shadow" lemma="Shadow" stem="shadow" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="Sun" lemma="Sun" stem="sun" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="concerned" lemma="concern" stem="concern" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="efforts" lemma="effort" stem="effort" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="woman" lemma="woman" stem="woman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="escape" lemma="escape" stem="escap" pos="VB" type="Word" isStopWord="false" ner="CRIMINAL_CHARGE" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="shadow" lemma="shadow" stem="shadow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="novelist" lemma="novelist" stem="novelist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="father" lemma="father" stem="father" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (PRP$ Her) (JJ first) (NN novel)) (, ,) (`` ``) (NP (NP (NNP Shadow)) (PP (IN of) (NP (DT a) (NNP Sun)))) (, ,) ('' '')) (VP (VBD concerned) (NP (NP (DT the) (NNS efforts)) (PP (IN of) (NP (DT a) (NN woman) (S (VP (TO to) (VP (VB escape) (NP (NP (DT the) (NN shadow)) (PP (IN of) (NP (PRP$ her) (NN novelist) (NN father))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Shadow of a Sun" type="NP">
          <tokens>
            <token id="6" string="Shadow" />
            <token id="7" string="of" />
            <token id="8" string="a" />
            <token id="9" string="Sun" />
          </tokens>
        </chunking>
        <chunking id="2" string="the efforts" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="efforts" />
          </tokens>
        </chunking>
        <chunking id="3" string="the efforts of a woman to escape the shadow of her novelist father" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="efforts" />
            <token id="15" string="of" />
            <token id="16" string="a" />
            <token id="17" string="woman" />
            <token id="18" string="to" />
            <token id="19" string="escape" />
            <token id="20" string="the" />
            <token id="21" string="shadow" />
            <token id="22" string="of" />
            <token id="23" string="her" />
            <token id="24" string="novelist" />
            <token id="25" string="father" />
          </tokens>
        </chunking>
        <chunking id="4" string="a Sun" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="Sun" />
          </tokens>
        </chunking>
        <chunking id="5" string="a woman to escape the shadow of her novelist father" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="woman" />
            <token id="18" string="to" />
            <token id="19" string="escape" />
            <token id="20" string="the" />
            <token id="21" string="shadow" />
            <token id="22" string="of" />
            <token id="23" string="her" />
            <token id="24" string="novelist" />
            <token id="25" string="father" />
          </tokens>
        </chunking>
        <chunking id="6" string="concerned the efforts of a woman to escape the shadow of her novelist father" type="VP">
          <tokens>
            <token id="12" string="concerned" />
            <token id="13" string="the" />
            <token id="14" string="efforts" />
            <token id="15" string="of" />
            <token id="16" string="a" />
            <token id="17" string="woman" />
            <token id="18" string="to" />
            <token id="19" string="escape" />
            <token id="20" string="the" />
            <token id="21" string="shadow" />
            <token id="22" string="of" />
            <token id="23" string="her" />
            <token id="24" string="novelist" />
            <token id="25" string="father" />
          </tokens>
        </chunking>
        <chunking id="7" string="Her first novel" type="NP">
          <tokens>
            <token id="1" string="Her" />
            <token id="2" string="first" />
            <token id="3" string="novel" />
          </tokens>
        </chunking>
        <chunking id="8" string="her novelist father" type="NP">
          <tokens>
            <token id="23" string="her" />
            <token id="24" string="novelist" />
            <token id="25" string="father" />
          </tokens>
        </chunking>
        <chunking id="9" string="Shadow" type="NP">
          <tokens>
            <token id="6" string="Shadow" />
          </tokens>
        </chunking>
        <chunking id="10" string="escape the shadow of her novelist father" type="VP">
          <tokens>
            <token id="19" string="escape" />
            <token id="20" string="the" />
            <token id="21" string="shadow" />
            <token id="22" string="of" />
            <token id="23" string="her" />
            <token id="24" string="novelist" />
            <token id="25" string="father" />
          </tokens>
        </chunking>
        <chunking id="11" string="the shadow" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="shadow" />
          </tokens>
        </chunking>
        <chunking id="12" string="the shadow of her novelist father" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="shadow" />
            <token id="22" string="of" />
            <token id="23" string="her" />
            <token id="24" string="novelist" />
            <token id="25" string="father" />
          </tokens>
        </chunking>
        <chunking id="13" string="Her first novel , `` Shadow of a Sun , ''" type="NP">
          <tokens>
            <token id="1" string="Her" />
            <token id="2" string="first" />
            <token id="3" string="novel" />
            <token id="4" string="," />
            <token id="5" string="``" />
            <token id="6" string="Shadow" />
            <token id="7" string="of" />
            <token id="8" string="a" />
            <token id="9" string="Sun" />
            <token id="10" string="," />
            <token id="11" string="''" />
          </tokens>
        </chunking>
        <chunking id="14" string="to escape the shadow of her novelist father" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="escape" />
            <token id="20" string="the" />
            <token id="21" string="shadow" />
            <token id="22" string="of" />
            <token id="23" string="her" />
            <token id="24" string="novelist" />
            <token id="25" string="father" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">novel</governor>
          <dependent id="1">Her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">novel</governor>
          <dependent id="2">first</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">concerned</governor>
          <dependent id="3">novel</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">novel</governor>
          <dependent id="6">Shadow</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Sun</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Sun</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">Shadow</governor>
          <dependent id="9">Sun</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">concerned</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">efforts</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">concerned</governor>
          <dependent id="14">efforts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">woman</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">woman</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">efforts</governor>
          <dependent id="17">woman</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">escape</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="17">woman</governor>
          <dependent id="19">escape</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">shadow</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">escape</governor>
          <dependent id="21">shadow</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">father</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="25">father</governor>
          <dependent id="23">her</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">father</governor>
          <dependent id="24">novelist</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">shadow</governor>
          <dependent id="25">father</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="2" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="escape" type="CRIMINAL_CHARGE" score="0.0">
          <tokens>
            <token id="19" string="escape" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="false">
      <content>A 1978 work, ``The Virgin in the Garden,&amp;apost;&amp;apost; makes allegorical allusions to Shakespeare and other English literary geniuses in a tale of a play performed at a country house.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="1978" lemma="1978" stem="1978" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="work" lemma="work" stem="work" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Virgin" lemma="virgin" stem="virgin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Garden" lemma="Garden" stem="garden" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="makes" lemma="make" stem="make" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="allegorical" lemma="allegorical" stem="allegor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="allusions" lemma="allusion" stem="allus" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Shakespeare" lemma="Shakespeare" stem="shakespear" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="English" lemma="english" stem="english" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="21" string="literary" lemma="literary" stem="literari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="geniuses" lemma="genius" stem="genius" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="tale" lemma="tale" stem="tale" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="play" lemma="play" stem="plai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="performed" lemma="perform" stem="perform" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="country" lemma="country" stem="countri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="house" lemma="house" stem="hous" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT A) (CD 1978) (NN work)) (, ,) (`` ``) (NP (NP (DT The) (NN Virgin)) (PP (IN in) (NP (DT the) (NNP Garden)))) (, ,) ('' '')) (VP (VBZ makes) (NP (JJ allegorical) (NNS allusions)) (PP (TO to) (NP (NP (NNP Shakespeare)) (CC and) (NP (NP (JJ other) (JJ English) (JJ literary) (NNS geniuses)) (PP (IN in) (NP (NP (DT a) (NN tale)) (PP (IN of) (NP (NP (DT a) (NN play)) (VP (VBN performed) (PP (IN at) (NP (DT a) (NN country) (NN house)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="other English literary geniuses" type="NP">
          <tokens>
            <token id="19" string="other" />
            <token id="20" string="English" />
            <token id="21" string="literary" />
            <token id="22" string="geniuses" />
          </tokens>
        </chunking>
        <chunking id="2" string="A 1978 work , `` The Virgin in the Garden , ''" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="1978" />
            <token id="3" string="work" />
            <token id="4" string="," />
            <token id="5" string="``" />
            <token id="6" string="The" />
            <token id="7" string="Virgin" />
            <token id="8" string="in" />
            <token id="9" string="the" />
            <token id="10" string="Garden" />
            <token id="11" string="," />
            <token id="12" string="''" />
          </tokens>
        </chunking>
        <chunking id="3" string="The Virgin in the Garden" type="NP">
          <tokens>
            <token id="6" string="The" />
            <token id="7" string="Virgin" />
            <token id="8" string="in" />
            <token id="9" string="the" />
            <token id="10" string="Garden" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Garden" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="Garden" />
          </tokens>
        </chunking>
        <chunking id="5" string="Shakespeare" type="NP">
          <tokens>
            <token id="17" string="Shakespeare" />
          </tokens>
        </chunking>
        <chunking id="6" string="makes allegorical allusions to Shakespeare and other English literary geniuses in a tale of a play performed at a country house" type="VP">
          <tokens>
            <token id="13" string="makes" />
            <token id="14" string="allegorical" />
            <token id="15" string="allusions" />
            <token id="16" string="to" />
            <token id="17" string="Shakespeare" />
            <token id="18" string="and" />
            <token id="19" string="other" />
            <token id="20" string="English" />
            <token id="21" string="literary" />
            <token id="22" string="geniuses" />
            <token id="23" string="in" />
            <token id="24" string="a" />
            <token id="25" string="tale" />
            <token id="26" string="of" />
            <token id="27" string="a" />
            <token id="28" string="play" />
            <token id="29" string="performed" />
            <token id="30" string="at" />
            <token id="31" string="a" />
            <token id="32" string="country" />
            <token id="33" string="house" />
          </tokens>
        </chunking>
        <chunking id="7" string="a play" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="play" />
          </tokens>
        </chunking>
        <chunking id="8" string="performed at a country house" type="VP">
          <tokens>
            <token id="29" string="performed" />
            <token id="30" string="at" />
            <token id="31" string="a" />
            <token id="32" string="country" />
            <token id="33" string="house" />
          </tokens>
        </chunking>
        <chunking id="9" string="other English literary geniuses in a tale of a play performed at a country house" type="NP">
          <tokens>
            <token id="19" string="other" />
            <token id="20" string="English" />
            <token id="21" string="literary" />
            <token id="22" string="geniuses" />
            <token id="23" string="in" />
            <token id="24" string="a" />
            <token id="25" string="tale" />
            <token id="26" string="of" />
            <token id="27" string="a" />
            <token id="28" string="play" />
            <token id="29" string="performed" />
            <token id="30" string="at" />
            <token id="31" string="a" />
            <token id="32" string="country" />
            <token id="33" string="house" />
          </tokens>
        </chunking>
        <chunking id="10" string="a tale of a play performed at a country house" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="tale" />
            <token id="26" string="of" />
            <token id="27" string="a" />
            <token id="28" string="play" />
            <token id="29" string="performed" />
            <token id="30" string="at" />
            <token id="31" string="a" />
            <token id="32" string="country" />
            <token id="33" string="house" />
          </tokens>
        </chunking>
        <chunking id="11" string="a country house" type="NP">
          <tokens>
            <token id="31" string="a" />
            <token id="32" string="country" />
            <token id="33" string="house" />
          </tokens>
        </chunking>
        <chunking id="12" string="A 1978 work" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="1978" />
            <token id="3" string="work" />
          </tokens>
        </chunking>
        <chunking id="13" string="The Virgin" type="NP">
          <tokens>
            <token id="6" string="The" />
            <token id="7" string="Virgin" />
          </tokens>
        </chunking>
        <chunking id="14" string="Shakespeare and other English literary geniuses in a tale of a play performed at a country house" type="NP">
          <tokens>
            <token id="17" string="Shakespeare" />
            <token id="18" string="and" />
            <token id="19" string="other" />
            <token id="20" string="English" />
            <token id="21" string="literary" />
            <token id="22" string="geniuses" />
            <token id="23" string="in" />
            <token id="24" string="a" />
            <token id="25" string="tale" />
            <token id="26" string="of" />
            <token id="27" string="a" />
            <token id="28" string="play" />
            <token id="29" string="performed" />
            <token id="30" string="at" />
            <token id="31" string="a" />
            <token id="32" string="country" />
            <token id="33" string="house" />
          </tokens>
        </chunking>
        <chunking id="15" string="allegorical allusions" type="NP">
          <tokens>
            <token id="14" string="allegorical" />
            <token id="15" string="allusions" />
          </tokens>
        </chunking>
        <chunking id="16" string="a tale" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="tale" />
          </tokens>
        </chunking>
        <chunking id="17" string="a play performed at a country house" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="play" />
            <token id="29" string="performed" />
            <token id="30" string="at" />
            <token id="31" string="a" />
            <token id="32" string="country" />
            <token id="33" string="house" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">work</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="3">work</governor>
          <dependent id="2">1978</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">makes</governor>
          <dependent id="3">work</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">Virgin</governor>
          <dependent id="6">The</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">work</governor>
          <dependent id="7">Virgin</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Garden</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">Garden</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">Virgin</governor>
          <dependent id="10">Garden</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">makes</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">allusions</governor>
          <dependent id="14">allegorical</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">makes</governor>
          <dependent id="15">allusions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Shakespeare</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">makes</governor>
          <dependent id="17">Shakespeare</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">Shakespeare</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">geniuses</governor>
          <dependent id="19">other</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">geniuses</governor>
          <dependent id="20">English</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">geniuses</governor>
          <dependent id="21">literary</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">Shakespeare</governor>
          <dependent id="22">geniuses</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">tale</governor>
          <dependent id="23">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">tale</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">geniuses</governor>
          <dependent id="25">tale</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">play</governor>
          <dependent id="26">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">play</governor>
          <dependent id="27">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">tale</governor>
          <dependent id="28">play</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="28">play</governor>
          <dependent id="29">performed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">house</governor>
          <dependent id="30">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">house</governor>
          <dependent id="31">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">house</governor>
          <dependent id="32">country</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">performed</governor>
          <dependent id="33">house</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Garden" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="Garden" />
          </tokens>
        </entity>
        <entity id="2" string="Shakespeare" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Shakespeare" />
          </tokens>
        </entity>
        <entity id="3" string="English" type="MISC" score="0.0">
          <tokens>
            <token id="20" string="English" />
          </tokens>
        </entity>
        <entity id="4" string="1978" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="1978" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>Ms. Byatt taught English and American literature at University College in London until 1983, when she quit to write fulltime.</content>
      <tokens>
        <token id="1" string="Ms." lemma="Ms." stem="ms." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="Byatt" lemma="Byatt" stem="byatt" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="taught" lemma="teach" stem="taught" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="English" lemma="English" stem="english" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="American" lemma="American" stem="american" pos="NNP" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="7" string="literature" lemma="literature" stem="literatur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="University" lemma="University" stem="univers" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="10" string="College" lemma="College" stem="colleg" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="London" lemma="London" stem="london" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="13" string="until" lemma="until" stem="until" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="1983" lemma="1983" stem="1983" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="quit" lemma="quit" stem="quit" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="write" lemma="write" stem="write" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="fulltime" lemma="fulltime" stem="fulltim" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Ms.) (NNP Byatt)) (VP (VBD taught) (NP (NNP English) (CC and) (NNP American) (NN literature)) (PP (IN at) (NP (NP (NNP University) (NNP College)) (PP (IN in) (NP (NNP London))))) (PP (IN until) (NP (CD 1983))) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (PRP she)) (VP (VBD quit) (S (VP (TO to) (VP (VB write) (ADJP (JJ fulltime))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Ms. Byatt" type="NP">
          <tokens>
            <token id="1" string="Ms." />
            <token id="2" string="Byatt" />
          </tokens>
        </chunking>
        <chunking id="2" string="to write fulltime" type="VP">
          <tokens>
            <token id="19" string="to" />
            <token id="20" string="write" />
            <token id="21" string="fulltime" />
          </tokens>
        </chunking>
        <chunking id="3" string="when she quit to write fulltime" type="SBAR">
          <tokens>
            <token id="16" string="when" />
            <token id="17" string="she" />
            <token id="18" string="quit" />
            <token id="19" string="to" />
            <token id="20" string="write" />
            <token id="21" string="fulltime" />
          </tokens>
        </chunking>
        <chunking id="4" string="write fulltime" type="VP">
          <tokens>
            <token id="20" string="write" />
            <token id="21" string="fulltime" />
          </tokens>
        </chunking>
        <chunking id="5" string="English and American literature" type="NP">
          <tokens>
            <token id="4" string="English" />
            <token id="5" string="and" />
            <token id="6" string="American" />
            <token id="7" string="literature" />
          </tokens>
        </chunking>
        <chunking id="6" string="University College" type="NP">
          <tokens>
            <token id="9" string="University" />
            <token id="10" string="College" />
          </tokens>
        </chunking>
        <chunking id="7" string="when" type="WHADVP">
          <tokens>
            <token id="16" string="when" />
          </tokens>
        </chunking>
        <chunking id="8" string="she" type="NP">
          <tokens>
            <token id="17" string="she" />
          </tokens>
        </chunking>
        <chunking id="9" string="quit to write fulltime" type="VP">
          <tokens>
            <token id="18" string="quit" />
            <token id="19" string="to" />
            <token id="20" string="write" />
            <token id="21" string="fulltime" />
          </tokens>
        </chunking>
        <chunking id="10" string="taught English and American literature at University College in London until 1983 , when she quit to write fulltime" type="VP">
          <tokens>
            <token id="3" string="taught" />
            <token id="4" string="English" />
            <token id="5" string="and" />
            <token id="6" string="American" />
            <token id="7" string="literature" />
            <token id="8" string="at" />
            <token id="9" string="University" />
            <token id="10" string="College" />
            <token id="11" string="in" />
            <token id="12" string="London" />
            <token id="13" string="until" />
            <token id="14" string="1983" />
            <token id="15" string="," />
            <token id="16" string="when" />
            <token id="17" string="she" />
            <token id="18" string="quit" />
            <token id="19" string="to" />
            <token id="20" string="write" />
            <token id="21" string="fulltime" />
          </tokens>
        </chunking>
        <chunking id="11" string="University College in London" type="NP">
          <tokens>
            <token id="9" string="University" />
            <token id="10" string="College" />
            <token id="11" string="in" />
            <token id="12" string="London" />
          </tokens>
        </chunking>
        <chunking id="12" string="1983" type="NP">
          <tokens>
            <token id="14" string="1983" />
          </tokens>
        </chunking>
        <chunking id="13" string="London" type="NP">
          <tokens>
            <token id="12" string="London" />
          </tokens>
        </chunking>
        <chunking id="14" string="fulltime" type="ADJP">
          <tokens>
            <token id="21" string="fulltime" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Byatt</governor>
          <dependent id="1">Ms.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">taught</governor>
          <dependent id="2">Byatt</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">taught</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">literature</governor>
          <dependent id="4">English</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">English</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">English</governor>
          <dependent id="6">American</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">taught</governor>
          <dependent id="7">literature</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">College</governor>
          <dependent id="8">at</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">College</governor>
          <dependent id="9">University</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">taught</governor>
          <dependent id="10">College</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">London</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">College</governor>
          <dependent id="12">London</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">1983</governor>
          <dependent id="13">until</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">taught</governor>
          <dependent id="14">1983</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">quit</governor>
          <dependent id="16">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">quit</governor>
          <dependent id="17">she</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">taught</governor>
          <dependent id="18">quit</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">write</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">quit</governor>
          <dependent id="20">write</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="20">write</governor>
          <dependent id="21">fulltime</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Byatt" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Byatt" />
          </tokens>
        </entity>
        <entity id="2" string="1983" type="DATE" score="0.0">
          <tokens>
            <token id="14" string="1983" />
          </tokens>
        </entity>
        <entity id="3" string="London" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="London" />
          </tokens>
        </entity>
        <entity id="4" string="University College" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="9" string="University" />
            <token id="10" string="College" />
          </tokens>
        </entity>
        <entity id="5" string="American" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="6" string="American" />
          </tokens>
        </entity>
        <entity id="6" string="English" type="MISC" score="0.0">
          <tokens>
            <token id="4" string="English" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>Other finalists this year were 1979 Booker Prize winner Penelope Fitzgerald with ``The Gate of Angels,&amp;apost;&amp;apost; Irish novelist John McGahern&amp;apost;s ``Amongst Women,&amp;apost;&amp;apost; Canadian-born Mordecai Richler&amp;apost;s ``Solomon Gursky Was Here,&amp;apost;&amp;apost; Brian Moore&amp;apost;s ``Lies of Silence,&amp;apost;&amp;apost; and Beryl Bainbridge&amp;apost;s ``An Awfully Big Adventure.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="Other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="finalists" lemma="finalist" stem="finalist" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="true" />
        <token id="4" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="true" />
        <token id="5" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="1979" lemma="1979" stem="1979" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="8" string="Prize" lemma="Prize" stem="prize" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="9" string="winner" lemma="winner" stem="winner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Penelope" lemma="Penelope" stem="penelop" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="Fitzgerald" lemma="Fitzgerald" stem="fitzgerald" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Gate" lemma="gate" stem="gate" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Angels" lemma="Angels" stem="angel" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Irish" lemma="irish" stem="irish" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="21" string="novelist" lemma="novelist" stem="novelist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="23" string="McGahern" lemma="McGahern" stem="mcgahern" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="24" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Amongst" lemma="Amongst" stem="amongst" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="Women" lemma="Women" stem="women" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="Canadian-born" lemma="Canadian-born" stem="canadian-born" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="Mordecai" lemma="Mordecai" stem="mordecai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="32" string="Richler" lemma="Richler" stem="richler" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="33" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="Solomon" lemma="Solomon" stem="solomon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="36" string="Gursky" lemma="Gursky" stem="gurski" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="37" string="Was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="Here" lemma="here" stem="here" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="Brian" lemma="Brian" stem="brian" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="42" string="Moore" lemma="Moore" stem="moor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="43" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="44" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="45" string="Lies" lemma="lie" stem="li" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="46" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="47" string="Silence" lemma="silence" stem="silenc" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="48" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="49" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="50" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="51" string="Beryl" lemma="Beryl" stem="beryl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="52" string="Bainbridge" lemma="Bainbridge" stem="bainbridg" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="53" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="54" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="55" string="An" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="56" string="Awfully" lemma="awfully" stem="awfulli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="57" string="Big" lemma="big" stem="big" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="58" string="Adventure" lemma="adventure" stem="adventur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="59" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="60" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (JJ Other) (NNS finalists)) (NP-TMP (DT this) (NN year))) (VP (VBD were) (NP (NP (CD 1979)) (SBAR (S (NP (NP (NNP Booker) (NNP Prize) (NN winner) (NNP Penelope) (NNP Fitzgerald)) (PP (IN with) (NP (`` ``) (VP (NP (DT The) (NN Gate)) (PP (IN of) (NP (NP (NNPS Angels)) (, ,) ('' '') (NP (NP (JJ Irish) (NN novelist) (NNP John) (NNP McGahern) (POS 's)) (`` ``) (NNP Amongst) (NNP Women))))) (, ,) ('' '') (NP (NP (NNP Canadian-born) (NNP Mordecai) (NNP Richler) (POS 's)) (`` ``) (NNP Solomon) (NNP Gursky))))) (VP (VBD Was) (NP (NP (RB Here)) (, ,) ('' '') (NP (NP (NP (NNP Brian) (NNP Moore) (POS 's)) (NX (`` ``) (NP (NNS Lies)) (PP (IN of) (NP (NN Silence))) (, ,) ('' ''))) (CC and) (NP (NP (NNP Beryl) (NNP Bainbridge) (POS 's)) (ADJP (NP (NP (`` ``) (DT An)) (ADVP (RB Awfully))) (JJ Big)) (NN Adventure))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Canadian-born Mordecai Richler 's" type="NP">
          <tokens>
            <token id="30" string="Canadian-born" />
            <token id="31" string="Mordecai" />
            <token id="32" string="Richler" />
            <token id="33" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="Here , '' Brian Moore 's `` Lies of Silence , '' and Beryl Bainbridge 's `` An Awfully Big Adventure" type="NP">
          <tokens>
            <token id="38" string="Here" />
            <token id="39" string="," />
            <token id="40" string="''" />
            <token id="41" string="Brian" />
            <token id="42" string="Moore" />
            <token id="43" string="'s" />
            <token id="44" string="``" />
            <token id="45" string="Lies" />
            <token id="46" string="of" />
            <token id="47" string="Silence" />
            <token id="48" string="," />
            <token id="49" string="''" />
            <token id="50" string="and" />
            <token id="51" string="Beryl" />
            <token id="52" string="Bainbridge" />
            <token id="53" string="'s" />
            <token id="54" string="``" />
            <token id="55" string="An" />
            <token id="56" string="Awfully" />
            <token id="57" string="Big" />
            <token id="58" string="Adventure" />
          </tokens>
        </chunking>
        <chunking id="3" string="Angels , '' Irish novelist John McGahern 's `` Amongst Women" type="NP">
          <tokens>
            <token id="17" string="Angels" />
            <token id="18" string="," />
            <token id="19" string="''" />
            <token id="20" string="Irish" />
            <token id="21" string="novelist" />
            <token id="22" string="John" />
            <token id="23" string="McGahern" />
            <token id="24" string="'s" />
            <token id="25" string="``" />
            <token id="26" string="Amongst" />
            <token id="27" string="Women" />
          </tokens>
        </chunking>
        <chunking id="4" string="`` An Awfully" type="NP">
          <tokens>
            <token id="54" string="``" />
            <token id="55" string="An" />
            <token id="56" string="Awfully" />
          </tokens>
        </chunking>
        <chunking id="5" string="`` The Gate of Angels , '' Irish novelist John McGahern 's `` Amongst Women , '' Canadian-born Mordecai Richler 's `` Solomon Gursky" type="NP">
          <tokens>
            <token id="13" string="``" />
            <token id="14" string="The" />
            <token id="15" string="Gate" />
            <token id="16" string="of" />
            <token id="17" string="Angels" />
            <token id="18" string="," />
            <token id="19" string="''" />
            <token id="20" string="Irish" />
            <token id="21" string="novelist" />
            <token id="22" string="John" />
            <token id="23" string="McGahern" />
            <token id="24" string="'s" />
            <token id="25" string="``" />
            <token id="26" string="Amongst" />
            <token id="27" string="Women" />
            <token id="28" string="," />
            <token id="29" string="''" />
            <token id="30" string="Canadian-born" />
            <token id="31" string="Mordecai" />
            <token id="32" string="Richler" />
            <token id="33" string="'s" />
            <token id="34" string="``" />
            <token id="35" string="Solomon" />
            <token id="36" string="Gursky" />
          </tokens>
        </chunking>
        <chunking id="6" string="Was Here , '' Brian Moore 's `` Lies of Silence , '' and Beryl Bainbridge 's `` An Awfully Big Adventure" type="VP">
          <tokens>
            <token id="37" string="Was" />
            <token id="38" string="Here" />
            <token id="39" string="," />
            <token id="40" string="''" />
            <token id="41" string="Brian" />
            <token id="42" string="Moore" />
            <token id="43" string="'s" />
            <token id="44" string="``" />
            <token id="45" string="Lies" />
            <token id="46" string="of" />
            <token id="47" string="Silence" />
            <token id="48" string="," />
            <token id="49" string="''" />
            <token id="50" string="and" />
            <token id="51" string="Beryl" />
            <token id="52" string="Bainbridge" />
            <token id="53" string="'s" />
            <token id="54" string="``" />
            <token id="55" string="An" />
            <token id="56" string="Awfully" />
            <token id="57" string="Big" />
            <token id="58" string="Adventure" />
          </tokens>
        </chunking>
        <chunking id="7" string="Other finalists" type="NP">
          <tokens>
            <token id="1" string="Other" />
            <token id="2" string="finalists" />
          </tokens>
        </chunking>
        <chunking id="8" string="Here" type="NP">
          <tokens>
            <token id="38" string="Here" />
          </tokens>
        </chunking>
        <chunking id="9" string="`` An Awfully Big" type="ADJP">
          <tokens>
            <token id="54" string="``" />
            <token id="55" string="An" />
            <token id="56" string="Awfully" />
            <token id="57" string="Big" />
          </tokens>
        </chunking>
        <chunking id="10" string="Lies" type="NP">
          <tokens>
            <token id="45" string="Lies" />
          </tokens>
        </chunking>
        <chunking id="11" string="were 1979 Booker Prize winner Penelope Fitzgerald with `` The Gate of Angels , '' Irish novelist John McGahern 's `` Amongst Women , '' Canadian-born Mordecai Richler 's `` Solomon Gursky Was Here , '' Brian Moore 's `` Lies of Silence , '' and Beryl Bainbridge 's `` An Awfully Big Adventure" type="VP">
          <tokens>
            <token id="5" string="were" />
            <token id="6" string="1979" />
            <token id="7" string="Booker" />
            <token id="8" string="Prize" />
            <token id="9" string="winner" />
            <token id="10" string="Penelope" />
            <token id="11" string="Fitzgerald" />
            <token id="12" string="with" />
            <token id="13" string="``" />
            <token id="14" string="The" />
            <token id="15" string="Gate" />
            <token id="16" string="of" />
            <token id="17" string="Angels" />
            <token id="18" string="," />
            <token id="19" string="''" />
            <token id="20" string="Irish" />
            <token id="21" string="novelist" />
            <token id="22" string="John" />
            <token id="23" string="McGahern" />
            <token id="24" string="'s" />
            <token id="25" string="``" />
            <token id="26" string="Amongst" />
            <token id="27" string="Women" />
            <token id="28" string="," />
            <token id="29" string="''" />
            <token id="30" string="Canadian-born" />
            <token id="31" string="Mordecai" />
            <token id="32" string="Richler" />
            <token id="33" string="'s" />
            <token id="34" string="``" />
            <token id="35" string="Solomon" />
            <token id="36" string="Gursky" />
            <token id="37" string="Was" />
            <token id="38" string="Here" />
            <token id="39" string="," />
            <token id="40" string="''" />
            <token id="41" string="Brian" />
            <token id="42" string="Moore" />
            <token id="43" string="'s" />
            <token id="44" string="``" />
            <token id="45" string="Lies" />
            <token id="46" string="of" />
            <token id="47" string="Silence" />
            <token id="48" string="," />
            <token id="49" string="''" />
            <token id="50" string="and" />
            <token id="51" string="Beryl" />
            <token id="52" string="Bainbridge" />
            <token id="53" string="'s" />
            <token id="54" string="``" />
            <token id="55" string="An" />
            <token id="56" string="Awfully" />
            <token id="57" string="Big" />
            <token id="58" string="Adventure" />
          </tokens>
        </chunking>
        <chunking id="12" string="The Gate" type="NP">
          <tokens>
            <token id="14" string="The" />
            <token id="15" string="Gate" />
          </tokens>
        </chunking>
        <chunking id="13" string="Brian Moore 's" type="NP">
          <tokens>
            <token id="41" string="Brian" />
            <token id="42" string="Moore" />
            <token id="43" string="'s" />
          </tokens>
        </chunking>
        <chunking id="14" string="Booker Prize winner Penelope Fitzgerald with `` The Gate of Angels , '' Irish novelist John McGahern 's `` Amongst Women , '' Canadian-born Mordecai Richler 's `` Solomon Gursky Was Here , '' Brian Moore 's `` Lies of Silence , '' and Beryl Bainbridge 's `` An Awfully Big Adventure" type="SBAR">
          <tokens>
            <token id="7" string="Booker" />
            <token id="8" string="Prize" />
            <token id="9" string="winner" />
            <token id="10" string="Penelope" />
            <token id="11" string="Fitzgerald" />
            <token id="12" string="with" />
            <token id="13" string="``" />
            <token id="14" string="The" />
            <token id="15" string="Gate" />
            <token id="16" string="of" />
            <token id="17" string="Angels" />
            <token id="18" string="," />
            <token id="19" string="''" />
            <token id="20" string="Irish" />
            <token id="21" string="novelist" />
            <token id="22" string="John" />
            <token id="23" string="McGahern" />
            <token id="24" string="'s" />
            <token id="25" string="``" />
            <token id="26" string="Amongst" />
            <token id="27" string="Women" />
            <token id="28" string="," />
            <token id="29" string="''" />
            <token id="30" string="Canadian-born" />
            <token id="31" string="Mordecai" />
            <token id="32" string="Richler" />
            <token id="33" string="'s" />
            <token id="34" string="``" />
            <token id="35" string="Solomon" />
            <token id="36" string="Gursky" />
            <token id="37" string="Was" />
            <token id="38" string="Here" />
            <token id="39" string="," />
            <token id="40" string="''" />
            <token id="41" string="Brian" />
            <token id="42" string="Moore" />
            <token id="43" string="'s" />
            <token id="44" string="``" />
            <token id="45" string="Lies" />
            <token id="46" string="of" />
            <token id="47" string="Silence" />
            <token id="48" string="," />
            <token id="49" string="''" />
            <token id="50" string="and" />
            <token id="51" string="Beryl" />
            <token id="52" string="Bainbridge" />
            <token id="53" string="'s" />
            <token id="54" string="``" />
            <token id="55" string="An" />
            <token id="56" string="Awfully" />
            <token id="57" string="Big" />
            <token id="58" string="Adventure" />
          </tokens>
        </chunking>
        <chunking id="15" string="Silence" type="NP">
          <tokens>
            <token id="47" string="Silence" />
          </tokens>
        </chunking>
        <chunking id="16" string="Irish novelist John McGahern 's" type="NP">
          <tokens>
            <token id="20" string="Irish" />
            <token id="21" string="novelist" />
            <token id="22" string="John" />
            <token id="23" string="McGahern" />
            <token id="24" string="'s" />
          </tokens>
        </chunking>
        <chunking id="17" string="Beryl Bainbridge 's" type="NP">
          <tokens>
            <token id="51" string="Beryl" />
            <token id="52" string="Bainbridge" />
            <token id="53" string="'s" />
          </tokens>
        </chunking>
        <chunking id="18" string="Beryl Bainbridge 's `` An Awfully Big Adventure" type="NP">
          <tokens>
            <token id="51" string="Beryl" />
            <token id="52" string="Bainbridge" />
            <token id="53" string="'s" />
            <token id="54" string="``" />
            <token id="55" string="An" />
            <token id="56" string="Awfully" />
            <token id="57" string="Big" />
            <token id="58" string="Adventure" />
          </tokens>
        </chunking>
        <chunking id="19" string="Brian Moore 's `` Lies of Silence , '' and Beryl Bainbridge 's `` An Awfully Big Adventure" type="NP">
          <tokens>
            <token id="41" string="Brian" />
            <token id="42" string="Moore" />
            <token id="43" string="'s" />
            <token id="44" string="``" />
            <token id="45" string="Lies" />
            <token id="46" string="of" />
            <token id="47" string="Silence" />
            <token id="48" string="," />
            <token id="49" string="''" />
            <token id="50" string="and" />
            <token id="51" string="Beryl" />
            <token id="52" string="Bainbridge" />
            <token id="53" string="'s" />
            <token id="54" string="``" />
            <token id="55" string="An" />
            <token id="56" string="Awfully" />
            <token id="57" string="Big" />
            <token id="58" string="Adventure" />
          </tokens>
        </chunking>
        <chunking id="20" string="Irish novelist John McGahern 's `` Amongst Women" type="NP">
          <tokens>
            <token id="20" string="Irish" />
            <token id="21" string="novelist" />
            <token id="22" string="John" />
            <token id="23" string="McGahern" />
            <token id="24" string="'s" />
            <token id="25" string="``" />
            <token id="26" string="Amongst" />
            <token id="27" string="Women" />
          </tokens>
        </chunking>
        <chunking id="21" string="Booker Prize winner Penelope Fitzgerald with `` The Gate of Angels , '' Irish novelist John McGahern 's `` Amongst Women , '' Canadian-born Mordecai Richler 's `` Solomon Gursky" type="NP">
          <tokens>
            <token id="7" string="Booker" />
            <token id="8" string="Prize" />
            <token id="9" string="winner" />
            <token id="10" string="Penelope" />
            <token id="11" string="Fitzgerald" />
            <token id="12" string="with" />
            <token id="13" string="``" />
            <token id="14" string="The" />
            <token id="15" string="Gate" />
            <token id="16" string="of" />
            <token id="17" string="Angels" />
            <token id="18" string="," />
            <token id="19" string="''" />
            <token id="20" string="Irish" />
            <token id="21" string="novelist" />
            <token id="22" string="John" />
            <token id="23" string="McGahern" />
            <token id="24" string="'s" />
            <token id="25" string="``" />
            <token id="26" string="Amongst" />
            <token id="27" string="Women" />
            <token id="28" string="," />
            <token id="29" string="''" />
            <token id="30" string="Canadian-born" />
            <token id="31" string="Mordecai" />
            <token id="32" string="Richler" />
            <token id="33" string="'s" />
            <token id="34" string="``" />
            <token id="35" string="Solomon" />
            <token id="36" string="Gursky" />
          </tokens>
        </chunking>
        <chunking id="22" string="Other finalists this year" type="NP">
          <tokens>
            <token id="1" string="Other" />
            <token id="2" string="finalists" />
            <token id="3" string="this" />
            <token id="4" string="year" />
          </tokens>
        </chunking>
        <chunking id="23" string="Booker Prize winner Penelope Fitzgerald" type="NP">
          <tokens>
            <token id="7" string="Booker" />
            <token id="8" string="Prize" />
            <token id="9" string="winner" />
            <token id="10" string="Penelope" />
            <token id="11" string="Fitzgerald" />
          </tokens>
        </chunking>
        <chunking id="24" string="Canadian-born Mordecai Richler 's `` Solomon Gursky" type="NP">
          <tokens>
            <token id="30" string="Canadian-born" />
            <token id="31" string="Mordecai" />
            <token id="32" string="Richler" />
            <token id="33" string="'s" />
            <token id="34" string="``" />
            <token id="35" string="Solomon" />
            <token id="36" string="Gursky" />
          </tokens>
        </chunking>
        <chunking id="25" string="1979 Booker Prize winner Penelope Fitzgerald with `` The Gate of Angels , '' Irish novelist John McGahern 's `` Amongst Women , '' Canadian-born Mordecai Richler 's `` Solomon Gursky Was Here , '' Brian Moore 's `` Lies of Silence , '' and Beryl Bainbridge 's `` An Awfully Big Adventure" type="NP">
          <tokens>
            <token id="6" string="1979" />
            <token id="7" string="Booker" />
            <token id="8" string="Prize" />
            <token id="9" string="winner" />
            <token id="10" string="Penelope" />
            <token id="11" string="Fitzgerald" />
            <token id="12" string="with" />
            <token id="13" string="``" />
            <token id="14" string="The" />
            <token id="15" string="Gate" />
            <token id="16" string="of" />
            <token id="17" string="Angels" />
            <token id="18" string="," />
            <token id="19" string="''" />
            <token id="20" string="Irish" />
            <token id="21" string="novelist" />
            <token id="22" string="John" />
            <token id="23" string="McGahern" />
            <token id="24" string="'s" />
            <token id="25" string="``" />
            <token id="26" string="Amongst" />
            <token id="27" string="Women" />
            <token id="28" string="," />
            <token id="29" string="''" />
            <token id="30" string="Canadian-born" />
            <token id="31" string="Mordecai" />
            <token id="32" string="Richler" />
            <token id="33" string="'s" />
            <token id="34" string="``" />
            <token id="35" string="Solomon" />
            <token id="36" string="Gursky" />
            <token id="37" string="Was" />
            <token id="38" string="Here" />
            <token id="39" string="," />
            <token id="40" string="''" />
            <token id="41" string="Brian" />
            <token id="42" string="Moore" />
            <token id="43" string="'s" />
            <token id="44" string="``" />
            <token id="45" string="Lies" />
            <token id="46" string="of" />
            <token id="47" string="Silence" />
            <token id="48" string="," />
            <token id="49" string="''" />
            <token id="50" string="and" />
            <token id="51" string="Beryl" />
            <token id="52" string="Bainbridge" />
            <token id="53" string="'s" />
            <token id="54" string="``" />
            <token id="55" string="An" />
            <token id="56" string="Awfully" />
            <token id="57" string="Big" />
            <token id="58" string="Adventure" />
          </tokens>
        </chunking>
        <chunking id="26" string="The Gate of Angels , '' Irish novelist John McGahern 's `` Amongst Women" type="VP">
          <tokens>
            <token id="14" string="The" />
            <token id="15" string="Gate" />
            <token id="16" string="of" />
            <token id="17" string="Angels" />
            <token id="18" string="," />
            <token id="19" string="''" />
            <token id="20" string="Irish" />
            <token id="21" string="novelist" />
            <token id="22" string="John" />
            <token id="23" string="McGahern" />
            <token id="24" string="'s" />
            <token id="25" string="``" />
            <token id="26" string="Amongst" />
            <token id="27" string="Women" />
          </tokens>
        </chunking>
        <chunking id="27" string="Angels" type="NP">
          <tokens>
            <token id="17" string="Angels" />
          </tokens>
        </chunking>
        <chunking id="28" string="`` An" type="NP">
          <tokens>
            <token id="54" string="``" />
            <token id="55" string="An" />
          </tokens>
        </chunking>
        <chunking id="29" string="Brian Moore 's `` Lies of Silence , ''" type="NP">
          <tokens>
            <token id="41" string="Brian" />
            <token id="42" string="Moore" />
            <token id="43" string="'s" />
            <token id="44" string="``" />
            <token id="45" string="Lies" />
            <token id="46" string="of" />
            <token id="47" string="Silence" />
            <token id="48" string="," />
            <token id="49" string="''" />
          </tokens>
        </chunking>
        <chunking id="30" string="1979" type="NP">
          <tokens>
            <token id="6" string="1979" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">finalists</governor>
          <dependent id="1">Other</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">1979</governor>
          <dependent id="2">finalists</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">year</governor>
          <dependent id="3">this</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="2">finalists</governor>
          <dependent id="4">year</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">1979</governor>
          <dependent id="5">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">1979</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Fitzgerald</governor>
          <dependent id="7">Booker</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Fitzgerald</governor>
          <dependent id="8">Prize</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Fitzgerald</governor>
          <dependent id="9">winner</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Fitzgerald</governor>
          <dependent id="10">Penelope</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="38">Here</governor>
          <dependent id="11">Fitzgerald</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">Gursky</governor>
          <dependent id="12">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">Gate</governor>
          <dependent id="14">The</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="36">Gursky</governor>
          <dependent id="15">Gate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Angels</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">Gate</governor>
          <dependent id="17">Angels</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">McGahern</governor>
          <dependent id="20">Irish</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">McGahern</governor>
          <dependent id="21">novelist</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">McGahern</governor>
          <dependent id="22">John</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="27">Women</governor>
          <dependent id="23">McGahern</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">McGahern</governor>
          <dependent id="24">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Women</governor>
          <dependent id="26">Amongst</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">Angels</governor>
          <dependent id="27">Women</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">Richler</governor>
          <dependent id="30">Canadian-born</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">Richler</governor>
          <dependent id="31">Mordecai</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="36">Gursky</governor>
          <dependent id="32">Richler</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">Richler</governor>
          <dependent id="33">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">Gursky</governor>
          <dependent id="35">Solomon</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">Fitzgerald</governor>
          <dependent id="36">Gursky</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="38">Here</governor>
          <dependent id="37">Was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">1979</governor>
          <dependent id="38">Here</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="42">Moore</governor>
          <dependent id="41">Brian</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="45">Lies</governor>
          <dependent id="42">Moore</dependent>
        </dependency>
        <dependency type="case">
          <governor id="42">Moore</governor>
          <dependent id="43">'s</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="38">Here</governor>
          <dependent id="45">Lies</dependent>
        </dependency>
        <dependency type="case">
          <governor id="47">Silence</governor>
          <dependent id="46">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="45">Lies</governor>
          <dependent id="47">Silence</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="45">Lies</governor>
          <dependent id="50">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="52">Bainbridge</governor>
          <dependent id="51">Beryl</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="58">Adventure</governor>
          <dependent id="52">Bainbridge</dependent>
        </dependency>
        <dependency type="case">
          <governor id="52">Bainbridge</governor>
          <dependent id="53">'s</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="57">Big</governor>
          <dependent id="55">An</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="55">An</governor>
          <dependent id="56">Awfully</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="58">Adventure</governor>
          <dependent id="57">Big</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="45">Lies</governor>
          <dependent id="58">Adventure</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mordecai Richler" type="PERSON" score="0.0">
          <tokens>
            <token id="31" string="Mordecai" />
            <token id="32" string="Richler" />
          </tokens>
        </entity>
        <entity id="2" string="Brian Moore" type="PERSON" score="0.0">
          <tokens>
            <token id="41" string="Brian" />
            <token id="42" string="Moore" />
          </tokens>
        </entity>
        <entity id="3" string="John McGahern" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="John" />
            <token id="23" string="McGahern" />
          </tokens>
        </entity>
        <entity id="4" string="Solomon Gursky" type="PERSON" score="0.0">
          <tokens>
            <token id="35" string="Solomon" />
            <token id="36" string="Gursky" />
          </tokens>
        </entity>
        <entity id="5" string="Beryl Bainbridge" type="PERSON" score="0.0">
          <tokens>
            <token id="51" string="Beryl" />
            <token id="52" string="Bainbridge" />
          </tokens>
        </entity>
        <entity id="6" string="Penelope Fitzgerald" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Penelope" />
            <token id="11" string="Fitzgerald" />
          </tokens>
        </entity>
        <entity id="7" string="Booker Prize" type="MISC" score="0.0">
          <tokens>
            <token id="7" string="Booker" />
            <token id="8" string="Prize" />
          </tokens>
        </entity>
        <entity id="8" string="this year" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="this" />
            <token id="4" string="year" />
          </tokens>
        </entity>
        <entity id="9" string="1979" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="1979" />
          </tokens>
        </entity>
        <entity id="10" string="Irish" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="20" string="Irish" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>They were chosen from a list of 113 books published in the United Kingdom in 1989.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="chosen" lemma="choose" stem="chosen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="list" lemma="list" stem="list" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="113" lemma="113" stem="113" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="9" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="published" lemma="publish" stem="publish" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="United" lemma="United" stem="unite" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="14" string="Kingdom" lemma="Kingdom" stem="kingdom" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="1989" lemma="1989" stem="1989" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBD were) (VP (VBN chosen) (PP (IN from) (NP (NP (DT a) (NN list)) (PP (IN of) (NP (NP (CD 113) (NNS books)) (VP (VBN published) (PP (IN in) (NP (NP (DT the) (NNP United) (NNP Kingdom)) (PP (IN in) (NP (CD 1989)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="published in the United Kingdom in 1989" type="VP">
          <tokens>
            <token id="10" string="published" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="United" />
            <token id="14" string="Kingdom" />
            <token id="15" string="in" />
            <token id="16" string="1989" />
          </tokens>
        </chunking>
        <chunking id="3" string="the United Kingdom" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="United" />
            <token id="14" string="Kingdom" />
          </tokens>
        </chunking>
        <chunking id="4" string="chosen from a list of 113 books published in the United Kingdom in 1989" type="VP">
          <tokens>
            <token id="3" string="chosen" />
            <token id="4" string="from" />
            <token id="5" string="a" />
            <token id="6" string="list" />
            <token id="7" string="of" />
            <token id="8" string="113" />
            <token id="9" string="books" />
            <token id="10" string="published" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="United" />
            <token id="14" string="Kingdom" />
            <token id="15" string="in" />
            <token id="16" string="1989" />
          </tokens>
        </chunking>
        <chunking id="5" string="a list" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="list" />
          </tokens>
        </chunking>
        <chunking id="6" string="a list of 113 books published in the United Kingdom in 1989" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="list" />
            <token id="7" string="of" />
            <token id="8" string="113" />
            <token id="9" string="books" />
            <token id="10" string="published" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="United" />
            <token id="14" string="Kingdom" />
            <token id="15" string="in" />
            <token id="16" string="1989" />
          </tokens>
        </chunking>
        <chunking id="7" string="113 books" type="NP">
          <tokens>
            <token id="8" string="113" />
            <token id="9" string="books" />
          </tokens>
        </chunking>
        <chunking id="8" string="were chosen from a list of 113 books published in the United Kingdom in 1989" type="VP">
          <tokens>
            <token id="2" string="were" />
            <token id="3" string="chosen" />
            <token id="4" string="from" />
            <token id="5" string="a" />
            <token id="6" string="list" />
            <token id="7" string="of" />
            <token id="8" string="113" />
            <token id="9" string="books" />
            <token id="10" string="published" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="United" />
            <token id="14" string="Kingdom" />
            <token id="15" string="in" />
            <token id="16" string="1989" />
          </tokens>
        </chunking>
        <chunking id="9" string="113 books published in the United Kingdom in 1989" type="NP">
          <tokens>
            <token id="8" string="113" />
            <token id="9" string="books" />
            <token id="10" string="published" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="United" />
            <token id="14" string="Kingdom" />
            <token id="15" string="in" />
            <token id="16" string="1989" />
          </tokens>
        </chunking>
        <chunking id="10" string="the United Kingdom in 1989" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="United" />
            <token id="14" string="Kingdom" />
            <token id="15" string="in" />
            <token id="16" string="1989" />
          </tokens>
        </chunking>
        <chunking id="11" string="1989" type="NP">
          <tokens>
            <token id="16" string="1989" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="3">chosen</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="3">chosen</governor>
          <dependent id="2">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">chosen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">list</governor>
          <dependent id="4">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">list</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">chosen</governor>
          <dependent id="6">list</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">books</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">books</governor>
          <dependent id="8">113</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">list</governor>
          <dependent id="9">books</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="9">books</governor>
          <dependent id="10">published</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Kingdom</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">Kingdom</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Kingdom</governor>
          <dependent id="13">United</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">published</governor>
          <dependent id="14">Kingdom</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">1989</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">Kingdom</governor>
          <dependent id="16">1989</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="113" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="113" />
          </tokens>
        </entity>
        <entity id="2" string="United Kingdom" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="United" />
            <token id="14" string="Kingdom" />
          </tokens>
        </entity>
        <entity id="3" string="1989" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="1989" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="false">
      <content>The Booker Prize is sponsored by Booker, an international food and agriculture business, and administered by The Book Trust.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Prize" lemma="Prize" stem="prize" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="sponsored" lemma="sponsor" stem="sponsor" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="international" lemma="international" stem="intern" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="food" lemma="food" stem="food" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="agriculture" lemma="agriculture" stem="agricultur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="business" lemma="business" stem="busi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="administered" lemma="administer" stem="administ" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Book" lemma="Book" stem="book" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="Trust" lemma="Trust" stem="trust" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP Booker) (NNP Prize)) (VP (VBZ is) (VP (VP (VBN sponsored) (PP (IN by) (NP (NP (NNP Booker)) (, ,) (NP (DT an) (JJ international) (NN food) (CC and) (NN agriculture) (NN business)) (, ,)))) (CC and) (VP (VBN administered) (PP (IN by) (NP (DT The) (NNP Book) (NNP Trust)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="an international food and agriculture business" type="NP">
          <tokens>
            <token id="9" string="an" />
            <token id="10" string="international" />
            <token id="11" string="food" />
            <token id="12" string="and" />
            <token id="13" string="agriculture" />
            <token id="14" string="business" />
          </tokens>
        </chunking>
        <chunking id="2" string="Booker , an international food and agriculture business ," type="NP">
          <tokens>
            <token id="7" string="Booker" />
            <token id="8" string="," />
            <token id="9" string="an" />
            <token id="10" string="international" />
            <token id="11" string="food" />
            <token id="12" string="and" />
            <token id="13" string="agriculture" />
            <token id="14" string="business" />
            <token id="15" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="is sponsored by Booker , an international food and agriculture business , and administered by The Book Trust" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="sponsored" />
            <token id="6" string="by" />
            <token id="7" string="Booker" />
            <token id="8" string="," />
            <token id="9" string="an" />
            <token id="10" string="international" />
            <token id="11" string="food" />
            <token id="12" string="and" />
            <token id="13" string="agriculture" />
            <token id="14" string="business" />
            <token id="15" string="," />
            <token id="16" string="and" />
            <token id="17" string="administered" />
            <token id="18" string="by" />
            <token id="19" string="The" />
            <token id="20" string="Book" />
            <token id="21" string="Trust" />
          </tokens>
        </chunking>
        <chunking id="4" string="sponsored by Booker , an international food and agriculture business ," type="VP">
          <tokens>
            <token id="5" string="sponsored" />
            <token id="6" string="by" />
            <token id="7" string="Booker" />
            <token id="8" string="," />
            <token id="9" string="an" />
            <token id="10" string="international" />
            <token id="11" string="food" />
            <token id="12" string="and" />
            <token id="13" string="agriculture" />
            <token id="14" string="business" />
            <token id="15" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="Booker" type="NP">
          <tokens>
            <token id="7" string="Booker" />
          </tokens>
        </chunking>
        <chunking id="6" string="The Booker Prize" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Booker" />
            <token id="3" string="Prize" />
          </tokens>
        </chunking>
        <chunking id="7" string="The Book Trust" type="NP">
          <tokens>
            <token id="19" string="The" />
            <token id="20" string="Book" />
            <token id="21" string="Trust" />
          </tokens>
        </chunking>
        <chunking id="8" string="sponsored by Booker , an international food and agriculture business , and administered by The Book Trust" type="VP">
          <tokens>
            <token id="5" string="sponsored" />
            <token id="6" string="by" />
            <token id="7" string="Booker" />
            <token id="8" string="," />
            <token id="9" string="an" />
            <token id="10" string="international" />
            <token id="11" string="food" />
            <token id="12" string="and" />
            <token id="13" string="agriculture" />
            <token id="14" string="business" />
            <token id="15" string="," />
            <token id="16" string="and" />
            <token id="17" string="administered" />
            <token id="18" string="by" />
            <token id="19" string="The" />
            <token id="20" string="Book" />
            <token id="21" string="Trust" />
          </tokens>
        </chunking>
        <chunking id="9" string="administered by The Book Trust" type="VP">
          <tokens>
            <token id="17" string="administered" />
            <token id="18" string="by" />
            <token id="19" string="The" />
            <token id="20" string="Book" />
            <token id="21" string="Trust" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">Prize</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Prize</governor>
          <dependent id="2">Booker</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">sponsored</governor>
          <dependent id="3">Prize</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">sponsored</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">sponsored</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Booker</governor>
          <dependent id="6">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">sponsored</governor>
          <dependent id="7">Booker</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">food</governor>
          <dependent id="9">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">food</governor>
          <dependent id="10">international</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="7">Booker</governor>
          <dependent id="11">food</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">food</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">business</governor>
          <dependent id="13">agriculture</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">food</governor>
          <dependent id="14">business</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">sponsored</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">sponsored</governor>
          <dependent id="17">administered</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Trust</governor>
          <dependent id="18">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">Trust</governor>
          <dependent id="19">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Trust</governor>
          <dependent id="20">Book</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">administered</governor>
          <dependent id="21">Trust</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Booker" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Booker" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>It is Britain&amp;apost;s top literary award.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Britain" lemma="Britain" stem="britain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="top" lemma="top" stem="top" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="literary" lemma="literary" stem="literari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="award" lemma="award" stem="award" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ is) (NP (NP (NNP Britain) (POS 's)) (JJ top) (JJ literary) (NN award))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Britain 's top literary award" type="NP">
          <tokens>
            <token id="3" string="Britain" />
            <token id="4" string="'s" />
            <token id="5" string="top" />
            <token id="6" string="literary" />
            <token id="7" string="award" />
          </tokens>
        </chunking>
        <chunking id="2" string="Britain 's" type="NP">
          <tokens>
            <token id="3" string="Britain" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="4" string="is Britain 's top literary award" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="Britain" />
            <token id="4" string="'s" />
            <token id="5" string="top" />
            <token id="6" string="literary" />
            <token id="7" string="award" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">award</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">award</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">award</governor>
          <dependent id="3">Britain</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">Britain</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">award</governor>
          <dependent id="5">top</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">award</governor>
          <dependent id="6">literary</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">award</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Britain" type="LOCATION" score="0.0">
          <tokens>
            <token id="3" string="Britain" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="9-10-11" string="the Booker Prize" id_sentence="1" />
      <mentions>
        <mention ids_tokens="7-8" string="Booker Prize" id_sentence="14" />
        <mention ids_tokens="1" string="It" id_sentence="17" />
        <mention ids_tokens="3-7" string="Britain's top literary award" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="3-4-5-6-7" string="novelist A.S. Byatt on Tuesday" id_sentence="1" />
      <mentions>
        <mention ids_tokens="21-22" string="A.S. Byatt" id_sentence="5" />
        <mention ids_tokens="1-22" string="Ms. Byatt , who earlier this month won the $ 43,000 Irish Times-Aer Lingus prize for international fiction for the same work" id_sentence="7" />
        <mention ids_tokens="1-2" string="Ms. Byatt" id_sentence="7" />
        <mention ids_tokens="2" string="Byatt" id_sentence="7" />
        <mention ids_tokens="6" string="she" id_sentence="8" />
        <mention ids_tokens="1-6" string="Ms. Byatt , born in 1936" id_sentence="10" />
        <mention ids_tokens="1-2" string="Ms. Byatt" id_sentence="10" />
        <mention ids_tokens="2" string="Byatt" id_sentence="10" />
        <mention ids_tokens="9-19" string="the daughter of a lawyer and sister of novelist Margaret Drabble" id_sentence="10" />
        <mention ids_tokens="1" string="Her" id_sentence="11" />
        <mention ids_tokens="23" string="her" id_sentence="11" />
        <mention ids_tokens="1-2" string="Ms. Byatt" id_sentence="13" />
        <mention ids_tokens="17" string="she" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="1-2-3" string="The five judges" id_sentence="2" />
      <mentions>
        <mention ids_tokens="33-34" string="the judges" id_sentence="5" />
      </mentions>
    </coreference>
    <coreference id="8" type="NOMINAL">
      <referenced ids_tokens="9-10-11-12" string="the $ 39,000 prize" id_sentence="2" />
      <mentions>
        <mention ids_tokens="15-16" string="the prize" id_sentence="4" />
      </mentions>
    </coreference>
    <coreference id="11" type="PROPER">
      <referenced ids_tokens="1-2-3" string="Last year 's" id_sentence="3" />
      <mentions>
        <mention ids_tokens="3-4" string="this year" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="14" type="PROPER">
      <referenced ids_tokens="21-22" string="London 's" id_sentence="4" />
      <mentions>
        <mention ids_tokens="12" string="London" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="16" type="NOMINAL">
      <referenced ids_tokens="9-10-11-12" string="the judge 's panel" id_sentence="4" />
      <mentions>
        <mention ids_tokens="2-3" string="The panel" id_sentence="6" />
      </mentions>
    </coreference>
    <coreference id="22" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4" string="Other finalists this year" id_sentence="14" />
      <mentions>
        <mention ids_tokens="1" string="They" id_sentence="15" />
      </mentions>
    </coreference>
  </coreferences>
</document>
