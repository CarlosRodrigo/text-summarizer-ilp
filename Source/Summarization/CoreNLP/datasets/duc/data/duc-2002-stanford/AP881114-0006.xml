<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP881114-0006">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Dan Quayle is likely to be a ``man on the outside&amp;apost;&amp;apost; in George Bush&amp;apost;s White House following a vice presidential candidacy that began in a furor but settled into obscurity, experts say.</content>
      <tokens>
        <token id="1" string="Dan" lemma="Dan" stem="dan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Quayle" lemma="Quayle" stem="quayl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="likely" lemma="likely" stem="like" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="outside" lemma="outside" stem="outsid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="George" lemma="George" stem="georg" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="17" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="White" lemma="White" stem="white" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="19" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="20" string="following" lemma="follow" stem="follow" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="vice" lemma="vice" stem="vice" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="presidential" lemma="presidential" stem="presidenti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="candidacy" lemma="candidacy" stem="candidaci" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="furor" lemma="furor" stem="furor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="settled" lemma="settle" stem="settl" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="obscurity" lemma="obscurity" stem="obscur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="experts" lemma="expert" stem="expert" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Dan) (NNP Quayle)) (VP (VBZ is) (ADJP (JJ likely) (S (VP (TO to) (VP (VB be) (NP (NP (DT a) (`` ``) (NN man)) (PP (IN on) (NP (NP (DT the) (JJ outside)) ('' '') (PP (IN in) (NP (NP (NNP George) (NNP Bush) (POS 's)) (NNP White) (NNP House))))) (PP (VBG following) (NP (NP (DT a) (NN vice) (JJ presidential) (NN candidacy)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBD began) (PP (IN in) (NP (DT a) (NN furor)))) (CC but) (VP (VBD settled) (PP (IN into) (NP (NN obscurity)))))))))))))))) (, ,) (NP (NNS experts)) (VP (VBP say)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="George Bush 's White House" type="NP">
          <tokens>
            <token id="15" string="George" />
            <token id="16" string="Bush" />
            <token id="17" string="'s" />
            <token id="18" string="White" />
            <token id="19" string="House" />
          </tokens>
        </chunking>
        <chunking id="2" string="be a `` man on the outside '' in George Bush 's White House following a vice presidential candidacy that began in a furor but settled into obscurity" type="VP">
          <tokens>
            <token id="6" string="be" />
            <token id="7" string="a" />
            <token id="8" string="``" />
            <token id="9" string="man" />
            <token id="10" string="on" />
            <token id="11" string="the" />
            <token id="12" string="outside" />
            <token id="13" string="''" />
            <token id="14" string="in" />
            <token id="15" string="George" />
            <token id="16" string="Bush" />
            <token id="17" string="'s" />
            <token id="18" string="White" />
            <token id="19" string="House" />
            <token id="20" string="following" />
            <token id="21" string="a" />
            <token id="22" string="vice" />
            <token id="23" string="presidential" />
            <token id="24" string="candidacy" />
            <token id="25" string="that" />
            <token id="26" string="began" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="furor" />
            <token id="30" string="but" />
            <token id="31" string="settled" />
            <token id="32" string="into" />
            <token id="33" string="obscurity" />
          </tokens>
        </chunking>
        <chunking id="3" string="George Bush 's" type="NP">
          <tokens>
            <token id="15" string="George" />
            <token id="16" string="Bush" />
            <token id="17" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="say" type="VP">
          <tokens>
            <token id="36" string="say" />
          </tokens>
        </chunking>
        <chunking id="5" string="Dan Quayle" type="NP">
          <tokens>
            <token id="1" string="Dan" />
            <token id="2" string="Quayle" />
          </tokens>
        </chunking>
        <chunking id="6" string="obscurity" type="NP">
          <tokens>
            <token id="33" string="obscurity" />
          </tokens>
        </chunking>
        <chunking id="7" string="a furor" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="furor" />
          </tokens>
        </chunking>
        <chunking id="8" string="that began in a furor but settled into obscurity" type="SBAR">
          <tokens>
            <token id="25" string="that" />
            <token id="26" string="began" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="furor" />
            <token id="30" string="but" />
            <token id="31" string="settled" />
            <token id="32" string="into" />
            <token id="33" string="obscurity" />
          </tokens>
        </chunking>
        <chunking id="9" string="a vice presidential candidacy" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="vice" />
            <token id="23" string="presidential" />
            <token id="24" string="candidacy" />
          </tokens>
        </chunking>
        <chunking id="10" string="likely to be a `` man on the outside '' in George Bush 's White House following a vice presidential candidacy that began in a furor but settled into obscurity" type="ADJP">
          <tokens>
            <token id="4" string="likely" />
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="a" />
            <token id="8" string="``" />
            <token id="9" string="man" />
            <token id="10" string="on" />
            <token id="11" string="the" />
            <token id="12" string="outside" />
            <token id="13" string="''" />
            <token id="14" string="in" />
            <token id="15" string="George" />
            <token id="16" string="Bush" />
            <token id="17" string="'s" />
            <token id="18" string="White" />
            <token id="19" string="House" />
            <token id="20" string="following" />
            <token id="21" string="a" />
            <token id="22" string="vice" />
            <token id="23" string="presidential" />
            <token id="24" string="candidacy" />
            <token id="25" string="that" />
            <token id="26" string="began" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="furor" />
            <token id="30" string="but" />
            <token id="31" string="settled" />
            <token id="32" string="into" />
            <token id="33" string="obscurity" />
          </tokens>
        </chunking>
        <chunking id="11" string="began in a furor but settled into obscurity" type="VP">
          <tokens>
            <token id="26" string="began" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="furor" />
            <token id="30" string="but" />
            <token id="31" string="settled" />
            <token id="32" string="into" />
            <token id="33" string="obscurity" />
          </tokens>
        </chunking>
        <chunking id="12" string="began in a furor" type="VP">
          <tokens>
            <token id="26" string="began" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="furor" />
          </tokens>
        </chunking>
        <chunking id="13" string="the outside" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="outside" />
          </tokens>
        </chunking>
        <chunking id="14" string="a vice presidential candidacy that began in a furor but settled into obscurity" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="vice" />
            <token id="23" string="presidential" />
            <token id="24" string="candidacy" />
            <token id="25" string="that" />
            <token id="26" string="began" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="furor" />
            <token id="30" string="but" />
            <token id="31" string="settled" />
            <token id="32" string="into" />
            <token id="33" string="obscurity" />
          </tokens>
        </chunking>
        <chunking id="15" string="a `` man" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="``" />
            <token id="9" string="man" />
          </tokens>
        </chunking>
        <chunking id="16" string="is likely to be a `` man on the outside '' in George Bush 's White House following a vice presidential candidacy that began in a furor but settled into obscurity" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="likely" />
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="a" />
            <token id="8" string="``" />
            <token id="9" string="man" />
            <token id="10" string="on" />
            <token id="11" string="the" />
            <token id="12" string="outside" />
            <token id="13" string="''" />
            <token id="14" string="in" />
            <token id="15" string="George" />
            <token id="16" string="Bush" />
            <token id="17" string="'s" />
            <token id="18" string="White" />
            <token id="19" string="House" />
            <token id="20" string="following" />
            <token id="21" string="a" />
            <token id="22" string="vice" />
            <token id="23" string="presidential" />
            <token id="24" string="candidacy" />
            <token id="25" string="that" />
            <token id="26" string="began" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="furor" />
            <token id="30" string="but" />
            <token id="31" string="settled" />
            <token id="32" string="into" />
            <token id="33" string="obscurity" />
          </tokens>
        </chunking>
        <chunking id="17" string="a `` man on the outside '' in George Bush 's White House following a vice presidential candidacy that began in a furor but settled into obscurity" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="``" />
            <token id="9" string="man" />
            <token id="10" string="on" />
            <token id="11" string="the" />
            <token id="12" string="outside" />
            <token id="13" string="''" />
            <token id="14" string="in" />
            <token id="15" string="George" />
            <token id="16" string="Bush" />
            <token id="17" string="'s" />
            <token id="18" string="White" />
            <token id="19" string="House" />
            <token id="20" string="following" />
            <token id="21" string="a" />
            <token id="22" string="vice" />
            <token id="23" string="presidential" />
            <token id="24" string="candidacy" />
            <token id="25" string="that" />
            <token id="26" string="began" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="furor" />
            <token id="30" string="but" />
            <token id="31" string="settled" />
            <token id="32" string="into" />
            <token id="33" string="obscurity" />
          </tokens>
        </chunking>
        <chunking id="18" string="experts" type="NP">
          <tokens>
            <token id="35" string="experts" />
          </tokens>
        </chunking>
        <chunking id="19" string="the outside '' in George Bush 's White House" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="outside" />
            <token id="13" string="''" />
            <token id="14" string="in" />
            <token id="15" string="George" />
            <token id="16" string="Bush" />
            <token id="17" string="'s" />
            <token id="18" string="White" />
            <token id="19" string="House" />
          </tokens>
        </chunking>
        <chunking id="20" string="settled into obscurity" type="VP">
          <tokens>
            <token id="31" string="settled" />
            <token id="32" string="into" />
            <token id="33" string="obscurity" />
          </tokens>
        </chunking>
        <chunking id="21" string="to be a `` man on the outside '' in George Bush 's White House following a vice presidential candidacy that began in a furor but settled into obscurity" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="a" />
            <token id="8" string="``" />
            <token id="9" string="man" />
            <token id="10" string="on" />
            <token id="11" string="the" />
            <token id="12" string="outside" />
            <token id="13" string="''" />
            <token id="14" string="in" />
            <token id="15" string="George" />
            <token id="16" string="Bush" />
            <token id="17" string="'s" />
            <token id="18" string="White" />
            <token id="19" string="House" />
            <token id="20" string="following" />
            <token id="21" string="a" />
            <token id="22" string="vice" />
            <token id="23" string="presidential" />
            <token id="24" string="candidacy" />
            <token id="25" string="that" />
            <token id="26" string="began" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="furor" />
            <token id="30" string="but" />
            <token id="31" string="settled" />
            <token id="32" string="into" />
            <token id="33" string="obscurity" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Quayle</governor>
          <dependent id="1">Dan</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">likely</governor>
          <dependent id="2">Quayle</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">likely</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="36">say</governor>
          <dependent id="4">likely</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">man</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">man</governor>
          <dependent id="6">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">man</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">likely</governor>
          <dependent id="9">man</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">outside</governor>
          <dependent id="10">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">outside</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">man</governor>
          <dependent id="12">outside</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">House</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Bush</governor>
          <dependent id="15">George</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">House</governor>
          <dependent id="16">Bush</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Bush</governor>
          <dependent id="17">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">House</governor>
          <dependent id="18">White</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">outside</governor>
          <dependent id="19">House</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">candidacy</governor>
          <dependent id="20">following</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">candidacy</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">candidacy</governor>
          <dependent id="22">vice</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">candidacy</governor>
          <dependent id="23">presidential</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">man</governor>
          <dependent id="24">candidacy</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">began</governor>
          <dependent id="25">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="24">candidacy</governor>
          <dependent id="26">began</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">furor</governor>
          <dependent id="27">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">furor</governor>
          <dependent id="28">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">began</governor>
          <dependent id="29">furor</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="26">began</governor>
          <dependent id="30">but</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="26">began</governor>
          <dependent id="31">settled</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">obscurity</governor>
          <dependent id="32">into</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">settled</governor>
          <dependent id="33">obscurity</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">say</governor>
          <dependent id="35">experts</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="36">say</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="White House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="18" string="White" />
            <token id="19" string="House" />
          </tokens>
        </entity>
        <entity id="2" string="Dan Quayle" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Dan" />
            <token id="2" string="Quayle" />
          </tokens>
        </entity>
        <entity id="3" string="George Bush" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="George" />
            <token id="16" string="Bush" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>Encumbered by his image as a political novice who needed a bevy of professional handlers to survive early campaign controversies, Quayle enters a Bush administration in which he has few intimates or allies.</content>
      <tokens>
        <token id="1" string="Encumbered" lemma="encumber" stem="encumber" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="image" lemma="image" stem="imag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="novice" lemma="novice" stem="novic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="needed" lemma="need" stem="need" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="bevy" lemma="bevy" stem="bevi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="professional" lemma="professional" stem="profession" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="handlers" lemma="handler" stem="handler" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="survive" lemma="survive" stem="surviv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="early" lemma="early" stem="earli" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="campaign" lemma="campaign" stem="campaign" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="controversies" lemma="controversy" stem="controversi" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Quayle" lemma="Quayle" stem="quayl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="23" string="enters" lemma="enter" stem="enter" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="26" string="administration" lemma="administration" stem="administr" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="30" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="32" string="intimates" lemma="intimate" stem="intim" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="34" string="allies" lemma="ally" stem="alli" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBN Encumbered) (PP (IN by) (NP (PRP$ his) (NN image))) (PP (IN as) (NP (NP (DT a) (JJ political) (NN novice)) (SBAR (WHNP (WP who)) (S (VP (VBD needed) (NP (NP (DT a) (NN bevy)) (PP (IN of) (NP (JJ professional) (NNS handlers)))) (S (VP (TO to) (VP (VB survive) (NP (JJ early) (NN campaign) (NNS controversies)))))))))))) (, ,) (NP (NNP Quayle)) (VP (VBZ enters) (NP (NP (DT a) (NNP Bush) (NN administration)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (PRP he)) (VP (VBZ has) (NP (JJ few) (NNS intimates) (CC or) (NNS allies))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a Bush administration in which he has few intimates or allies" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="Bush" />
            <token id="26" string="administration" />
            <token id="27" string="in" />
            <token id="28" string="which" />
            <token id="29" string="he" />
            <token id="30" string="has" />
            <token id="31" string="few" />
            <token id="32" string="intimates" />
            <token id="33" string="or" />
            <token id="34" string="allies" />
          </tokens>
        </chunking>
        <chunking id="2" string="Encumbered by his image as a political novice who needed a bevy of professional handlers to survive early campaign controversies" type="VP">
          <tokens>
            <token id="1" string="Encumbered" />
            <token id="2" string="by" />
            <token id="3" string="his" />
            <token id="4" string="image" />
            <token id="5" string="as" />
            <token id="6" string="a" />
            <token id="7" string="political" />
            <token id="8" string="novice" />
            <token id="9" string="who" />
            <token id="10" string="needed" />
            <token id="11" string="a" />
            <token id="12" string="bevy" />
            <token id="13" string="of" />
            <token id="14" string="professional" />
            <token id="15" string="handlers" />
            <token id="16" string="to" />
            <token id="17" string="survive" />
            <token id="18" string="early" />
            <token id="19" string="campaign" />
            <token id="20" string="controversies" />
          </tokens>
        </chunking>
        <chunking id="3" string="a political novice" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="political" />
            <token id="8" string="novice" />
          </tokens>
        </chunking>
        <chunking id="4" string="Quayle" type="NP">
          <tokens>
            <token id="22" string="Quayle" />
          </tokens>
        </chunking>
        <chunking id="5" string="to survive early campaign controversies" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="survive" />
            <token id="18" string="early" />
            <token id="19" string="campaign" />
            <token id="20" string="controversies" />
          </tokens>
        </chunking>
        <chunking id="6" string="survive early campaign controversies" type="VP">
          <tokens>
            <token id="17" string="survive" />
            <token id="18" string="early" />
            <token id="19" string="campaign" />
            <token id="20" string="controversies" />
          </tokens>
        </chunking>
        <chunking id="7" string="enters a Bush administration in which he has few intimates or allies" type="VP">
          <tokens>
            <token id="23" string="enters" />
            <token id="24" string="a" />
            <token id="25" string="Bush" />
            <token id="26" string="administration" />
            <token id="27" string="in" />
            <token id="28" string="which" />
            <token id="29" string="he" />
            <token id="30" string="has" />
            <token id="31" string="few" />
            <token id="32" string="intimates" />
            <token id="33" string="or" />
            <token id="34" string="allies" />
          </tokens>
        </chunking>
        <chunking id="8" string="has few intimates or allies" type="VP">
          <tokens>
            <token id="30" string="has" />
            <token id="31" string="few" />
            <token id="32" string="intimates" />
            <token id="33" string="or" />
            <token id="34" string="allies" />
          </tokens>
        </chunking>
        <chunking id="9" string="his image" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="image" />
          </tokens>
        </chunking>
        <chunking id="10" string="professional handlers" type="NP">
          <tokens>
            <token id="14" string="professional" />
            <token id="15" string="handlers" />
          </tokens>
        </chunking>
        <chunking id="11" string="few intimates or allies" type="NP">
          <tokens>
            <token id="31" string="few" />
            <token id="32" string="intimates" />
            <token id="33" string="or" />
            <token id="34" string="allies" />
          </tokens>
        </chunking>
        <chunking id="12" string="a political novice who needed a bevy of professional handlers to survive early campaign controversies" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="political" />
            <token id="8" string="novice" />
            <token id="9" string="who" />
            <token id="10" string="needed" />
            <token id="11" string="a" />
            <token id="12" string="bevy" />
            <token id="13" string="of" />
            <token id="14" string="professional" />
            <token id="15" string="handlers" />
            <token id="16" string="to" />
            <token id="17" string="survive" />
            <token id="18" string="early" />
            <token id="19" string="campaign" />
            <token id="20" string="controversies" />
          </tokens>
        </chunking>
        <chunking id="13" string="in which he has few intimates or allies" type="SBAR">
          <tokens>
            <token id="27" string="in" />
            <token id="28" string="which" />
            <token id="29" string="he" />
            <token id="30" string="has" />
            <token id="31" string="few" />
            <token id="32" string="intimates" />
            <token id="33" string="or" />
            <token id="34" string="allies" />
          </tokens>
        </chunking>
        <chunking id="14" string="a bevy" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="bevy" />
          </tokens>
        </chunking>
        <chunking id="15" string="needed a bevy of professional handlers to survive early campaign controversies" type="VP">
          <tokens>
            <token id="10" string="needed" />
            <token id="11" string="a" />
            <token id="12" string="bevy" />
            <token id="13" string="of" />
            <token id="14" string="professional" />
            <token id="15" string="handlers" />
            <token id="16" string="to" />
            <token id="17" string="survive" />
            <token id="18" string="early" />
            <token id="19" string="campaign" />
            <token id="20" string="controversies" />
          </tokens>
        </chunking>
        <chunking id="16" string="a Bush administration" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="Bush" />
            <token id="26" string="administration" />
          </tokens>
        </chunking>
        <chunking id="17" string="a bevy of professional handlers" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="bevy" />
            <token id="13" string="of" />
            <token id="14" string="professional" />
            <token id="15" string="handlers" />
          </tokens>
        </chunking>
        <chunking id="18" string="early campaign controversies" type="NP">
          <tokens>
            <token id="18" string="early" />
            <token id="19" string="campaign" />
            <token id="20" string="controversies" />
          </tokens>
        </chunking>
        <chunking id="19" string="he" type="NP">
          <tokens>
            <token id="29" string="he" />
          </tokens>
        </chunking>
        <chunking id="20" string="who needed a bevy of professional handlers to survive early campaign controversies" type="SBAR">
          <tokens>
            <token id="9" string="who" />
            <token id="10" string="needed" />
            <token id="11" string="a" />
            <token id="12" string="bevy" />
            <token id="13" string="of" />
            <token id="14" string="professional" />
            <token id="15" string="handlers" />
            <token id="16" string="to" />
            <token id="17" string="survive" />
            <token id="18" string="early" />
            <token id="19" string="campaign" />
            <token id="20" string="controversies" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="23">enters</governor>
          <dependent id="1">Encumbered</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">image</governor>
          <dependent id="2">by</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">image</governor>
          <dependent id="3">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Encumbered</governor>
          <dependent id="4">image</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">novice</governor>
          <dependent id="5">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">novice</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">novice</governor>
          <dependent id="7">political</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Encumbered</governor>
          <dependent id="8">novice</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">needed</governor>
          <dependent id="9">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">novice</governor>
          <dependent id="10">needed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">bevy</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">needed</governor>
          <dependent id="12">bevy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">handlers</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">handlers</governor>
          <dependent id="14">professional</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">bevy</governor>
          <dependent id="15">handlers</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">survive</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">needed</governor>
          <dependent id="17">survive</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">controversies</governor>
          <dependent id="18">early</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">controversies</governor>
          <dependent id="19">campaign</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">survive</governor>
          <dependent id="20">controversies</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">enters</governor>
          <dependent id="22">Quayle</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="23">enters</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">administration</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">administration</governor>
          <dependent id="25">Bush</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">enters</governor>
          <dependent id="26">administration</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">which</governor>
          <dependent id="27">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">has</governor>
          <dependent id="28">which</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">has</governor>
          <dependent id="29">he</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="26">administration</governor>
          <dependent id="30">has</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">intimates</governor>
          <dependent id="31">few</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">has</governor>
          <dependent id="32">intimates</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="32">intimates</governor>
          <dependent id="33">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="32">intimates</governor>
          <dependent id="34">allies</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Quayle" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Quayle" />
          </tokens>
        </entity>
        <entity id="2" string="Bush" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Bush" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>Relegated in the campaign to small towns and safe GOP areas, Quayle as vice president is likely to be given a traditional ceremonial role _ going to political gatherings and state funerals _ rather than the advisory role that Walter Mondale and even Bush had, some scholars feel.</content>
      <tokens>
        <token id="1" string="Relegated" lemma="relegate" stem="releg" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="campaign" lemma="campaign" stem="campaign" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="small" lemma="small" stem="small" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="towns" lemma="town" stem="town" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="safe" lemma="safe" stem="safe" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="GOP" lemma="GOP" stem="gop" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="11" string="areas" lemma="area" stem="area" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Quayle" lemma="Quayle" stem="quayl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="14" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="vice" lemma="vice" stem="vice" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="president" lemma="president" stem="presid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="likely" lemma="likely" stem="like" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="given" lemma="give" stem="given" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="traditional" lemma="traditional" stem="tradit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="ceremonial" lemma="ceremonial" stem="ceremoni" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="role" lemma="role" stem="role" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="gatherings" lemma="gathering" stem="gather" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="funerals" lemma="funeral" stem="funer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="_" lemma="_" stem="_" pos="VBP" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="rather" lemma="rather" stem="rather" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="advisory" lemma="advisory" stem="advisori" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="role" lemma="role" stem="role" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="Walter" lemma="Walter" stem="walter" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="42" string="Mondale" lemma="Mondale" stem="mondal" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="43" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="45" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="46" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="scholars" lemma="scholar" stem="scholar" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="50" string="feel" lemma="feel" stem="feel" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="51" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBN Relegated) (PP (IN in) (NP (DT the) (NN campaign))) (PP (TO to) (NP (NP (JJ small) (NNS towns)) (CC and) (NP (JJ safe) (NNP GOP) (NNS areas)))) (, ,) (SBAR (NP (NNP Quayle)) (IN as) (S (S (NP (NN vice) (NN president)) (VP (VBZ is) (ADJP (JJ likely) (S (VP (TO to) (VP (VB be) (VP (VBN given) (NP (DT a) (JJ traditional) (JJ ceremonial) (NN role)) (NP (NP (NN _)) (VP (VBG going) (PP (TO to) (NP (JJ political) (NNS gatherings)))))))))))) (CC and) (S (NP (NN state) (NNS funerals)) (VP (VBP _) (PP (RB rather) (IN than) (NP (NP (DT the) (JJ advisory) (NN role)) (SBAR (WHNP (WDT that)) (S (NP (NP (NNP Walter) (NNP Mondale)) (CC and) (NP (RB even) (NNP Bush))) (VP (VBD had)))))))))))) (, ,) (NP (DT some) (NNS scholars)) (VP (VBP feel)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="vice president" type="NP">
          <tokens>
            <token id="15" string="vice" />
            <token id="16" string="president" />
          </tokens>
        </chunking>
        <chunking id="2" string="Quayle" type="NP">
          <tokens>
            <token id="13" string="Quayle" />
          </tokens>
        </chunking>
        <chunking id="3" string="to be given a traditional ceremonial role _ going to political gatherings" type="VP">
          <tokens>
            <token id="19" string="to" />
            <token id="20" string="be" />
            <token id="21" string="given" />
            <token id="22" string="a" />
            <token id="23" string="traditional" />
            <token id="24" string="ceremonial" />
            <token id="25" string="role" />
            <token id="26" string="_" />
            <token id="27" string="going" />
            <token id="28" string="to" />
            <token id="29" string="political" />
            <token id="30" string="gatherings" />
          </tokens>
        </chunking>
        <chunking id="4" string="Quayle as vice president is likely to be given a traditional ceremonial role _ going to political gatherings and state funerals _ rather than the advisory role that Walter Mondale and even Bush had" type="SBAR">
          <tokens>
            <token id="13" string="Quayle" />
            <token id="14" string="as" />
            <token id="15" string="vice" />
            <token id="16" string="president" />
            <token id="17" string="is" />
            <token id="18" string="likely" />
            <token id="19" string="to" />
            <token id="20" string="be" />
            <token id="21" string="given" />
            <token id="22" string="a" />
            <token id="23" string="traditional" />
            <token id="24" string="ceremonial" />
            <token id="25" string="role" />
            <token id="26" string="_" />
            <token id="27" string="going" />
            <token id="28" string="to" />
            <token id="29" string="political" />
            <token id="30" string="gatherings" />
            <token id="31" string="and" />
            <token id="32" string="state" />
            <token id="33" string="funerals" />
            <token id="34" string="_" />
            <token id="35" string="rather" />
            <token id="36" string="than" />
            <token id="37" string="the" />
            <token id="38" string="advisory" />
            <token id="39" string="role" />
            <token id="40" string="that" />
            <token id="41" string="Walter" />
            <token id="42" string="Mondale" />
            <token id="43" string="and" />
            <token id="44" string="even" />
            <token id="45" string="Bush" />
            <token id="46" string="had" />
          </tokens>
        </chunking>
        <chunking id="5" string="a traditional ceremonial role" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="traditional" />
            <token id="24" string="ceremonial" />
            <token id="25" string="role" />
          </tokens>
        </chunking>
        <chunking id="6" string="that Walter Mondale and even Bush had" type="SBAR">
          <tokens>
            <token id="40" string="that" />
            <token id="41" string="Walter" />
            <token id="42" string="Mondale" />
            <token id="43" string="and" />
            <token id="44" string="even" />
            <token id="45" string="Bush" />
            <token id="46" string="had" />
          </tokens>
        </chunking>
        <chunking id="7" string="safe GOP areas" type="NP">
          <tokens>
            <token id="9" string="safe" />
            <token id="10" string="GOP" />
            <token id="11" string="areas" />
          </tokens>
        </chunking>
        <chunking id="8" string="likely to be given a traditional ceremonial role _ going to political gatherings" type="ADJP">
          <tokens>
            <token id="18" string="likely" />
            <token id="19" string="to" />
            <token id="20" string="be" />
            <token id="21" string="given" />
            <token id="22" string="a" />
            <token id="23" string="traditional" />
            <token id="24" string="ceremonial" />
            <token id="25" string="role" />
            <token id="26" string="_" />
            <token id="27" string="going" />
            <token id="28" string="to" />
            <token id="29" string="political" />
            <token id="30" string="gatherings" />
          </tokens>
        </chunking>
        <chunking id="9" string="given a traditional ceremonial role _ going to political gatherings" type="VP">
          <tokens>
            <token id="21" string="given" />
            <token id="22" string="a" />
            <token id="23" string="traditional" />
            <token id="24" string="ceremonial" />
            <token id="25" string="role" />
            <token id="26" string="_" />
            <token id="27" string="going" />
            <token id="28" string="to" />
            <token id="29" string="political" />
            <token id="30" string="gatherings" />
          </tokens>
        </chunking>
        <chunking id="10" string="Walter Mondale" type="NP">
          <tokens>
            <token id="41" string="Walter" />
            <token id="42" string="Mondale" />
          </tokens>
        </chunking>
        <chunking id="11" string="small towns and safe GOP areas" type="NP">
          <tokens>
            <token id="6" string="small" />
            <token id="7" string="towns" />
            <token id="8" string="and" />
            <token id="9" string="safe" />
            <token id="10" string="GOP" />
            <token id="11" string="areas" />
          </tokens>
        </chunking>
        <chunking id="12" string="some scholars" type="NP">
          <tokens>
            <token id="48" string="some" />
            <token id="49" string="scholars" />
          </tokens>
        </chunking>
        <chunking id="13" string="even Bush" type="NP">
          <tokens>
            <token id="44" string="even" />
            <token id="45" string="Bush" />
          </tokens>
        </chunking>
        <chunking id="14" string="Relegated in the campaign to small towns and safe GOP areas , Quayle as vice president is likely to be given a traditional ceremonial role _ going to political gatherings and state funerals _ rather than the advisory role that Walter Mondale and even Bush had" type="VP">
          <tokens>
            <token id="1" string="Relegated" />
            <token id="2" string="in" />
            <token id="3" string="the" />
            <token id="4" string="campaign" />
            <token id="5" string="to" />
            <token id="6" string="small" />
            <token id="7" string="towns" />
            <token id="8" string="and" />
            <token id="9" string="safe" />
            <token id="10" string="GOP" />
            <token id="11" string="areas" />
            <token id="12" string="," />
            <token id="13" string="Quayle" />
            <token id="14" string="as" />
            <token id="15" string="vice" />
            <token id="16" string="president" />
            <token id="17" string="is" />
            <token id="18" string="likely" />
            <token id="19" string="to" />
            <token id="20" string="be" />
            <token id="21" string="given" />
            <token id="22" string="a" />
            <token id="23" string="traditional" />
            <token id="24" string="ceremonial" />
            <token id="25" string="role" />
            <token id="26" string="_" />
            <token id="27" string="going" />
            <token id="28" string="to" />
            <token id="29" string="political" />
            <token id="30" string="gatherings" />
            <token id="31" string="and" />
            <token id="32" string="state" />
            <token id="33" string="funerals" />
            <token id="34" string="_" />
            <token id="35" string="rather" />
            <token id="36" string="than" />
            <token id="37" string="the" />
            <token id="38" string="advisory" />
            <token id="39" string="role" />
            <token id="40" string="that" />
            <token id="41" string="Walter" />
            <token id="42" string="Mondale" />
            <token id="43" string="and" />
            <token id="44" string="even" />
            <token id="45" string="Bush" />
            <token id="46" string="had" />
          </tokens>
        </chunking>
        <chunking id="15" string="_ rather than the advisory role that Walter Mondale and even Bush had" type="VP">
          <tokens>
            <token id="34" string="_" />
            <token id="35" string="rather" />
            <token id="36" string="than" />
            <token id="37" string="the" />
            <token id="38" string="advisory" />
            <token id="39" string="role" />
            <token id="40" string="that" />
            <token id="41" string="Walter" />
            <token id="42" string="Mondale" />
            <token id="43" string="and" />
            <token id="44" string="even" />
            <token id="45" string="Bush" />
            <token id="46" string="had" />
          </tokens>
        </chunking>
        <chunking id="16" string="be given a traditional ceremonial role _ going to political gatherings" type="VP">
          <tokens>
            <token id="20" string="be" />
            <token id="21" string="given" />
            <token id="22" string="a" />
            <token id="23" string="traditional" />
            <token id="24" string="ceremonial" />
            <token id="25" string="role" />
            <token id="26" string="_" />
            <token id="27" string="going" />
            <token id="28" string="to" />
            <token id="29" string="political" />
            <token id="30" string="gatherings" />
          </tokens>
        </chunking>
        <chunking id="17" string="the advisory role" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="advisory" />
            <token id="39" string="role" />
          </tokens>
        </chunking>
        <chunking id="18" string="is likely to be given a traditional ceremonial role _ going to political gatherings" type="VP">
          <tokens>
            <token id="17" string="is" />
            <token id="18" string="likely" />
            <token id="19" string="to" />
            <token id="20" string="be" />
            <token id="21" string="given" />
            <token id="22" string="a" />
            <token id="23" string="traditional" />
            <token id="24" string="ceremonial" />
            <token id="25" string="role" />
            <token id="26" string="_" />
            <token id="27" string="going" />
            <token id="28" string="to" />
            <token id="29" string="political" />
            <token id="30" string="gatherings" />
          </tokens>
        </chunking>
        <chunking id="19" string="Walter Mondale and even Bush" type="NP">
          <tokens>
            <token id="41" string="Walter" />
            <token id="42" string="Mondale" />
            <token id="43" string="and" />
            <token id="44" string="even" />
            <token id="45" string="Bush" />
          </tokens>
        </chunking>
        <chunking id="20" string="going to political gatherings" type="VP">
          <tokens>
            <token id="27" string="going" />
            <token id="28" string="to" />
            <token id="29" string="political" />
            <token id="30" string="gatherings" />
          </tokens>
        </chunking>
        <chunking id="21" string="political gatherings" type="NP">
          <tokens>
            <token id="29" string="political" />
            <token id="30" string="gatherings" />
          </tokens>
        </chunking>
        <chunking id="22" string="the campaign" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="campaign" />
          </tokens>
        </chunking>
        <chunking id="23" string="small towns" type="NP">
          <tokens>
            <token id="6" string="small" />
            <token id="7" string="towns" />
          </tokens>
        </chunking>
        <chunking id="24" string="the advisory role that Walter Mondale and even Bush had" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="advisory" />
            <token id="39" string="role" />
            <token id="40" string="that" />
            <token id="41" string="Walter" />
            <token id="42" string="Mondale" />
            <token id="43" string="and" />
            <token id="44" string="even" />
            <token id="45" string="Bush" />
            <token id="46" string="had" />
          </tokens>
        </chunking>
        <chunking id="25" string="state funerals" type="NP">
          <tokens>
            <token id="32" string="state" />
            <token id="33" string="funerals" />
          </tokens>
        </chunking>
        <chunking id="26" string="feel" type="VP">
          <tokens>
            <token id="50" string="feel" />
          </tokens>
        </chunking>
        <chunking id="27" string="had" type="VP">
          <tokens>
            <token id="46" string="had" />
          </tokens>
        </chunking>
        <chunking id="28" string="_ going to political gatherings" type="NP">
          <tokens>
            <token id="26" string="_" />
            <token id="27" string="going" />
            <token id="28" string="to" />
            <token id="29" string="political" />
            <token id="30" string="gatherings" />
          </tokens>
        </chunking>
        <chunking id="29" string="_" type="NP">
          <tokens>
            <token id="26" string="_" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="50">feel</governor>
          <dependent id="1">Relegated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">campaign</governor>
          <dependent id="2">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">campaign</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Relegated</governor>
          <dependent id="4">campaign</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">towns</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">towns</governor>
          <dependent id="6">small</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Relegated</governor>
          <dependent id="7">towns</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">towns</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">areas</governor>
          <dependent id="9">safe</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">areas</governor>
          <dependent id="10">GOP</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">towns</governor>
          <dependent id="11">areas</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="18">likely</governor>
          <dependent id="13">Quayle</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">likely</governor>
          <dependent id="14">as</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">president</governor>
          <dependent id="15">vice</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">likely</governor>
          <dependent id="16">president</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="18">likely</governor>
          <dependent id="17">is</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="1">Relegated</governor>
          <dependent id="18">likely</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">given</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="21">given</governor>
          <dependent id="20">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">likely</governor>
          <dependent id="21">given</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">role</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">role</governor>
          <dependent id="23">traditional</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">role</governor>
          <dependent id="24">ceremonial</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="21">given</governor>
          <dependent id="25">role</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">given</governor>
          <dependent id="26">_</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="26">_</governor>
          <dependent id="27">going</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">gatherings</governor>
          <dependent id="28">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">gatherings</governor>
          <dependent id="29">political</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">going</governor>
          <dependent id="30">gatherings</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">likely</governor>
          <dependent id="31">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">funerals</governor>
          <dependent id="32">state</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">_</governor>
          <dependent id="33">funerals</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">likely</governor>
          <dependent id="34">_</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">role</governor>
          <dependent id="35">rather</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="35">rather</governor>
          <dependent id="36">than</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">role</governor>
          <dependent id="37">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="39">role</governor>
          <dependent id="38">advisory</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">_</governor>
          <dependent id="39">role</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="46">had</governor>
          <dependent id="40">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="42">Mondale</governor>
          <dependent id="41">Walter</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="46">had</governor>
          <dependent id="42">Mondale</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="42">Mondale</governor>
          <dependent id="43">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="45">Bush</governor>
          <dependent id="44">even</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="42">Mondale</governor>
          <dependent id="45">Bush</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="39">role</governor>
          <dependent id="46">had</dependent>
        </dependency>
        <dependency type="det">
          <governor id="49">scholars</governor>
          <dependent id="48">some</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="50">feel</governor>
          <dependent id="49">scholars</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="50">feel</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Quayle" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Quayle" />
          </tokens>
        </entity>
        <entity id="2" string="GOP" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="10" string="GOP" />
          </tokens>
        </entity>
        <entity id="3" string="Walter Mondale" type="PERSON" score="0.0">
          <tokens>
            <token id="41" string="Walter" />
            <token id="42" string="Mondale" />
          </tokens>
        </entity>
        <entity id="4" string="Bush" type="PERSON" score="0.0">
          <tokens>
            <token id="45" string="Bush" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="false">
      <content>``Dan Quayle is going to set the vice presidency back about a decade or more.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Dan" lemma="Dan" stem="dan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="Quayle" lemma="Quayle" stem="quayl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="set" lemma="set" stem="set" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="vice" lemma="vice" stem="vice" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="presidency" lemma="presidency" stem="presid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="14" string="decade" lemma="decade" stem="decad" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="15" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NNP Dan) (NNP Quayle)) (VP (VBZ is) (VP (VBG going) (S (VP (TO to) (VP (VB set) (NP (DT the) (NN vice) (NN presidency)) (ADVP (RB back)) (PP (IN about) (NP (DT a) (NN decade) (QP (CC or) (JJR more))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="going to set the vice presidency back about a decade or more" type="VP">
          <tokens>
            <token id="5" string="going" />
            <token id="6" string="to" />
            <token id="7" string="set" />
            <token id="8" string="the" />
            <token id="9" string="vice" />
            <token id="10" string="presidency" />
            <token id="11" string="back" />
            <token id="12" string="about" />
            <token id="13" string="a" />
            <token id="14" string="decade" />
            <token id="15" string="or" />
            <token id="16" string="more" />
          </tokens>
        </chunking>
        <chunking id="2" string="the vice presidency" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="vice" />
            <token id="10" string="presidency" />
          </tokens>
        </chunking>
        <chunking id="3" string="to set the vice presidency back about a decade or more" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="set" />
            <token id="8" string="the" />
            <token id="9" string="vice" />
            <token id="10" string="presidency" />
            <token id="11" string="back" />
            <token id="12" string="about" />
            <token id="13" string="a" />
            <token id="14" string="decade" />
            <token id="15" string="or" />
            <token id="16" string="more" />
          </tokens>
        </chunking>
        <chunking id="4" string="is going to set the vice presidency back about a decade or more" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="going" />
            <token id="6" string="to" />
            <token id="7" string="set" />
            <token id="8" string="the" />
            <token id="9" string="vice" />
            <token id="10" string="presidency" />
            <token id="11" string="back" />
            <token id="12" string="about" />
            <token id="13" string="a" />
            <token id="14" string="decade" />
            <token id="15" string="or" />
            <token id="16" string="more" />
          </tokens>
        </chunking>
        <chunking id="5" string="set the vice presidency back about a decade or more" type="VP">
          <tokens>
            <token id="7" string="set" />
            <token id="8" string="the" />
            <token id="9" string="vice" />
            <token id="10" string="presidency" />
            <token id="11" string="back" />
            <token id="12" string="about" />
            <token id="13" string="a" />
            <token id="14" string="decade" />
            <token id="15" string="or" />
            <token id="16" string="more" />
          </tokens>
        </chunking>
        <chunking id="6" string="a decade or more" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="decade" />
            <token id="15" string="or" />
            <token id="16" string="more" />
          </tokens>
        </chunking>
        <chunking id="7" string="Dan Quayle" type="NP">
          <tokens>
            <token id="2" string="Dan" />
            <token id="3" string="Quayle" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Quayle</governor>
          <dependent id="2">Dan</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">going</governor>
          <dependent id="3">Quayle</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">going</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">set</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">going</governor>
          <dependent id="7">set</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">presidency</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">presidency</governor>
          <dependent id="9">vice</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">set</governor>
          <dependent id="10">presidency</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">set</governor>
          <dependent id="11">back</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">decade</governor>
          <dependent id="12">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">decade</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">set</governor>
          <dependent id="14">decade</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">more</governor>
          <dependent id="15">or</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">decade</governor>
          <dependent id="16">more</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Dan Quayle" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Dan" />
            <token id="3" string="Quayle" />
          </tokens>
        </entity>
        <entity id="2" string="about a decade" type="DURATION" score="0.0">
          <tokens>
            <token id="12" string="about" />
            <token id="13" string="a" />
            <token id="14" string="decade" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>One thing that political scientists have been talking about is just how much the vice presidency has grown.</content>
      <tokens>
        <token id="1" string="One" lemma="one" stem="one" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="2" string="thing" lemma="thing" stem="thing" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="scientists" lemma="scientist" stem="scientist" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="talking" lemma="talk" stem="talk" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="about" lemma="about" stem="about" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="much" lemma="much" stem="much" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="vice" lemma="vice" stem="vice" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="presidency" lemma="presidency" stem="presid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="grown" lemma="grow" stem="grown" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (CD One) (NN thing) (SBAR (WHNP (WDT that)) (S (NP (JJ political) (NNS scientists)) (VP (VBP have) (VP (VBN been) (VP (VBG talking) (ADVP (RB about)))))))) (VP (VBZ is) (SBAR (WHADVP (RB just) (WRB how) (RB much)) (S (NP (DT the) (NN vice) (NN presidency)) (VP (VBZ has) (VP (VBN grown)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="One thing that political scientists have been talking about" type="NP">
          <tokens>
            <token id="1" string="One" />
            <token id="2" string="thing" />
            <token id="3" string="that" />
            <token id="4" string="political" />
            <token id="5" string="scientists" />
            <token id="6" string="have" />
            <token id="7" string="been" />
            <token id="8" string="talking" />
            <token id="9" string="about" />
          </tokens>
        </chunking>
        <chunking id="2" string="have been talking about" type="VP">
          <tokens>
            <token id="6" string="have" />
            <token id="7" string="been" />
            <token id="8" string="talking" />
            <token id="9" string="about" />
          </tokens>
        </chunking>
        <chunking id="3" string="the vice presidency" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="vice" />
            <token id="16" string="presidency" />
          </tokens>
        </chunking>
        <chunking id="4" string="political scientists" type="NP">
          <tokens>
            <token id="4" string="political" />
            <token id="5" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="5" string="talking about" type="VP">
          <tokens>
            <token id="8" string="talking" />
            <token id="9" string="about" />
          </tokens>
        </chunking>
        <chunking id="6" string="is just how much the vice presidency has grown" type="VP">
          <tokens>
            <token id="10" string="is" />
            <token id="11" string="just" />
            <token id="12" string="how" />
            <token id="13" string="much" />
            <token id="14" string="the" />
            <token id="15" string="vice" />
            <token id="16" string="presidency" />
            <token id="17" string="has" />
            <token id="18" string="grown" />
          </tokens>
        </chunking>
        <chunking id="7" string="just how much the vice presidency has grown" type="SBAR">
          <tokens>
            <token id="11" string="just" />
            <token id="12" string="how" />
            <token id="13" string="much" />
            <token id="14" string="the" />
            <token id="15" string="vice" />
            <token id="16" string="presidency" />
            <token id="17" string="has" />
            <token id="18" string="grown" />
          </tokens>
        </chunking>
        <chunking id="8" string="has grown" type="VP">
          <tokens>
            <token id="17" string="has" />
            <token id="18" string="grown" />
          </tokens>
        </chunking>
        <chunking id="9" string="been talking about" type="VP">
          <tokens>
            <token id="7" string="been" />
            <token id="8" string="talking" />
            <token id="9" string="about" />
          </tokens>
        </chunking>
        <chunking id="10" string="just how much" type="WHADVP">
          <tokens>
            <token id="11" string="just" />
            <token id="12" string="how" />
            <token id="13" string="much" />
          </tokens>
        </chunking>
        <chunking id="11" string="grown" type="VP">
          <tokens>
            <token id="18" string="grown" />
          </tokens>
        </chunking>
        <chunking id="12" string="that political scientists have been talking about" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="political" />
            <token id="5" string="scientists" />
            <token id="6" string="have" />
            <token id="7" string="been" />
            <token id="8" string="talking" />
            <token id="9" string="about" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nummod">
          <governor id="2">thing</governor>
          <dependent id="1">One</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">is</governor>
          <dependent id="2">thing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">talking</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">scientists</governor>
          <dependent id="4">political</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">talking</governor>
          <dependent id="5">scientists</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">talking</governor>
          <dependent id="6">have</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">talking</governor>
          <dependent id="7">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">thing</governor>
          <dependent id="8">talking</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">talking</governor>
          <dependent id="9">about</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">much</governor>
          <dependent id="11">just</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">much</governor>
          <dependent id="12">how</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">grown</governor>
          <dependent id="13">much</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">presidency</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">presidency</governor>
          <dependent id="15">vice</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">grown</governor>
          <dependent id="16">presidency</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">grown</governor>
          <dependent id="17">has</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">is</governor>
          <dependent id="18">grown</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="One" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="One" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>... With Quayle, it&amp;apost;s just going to retreat to the old days of politics and funerals,&amp;apost;&amp;apost; said Ryan Barilleaux, a professor of political science at Miami University in Oxford, Ohio, who studies the American presidency.</content>
      <tokens>
        <token id="1" string="..." lemma="..." stem="..." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="With" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Quayle" lemma="Quayle" stem="quayl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="retreat" lemma="retreat" stem="retreat" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="13" string="old" lemma="old" stem="old" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="14" string="days" lemma="day" stem="dai" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="politics" lemma="politics" stem="polit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="funerals" lemma="funeral" stem="funer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="Ryan" lemma="Ryan" stem="ryan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="23" string="Barilleaux" lemma="Barilleaux" stem="barilleaux" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="professor" lemma="professor" stem="professor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="science" lemma="science" stem="scienc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="Miami" lemma="Miami" stem="miami" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="32" string="University" lemma="University" stem="univers" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="33" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="34" string="Oxford" lemma="Oxford" stem="oxford" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="35" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="Ohio" lemma="Ohio" stem="ohio" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="37" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="studies" lemma="study" stem="studi" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="41" string="American" lemma="american" stem="american" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="42" string="presidency" lemma="presidency" stem="presid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="43" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ...) (PP (IN With) (NP (NNP Quayle))) (, ,) (NP (PRP it)) (VP (VBZ 's) (ADVP (RB just)) (VP (VBG going) (S (VP (TO to) (VP (VB retreat) (PP (TO to) (NP (NP (DT the) (JJ old) (NNS days)) (PP (IN of) (NP (NNS politics) (CC and) (NNS funerals))))) (PRN (, ,) ('' '') (SINV (VP (VBD said)) (NP (NNP Ryan) (NNP Barilleaux))) (, ,)) (NP (NP (DT a) (NN professor)) (PP (IN of) (NP (JJ political) (NN science)))) (PP (IN at) (NP (NP (NNP Miami) (NNP University)) (PP (IN in) (NP (NP (NNP Oxford) (, ,) (NNP Ohio)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBZ studies) (NP (DT the) (JJ American) (NN presidency)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Quayle" type="NP">
          <tokens>
            <token id="3" string="Quayle" />
          </tokens>
        </chunking>
        <chunking id="2" string="'s just going to retreat to the old days of politics and funerals , '' said Ryan Barilleaux , a professor of political science at Miami University in Oxford , Ohio , who studies the American presidency" type="VP">
          <tokens>
            <token id="6" string="'s" />
            <token id="7" string="just" />
            <token id="8" string="going" />
            <token id="9" string="to" />
            <token id="10" string="retreat" />
            <token id="11" string="to" />
            <token id="12" string="the" />
            <token id="13" string="old" />
            <token id="14" string="days" />
            <token id="15" string="of" />
            <token id="16" string="politics" />
            <token id="17" string="and" />
            <token id="18" string="funerals" />
            <token id="19" string="," />
            <token id="20" string="''" />
            <token id="21" string="said" />
            <token id="22" string="Ryan" />
            <token id="23" string="Barilleaux" />
            <token id="24" string="," />
            <token id="25" string="a" />
            <token id="26" string="professor" />
            <token id="27" string="of" />
            <token id="28" string="political" />
            <token id="29" string="science" />
            <token id="30" string="at" />
            <token id="31" string="Miami" />
            <token id="32" string="University" />
            <token id="33" string="in" />
            <token id="34" string="Oxford" />
            <token id="35" string="," />
            <token id="36" string="Ohio" />
            <token id="37" string="," />
            <token id="38" string="who" />
            <token id="39" string="studies" />
            <token id="40" string="the" />
            <token id="41" string="American" />
            <token id="42" string="presidency" />
          </tokens>
        </chunking>
        <chunking id="3" string="Oxford , Ohio , who studies the American presidency" type="NP">
          <tokens>
            <token id="34" string="Oxford" />
            <token id="35" string="," />
            <token id="36" string="Ohio" />
            <token id="37" string="," />
            <token id="38" string="who" />
            <token id="39" string="studies" />
            <token id="40" string="the" />
            <token id="41" string="American" />
            <token id="42" string="presidency" />
          </tokens>
        </chunking>
        <chunking id="4" string="the old days of politics and funerals" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="old" />
            <token id="14" string="days" />
            <token id="15" string="of" />
            <token id="16" string="politics" />
            <token id="17" string="and" />
            <token id="18" string="funerals" />
          </tokens>
        </chunking>
        <chunking id="5" string="Miami University in Oxford , Ohio , who studies the American presidency" type="NP">
          <tokens>
            <token id="31" string="Miami" />
            <token id="32" string="University" />
            <token id="33" string="in" />
            <token id="34" string="Oxford" />
            <token id="35" string="," />
            <token id="36" string="Ohio" />
            <token id="37" string="," />
            <token id="38" string="who" />
            <token id="39" string="studies" />
            <token id="40" string="the" />
            <token id="41" string="American" />
            <token id="42" string="presidency" />
          </tokens>
        </chunking>
        <chunking id="6" string="studies the American presidency" type="VP">
          <tokens>
            <token id="39" string="studies" />
            <token id="40" string="the" />
            <token id="41" string="American" />
            <token id="42" string="presidency" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="5" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="Ryan Barilleaux" type="NP">
          <tokens>
            <token id="22" string="Ryan" />
            <token id="23" string="Barilleaux" />
          </tokens>
        </chunking>
        <chunking id="9" string="the American presidency" type="NP">
          <tokens>
            <token id="40" string="the" />
            <token id="41" string="American" />
            <token id="42" string="presidency" />
          </tokens>
        </chunking>
        <chunking id="10" string="political science" type="NP">
          <tokens>
            <token id="28" string="political" />
            <token id="29" string="science" />
          </tokens>
        </chunking>
        <chunking id="11" string="Oxford , Ohio" type="NP">
          <tokens>
            <token id="34" string="Oxford" />
            <token id="35" string="," />
            <token id="36" string="Ohio" />
          </tokens>
        </chunking>
        <chunking id="12" string="retreat to the old days of politics and funerals , '' said Ryan Barilleaux , a professor of political science at Miami University in Oxford , Ohio , who studies the American presidency" type="VP">
          <tokens>
            <token id="10" string="retreat" />
            <token id="11" string="to" />
            <token id="12" string="the" />
            <token id="13" string="old" />
            <token id="14" string="days" />
            <token id="15" string="of" />
            <token id="16" string="politics" />
            <token id="17" string="and" />
            <token id="18" string="funerals" />
            <token id="19" string="," />
            <token id="20" string="''" />
            <token id="21" string="said" />
            <token id="22" string="Ryan" />
            <token id="23" string="Barilleaux" />
            <token id="24" string="," />
            <token id="25" string="a" />
            <token id="26" string="professor" />
            <token id="27" string="of" />
            <token id="28" string="political" />
            <token id="29" string="science" />
            <token id="30" string="at" />
            <token id="31" string="Miami" />
            <token id="32" string="University" />
            <token id="33" string="in" />
            <token id="34" string="Oxford" />
            <token id="35" string="," />
            <token id="36" string="Ohio" />
            <token id="37" string="," />
            <token id="38" string="who" />
            <token id="39" string="studies" />
            <token id="40" string="the" />
            <token id="41" string="American" />
            <token id="42" string="presidency" />
          </tokens>
        </chunking>
        <chunking id="13" string="to retreat to the old days of politics and funerals , '' said Ryan Barilleaux , a professor of political science at Miami University in Oxford , Ohio , who studies the American presidency" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="retreat" />
            <token id="11" string="to" />
            <token id="12" string="the" />
            <token id="13" string="old" />
            <token id="14" string="days" />
            <token id="15" string="of" />
            <token id="16" string="politics" />
            <token id="17" string="and" />
            <token id="18" string="funerals" />
            <token id="19" string="," />
            <token id="20" string="''" />
            <token id="21" string="said" />
            <token id="22" string="Ryan" />
            <token id="23" string="Barilleaux" />
            <token id="24" string="," />
            <token id="25" string="a" />
            <token id="26" string="professor" />
            <token id="27" string="of" />
            <token id="28" string="political" />
            <token id="29" string="science" />
            <token id="30" string="at" />
            <token id="31" string="Miami" />
            <token id="32" string="University" />
            <token id="33" string="in" />
            <token id="34" string="Oxford" />
            <token id="35" string="," />
            <token id="36" string="Ohio" />
            <token id="37" string="," />
            <token id="38" string="who" />
            <token id="39" string="studies" />
            <token id="40" string="the" />
            <token id="41" string="American" />
            <token id="42" string="presidency" />
          </tokens>
        </chunking>
        <chunking id="14" string="Miami University" type="NP">
          <tokens>
            <token id="31" string="Miami" />
            <token id="32" string="University" />
          </tokens>
        </chunking>
        <chunking id="15" string="the old days" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="old" />
            <token id="14" string="days" />
          </tokens>
        </chunking>
        <chunking id="16" string="politics and funerals" type="NP">
          <tokens>
            <token id="16" string="politics" />
            <token id="17" string="and" />
            <token id="18" string="funerals" />
          </tokens>
        </chunking>
        <chunking id="17" string="going to retreat to the old days of politics and funerals , '' said Ryan Barilleaux , a professor of political science at Miami University in Oxford , Ohio , who studies the American presidency" type="VP">
          <tokens>
            <token id="8" string="going" />
            <token id="9" string="to" />
            <token id="10" string="retreat" />
            <token id="11" string="to" />
            <token id="12" string="the" />
            <token id="13" string="old" />
            <token id="14" string="days" />
            <token id="15" string="of" />
            <token id="16" string="politics" />
            <token id="17" string="and" />
            <token id="18" string="funerals" />
            <token id="19" string="," />
            <token id="20" string="''" />
            <token id="21" string="said" />
            <token id="22" string="Ryan" />
            <token id="23" string="Barilleaux" />
            <token id="24" string="," />
            <token id="25" string="a" />
            <token id="26" string="professor" />
            <token id="27" string="of" />
            <token id="28" string="political" />
            <token id="29" string="science" />
            <token id="30" string="at" />
            <token id="31" string="Miami" />
            <token id="32" string="University" />
            <token id="33" string="in" />
            <token id="34" string="Oxford" />
            <token id="35" string="," />
            <token id="36" string="Ohio" />
            <token id="37" string="," />
            <token id="38" string="who" />
            <token id="39" string="studies" />
            <token id="40" string="the" />
            <token id="41" string="American" />
            <token id="42" string="presidency" />
          </tokens>
        </chunking>
        <chunking id="18" string="a professor of political science" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="professor" />
            <token id="27" string="of" />
            <token id="28" string="political" />
            <token id="29" string="science" />
          </tokens>
        </chunking>
        <chunking id="19" string="a professor" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="professor" />
          </tokens>
        </chunking>
        <chunking id="20" string="said" type="VP">
          <tokens>
            <token id="21" string="said" />
          </tokens>
        </chunking>
        <chunking id="21" string="who studies the American presidency" type="SBAR">
          <tokens>
            <token id="38" string="who" />
            <token id="39" string="studies" />
            <token id="40" string="the" />
            <token id="41" string="American" />
            <token id="42" string="presidency" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">Quayle</governor>
          <dependent id="2">With</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">going</governor>
          <dependent id="3">Quayle</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">going</governor>
          <dependent id="5">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">going</governor>
          <dependent id="6">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">going</governor>
          <dependent id="7">just</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">retreat</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">going</governor>
          <dependent id="10">retreat</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">days</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">days</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">days</governor>
          <dependent id="13">old</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">retreat</governor>
          <dependent id="14">days</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">politics</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">days</governor>
          <dependent id="16">politics</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">politics</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">politics</governor>
          <dependent id="18">funerals</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="10">retreat</governor>
          <dependent id="21">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Barilleaux</governor>
          <dependent id="22">Ryan</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">said</governor>
          <dependent id="23">Barilleaux</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">professor</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">retreat</governor>
          <dependent id="26">professor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">science</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">science</governor>
          <dependent id="28">political</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">professor</governor>
          <dependent id="29">science</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">University</governor>
          <dependent id="30">at</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">University</governor>
          <dependent id="31">Miami</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">retreat</governor>
          <dependent id="32">University</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">Ohio</governor>
          <dependent id="33">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">Ohio</governor>
          <dependent id="34">Oxford</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">University</governor>
          <dependent id="36">Ohio</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="39">studies</governor>
          <dependent id="38">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="36">Ohio</governor>
          <dependent id="39">studies</dependent>
        </dependency>
        <dependency type="det">
          <governor id="42">presidency</governor>
          <dependent id="40">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="42">presidency</governor>
          <dependent id="41">American</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="39">studies</governor>
          <dependent id="42">presidency</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Miami University in Oxford" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="31" string="Miami" />
            <token id="32" string="University" />
            <token id="33" string="in" />
            <token id="34" string="Oxford" />
          </tokens>
        </entity>
        <entity id="2" string="Quayle" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Quayle" />
          </tokens>
        </entity>
        <entity id="3" string="the old days" type="DURATION" score="0.0">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="old" />
            <token id="14" string="days" />
          </tokens>
        </entity>
        <entity id="4" string="Ryan Barilleaux" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Ryan" />
            <token id="23" string="Barilleaux" />
          </tokens>
        </entity>
        <entity id="5" string="Ohio" type="LOCATION" score="0.0">
          <tokens>
            <token id="36" string="Ohio" />
          </tokens>
        </entity>
        <entity id="6" string="American" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="41" string="American" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>Bush rarely mentioned his 41-year-old running mate during the campaign.</content>
      <tokens>
        <token id="1" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="rarely" lemma="rarely" stem="rare" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="mentioned" lemma="mention" stem="mention" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="41-year-old" lemma="41-year-old" stem="41-year-old" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="6" string="running" lemma="running" stem="run" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="mate" lemma="mate" stem="mate" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="campaign" lemma="campaign" stem="campaign" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Bush)) (ADVP (RB rarely)) (VP (VBD mentioned) (NP (PRP$ his) (JJ 41-year-old) (NN running) (NN mate)) (PP (IN during) (NP (DT the) (NN campaign)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his 41-year-old running mate" type="NP">
          <tokens>
            <token id="4" string="his" />
            <token id="5" string="41-year-old" />
            <token id="6" string="running" />
            <token id="7" string="mate" />
          </tokens>
        </chunking>
        <chunking id="2" string="the campaign" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="campaign" />
          </tokens>
        </chunking>
        <chunking id="3" string="mentioned his 41-year-old running mate during the campaign" type="VP">
          <tokens>
            <token id="3" string="mentioned" />
            <token id="4" string="his" />
            <token id="5" string="41-year-old" />
            <token id="6" string="running" />
            <token id="7" string="mate" />
            <token id="8" string="during" />
            <token id="9" string="the" />
            <token id="10" string="campaign" />
          </tokens>
        </chunking>
        <chunking id="4" string="Bush" type="NP">
          <tokens>
            <token id="1" string="Bush" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">mentioned</governor>
          <dependent id="1">Bush</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">mentioned</governor>
          <dependent id="2">rarely</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">mentioned</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">mate</governor>
          <dependent id="4">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">mate</governor>
          <dependent id="5">41-year-old</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">mate</governor>
          <dependent id="6">running</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">mentioned</governor>
          <dependent id="7">mate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">campaign</governor>
          <dependent id="8">during</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">campaign</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">mentioned</governor>
          <dependent id="10">campaign</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="41-year-old" type="DURATION" score="0.0">
          <tokens>
            <token id="5" string="41-year-old" />
          </tokens>
        </entity>
        <entity id="2" string="Bush" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Bush" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>When asked, Bush employed the stock lines that Quayle would ``make an outstanding vice president&amp;apost;&amp;apost; and had been ``tempered by steel&amp;apost;&amp;apost; as he weathered the early furor over his military service, academic record and personal life.</content>
      <tokens>
        <token id="1" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="asked" lemma="ask" stem="ask" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="employed" lemma="employ" stem="emploi" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="stock" lemma="stock" stem="stock" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="lines" lemma="line" stem="line" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Quayle" lemma="Quayle" stem="quayl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="outstanding" lemma="outstanding" stem="outstand" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="vice" lemma="vice" stem="vice" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="president" lemma="president" stem="presid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="tempered" lemma="temper" stem="temper" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="steel" lemma="steel" stem="steel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="weathered" lemma="weather" stem="weather" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="early" lemma="early" stem="earli" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="furor" lemma="furor" stem="furor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="military" lemma="military" stem="militari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="service" lemma="service" stem="servic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="academic" lemma="academic" stem="academ" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="record" lemma="record" stem="record" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="personal" lemma="personal" stem="person" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHADVP (WRB When)) (S (VP (VBN asked)))) (, ,) (NP (NNP Bush)) (VP (VP (VBD employed) (NP (NP (DT the) (NN stock) (NNS lines)) (SBAR (WHNP (WDT that)) (S (NP (NNP Quayle)) (VP (MD would) (VP (`` ``) (VB make) (NP (DT an) (JJ outstanding) (NN vice) (NN president)) ('' ''))))))) (CC and) (VP (VBD had) (VP (VBN been) (VP (`` ``) (VBN tempered) (PP (IN by) (NP (NN steel))) ('' '') (SBAR (IN as) (S (NP (PRP he)) (VP (VBD weathered) (NP (DT the) (JJ early) (NN furor)) (PP (IN over) (NP (NP (PRP$ his) (JJ military) (NN service)) (, ,) (NP (JJ academic) (NN record)) (CC and) (NP (JJ personal) (NN life))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the stock lines that Quayle would `` make an outstanding vice president ''" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="stock" />
            <token id="8" string="lines" />
            <token id="9" string="that" />
            <token id="10" string="Quayle" />
            <token id="11" string="would" />
            <token id="12" string="``" />
            <token id="13" string="make" />
            <token id="14" string="an" />
            <token id="15" string="outstanding" />
            <token id="16" string="vice" />
            <token id="17" string="president" />
            <token id="18" string="''" />
          </tokens>
        </chunking>
        <chunking id="2" string="Quayle" type="NP">
          <tokens>
            <token id="10" string="Quayle" />
          </tokens>
        </chunking>
        <chunking id="3" string="an outstanding vice president" type="NP">
          <tokens>
            <token id="14" string="an" />
            <token id="15" string="outstanding" />
            <token id="16" string="vice" />
            <token id="17" string="president" />
          </tokens>
        </chunking>
        <chunking id="4" string="employed the stock lines that Quayle would `` make an outstanding vice president ''" type="VP">
          <tokens>
            <token id="5" string="employed" />
            <token id="6" string="the" />
            <token id="7" string="stock" />
            <token id="8" string="lines" />
            <token id="9" string="that" />
            <token id="10" string="Quayle" />
            <token id="11" string="would" />
            <token id="12" string="``" />
            <token id="13" string="make" />
            <token id="14" string="an" />
            <token id="15" string="outstanding" />
            <token id="16" string="vice" />
            <token id="17" string="president" />
            <token id="18" string="''" />
          </tokens>
        </chunking>
        <chunking id="5" string="as he weathered the early furor over his military service , academic record and personal life" type="SBAR">
          <tokens>
            <token id="27" string="as" />
            <token id="28" string="he" />
            <token id="29" string="weathered" />
            <token id="30" string="the" />
            <token id="31" string="early" />
            <token id="32" string="furor" />
            <token id="33" string="over" />
            <token id="34" string="his" />
            <token id="35" string="military" />
            <token id="36" string="service" />
            <token id="37" string="," />
            <token id="38" string="academic" />
            <token id="39" string="record" />
            <token id="40" string="and" />
            <token id="41" string="personal" />
            <token id="42" string="life" />
          </tokens>
        </chunking>
        <chunking id="6" string="employed the stock lines that Quayle would `` make an outstanding vice president '' and had been `` tempered by steel '' as he weathered the early furor over his military service , academic record and personal life" type="VP">
          <tokens>
            <token id="5" string="employed" />
            <token id="6" string="the" />
            <token id="7" string="stock" />
            <token id="8" string="lines" />
            <token id="9" string="that" />
            <token id="10" string="Quayle" />
            <token id="11" string="would" />
            <token id="12" string="``" />
            <token id="13" string="make" />
            <token id="14" string="an" />
            <token id="15" string="outstanding" />
            <token id="16" string="vice" />
            <token id="17" string="president" />
            <token id="18" string="''" />
            <token id="19" string="and" />
            <token id="20" string="had" />
            <token id="21" string="been" />
            <token id="22" string="``" />
            <token id="23" string="tempered" />
            <token id="24" string="by" />
            <token id="25" string="steel" />
            <token id="26" string="''" />
            <token id="27" string="as" />
            <token id="28" string="he" />
            <token id="29" string="weathered" />
            <token id="30" string="the" />
            <token id="31" string="early" />
            <token id="32" string="furor" />
            <token id="33" string="over" />
            <token id="34" string="his" />
            <token id="35" string="military" />
            <token id="36" string="service" />
            <token id="37" string="," />
            <token id="38" string="academic" />
            <token id="39" string="record" />
            <token id="40" string="and" />
            <token id="41" string="personal" />
            <token id="42" string="life" />
          </tokens>
        </chunking>
        <chunking id="7" string="the stock lines" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="stock" />
            <token id="8" string="lines" />
          </tokens>
        </chunking>
        <chunking id="8" string="academic record" type="NP">
          <tokens>
            <token id="38" string="academic" />
            <token id="39" string="record" />
          </tokens>
        </chunking>
        <chunking id="9" string="When" type="WHADVP">
          <tokens>
            <token id="1" string="When" />
          </tokens>
        </chunking>
        <chunking id="10" string="personal life" type="NP">
          <tokens>
            <token id="41" string="personal" />
            <token id="42" string="life" />
          </tokens>
        </chunking>
        <chunking id="11" string="been `` tempered by steel '' as he weathered the early furor over his military service , academic record and personal life" type="VP">
          <tokens>
            <token id="21" string="been" />
            <token id="22" string="``" />
            <token id="23" string="tempered" />
            <token id="24" string="by" />
            <token id="25" string="steel" />
            <token id="26" string="''" />
            <token id="27" string="as" />
            <token id="28" string="he" />
            <token id="29" string="weathered" />
            <token id="30" string="the" />
            <token id="31" string="early" />
            <token id="32" string="furor" />
            <token id="33" string="over" />
            <token id="34" string="his" />
            <token id="35" string="military" />
            <token id="36" string="service" />
            <token id="37" string="," />
            <token id="38" string="academic" />
            <token id="39" string="record" />
            <token id="40" string="and" />
            <token id="41" string="personal" />
            <token id="42" string="life" />
          </tokens>
        </chunking>
        <chunking id="12" string="`` make an outstanding vice president ''" type="VP">
          <tokens>
            <token id="12" string="``" />
            <token id="13" string="make" />
            <token id="14" string="an" />
            <token id="15" string="outstanding" />
            <token id="16" string="vice" />
            <token id="17" string="president" />
            <token id="18" string="''" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="28" string="he" />
          </tokens>
        </chunking>
        <chunking id="14" string="that Quayle would `` make an outstanding vice president ''" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="Quayle" />
            <token id="11" string="would" />
            <token id="12" string="``" />
            <token id="13" string="make" />
            <token id="14" string="an" />
            <token id="15" string="outstanding" />
            <token id="16" string="vice" />
            <token id="17" string="president" />
            <token id="18" string="''" />
          </tokens>
        </chunking>
        <chunking id="15" string="When asked" type="SBAR">
          <tokens>
            <token id="1" string="When" />
            <token id="2" string="asked" />
          </tokens>
        </chunking>
        <chunking id="16" string="steel" type="NP">
          <tokens>
            <token id="25" string="steel" />
          </tokens>
        </chunking>
        <chunking id="17" string="his military service , academic record and personal life" type="NP">
          <tokens>
            <token id="34" string="his" />
            <token id="35" string="military" />
            <token id="36" string="service" />
            <token id="37" string="," />
            <token id="38" string="academic" />
            <token id="39" string="record" />
            <token id="40" string="and" />
            <token id="41" string="personal" />
            <token id="42" string="life" />
          </tokens>
        </chunking>
        <chunking id="18" string="his military service" type="NP">
          <tokens>
            <token id="34" string="his" />
            <token id="35" string="military" />
            <token id="36" string="service" />
          </tokens>
        </chunking>
        <chunking id="19" string="weathered the early furor over his military service , academic record and personal life" type="VP">
          <tokens>
            <token id="29" string="weathered" />
            <token id="30" string="the" />
            <token id="31" string="early" />
            <token id="32" string="furor" />
            <token id="33" string="over" />
            <token id="34" string="his" />
            <token id="35" string="military" />
            <token id="36" string="service" />
            <token id="37" string="," />
            <token id="38" string="academic" />
            <token id="39" string="record" />
            <token id="40" string="and" />
            <token id="41" string="personal" />
            <token id="42" string="life" />
          </tokens>
        </chunking>
        <chunking id="20" string="the early furor" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="early" />
            <token id="32" string="furor" />
          </tokens>
        </chunking>
        <chunking id="21" string="`` tempered by steel '' as he weathered the early furor over his military service , academic record and personal life" type="VP">
          <tokens>
            <token id="22" string="``" />
            <token id="23" string="tempered" />
            <token id="24" string="by" />
            <token id="25" string="steel" />
            <token id="26" string="''" />
            <token id="27" string="as" />
            <token id="28" string="he" />
            <token id="29" string="weathered" />
            <token id="30" string="the" />
            <token id="31" string="early" />
            <token id="32" string="furor" />
            <token id="33" string="over" />
            <token id="34" string="his" />
            <token id="35" string="military" />
            <token id="36" string="service" />
            <token id="37" string="," />
            <token id="38" string="academic" />
            <token id="39" string="record" />
            <token id="40" string="and" />
            <token id="41" string="personal" />
            <token id="42" string="life" />
          </tokens>
        </chunking>
        <chunking id="22" string="Bush" type="NP">
          <tokens>
            <token id="4" string="Bush" />
          </tokens>
        </chunking>
        <chunking id="23" string="would `` make an outstanding vice president ''" type="VP">
          <tokens>
            <token id="11" string="would" />
            <token id="12" string="``" />
            <token id="13" string="make" />
            <token id="14" string="an" />
            <token id="15" string="outstanding" />
            <token id="16" string="vice" />
            <token id="17" string="president" />
            <token id="18" string="''" />
          </tokens>
        </chunking>
        <chunking id="24" string="asked" type="VP">
          <tokens>
            <token id="2" string="asked" />
          </tokens>
        </chunking>
        <chunking id="25" string="had been `` tempered by steel '' as he weathered the early furor over his military service , academic record and personal life" type="VP">
          <tokens>
            <token id="20" string="had" />
            <token id="21" string="been" />
            <token id="22" string="``" />
            <token id="23" string="tempered" />
            <token id="24" string="by" />
            <token id="25" string="steel" />
            <token id="26" string="''" />
            <token id="27" string="as" />
            <token id="28" string="he" />
            <token id="29" string="weathered" />
            <token id="30" string="the" />
            <token id="31" string="early" />
            <token id="32" string="furor" />
            <token id="33" string="over" />
            <token id="34" string="his" />
            <token id="35" string="military" />
            <token id="36" string="service" />
            <token id="37" string="," />
            <token id="38" string="academic" />
            <token id="39" string="record" />
            <token id="40" string="and" />
            <token id="41" string="personal" />
            <token id="42" string="life" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="2">asked</governor>
          <dependent id="1">When</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">employed</governor>
          <dependent id="2">asked</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">employed</governor>
          <dependent id="4">Bush</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">employed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">lines</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">lines</governor>
          <dependent id="7">stock</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">employed</governor>
          <dependent id="8">lines</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">make</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">make</governor>
          <dependent id="10">Quayle</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">make</governor>
          <dependent id="11">would</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">lines</governor>
          <dependent id="13">make</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">president</governor>
          <dependent id="14">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">president</governor>
          <dependent id="15">outstanding</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">president</governor>
          <dependent id="16">vice</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">make</governor>
          <dependent id="17">president</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">employed</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="23">tempered</governor>
          <dependent id="20">had</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="23">tempered</governor>
          <dependent id="21">been</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">employed</governor>
          <dependent id="23">tempered</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">steel</governor>
          <dependent id="24">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">tempered</governor>
          <dependent id="25">steel</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">weathered</governor>
          <dependent id="27">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">weathered</governor>
          <dependent id="28">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="23">tempered</governor>
          <dependent id="29">weathered</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">furor</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">furor</governor>
          <dependent id="31">early</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">weathered</governor>
          <dependent id="32">furor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">service</governor>
          <dependent id="33">over</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="36">service</governor>
          <dependent id="34">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="36">service</governor>
          <dependent id="35">military</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">weathered</governor>
          <dependent id="36">service</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="39">record</governor>
          <dependent id="38">academic</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="36">service</governor>
          <dependent id="39">record</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="36">service</governor>
          <dependent id="40">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="42">life</governor>
          <dependent id="41">personal</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="36">service</governor>
          <dependent id="42">life</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Quayle" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Quayle" />
          </tokens>
        </entity>
        <entity id="2" string="Bush" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Bush" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>The president-elect told reporters Quayle would have access to the same papers, information and intelligence that is available to the president.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="president-elect" lemma="president-elect" stem="president-elect" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="reporters" lemma="reporter" stem="report" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="Quayle" lemma="Quayle" stem="quayl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="access" lemma="access" stem="access" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="same" lemma="same" stem="same" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="papers" lemma="papers" stem="paper" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="information" lemma="information" stem="inform" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="intelligence" lemma="intelligence" stem="intellig" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="available" lemma="available" stem="avail" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="22" string="president" lemma="president" stem="presid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN president-elect)) (VP (VBD told) (NP (NP (NNS reporters)) (SBAR (S (NP (NNP Quayle)) (VP (MD would) (VP (VB have) (NP (NP (NN access)) (PP (TO to) (NP (DT the) (JJ same) (NNS papers) (, ,) (NN information) (CC and) (NN intelligence))) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADJP (JJ available) (PP (TO to) (NP (DT the) (NN president)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="reporters" type="NP">
          <tokens>
            <token id="4" string="reporters" />
          </tokens>
        </chunking>
        <chunking id="2" string="the president" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="president" />
          </tokens>
        </chunking>
        <chunking id="3" string="Quayle" type="NP">
          <tokens>
            <token id="5" string="Quayle" />
          </tokens>
        </chunking>
        <chunking id="4" string="Quayle would have access to the same papers , information and intelligence that is available to the president" type="SBAR">
          <tokens>
            <token id="5" string="Quayle" />
            <token id="6" string="would" />
            <token id="7" string="have" />
            <token id="8" string="access" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="same" />
            <token id="12" string="papers" />
            <token id="13" string="," />
            <token id="14" string="information" />
            <token id="15" string="and" />
            <token id="16" string="intelligence" />
            <token id="17" string="that" />
            <token id="18" string="is" />
            <token id="19" string="available" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="president" />
          </tokens>
        </chunking>
        <chunking id="5" string="access" type="NP">
          <tokens>
            <token id="8" string="access" />
          </tokens>
        </chunking>
        <chunking id="6" string="is available to the president" type="VP">
          <tokens>
            <token id="18" string="is" />
            <token id="19" string="available" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="president" />
          </tokens>
        </chunking>
        <chunking id="7" string="the same papers , information and intelligence" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="same" />
            <token id="12" string="papers" />
            <token id="13" string="," />
            <token id="14" string="information" />
            <token id="15" string="and" />
            <token id="16" string="intelligence" />
          </tokens>
        </chunking>
        <chunking id="8" string="would have access to the same papers , information and intelligence that is available to the president" type="VP">
          <tokens>
            <token id="6" string="would" />
            <token id="7" string="have" />
            <token id="8" string="access" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="same" />
            <token id="12" string="papers" />
            <token id="13" string="," />
            <token id="14" string="information" />
            <token id="15" string="and" />
            <token id="16" string="intelligence" />
            <token id="17" string="that" />
            <token id="18" string="is" />
            <token id="19" string="available" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="president" />
          </tokens>
        </chunking>
        <chunking id="9" string="told reporters Quayle would have access to the same papers , information and intelligence that is available to the president" type="VP">
          <tokens>
            <token id="3" string="told" />
            <token id="4" string="reporters" />
            <token id="5" string="Quayle" />
            <token id="6" string="would" />
            <token id="7" string="have" />
            <token id="8" string="access" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="same" />
            <token id="12" string="papers" />
            <token id="13" string="," />
            <token id="14" string="information" />
            <token id="15" string="and" />
            <token id="16" string="intelligence" />
            <token id="17" string="that" />
            <token id="18" string="is" />
            <token id="19" string="available" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="president" />
          </tokens>
        </chunking>
        <chunking id="10" string="access to the same papers , information and intelligence that is available to the president" type="NP">
          <tokens>
            <token id="8" string="access" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="same" />
            <token id="12" string="papers" />
            <token id="13" string="," />
            <token id="14" string="information" />
            <token id="15" string="and" />
            <token id="16" string="intelligence" />
            <token id="17" string="that" />
            <token id="18" string="is" />
            <token id="19" string="available" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="president" />
          </tokens>
        </chunking>
        <chunking id="11" string="available to the president" type="ADJP">
          <tokens>
            <token id="19" string="available" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="president" />
          </tokens>
        </chunking>
        <chunking id="12" string="have access to the same papers , information and intelligence that is available to the president" type="VP">
          <tokens>
            <token id="7" string="have" />
            <token id="8" string="access" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="same" />
            <token id="12" string="papers" />
            <token id="13" string="," />
            <token id="14" string="information" />
            <token id="15" string="and" />
            <token id="16" string="intelligence" />
            <token id="17" string="that" />
            <token id="18" string="is" />
            <token id="19" string="available" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="president" />
          </tokens>
        </chunking>
        <chunking id="13" string="The president-elect" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="president-elect" />
          </tokens>
        </chunking>
        <chunking id="14" string="reporters Quayle would have access to the same papers , information and intelligence that is available to the president" type="NP">
          <tokens>
            <token id="4" string="reporters" />
            <token id="5" string="Quayle" />
            <token id="6" string="would" />
            <token id="7" string="have" />
            <token id="8" string="access" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="same" />
            <token id="12" string="papers" />
            <token id="13" string="," />
            <token id="14" string="information" />
            <token id="15" string="and" />
            <token id="16" string="intelligence" />
            <token id="17" string="that" />
            <token id="18" string="is" />
            <token id="19" string="available" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="president" />
          </tokens>
        </chunking>
        <chunking id="15" string="that is available to the president" type="SBAR">
          <tokens>
            <token id="17" string="that" />
            <token id="18" string="is" />
            <token id="19" string="available" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="president" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">president-elect</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">told</governor>
          <dependent id="2">president-elect</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">told</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">told</governor>
          <dependent id="4">reporters</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">have</governor>
          <dependent id="5">Quayle</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">have</governor>
          <dependent id="6">would</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">reporters</governor>
          <dependent id="7">have</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">have</governor>
          <dependent id="8">access</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">papers</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">papers</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">papers</governor>
          <dependent id="11">same</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">access</governor>
          <dependent id="12">papers</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">papers</governor>
          <dependent id="14">information</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">papers</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">papers</governor>
          <dependent id="16">intelligence</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">available</governor>
          <dependent id="17">that</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">available</governor>
          <dependent id="18">is</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">access</governor>
          <dependent id="19">available</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">president</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">president</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">available</governor>
          <dependent id="22">president</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Quayle" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Quayle" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>But he would go no further in describing what assignments he would give Quayle.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="go" lemma="go" stem="go" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="further" lemma="further" stem="further" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="describing" lemma="describe" stem="describ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="assignments" lemma="assignment" stem="assign" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="give" lemma="give" stem="give" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="Quayle" lemma="Quayle" stem="quayl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (PRP he)) (VP (MD would) (VP (VB go) (ADVP (DT no) (RBR further)) (PP (IN in) (S (VP (VBG describing) (SBAR (WHNP (WP what)) (S (NP (NP (NNS assignments)) (NP (PRP he))) (VP (MD would) (VP (VB give) (NP (NNP Quayle))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="assignments he" type="NP">
          <tokens>
            <token id="10" string="assignments" />
            <token id="11" string="he" />
          </tokens>
        </chunking>
        <chunking id="2" string="assignments" type="NP">
          <tokens>
            <token id="10" string="assignments" />
          </tokens>
        </chunking>
        <chunking id="3" string="give Quayle" type="VP">
          <tokens>
            <token id="13" string="give" />
            <token id="14" string="Quayle" />
          </tokens>
        </chunking>
        <chunking id="4" string="would go no further in describing what assignments he would give Quayle" type="VP">
          <tokens>
            <token id="3" string="would" />
            <token id="4" string="go" />
            <token id="5" string="no" />
            <token id="6" string="further" />
            <token id="7" string="in" />
            <token id="8" string="describing" />
            <token id="9" string="what" />
            <token id="10" string="assignments" />
            <token id="11" string="he" />
            <token id="12" string="would" />
            <token id="13" string="give" />
            <token id="14" string="Quayle" />
          </tokens>
        </chunking>
        <chunking id="5" string="Quayle" type="NP">
          <tokens>
            <token id="14" string="Quayle" />
          </tokens>
        </chunking>
        <chunking id="6" string="he" type="NP">
          <tokens>
            <token id="2" string="he" />
          </tokens>
        </chunking>
        <chunking id="7" string="describing what assignments he would give Quayle" type="VP">
          <tokens>
            <token id="8" string="describing" />
            <token id="9" string="what" />
            <token id="10" string="assignments" />
            <token id="11" string="he" />
            <token id="12" string="would" />
            <token id="13" string="give" />
            <token id="14" string="Quayle" />
          </tokens>
        </chunking>
        <chunking id="8" string="would give Quayle" type="VP">
          <tokens>
            <token id="12" string="would" />
            <token id="13" string="give" />
            <token id="14" string="Quayle" />
          </tokens>
        </chunking>
        <chunking id="9" string="go no further in describing what assignments he would give Quayle" type="VP">
          <tokens>
            <token id="4" string="go" />
            <token id="5" string="no" />
            <token id="6" string="further" />
            <token id="7" string="in" />
            <token id="8" string="describing" />
            <token id="9" string="what" />
            <token id="10" string="assignments" />
            <token id="11" string="he" />
            <token id="12" string="would" />
            <token id="13" string="give" />
            <token id="14" string="Quayle" />
          </tokens>
        </chunking>
        <chunking id="10" string="what assignments he would give Quayle" type="SBAR">
          <tokens>
            <token id="9" string="what" />
            <token id="10" string="assignments" />
            <token id="11" string="he" />
            <token id="12" string="would" />
            <token id="13" string="give" />
            <token id="14" string="Quayle" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">go</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">go</governor>
          <dependent id="2">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">go</governor>
          <dependent id="3">would</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">go</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">further</governor>
          <dependent id="5">no</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">go</governor>
          <dependent id="6">further</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">describing</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">go</governor>
          <dependent id="8">describing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">give</governor>
          <dependent id="9">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">give</governor>
          <dependent id="10">assignments</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">assignments</governor>
          <dependent id="11">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">give</governor>
          <dependent id="12">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">describing</governor>
          <dependent id="13">give</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">give</governor>
          <dependent id="14">Quayle</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Quayle" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Quayle" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>Quayle says Bush has talked to him about heading a space council, and that he assumes he&amp;apost;ll have a role in the administration&amp;apost;s anti-drug efforts.</content>
      <tokens>
        <token id="1" string="Quayle" lemma="Quayle" stem="quayl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="talked" lemma="talk" stem="talk" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="heading" lemma="head" stem="head" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="space" lemma="space" stem="space" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="council" lemma="council" stem="council" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="assumes" lemma="assume" stem="assum" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="'ll" lemma="will" stem="'ll" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="role" lemma="role" stem="role" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="administration" lemma="administration" stem="administr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="anti-drug" lemma="anti-drug" stem="anti-drug" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="efforts" lemma="effort" stem="effort" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Quayle)) (VP (VBZ says) (SBAR (SBAR (S (NP (NNP Bush)) (VP (VBZ has) (VP (VBN talked) (PP (TO to) (NP (PRP him))) (PP (IN about) (S (VP (VBG heading) (NP (DT a) (NN space) (NN council))))))))) (, ,) (CC and) (SBAR (IN that) (S (NP (PRP he)) (VP (VBZ assumes) (SBAR (S (NP (PRP he)) (VP (MD 'll) (VP (VB have) (NP (NP (DT a) (NN role)) (PP (IN in) (NP (NP (DT the) (NN administration) (POS 's)) (JJ anti-drug) (NNS efforts))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that he assumes he 'll have a role in the administration 's anti-drug efforts" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="he" />
            <token id="17" string="assumes" />
            <token id="18" string="he" />
            <token id="19" string="'ll" />
            <token id="20" string="have" />
            <token id="21" string="a" />
            <token id="22" string="role" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="administration" />
            <token id="26" string="'s" />
            <token id="27" string="anti-drug" />
            <token id="28" string="efforts" />
          </tokens>
        </chunking>
        <chunking id="2" string="Quayle" type="NP">
          <tokens>
            <token id="1" string="Quayle" />
          </tokens>
        </chunking>
        <chunking id="3" string="Bush has talked to him about heading a space council , and that he assumes he 'll have a role in the administration 's anti-drug efforts" type="SBAR">
          <tokens>
            <token id="3" string="Bush" />
            <token id="4" string="has" />
            <token id="5" string="talked" />
            <token id="6" string="to" />
            <token id="7" string="him" />
            <token id="8" string="about" />
            <token id="9" string="heading" />
            <token id="10" string="a" />
            <token id="11" string="space" />
            <token id="12" string="council" />
            <token id="13" string="," />
            <token id="14" string="and" />
            <token id="15" string="that" />
            <token id="16" string="he" />
            <token id="17" string="assumes" />
            <token id="18" string="he" />
            <token id="19" string="'ll" />
            <token id="20" string="have" />
            <token id="21" string="a" />
            <token id="22" string="role" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="administration" />
            <token id="26" string="'s" />
            <token id="27" string="anti-drug" />
            <token id="28" string="efforts" />
          </tokens>
        </chunking>
        <chunking id="4" string="him" type="NP">
          <tokens>
            <token id="7" string="him" />
          </tokens>
        </chunking>
        <chunking id="5" string="a role" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="role" />
          </tokens>
        </chunking>
        <chunking id="6" string="he 'll have a role in the administration 's anti-drug efforts" type="SBAR">
          <tokens>
            <token id="18" string="he" />
            <token id="19" string="'ll" />
            <token id="20" string="have" />
            <token id="21" string="a" />
            <token id="22" string="role" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="administration" />
            <token id="26" string="'s" />
            <token id="27" string="anti-drug" />
            <token id="28" string="efforts" />
          </tokens>
        </chunking>
        <chunking id="7" string="'ll have a role in the administration 's anti-drug efforts" type="VP">
          <tokens>
            <token id="19" string="'ll" />
            <token id="20" string="have" />
            <token id="21" string="a" />
            <token id="22" string="role" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="administration" />
            <token id="26" string="'s" />
            <token id="27" string="anti-drug" />
            <token id="28" string="efforts" />
          </tokens>
        </chunking>
        <chunking id="8" string="talked to him about heading a space council" type="VP">
          <tokens>
            <token id="5" string="talked" />
            <token id="6" string="to" />
            <token id="7" string="him" />
            <token id="8" string="about" />
            <token id="9" string="heading" />
            <token id="10" string="a" />
            <token id="11" string="space" />
            <token id="12" string="council" />
          </tokens>
        </chunking>
        <chunking id="9" string="have a role in the administration 's anti-drug efforts" type="VP">
          <tokens>
            <token id="20" string="have" />
            <token id="21" string="a" />
            <token id="22" string="role" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="administration" />
            <token id="26" string="'s" />
            <token id="27" string="anti-drug" />
            <token id="28" string="efforts" />
          </tokens>
        </chunking>
        <chunking id="10" string="a role in the administration 's anti-drug efforts" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="role" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="administration" />
            <token id="26" string="'s" />
            <token id="27" string="anti-drug" />
            <token id="28" string="efforts" />
          </tokens>
        </chunking>
        <chunking id="11" string="the administration 's anti-drug efforts" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="administration" />
            <token id="26" string="'s" />
            <token id="27" string="anti-drug" />
            <token id="28" string="efforts" />
          </tokens>
        </chunking>
        <chunking id="12" string="says Bush has talked to him about heading a space council , and that he assumes he 'll have a role in the administration 's anti-drug efforts" type="VP">
          <tokens>
            <token id="2" string="says" />
            <token id="3" string="Bush" />
            <token id="4" string="has" />
            <token id="5" string="talked" />
            <token id="6" string="to" />
            <token id="7" string="him" />
            <token id="8" string="about" />
            <token id="9" string="heading" />
            <token id="10" string="a" />
            <token id="11" string="space" />
            <token id="12" string="council" />
            <token id="13" string="," />
            <token id="14" string="and" />
            <token id="15" string="that" />
            <token id="16" string="he" />
            <token id="17" string="assumes" />
            <token id="18" string="he" />
            <token id="19" string="'ll" />
            <token id="20" string="have" />
            <token id="21" string="a" />
            <token id="22" string="role" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="administration" />
            <token id="26" string="'s" />
            <token id="27" string="anti-drug" />
            <token id="28" string="efforts" />
          </tokens>
        </chunking>
        <chunking id="13" string="Bush" type="NP">
          <tokens>
            <token id="3" string="Bush" />
          </tokens>
        </chunking>
        <chunking id="14" string="Bush has talked to him about heading a space council" type="SBAR">
          <tokens>
            <token id="3" string="Bush" />
            <token id="4" string="has" />
            <token id="5" string="talked" />
            <token id="6" string="to" />
            <token id="7" string="him" />
            <token id="8" string="about" />
            <token id="9" string="heading" />
            <token id="10" string="a" />
            <token id="11" string="space" />
            <token id="12" string="council" />
          </tokens>
        </chunking>
        <chunking id="15" string="the administration 's" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="administration" />
            <token id="26" string="'s" />
          </tokens>
        </chunking>
        <chunking id="16" string="has talked to him about heading a space council" type="VP">
          <tokens>
            <token id="4" string="has" />
            <token id="5" string="talked" />
            <token id="6" string="to" />
            <token id="7" string="him" />
            <token id="8" string="about" />
            <token id="9" string="heading" />
            <token id="10" string="a" />
            <token id="11" string="space" />
            <token id="12" string="council" />
          </tokens>
        </chunking>
        <chunking id="17" string="a space council" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="space" />
            <token id="12" string="council" />
          </tokens>
        </chunking>
        <chunking id="18" string="he" type="NP">
          <tokens>
            <token id="16" string="he" />
          </tokens>
        </chunking>
        <chunking id="19" string="assumes he 'll have a role in the administration 's anti-drug efforts" type="VP">
          <tokens>
            <token id="17" string="assumes" />
            <token id="18" string="he" />
            <token id="19" string="'ll" />
            <token id="20" string="have" />
            <token id="21" string="a" />
            <token id="22" string="role" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="administration" />
            <token id="26" string="'s" />
            <token id="27" string="anti-drug" />
            <token id="28" string="efforts" />
          </tokens>
        </chunking>
        <chunking id="20" string="heading a space council" type="VP">
          <tokens>
            <token id="9" string="heading" />
            <token id="10" string="a" />
            <token id="11" string="space" />
            <token id="12" string="council" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">says</governor>
          <dependent id="1">Quayle</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">says</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">talked</governor>
          <dependent id="3">Bush</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">talked</governor>
          <dependent id="4">has</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">says</governor>
          <dependent id="5">talked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">him</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">talked</governor>
          <dependent id="7">him</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">heading</governor>
          <dependent id="8">about</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">talked</governor>
          <dependent id="9">heading</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">council</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">council</governor>
          <dependent id="11">space</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">heading</governor>
          <dependent id="12">council</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">talked</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">assumes</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">assumes</governor>
          <dependent id="16">he</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">talked</governor>
          <dependent id="17">assumes</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">have</governor>
          <dependent id="18">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">have</governor>
          <dependent id="19">'ll</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">assumes</governor>
          <dependent id="20">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">role</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">have</governor>
          <dependent id="22">role</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">efforts</governor>
          <dependent id="23">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">administration</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="28">efforts</governor>
          <dependent id="25">administration</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">administration</governor>
          <dependent id="26">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">efforts</governor>
          <dependent id="27">anti-drug</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">role</governor>
          <dependent id="28">efforts</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Quayle" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Quayle" />
          </tokens>
        </entity>
        <entity id="2" string="Bush" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Bush" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>``I will be a very close adviser to the president,&amp;apost;&amp;apost; Quayle said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="close" lemma="close" stem="close" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="adviser" lemma="adviser" stem="advis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="president" lemma="president" stem="presid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Quayle" lemma="Quayle" stem="quayl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="15" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (MD will) (VP (VB be) (NP (NP (DT a) (ADJP (RB very) (JJ close)) (NN adviser)) (PP (TO to) (NP (DT the) (NN president))))))) (, ,) ('' '') (NP (NNP Quayle)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a very close adviser to the president" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="very" />
            <token id="7" string="close" />
            <token id="8" string="adviser" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="president" />
          </tokens>
        </chunking>
        <chunking id="2" string="the president" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="president" />
          </tokens>
        </chunking>
        <chunking id="3" string="Quayle" type="NP">
          <tokens>
            <token id="14" string="Quayle" />
          </tokens>
        </chunking>
        <chunking id="4" string="will be a very close adviser to the president" type="VP">
          <tokens>
            <token id="3" string="will" />
            <token id="4" string="be" />
            <token id="5" string="a" />
            <token id="6" string="very" />
            <token id="7" string="close" />
            <token id="8" string="adviser" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="president" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="be a very close adviser to the president" type="VP">
          <tokens>
            <token id="4" string="be" />
            <token id="5" string="a" />
            <token id="6" string="very" />
            <token id="7" string="close" />
            <token id="8" string="adviser" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="president" />
          </tokens>
        </chunking>
        <chunking id="7" string="a very close adviser" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="very" />
            <token id="7" string="close" />
            <token id="8" string="adviser" />
          </tokens>
        </chunking>
        <chunking id="8" string="said" type="VP">
          <tokens>
            <token id="15" string="said" />
          </tokens>
        </chunking>
        <chunking id="9" string="very close" type="ADJP">
          <tokens>
            <token id="6" string="very" />
            <token id="7" string="close" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="8">adviser</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">adviser</governor>
          <dependent id="3">will</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">adviser</governor>
          <dependent id="4">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">adviser</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">close</governor>
          <dependent id="6">very</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">adviser</governor>
          <dependent id="7">close</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">said</governor>
          <dependent id="8">adviser</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">president</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">president</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">adviser</governor>
          <dependent id="11">president</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">said</governor>
          <dependent id="14">Quayle</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Quayle" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Quayle" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>But that&amp;apost;s not the way everyone sees it.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="everyone" lemma="everyone" stem="everyon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="sees" lemma="see" stem="see" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (DT that)) (VP (VBZ 's) (RB not) (NP (NP (DT the) (NN way) (NN everyone)) (SBAR (S (VP (VBZ sees) (NP (PRP it))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that" type="NP">
          <tokens>
            <token id="2" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="sees it" type="SBAR">
          <tokens>
            <token id="8" string="sees" />
            <token id="9" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="the way everyone" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="way" />
            <token id="7" string="everyone" />
          </tokens>
        </chunking>
        <chunking id="4" string="the way everyone sees it" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="way" />
            <token id="7" string="everyone" />
            <token id="8" string="sees" />
            <token id="9" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="'s not the way everyone sees it" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="not" />
            <token id="5" string="the" />
            <token id="6" string="way" />
            <token id="7" string="everyone" />
            <token id="8" string="sees" />
            <token id="9" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="9" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="7">everyone</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">everyone</governor>
          <dependent id="2">that</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">everyone</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">everyone</governor>
          <dependent id="4">not</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">everyone</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">everyone</governor>
          <dependent id="6">way</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">everyone</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">everyone</governor>
          <dependent id="8">sees</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">sees</governor>
          <dependent id="9">it</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>Both Bush and Mondale came to their vice presidential campaigns with substantial reputations and were able to place key staffers in important positions in the respective presidential campaigns, Barilleaux notes.</content>
      <tokens>
        <token id="1" string="Both" lemma="both" stem="both" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="3" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="Mondale" lemma="Mondale" stem="mondal" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="5" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="vice" lemma="vice" stem="vice" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="presidential" lemma="presidential" stem="presidenti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="campaigns" lemma="campaign" stem="campaign" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="substantial" lemma="substantial" stem="substanti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="reputations" lemma="reputation" stem="reput" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="able" lemma="able" stem="abl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="place" lemma="place" stem="place" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="key" lemma="key" stem="kei" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="staffers" lemma="staffer" stem="staffer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="important" lemma="important" stem="import" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="positions" lemma="position" stem="posit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="respective" lemma="respective" stem="respect" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="presidential" lemma="presidential" stem="presidenti" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="campaigns" lemma="campaign" stem="campaign" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="Barilleaux" lemma="Barilleaux" stem="barilleaux" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="31" string="notes" lemma="note" stem="note" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT Both) (NNP Bush) (CC and) (NNP Mondale)) (VP (VP (VBD came) (PP (TO to) (NP (PRP$ their) (NN vice))) (NP-TMP (NP (JJ presidential) (NNS campaigns)) (PP (IN with) (NP (JJ substantial) (NNS reputations))))) (CC and) (VP (VBD were) (ADJP (JJ able) (S (VP (TO to) (VP (VB place) (NP (JJ key) (NNS staffers)) (PP (IN in) (NP (JJ important) (NNS positions))))))) (PP (IN in) (NP (NP (DT the) (JJ respective) (JJ presidential) (NNS campaigns)) (, ,) (NP (NNP Barilleaux) (NNS notes)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="place key staffers in important positions" type="VP">
          <tokens>
            <token id="18" string="place" />
            <token id="19" string="key" />
            <token id="20" string="staffers" />
            <token id="21" string="in" />
            <token id="22" string="important" />
            <token id="23" string="positions" />
          </tokens>
        </chunking>
        <chunking id="2" string="their vice" type="NP">
          <tokens>
            <token id="7" string="their" />
            <token id="8" string="vice" />
          </tokens>
        </chunking>
        <chunking id="3" string="presidential campaigns" type="NP">
          <tokens>
            <token id="9" string="presidential" />
            <token id="10" string="campaigns" />
          </tokens>
        </chunking>
        <chunking id="4" string="the respective presidential campaigns" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="respective" />
            <token id="27" string="presidential" />
            <token id="28" string="campaigns" />
          </tokens>
        </chunking>
        <chunking id="5" string="important positions" type="NP">
          <tokens>
            <token id="22" string="important" />
            <token id="23" string="positions" />
          </tokens>
        </chunking>
        <chunking id="6" string="able to place key staffers in important positions" type="ADJP">
          <tokens>
            <token id="16" string="able" />
            <token id="17" string="to" />
            <token id="18" string="place" />
            <token id="19" string="key" />
            <token id="20" string="staffers" />
            <token id="21" string="in" />
            <token id="22" string="important" />
            <token id="23" string="positions" />
          </tokens>
        </chunking>
        <chunking id="7" string="key staffers" type="NP">
          <tokens>
            <token id="19" string="key" />
            <token id="20" string="staffers" />
          </tokens>
        </chunking>
        <chunking id="8" string="the respective presidential campaigns , Barilleaux notes" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="respective" />
            <token id="27" string="presidential" />
            <token id="28" string="campaigns" />
            <token id="29" string="," />
            <token id="30" string="Barilleaux" />
            <token id="31" string="notes" />
          </tokens>
        </chunking>
        <chunking id="9" string="Barilleaux notes" type="NP">
          <tokens>
            <token id="30" string="Barilleaux" />
            <token id="31" string="notes" />
          </tokens>
        </chunking>
        <chunking id="10" string="substantial reputations" type="NP">
          <tokens>
            <token id="12" string="substantial" />
            <token id="13" string="reputations" />
          </tokens>
        </chunking>
        <chunking id="11" string="were able to place key staffers in important positions in the respective presidential campaigns , Barilleaux notes" type="VP">
          <tokens>
            <token id="15" string="were" />
            <token id="16" string="able" />
            <token id="17" string="to" />
            <token id="18" string="place" />
            <token id="19" string="key" />
            <token id="20" string="staffers" />
            <token id="21" string="in" />
            <token id="22" string="important" />
            <token id="23" string="positions" />
            <token id="24" string="in" />
            <token id="25" string="the" />
            <token id="26" string="respective" />
            <token id="27" string="presidential" />
            <token id="28" string="campaigns" />
            <token id="29" string="," />
            <token id="30" string="Barilleaux" />
            <token id="31" string="notes" />
          </tokens>
        </chunking>
        <chunking id="12" string="came to their vice presidential campaigns with substantial reputations" type="VP">
          <tokens>
            <token id="5" string="came" />
            <token id="6" string="to" />
            <token id="7" string="their" />
            <token id="8" string="vice" />
            <token id="9" string="presidential" />
            <token id="10" string="campaigns" />
            <token id="11" string="with" />
            <token id="12" string="substantial" />
            <token id="13" string="reputations" />
          </tokens>
        </chunking>
        <chunking id="13" string="came to their vice presidential campaigns with substantial reputations and were able to place key staffers in important positions in the respective presidential campaigns , Barilleaux notes" type="VP">
          <tokens>
            <token id="5" string="came" />
            <token id="6" string="to" />
            <token id="7" string="their" />
            <token id="8" string="vice" />
            <token id="9" string="presidential" />
            <token id="10" string="campaigns" />
            <token id="11" string="with" />
            <token id="12" string="substantial" />
            <token id="13" string="reputations" />
            <token id="14" string="and" />
            <token id="15" string="were" />
            <token id="16" string="able" />
            <token id="17" string="to" />
            <token id="18" string="place" />
            <token id="19" string="key" />
            <token id="20" string="staffers" />
            <token id="21" string="in" />
            <token id="22" string="important" />
            <token id="23" string="positions" />
            <token id="24" string="in" />
            <token id="25" string="the" />
            <token id="26" string="respective" />
            <token id="27" string="presidential" />
            <token id="28" string="campaigns" />
            <token id="29" string="," />
            <token id="30" string="Barilleaux" />
            <token id="31" string="notes" />
          </tokens>
        </chunking>
        <chunking id="14" string="to place key staffers in important positions" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="place" />
            <token id="19" string="key" />
            <token id="20" string="staffers" />
            <token id="21" string="in" />
            <token id="22" string="important" />
            <token id="23" string="positions" />
          </tokens>
        </chunking>
        <chunking id="15" string="Both Bush and Mondale" type="NP">
          <tokens>
            <token id="1" string="Both" />
            <token id="2" string="Bush" />
            <token id="3" string="and" />
            <token id="4" string="Mondale" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc:preconj">
          <governor id="2">Bush</governor>
          <dependent id="1">Both</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">came</governor>
          <dependent id="2">Bush</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">Bush</governor>
          <dependent id="3">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">Bush</governor>
          <dependent id="4">Mondale</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">came</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">vice</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">vice</governor>
          <dependent id="7">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">came</governor>
          <dependent id="8">vice</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">campaigns</governor>
          <dependent id="9">presidential</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="5">came</governor>
          <dependent id="10">campaigns</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">reputations</governor>
          <dependent id="11">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">reputations</governor>
          <dependent id="12">substantial</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">campaigns</governor>
          <dependent id="13">reputations</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">came</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">able</governor>
          <dependent id="15">were</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">came</governor>
          <dependent id="16">able</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">place</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">able</governor>
          <dependent id="18">place</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">staffers</governor>
          <dependent id="19">key</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">place</governor>
          <dependent id="20">staffers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">positions</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">positions</governor>
          <dependent id="22">important</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">place</governor>
          <dependent id="23">positions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">campaigns</governor>
          <dependent id="24">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">campaigns</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">campaigns</governor>
          <dependent id="26">respective</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">campaigns</governor>
          <dependent id="27">presidential</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">able</governor>
          <dependent id="28">campaigns</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">notes</governor>
          <dependent id="30">Barilleaux</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="28">campaigns</governor>
          <dependent id="31">notes</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mondale" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Mondale" />
          </tokens>
        </entity>
        <entity id="2" string="Bush" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Bush" />
          </tokens>
        </entity>
        <entity id="3" string="Barilleaux" type="PERSON" score="0.0">
          <tokens>
            <token id="30" string="Barilleaux" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>``Dan Quayle has contributed nothing in the way of staff to the Bush campaign.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Dan" lemma="Dan" stem="dan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="Quayle" lemma="Quayle" stem="quayl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="contributed" lemma="contribute" stem="contribut" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="nothing" lemma="nothing" stem="noth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="staff" lemma="staff" stem="staff" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="15" string="campaign" lemma="campaign" stem="campaign" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NNP Dan) (NNP Quayle)) (VP (VBZ has) (VP (VBN contributed) (NP (NP (NN nothing)) (PP (IN in) (NP (NP (DT the) (NN way)) (PP (IN of) (NP (NN staff)))))) (PP (TO to) (NP (DT the) (NNP Bush) (NN campaign))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="contributed nothing in the way of staff to the Bush campaign" type="VP">
          <tokens>
            <token id="5" string="contributed" />
            <token id="6" string="nothing" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="way" />
            <token id="10" string="of" />
            <token id="11" string="staff" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="Bush" />
            <token id="15" string="campaign" />
          </tokens>
        </chunking>
        <chunking id="2" string="has contributed nothing in the way of staff to the Bush campaign" type="VP">
          <tokens>
            <token id="4" string="has" />
            <token id="5" string="contributed" />
            <token id="6" string="nothing" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="way" />
            <token id="10" string="of" />
            <token id="11" string="staff" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="Bush" />
            <token id="15" string="campaign" />
          </tokens>
        </chunking>
        <chunking id="3" string="the way" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="way" />
          </tokens>
        </chunking>
        <chunking id="4" string="staff" type="NP">
          <tokens>
            <token id="11" string="staff" />
          </tokens>
        </chunking>
        <chunking id="5" string="nothing" type="NP">
          <tokens>
            <token id="6" string="nothing" />
          </tokens>
        </chunking>
        <chunking id="6" string="the way of staff" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="way" />
            <token id="10" string="of" />
            <token id="11" string="staff" />
          </tokens>
        </chunking>
        <chunking id="7" string="nothing in the way of staff" type="NP">
          <tokens>
            <token id="6" string="nothing" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="way" />
            <token id="10" string="of" />
            <token id="11" string="staff" />
          </tokens>
        </chunking>
        <chunking id="8" string="Dan Quayle" type="NP">
          <tokens>
            <token id="2" string="Dan" />
            <token id="3" string="Quayle" />
          </tokens>
        </chunking>
        <chunking id="9" string="the Bush campaign" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="Bush" />
            <token id="15" string="campaign" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Quayle</governor>
          <dependent id="2">Dan</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">contributed</governor>
          <dependent id="3">Quayle</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">contributed</governor>
          <dependent id="4">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">contributed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">contributed</governor>
          <dependent id="6">nothing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">way</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">way</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">nothing</governor>
          <dependent id="9">way</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">staff</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">way</governor>
          <dependent id="11">staff</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">campaign</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">campaign</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">campaign</governor>
          <dependent id="14">Bush</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">contributed</governor>
          <dependent id="15">campaign</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Bush" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Bush" />
          </tokens>
        </entity>
        <entity id="2" string="Dan Quayle" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Dan" />
            <token id="3" string="Quayle" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>He doesn&amp;apost;t have his own big reputation on Capitol Hill.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="big" lemma="big" stem="big" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="reputation" lemma="reputation" stem="reput" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Capitol" lemma="Capitol" stem="capitol" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="11" string="Hill" lemma="Hill" stem="hill" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBZ does) (RB n't) (VP (VB have) (NP (NP (PRP$ his) (JJ own) (JJ big) (NN reputation)) (PP (IN on) (NP (NNP Capitol) (NNP Hill)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Capitol Hill" type="NP">
          <tokens>
            <token id="10" string="Capitol" />
            <token id="11" string="Hill" />
          </tokens>
        </chunking>
        <chunking id="2" string="have his own big reputation on Capitol Hill" type="VP">
          <tokens>
            <token id="4" string="have" />
            <token id="5" string="his" />
            <token id="6" string="own" />
            <token id="7" string="big" />
            <token id="8" string="reputation" />
            <token id="9" string="on" />
            <token id="10" string="Capitol" />
            <token id="11" string="Hill" />
          </tokens>
        </chunking>
        <chunking id="3" string="his own big reputation" type="NP">
          <tokens>
            <token id="5" string="his" />
            <token id="6" string="own" />
            <token id="7" string="big" />
            <token id="8" string="reputation" />
          </tokens>
        </chunking>
        <chunking id="4" string="does n't have his own big reputation on Capitol Hill" type="VP">
          <tokens>
            <token id="2" string="does" />
            <token id="3" string="n't" />
            <token id="4" string="have" />
            <token id="5" string="his" />
            <token id="6" string="own" />
            <token id="7" string="big" />
            <token id="8" string="reputation" />
            <token id="9" string="on" />
            <token id="10" string="Capitol" />
            <token id="11" string="Hill" />
          </tokens>
        </chunking>
        <chunking id="5" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="6" string="his own big reputation on Capitol Hill" type="NP">
          <tokens>
            <token id="5" string="his" />
            <token id="6" string="own" />
            <token id="7" string="big" />
            <token id="8" string="reputation" />
            <token id="9" string="on" />
            <token id="10" string="Capitol" />
            <token id="11" string="Hill" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">have</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">have</governor>
          <dependent id="2">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">have</governor>
          <dependent id="3">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">have</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">reputation</governor>
          <dependent id="5">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">reputation</governor>
          <dependent id="6">own</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">reputation</governor>
          <dependent id="7">big</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">have</governor>
          <dependent id="8">reputation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Hill</governor>
          <dependent id="9">on</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Hill</governor>
          <dependent id="10">Capitol</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">reputation</governor>
          <dependent id="11">Hill</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Capitol Hill" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="Capitol" />
            <token id="11" string="Hill" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>... Dan Quayle has no friends in a Bush White House except George Bush,&amp;apost;&amp;apost; Barilleaux says.</content>
      <tokens>
        <token id="1" string="..." lemma="..." stem="..." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Dan" lemma="Dan" stem="dan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="Quayle" lemma="Quayle" stem="quayl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="friends" lemma="friend" stem="friend" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="10" string="White" lemma="White" stem="white" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="11" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="12" string="except" lemma="except" stem="except" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="George" lemma="George" stem="georg" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="14" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Barilleaux" lemma="Barilleaux" stem="barilleaux" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="18" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ...) (S (S (NP (NNP Dan) (NNP Quayle)) (VP (VBZ has) (NP (NP (DT no) (NNS friends)) (PP (IN in) (NP (DT a) (NNP Bush) (NNP White) (NNP House) (IN except) (NNP George) (NNP Bush)))))) (, ,) ('' '') (NP (NNP Barilleaux)) (VP (VBZ says))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="no friends in a Bush White House except George Bush" type="NP">
          <tokens>
            <token id="5" string="no" />
            <token id="6" string="friends" />
            <token id="7" string="in" />
            <token id="8" string="a" />
            <token id="9" string="Bush" />
            <token id="10" string="White" />
            <token id="11" string="House" />
            <token id="12" string="except" />
            <token id="13" string="George" />
            <token id="14" string="Bush" />
          </tokens>
        </chunking>
        <chunking id="2" string="says" type="VP">
          <tokens>
            <token id="18" string="says" />
          </tokens>
        </chunking>
        <chunking id="3" string="has no friends in a Bush White House except George Bush" type="VP">
          <tokens>
            <token id="4" string="has" />
            <token id="5" string="no" />
            <token id="6" string="friends" />
            <token id="7" string="in" />
            <token id="8" string="a" />
            <token id="9" string="Bush" />
            <token id="10" string="White" />
            <token id="11" string="House" />
            <token id="12" string="except" />
            <token id="13" string="George" />
            <token id="14" string="Bush" />
          </tokens>
        </chunking>
        <chunking id="4" string="Barilleaux" type="NP">
          <tokens>
            <token id="17" string="Barilleaux" />
          </tokens>
        </chunking>
        <chunking id="5" string="a Bush White House except George Bush" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="Bush" />
            <token id="10" string="White" />
            <token id="11" string="House" />
            <token id="12" string="except" />
            <token id="13" string="George" />
            <token id="14" string="Bush" />
          </tokens>
        </chunking>
        <chunking id="6" string="Dan Quayle" type="NP">
          <tokens>
            <token id="2" string="Dan" />
            <token id="3" string="Quayle" />
          </tokens>
        </chunking>
        <chunking id="7" string="no friends" type="NP">
          <tokens>
            <token id="5" string="no" />
            <token id="6" string="friends" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Quayle</governor>
          <dependent id="2">Dan</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">has</governor>
          <dependent id="3">Quayle</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">says</governor>
          <dependent id="4">has</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">friends</governor>
          <dependent id="5">no</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">has</governor>
          <dependent id="6">friends</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Bush</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">Bush</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Bush</governor>
          <dependent id="9">Bush</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Bush</governor>
          <dependent id="10">White</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Bush</governor>
          <dependent id="11">House</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">Bush</governor>
          <dependent id="12">except</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Bush</governor>
          <dependent id="13">George</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">friends</governor>
          <dependent id="14">Bush</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">says</governor>
          <dependent id="17">Barilleaux</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">says</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Bush" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Bush" />
          </tokens>
        </entity>
        <entity id="2" string="Barilleaux" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Barilleaux" />
          </tokens>
        </entity>
        <entity id="3" string="White House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="10" string="White" />
            <token id="11" string="House" />
          </tokens>
        </entity>
        <entity id="4" string="Dan Quayle" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Dan" />
            <token id="3" string="Quayle" />
          </tokens>
        </entity>
        <entity id="5" string="George Bush" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="George" />
            <token id="14" string="Bush" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>``They&amp;apost;re going to give him a lot of window dressing, a space council, drug task force, but he&amp;apost;s going to be a man on the outside ... not a man who&amp;apost;s going to be consulted in a crisis, except on a pro forma basis.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="give" lemma="give" stem="give" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="window" lemma="window" stem="window" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="dressing" lemma="dress" stem="dress" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="space" lemma="space" stem="space" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="council" lemma="council" stem="council" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="task" lemma="task" stem="task" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="force" lemma="force" stem="forc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="outside" lemma="outside" stem="outsid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="..." lemma="..." stem="..." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="consulted" lemma="consult" stem="consult" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="crisis" lemma="crisis" stem="crisi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="except" lemma="except" stem="except" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="pro" lemma="pro" stem="pro" pos="FW" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="51" string="forma" lemma="forma" stem="forma" pos="FW" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="52" string="basis" lemma="basis" stem="basi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="53" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="54" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP They)) (VP (VBP 're) (VP (VBG going) (S (VP (TO to) (VP (VB give) (NP (PRP him)) (NP (NP (DT a) (NN lot)) (PP (IN of) (NP (NP (NN window)) (VP (VBG dressing)))) (, ,) (NP (NP (DT a) (NN space) (NN council)) (, ,) (NP (NN drug) (NN task) (NN force)))))))))) (, ,) (CC but) (S (NP (PRP he)) (VP (VBZ 's) (VP (VBG going) (S (VP (TO to) (VP (VB be) (NP (NP (DT a) (NN man)) (PP (IN on) (NP (NP (DT the) (NN outside)) (: ...) (RB not) (NP (NP (DT a) (NN man)) (SBAR (WHNP (WP who)) (S (VP (VBZ 's) (VP (VBG going) (S (VP (TO to) (VP (VB be) (VP (VBN consulted) (PP (IN in) (NP (DT a) (NN crisis))) (, ,) (PP (IN except) (PP (IN on) (NP (DT a) (ADJP (FW pro) (FW forma)) (NN basis)))))))))))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="2" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="drug task force" type="NP">
          <tokens>
            <token id="18" string="drug" />
            <token id="19" string="task" />
            <token id="20" string="force" />
          </tokens>
        </chunking>
        <chunking id="3" string="a crisis" type="NP">
          <tokens>
            <token id="44" string="a" />
            <token id="45" string="crisis" />
          </tokens>
        </chunking>
        <chunking id="4" string="a space council , drug task force" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="space" />
            <token id="16" string="council" />
            <token id="17" string="," />
            <token id="18" string="drug" />
            <token id="19" string="task" />
            <token id="20" string="force" />
          </tokens>
        </chunking>
        <chunking id="5" string="window" type="NP">
          <tokens>
            <token id="11" string="window" />
          </tokens>
        </chunking>
        <chunking id="6" string="'re going to give him a lot of window dressing , a space council , drug task force" type="VP">
          <tokens>
            <token id="3" string="'re" />
            <token id="4" string="going" />
            <token id="5" string="to" />
            <token id="6" string="give" />
            <token id="7" string="him" />
            <token id="8" string="a" />
            <token id="9" string="lot" />
            <token id="10" string="of" />
            <token id="11" string="window" />
            <token id="12" string="dressing" />
            <token id="13" string="," />
            <token id="14" string="a" />
            <token id="15" string="space" />
            <token id="16" string="council" />
            <token id="17" string="," />
            <token id="18" string="drug" />
            <token id="19" string="task" />
            <token id="20" string="force" />
          </tokens>
        </chunking>
        <chunking id="7" string="going to be consulted in a crisis , except on a pro forma basis" type="VP">
          <tokens>
            <token id="39" string="going" />
            <token id="40" string="to" />
            <token id="41" string="be" />
            <token id="42" string="consulted" />
            <token id="43" string="in" />
            <token id="44" string="a" />
            <token id="45" string="crisis" />
            <token id="46" string="," />
            <token id="47" string="except" />
            <token id="48" string="on" />
            <token id="49" string="a" />
            <token id="50" string="pro" />
            <token id="51" string="forma" />
            <token id="52" string="basis" />
          </tokens>
        </chunking>
        <chunking id="8" string="'s going to be a man on the outside ... not a man who 's going to be consulted in a crisis , except on a pro forma basis" type="VP">
          <tokens>
            <token id="24" string="'s" />
            <token id="25" string="going" />
            <token id="26" string="to" />
            <token id="27" string="be" />
            <token id="28" string="a" />
            <token id="29" string="man" />
            <token id="30" string="on" />
            <token id="31" string="the" />
            <token id="32" string="outside" />
            <token id="33" string="..." />
            <token id="34" string="not" />
            <token id="35" string="a" />
            <token id="36" string="man" />
            <token id="37" string="who" />
            <token id="38" string="'s" />
            <token id="39" string="going" />
            <token id="40" string="to" />
            <token id="41" string="be" />
            <token id="42" string="consulted" />
            <token id="43" string="in" />
            <token id="44" string="a" />
            <token id="45" string="crisis" />
            <token id="46" string="," />
            <token id="47" string="except" />
            <token id="48" string="on" />
            <token id="49" string="a" />
            <token id="50" string="pro" />
            <token id="51" string="forma" />
            <token id="52" string="basis" />
          </tokens>
        </chunking>
        <chunking id="9" string="be consulted in a crisis , except on a pro forma basis" type="VP">
          <tokens>
            <token id="41" string="be" />
            <token id="42" string="consulted" />
            <token id="43" string="in" />
            <token id="44" string="a" />
            <token id="45" string="crisis" />
            <token id="46" string="," />
            <token id="47" string="except" />
            <token id="48" string="on" />
            <token id="49" string="a" />
            <token id="50" string="pro" />
            <token id="51" string="forma" />
            <token id="52" string="basis" />
          </tokens>
        </chunking>
        <chunking id="10" string="a lot" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="lot" />
          </tokens>
        </chunking>
        <chunking id="11" string="a man who 's going to be consulted in a crisis , except on a pro forma basis" type="NP">
          <tokens>
            <token id="35" string="a" />
            <token id="36" string="man" />
            <token id="37" string="who" />
            <token id="38" string="'s" />
            <token id="39" string="going" />
            <token id="40" string="to" />
            <token id="41" string="be" />
            <token id="42" string="consulted" />
            <token id="43" string="in" />
            <token id="44" string="a" />
            <token id="45" string="crisis" />
            <token id="46" string="," />
            <token id="47" string="except" />
            <token id="48" string="on" />
            <token id="49" string="a" />
            <token id="50" string="pro" />
            <token id="51" string="forma" />
            <token id="52" string="basis" />
          </tokens>
        </chunking>
        <chunking id="12" string="a space council" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="space" />
            <token id="16" string="council" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="23" string="he" />
          </tokens>
        </chunking>
        <chunking id="14" string="a man" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="man" />
          </tokens>
        </chunking>
        <chunking id="15" string="a lot of window dressing , a space council , drug task force" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="lot" />
            <token id="10" string="of" />
            <token id="11" string="window" />
            <token id="12" string="dressing" />
            <token id="13" string="," />
            <token id="14" string="a" />
            <token id="15" string="space" />
            <token id="16" string="council" />
            <token id="17" string="," />
            <token id="18" string="drug" />
            <token id="19" string="task" />
            <token id="20" string="force" />
          </tokens>
        </chunking>
        <chunking id="16" string="be a man on the outside ... not a man who 's going to be consulted in a crisis , except on a pro forma basis" type="VP">
          <tokens>
            <token id="27" string="be" />
            <token id="28" string="a" />
            <token id="29" string="man" />
            <token id="30" string="on" />
            <token id="31" string="the" />
            <token id="32" string="outside" />
            <token id="33" string="..." />
            <token id="34" string="not" />
            <token id="35" string="a" />
            <token id="36" string="man" />
            <token id="37" string="who" />
            <token id="38" string="'s" />
            <token id="39" string="going" />
            <token id="40" string="to" />
            <token id="41" string="be" />
            <token id="42" string="consulted" />
            <token id="43" string="in" />
            <token id="44" string="a" />
            <token id="45" string="crisis" />
            <token id="46" string="," />
            <token id="47" string="except" />
            <token id="48" string="on" />
            <token id="49" string="a" />
            <token id="50" string="pro" />
            <token id="51" string="forma" />
            <token id="52" string="basis" />
          </tokens>
        </chunking>
        <chunking id="17" string="a man on the outside ... not a man who 's going to be consulted in a crisis , except on a pro forma basis" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="man" />
            <token id="30" string="on" />
            <token id="31" string="the" />
            <token id="32" string="outside" />
            <token id="33" string="..." />
            <token id="34" string="not" />
            <token id="35" string="a" />
            <token id="36" string="man" />
            <token id="37" string="who" />
            <token id="38" string="'s" />
            <token id="39" string="going" />
            <token id="40" string="to" />
            <token id="41" string="be" />
            <token id="42" string="consulted" />
            <token id="43" string="in" />
            <token id="44" string="a" />
            <token id="45" string="crisis" />
            <token id="46" string="," />
            <token id="47" string="except" />
            <token id="48" string="on" />
            <token id="49" string="a" />
            <token id="50" string="pro" />
            <token id="51" string="forma" />
            <token id="52" string="basis" />
          </tokens>
        </chunking>
        <chunking id="18" string="'s going to be consulted in a crisis , except on a pro forma basis" type="VP">
          <tokens>
            <token id="38" string="'s" />
            <token id="39" string="going" />
            <token id="40" string="to" />
            <token id="41" string="be" />
            <token id="42" string="consulted" />
            <token id="43" string="in" />
            <token id="44" string="a" />
            <token id="45" string="crisis" />
            <token id="46" string="," />
            <token id="47" string="except" />
            <token id="48" string="on" />
            <token id="49" string="a" />
            <token id="50" string="pro" />
            <token id="51" string="forma" />
            <token id="52" string="basis" />
          </tokens>
        </chunking>
        <chunking id="19" string="him" type="NP">
          <tokens>
            <token id="7" string="him" />
          </tokens>
        </chunking>
        <chunking id="20" string="to give him a lot of window dressing , a space council , drug task force" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="give" />
            <token id="7" string="him" />
            <token id="8" string="a" />
            <token id="9" string="lot" />
            <token id="10" string="of" />
            <token id="11" string="window" />
            <token id="12" string="dressing" />
            <token id="13" string="," />
            <token id="14" string="a" />
            <token id="15" string="space" />
            <token id="16" string="council" />
            <token id="17" string="," />
            <token id="18" string="drug" />
            <token id="19" string="task" />
            <token id="20" string="force" />
          </tokens>
        </chunking>
        <chunking id="21" string="consulted in a crisis , except on a pro forma basis" type="VP">
          <tokens>
            <token id="42" string="consulted" />
            <token id="43" string="in" />
            <token id="44" string="a" />
            <token id="45" string="crisis" />
            <token id="46" string="," />
            <token id="47" string="except" />
            <token id="48" string="on" />
            <token id="49" string="a" />
            <token id="50" string="pro" />
            <token id="51" string="forma" />
            <token id="52" string="basis" />
          </tokens>
        </chunking>
        <chunking id="22" string="a pro forma basis" type="NP">
          <tokens>
            <token id="49" string="a" />
            <token id="50" string="pro" />
            <token id="51" string="forma" />
            <token id="52" string="basis" />
          </tokens>
        </chunking>
        <chunking id="23" string="going to give him a lot of window dressing , a space council , drug task force" type="VP">
          <tokens>
            <token id="4" string="going" />
            <token id="5" string="to" />
            <token id="6" string="give" />
            <token id="7" string="him" />
            <token id="8" string="a" />
            <token id="9" string="lot" />
            <token id="10" string="of" />
            <token id="11" string="window" />
            <token id="12" string="dressing" />
            <token id="13" string="," />
            <token id="14" string="a" />
            <token id="15" string="space" />
            <token id="16" string="council" />
            <token id="17" string="," />
            <token id="18" string="drug" />
            <token id="19" string="task" />
            <token id="20" string="force" />
          </tokens>
        </chunking>
        <chunking id="24" string="going to be a man on the outside ... not a man who 's going to be consulted in a crisis , except on a pro forma basis" type="VP">
          <tokens>
            <token id="25" string="going" />
            <token id="26" string="to" />
            <token id="27" string="be" />
            <token id="28" string="a" />
            <token id="29" string="man" />
            <token id="30" string="on" />
            <token id="31" string="the" />
            <token id="32" string="outside" />
            <token id="33" string="..." />
            <token id="34" string="not" />
            <token id="35" string="a" />
            <token id="36" string="man" />
            <token id="37" string="who" />
            <token id="38" string="'s" />
            <token id="39" string="going" />
            <token id="40" string="to" />
            <token id="41" string="be" />
            <token id="42" string="consulted" />
            <token id="43" string="in" />
            <token id="44" string="a" />
            <token id="45" string="crisis" />
            <token id="46" string="," />
            <token id="47" string="except" />
            <token id="48" string="on" />
            <token id="49" string="a" />
            <token id="50" string="pro" />
            <token id="51" string="forma" />
            <token id="52" string="basis" />
          </tokens>
        </chunking>
        <chunking id="25" string="who 's going to be consulted in a crisis , except on a pro forma basis" type="SBAR">
          <tokens>
            <token id="37" string="who" />
            <token id="38" string="'s" />
            <token id="39" string="going" />
            <token id="40" string="to" />
            <token id="41" string="be" />
            <token id="42" string="consulted" />
            <token id="43" string="in" />
            <token id="44" string="a" />
            <token id="45" string="crisis" />
            <token id="46" string="," />
            <token id="47" string="except" />
            <token id="48" string="on" />
            <token id="49" string="a" />
            <token id="50" string="pro" />
            <token id="51" string="forma" />
            <token id="52" string="basis" />
          </tokens>
        </chunking>
        <chunking id="26" string="dressing" type="VP">
          <tokens>
            <token id="12" string="dressing" />
          </tokens>
        </chunking>
        <chunking id="27" string="the outside ... not a man who 's going to be consulted in a crisis , except on a pro forma basis" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="outside" />
            <token id="33" string="..." />
            <token id="34" string="not" />
            <token id="35" string="a" />
            <token id="36" string="man" />
            <token id="37" string="who" />
            <token id="38" string="'s" />
            <token id="39" string="going" />
            <token id="40" string="to" />
            <token id="41" string="be" />
            <token id="42" string="consulted" />
            <token id="43" string="in" />
            <token id="44" string="a" />
            <token id="45" string="crisis" />
            <token id="46" string="," />
            <token id="47" string="except" />
            <token id="48" string="on" />
            <token id="49" string="a" />
            <token id="50" string="pro" />
            <token id="51" string="forma" />
            <token id="52" string="basis" />
          </tokens>
        </chunking>
        <chunking id="28" string="to be consulted in a crisis , except on a pro forma basis" type="VP">
          <tokens>
            <token id="40" string="to" />
            <token id="41" string="be" />
            <token id="42" string="consulted" />
            <token id="43" string="in" />
            <token id="44" string="a" />
            <token id="45" string="crisis" />
            <token id="46" string="," />
            <token id="47" string="except" />
            <token id="48" string="on" />
            <token id="49" string="a" />
            <token id="50" string="pro" />
            <token id="51" string="forma" />
            <token id="52" string="basis" />
          </tokens>
        </chunking>
        <chunking id="29" string="window dressing" type="NP">
          <tokens>
            <token id="11" string="window" />
            <token id="12" string="dressing" />
          </tokens>
        </chunking>
        <chunking id="30" string="the outside" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="outside" />
          </tokens>
        </chunking>
        <chunking id="31" string="give him a lot of window dressing , a space council , drug task force" type="VP">
          <tokens>
            <token id="6" string="give" />
            <token id="7" string="him" />
            <token id="8" string="a" />
            <token id="9" string="lot" />
            <token id="10" string="of" />
            <token id="11" string="window" />
            <token id="12" string="dressing" />
            <token id="13" string="," />
            <token id="14" string="a" />
            <token id="15" string="space" />
            <token id="16" string="council" />
            <token id="17" string="," />
            <token id="18" string="drug" />
            <token id="19" string="task" />
            <token id="20" string="force" />
          </tokens>
        </chunking>
        <chunking id="32" string="to be a man on the outside ... not a man who 's going to be consulted in a crisis , except on a pro forma basis" type="VP">
          <tokens>
            <token id="26" string="to" />
            <token id="27" string="be" />
            <token id="28" string="a" />
            <token id="29" string="man" />
            <token id="30" string="on" />
            <token id="31" string="the" />
            <token id="32" string="outside" />
            <token id="33" string="..." />
            <token id="34" string="not" />
            <token id="35" string="a" />
            <token id="36" string="man" />
            <token id="37" string="who" />
            <token id="38" string="'s" />
            <token id="39" string="going" />
            <token id="40" string="to" />
            <token id="41" string="be" />
            <token id="42" string="consulted" />
            <token id="43" string="in" />
            <token id="44" string="a" />
            <token id="45" string="crisis" />
            <token id="46" string="," />
            <token id="47" string="except" />
            <token id="48" string="on" />
            <token id="49" string="a" />
            <token id="50" string="pro" />
            <token id="51" string="forma" />
            <token id="52" string="basis" />
          </tokens>
        </chunking>
        <chunking id="33" string="pro forma" type="ADJP">
          <tokens>
            <token id="50" string="pro" />
            <token id="51" string="forma" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">going</governor>
          <dependent id="2">They</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">going</governor>
          <dependent id="3">'re</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">give</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">going</governor>
          <dependent id="6">give</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="6">give</governor>
          <dependent id="7">him</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">lot</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">give</governor>
          <dependent id="9">lot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">window</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">lot</governor>
          <dependent id="11">window</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="11">window</governor>
          <dependent id="12">dressing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">council</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">council</governor>
          <dependent id="15">space</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="9">lot</governor>
          <dependent id="16">council</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">force</governor>
          <dependent id="18">drug</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">force</governor>
          <dependent id="19">task</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="16">council</governor>
          <dependent id="20">force</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">going</governor>
          <dependent id="22">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">going</governor>
          <dependent id="23">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="25">going</governor>
          <dependent id="24">'s</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">going</governor>
          <dependent id="25">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">man</governor>
          <dependent id="26">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="29">man</governor>
          <dependent id="27">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">man</governor>
          <dependent id="28">a</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="25">going</governor>
          <dependent id="29">man</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">outside</governor>
          <dependent id="30">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">outside</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">man</governor>
          <dependent id="32">outside</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="32">outside</governor>
          <dependent id="34">not</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">man</governor>
          <dependent id="35">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="32">outside</governor>
          <dependent id="36">man</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="39">going</governor>
          <dependent id="37">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="39">going</governor>
          <dependent id="38">'s</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="36">man</governor>
          <dependent id="39">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="42">consulted</governor>
          <dependent id="40">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="42">consulted</governor>
          <dependent id="41">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="39">going</governor>
          <dependent id="42">consulted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="45">crisis</governor>
          <dependent id="43">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="45">crisis</governor>
          <dependent id="44">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="42">consulted</governor>
          <dependent id="45">crisis</dependent>
        </dependency>
        <dependency type="case">
          <governor id="52">basis</governor>
          <dependent id="47">except</dependent>
        </dependency>
        <dependency type="case">
          <governor id="52">basis</governor>
          <dependent id="48">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="52">basis</governor>
          <dependent id="49">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="52">basis</governor>
          <dependent id="50">pro</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="50">pro</governor>
          <dependent id="51">forma</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="42">consulted</governor>
          <dependent id="52">basis</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>But Eddie Mahe Jr., a GOP consultant who worked with the Bush campaign, says Bush is likely to give Quayle a more active role in the administration than he had in the campaign.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Eddie" lemma="Eddie" stem="eddie" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Mahe" lemma="Mahe" stem="mahe" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="Jr." lemma="Jr." stem="jr." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="GOP" lemma="GOP" stem="gop" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="8" string="consultant" lemma="consultant" stem="consult" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="worked" lemma="work" stem="work" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="campaign" lemma="campaign" stem="campaign" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="18" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="likely" lemma="likely" stem="like" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="give" lemma="give" stem="give" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="Quayle" lemma="Quayle" stem="quayl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="active" lemma="active" stem="activ" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="role" lemma="role" stem="role" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="administration" lemma="administration" stem="administr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="30" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="campaign" lemma="campaign" stem="campaign" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NP (NNP Eddie) (NNP Mahe) (NNP Jr.)) (, ,) (NP (NP (DT a) (NNP GOP) (NN consultant)) (SBAR (WHNP (WP who)) (S (VP (VBD worked) (PP (IN with) (NP (DT the) (NNP Bush) (NN campaign))))))) (, ,)) (VP (VBZ says) (SBAR (S (NP (NNP Bush)) (VP (VBZ is) (ADJP (JJ likely) (S (VP (TO to) (VP (VB give) (NP (NNP Quayle)) (NP (NP (DT a) (ADJP (RBR more) (JJ active)) (NN role)) (PP (IN in) (NP (DT the) (NN administration)))))))) (SBAR (IN than) (S (NP (PRP he)) (VP (VBD had) (PP (IN in) (NP (DT the) (NN campaign)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="who worked with the Bush campaign" type="SBAR">
          <tokens>
            <token id="9" string="who" />
            <token id="10" string="worked" />
            <token id="11" string="with" />
            <token id="12" string="the" />
            <token id="13" string="Bush" />
            <token id="14" string="campaign" />
          </tokens>
        </chunking>
        <chunking id="2" string="the administration" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="administration" />
          </tokens>
        </chunking>
        <chunking id="3" string="Eddie Mahe Jr. , a GOP consultant who worked with the Bush campaign ," type="NP">
          <tokens>
            <token id="2" string="Eddie" />
            <token id="3" string="Mahe" />
            <token id="4" string="Jr." />
            <token id="5" string="," />
            <token id="6" string="a" />
            <token id="7" string="GOP" />
            <token id="8" string="consultant" />
            <token id="9" string="who" />
            <token id="10" string="worked" />
            <token id="11" string="with" />
            <token id="12" string="the" />
            <token id="13" string="Bush" />
            <token id="14" string="campaign" />
            <token id="15" string="," />
          </tokens>
        </chunking>
        <chunking id="4" string="Quayle" type="NP">
          <tokens>
            <token id="22" string="Quayle" />
          </tokens>
        </chunking>
        <chunking id="5" string="Bush is likely to give Quayle a more active role in the administration than he had in the campaign" type="SBAR">
          <tokens>
            <token id="17" string="Bush" />
            <token id="18" string="is" />
            <token id="19" string="likely" />
            <token id="20" string="to" />
            <token id="21" string="give" />
            <token id="22" string="Quayle" />
            <token id="23" string="a" />
            <token id="24" string="more" />
            <token id="25" string="active" />
            <token id="26" string="role" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="administration" />
            <token id="30" string="than" />
            <token id="31" string="he" />
            <token id="32" string="had" />
            <token id="33" string="in" />
            <token id="34" string="the" />
            <token id="35" string="campaign" />
          </tokens>
        </chunking>
        <chunking id="6" string="the campaign" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="campaign" />
          </tokens>
        </chunking>
        <chunking id="7" string="Eddie Mahe Jr." type="NP">
          <tokens>
            <token id="2" string="Eddie" />
            <token id="3" string="Mahe" />
            <token id="4" string="Jr." />
          </tokens>
        </chunking>
        <chunking id="8" string="worked with the Bush campaign" type="VP">
          <tokens>
            <token id="10" string="worked" />
            <token id="11" string="with" />
            <token id="12" string="the" />
            <token id="13" string="Bush" />
            <token id="14" string="campaign" />
          </tokens>
        </chunking>
        <chunking id="9" string="a GOP consultant who worked with the Bush campaign" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="GOP" />
            <token id="8" string="consultant" />
            <token id="9" string="who" />
            <token id="10" string="worked" />
            <token id="11" string="with" />
            <token id="12" string="the" />
            <token id="13" string="Bush" />
            <token id="14" string="campaign" />
          </tokens>
        </chunking>
        <chunking id="10" string="a more active role" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="more" />
            <token id="25" string="active" />
            <token id="26" string="role" />
          </tokens>
        </chunking>
        <chunking id="11" string="more active" type="ADJP">
          <tokens>
            <token id="24" string="more" />
            <token id="25" string="active" />
          </tokens>
        </chunking>
        <chunking id="12" string="than he had in the campaign" type="SBAR">
          <tokens>
            <token id="30" string="than" />
            <token id="31" string="he" />
            <token id="32" string="had" />
            <token id="33" string="in" />
            <token id="34" string="the" />
            <token id="35" string="campaign" />
          </tokens>
        </chunking>
        <chunking id="13" string="a more active role in the administration" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="more" />
            <token id="25" string="active" />
            <token id="26" string="role" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="administration" />
          </tokens>
        </chunking>
        <chunking id="14" string="likely to give Quayle a more active role in the administration" type="ADJP">
          <tokens>
            <token id="19" string="likely" />
            <token id="20" string="to" />
            <token id="21" string="give" />
            <token id="22" string="Quayle" />
            <token id="23" string="a" />
            <token id="24" string="more" />
            <token id="25" string="active" />
            <token id="26" string="role" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="administration" />
          </tokens>
        </chunking>
        <chunking id="15" string="says Bush is likely to give Quayle a more active role in the administration than he had in the campaign" type="VP">
          <tokens>
            <token id="16" string="says" />
            <token id="17" string="Bush" />
            <token id="18" string="is" />
            <token id="19" string="likely" />
            <token id="20" string="to" />
            <token id="21" string="give" />
            <token id="22" string="Quayle" />
            <token id="23" string="a" />
            <token id="24" string="more" />
            <token id="25" string="active" />
            <token id="26" string="role" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="administration" />
            <token id="30" string="than" />
            <token id="31" string="he" />
            <token id="32" string="had" />
            <token id="33" string="in" />
            <token id="34" string="the" />
            <token id="35" string="campaign" />
          </tokens>
        </chunking>
        <chunking id="16" string="Bush" type="NP">
          <tokens>
            <token id="17" string="Bush" />
          </tokens>
        </chunking>
        <chunking id="17" string="is likely to give Quayle a more active role in the administration than he had in the campaign" type="VP">
          <tokens>
            <token id="18" string="is" />
            <token id="19" string="likely" />
            <token id="20" string="to" />
            <token id="21" string="give" />
            <token id="22" string="Quayle" />
            <token id="23" string="a" />
            <token id="24" string="more" />
            <token id="25" string="active" />
            <token id="26" string="role" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="administration" />
            <token id="30" string="than" />
            <token id="31" string="he" />
            <token id="32" string="had" />
            <token id="33" string="in" />
            <token id="34" string="the" />
            <token id="35" string="campaign" />
          </tokens>
        </chunking>
        <chunking id="18" string="to give Quayle a more active role in the administration" type="VP">
          <tokens>
            <token id="20" string="to" />
            <token id="21" string="give" />
            <token id="22" string="Quayle" />
            <token id="23" string="a" />
            <token id="24" string="more" />
            <token id="25" string="active" />
            <token id="26" string="role" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="administration" />
          </tokens>
        </chunking>
        <chunking id="19" string="give Quayle a more active role in the administration" type="VP">
          <tokens>
            <token id="21" string="give" />
            <token id="22" string="Quayle" />
            <token id="23" string="a" />
            <token id="24" string="more" />
            <token id="25" string="active" />
            <token id="26" string="role" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="administration" />
          </tokens>
        </chunking>
        <chunking id="20" string="he" type="NP">
          <tokens>
            <token id="31" string="he" />
          </tokens>
        </chunking>
        <chunking id="21" string="had in the campaign" type="VP">
          <tokens>
            <token id="32" string="had" />
            <token id="33" string="in" />
            <token id="34" string="the" />
            <token id="35" string="campaign" />
          </tokens>
        </chunking>
        <chunking id="22" string="the Bush campaign" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="Bush" />
            <token id="14" string="campaign" />
          </tokens>
        </chunking>
        <chunking id="23" string="a GOP consultant" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="GOP" />
            <token id="8" string="consultant" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="16">says</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Jr.</governor>
          <dependent id="2">Eddie</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Jr.</governor>
          <dependent id="3">Mahe</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">says</governor>
          <dependent id="4">Jr.</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">consultant</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">consultant</governor>
          <dependent id="7">GOP</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="4">Jr.</governor>
          <dependent id="8">consultant</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">worked</governor>
          <dependent id="9">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">consultant</governor>
          <dependent id="10">worked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">campaign</governor>
          <dependent id="11">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">campaign</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">campaign</governor>
          <dependent id="13">Bush</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">worked</governor>
          <dependent id="14">campaign</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">says</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">likely</governor>
          <dependent id="17">Bush</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">likely</governor>
          <dependent id="18">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">says</governor>
          <dependent id="19">likely</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">give</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="19">likely</governor>
          <dependent id="21">give</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="21">give</governor>
          <dependent id="22">Quayle</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">role</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">active</governor>
          <dependent id="24">more</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">role</governor>
          <dependent id="25">active</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">give</governor>
          <dependent id="26">role</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">administration</governor>
          <dependent id="27">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">administration</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">role</governor>
          <dependent id="29">administration</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="32">had</governor>
          <dependent id="30">than</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">had</governor>
          <dependent id="31">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">likely</governor>
          <dependent id="32">had</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">campaign</governor>
          <dependent id="33">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">campaign</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">had</governor>
          <dependent id="35">campaign</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Quayle" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Quayle" />
          </tokens>
        </entity>
        <entity id="2" string="GOP" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="7" string="GOP" />
          </tokens>
        </entity>
        <entity id="3" string="Eddie Mahe Jr." type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Eddie" />
            <token id="3" string="Mahe" />
            <token id="4" string="Jr." />
          </tokens>
        </entity>
        <entity id="4" string="Bush" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Bush" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="false">
      <content>``Vindication demands that.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Vindication" lemma="vindication" stem="vindic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="demands" lemma="demand" stem="demand" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (`` ``) (NN Vindication)) (NP (NP (NNS demands)) (SBAR (WHNP (WDT that)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that" type="SBAR">
          <tokens>
            <token id="4" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="demands" type="NP">
          <tokens>
            <token id="3" string="demands" />
          </tokens>
        </chunking>
        <chunking id="3" string="demands that" type="NP">
          <tokens>
            <token id="3" string="demands" />
            <token id="4" string="that" />
          </tokens>
        </chunking>
        <chunking id="4" string="`` Vindication demands that ." type="NP">
          <tokens>
            <token id="1" string="``" />
            <token id="2" string="Vindication" />
            <token id="3" string="demands" />
            <token id="4" string="that" />
            <token id="5" string="." />
          </tokens>
        </chunking>
        <chunking id="5" string="`` Vindication" type="NP">
          <tokens>
            <token id="1" string="``" />
            <token id="2" string="Vindication" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">Vindication</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">Vindication</governor>
          <dependent id="3">demands</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">demands</governor>
          <dependent id="4">that</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>Both of them will want to prove how right the decision was,&amp;apost;&amp;apost; Mahe says.</content>
      <tokens>
        <token id="1" string="Both" lemma="both" stem="both" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="want" lemma="want" stem="want" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="prove" lemma="prove" stem="prove" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="right" lemma="right" stem="right" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="decision" lemma="decision" stem="decis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Mahe" lemma="Mahe" stem="mahe" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="16" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (DT Both)) (PP (IN of) (NP (PRP them)))) (VP (MD will) (VP (VB want) (S (VP (TO to) (VP (VB prove) (SBAR (WHADVP (WRB how)) (S (NP (JJ right) (DT the) (NN decision)) (VP (VBD was)))))))))) (, ,) ('' '') (NP (NNP Mahe)) (VP (VBZ says)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to prove how right the decision was" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="prove" />
            <token id="8" string="how" />
            <token id="9" string="right" />
            <token id="10" string="the" />
            <token id="11" string="decision" />
            <token id="12" string="was" />
          </tokens>
        </chunking>
        <chunking id="2" string="how right the decision was" type="SBAR">
          <tokens>
            <token id="8" string="how" />
            <token id="9" string="right" />
            <token id="10" string="the" />
            <token id="11" string="decision" />
            <token id="12" string="was" />
          </tokens>
        </chunking>
        <chunking id="3" string="was" type="VP">
          <tokens>
            <token id="12" string="was" />
          </tokens>
        </chunking>
        <chunking id="4" string="them" type="NP">
          <tokens>
            <token id="3" string="them" />
          </tokens>
        </chunking>
        <chunking id="5" string="Both of them" type="NP">
          <tokens>
            <token id="1" string="Both" />
            <token id="2" string="of" />
            <token id="3" string="them" />
          </tokens>
        </chunking>
        <chunking id="6" string="how" type="WHADVP">
          <tokens>
            <token id="8" string="how" />
          </tokens>
        </chunking>
        <chunking id="7" string="want to prove how right the decision was" type="VP">
          <tokens>
            <token id="5" string="want" />
            <token id="6" string="to" />
            <token id="7" string="prove" />
            <token id="8" string="how" />
            <token id="9" string="right" />
            <token id="10" string="the" />
            <token id="11" string="decision" />
            <token id="12" string="was" />
          </tokens>
        </chunking>
        <chunking id="8" string="says" type="VP">
          <tokens>
            <token id="16" string="says" />
          </tokens>
        </chunking>
        <chunking id="9" string="right the decision" type="NP">
          <tokens>
            <token id="9" string="right" />
            <token id="10" string="the" />
            <token id="11" string="decision" />
          </tokens>
        </chunking>
        <chunking id="10" string="prove how right the decision was" type="VP">
          <tokens>
            <token id="7" string="prove" />
            <token id="8" string="how" />
            <token id="9" string="right" />
            <token id="10" string="the" />
            <token id="11" string="decision" />
            <token id="12" string="was" />
          </tokens>
        </chunking>
        <chunking id="11" string="Mahe" type="NP">
          <tokens>
            <token id="15" string="Mahe" />
          </tokens>
        </chunking>
        <chunking id="12" string="will want to prove how right the decision was" type="VP">
          <tokens>
            <token id="4" string="will" />
            <token id="5" string="want" />
            <token id="6" string="to" />
            <token id="7" string="prove" />
            <token id="8" string="how" />
            <token id="9" string="right" />
            <token id="10" string="the" />
            <token id="11" string="decision" />
            <token id="12" string="was" />
          </tokens>
        </chunking>
        <chunking id="13" string="Both" type="NP">
          <tokens>
            <token id="1" string="Both" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">want</governor>
          <dependent id="1">Both</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">them</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Both</governor>
          <dependent id="3">them</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">want</governor>
          <dependent id="4">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">says</governor>
          <dependent id="5">want</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">prove</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">want</governor>
          <dependent id="7">prove</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">was</governor>
          <dependent id="8">how</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">decision</governor>
          <dependent id="9">right</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">decision</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">was</governor>
          <dependent id="11">decision</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">prove</governor>
          <dependent id="12">was</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">says</governor>
          <dependent id="15">Mahe</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">says</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mahe" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Mahe" />
          </tokens>
        </entity>
        <entity id="2" string="right" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="9" string="right" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>Democrats portrayed Quayle during the campaign as a lightweight, a man with little or no legislative accomplishments, untested and unqualified to be a heartbeat away from the presidency.</content>
      <tokens>
        <token id="1" string="Democrats" lemma="Democrats" stem="democrat" pos="NNPS" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="2" string="portrayed" lemma="portray" stem="portrai" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Quayle" lemma="Quayle" stem="quayl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="campaign" lemma="campaign" stem="campaign" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="lightweight" lemma="lightweight" stem="lightweight" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="little" lemma="little" stem="littl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="legislative" lemma="legislative" stem="legisl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="accomplishments" lemma="accomplishment" stem="accomplish" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="untested" lemma="untested" stem="untest" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="unqualified" lemma="unqualified" stem="unqualifi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="heartbeat" lemma="heartbeat" stem="heartbeat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="away" lemma="away" stem="awai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="presidency" lemma="presidency" stem="presid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNPS Democrats)) (VP (VBD portrayed) (NP (NNP Quayle)) (PP (IN during) (NP (NP (NP (DT the) (NN campaign)) (PP (IN as) (NP (DT a) (JJ lightweight)))) (, ,) (NP (NP (DT a) (NN man)) (PP (IN with) (NP (JJ little)))) (CC or) (NP (NP (DT no) (JJ legislative) (NNS accomplishments)) (, ,) (NP (JJ untested)) (CC and) (NP (JJ unqualified))))) (S (VP (TO to) (VP (VB be) (ADVP (NP (DT a) (NN heartbeat)) (RB away)) (PP (IN from) (NP (DT the) (NN presidency))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a man with little" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="man" />
            <token id="13" string="with" />
            <token id="14" string="little" />
          </tokens>
        </chunking>
        <chunking id="2" string="no legislative accomplishments" type="NP">
          <tokens>
            <token id="16" string="no" />
            <token id="17" string="legislative" />
            <token id="18" string="accomplishments" />
          </tokens>
        </chunking>
        <chunking id="3" string="be a heartbeat away from the presidency" type="VP">
          <tokens>
            <token id="24" string="be" />
            <token id="25" string="a" />
            <token id="26" string="heartbeat" />
            <token id="27" string="away" />
            <token id="28" string="from" />
            <token id="29" string="the" />
            <token id="30" string="presidency" />
          </tokens>
        </chunking>
        <chunking id="4" string="Quayle" type="NP">
          <tokens>
            <token id="3" string="Quayle" />
          </tokens>
        </chunking>
        <chunking id="5" string="the campaign as a lightweight" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="campaign" />
            <token id="7" string="as" />
            <token id="8" string="a" />
            <token id="9" string="lightweight" />
          </tokens>
        </chunking>
        <chunking id="6" string="the campaign as a lightweight , a man with little or no legislative accomplishments , untested and unqualified" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="campaign" />
            <token id="7" string="as" />
            <token id="8" string="a" />
            <token id="9" string="lightweight" />
            <token id="10" string="," />
            <token id="11" string="a" />
            <token id="12" string="man" />
            <token id="13" string="with" />
            <token id="14" string="little" />
            <token id="15" string="or" />
            <token id="16" string="no" />
            <token id="17" string="legislative" />
            <token id="18" string="accomplishments" />
            <token id="19" string="," />
            <token id="20" string="untested" />
            <token id="21" string="and" />
            <token id="22" string="unqualified" />
          </tokens>
        </chunking>
        <chunking id="7" string="the campaign" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="campaign" />
          </tokens>
        </chunking>
        <chunking id="8" string="untested" type="NP">
          <tokens>
            <token id="20" string="untested" />
          </tokens>
        </chunking>
        <chunking id="9" string="no legislative accomplishments , untested and unqualified" type="NP">
          <tokens>
            <token id="16" string="no" />
            <token id="17" string="legislative" />
            <token id="18" string="accomplishments" />
            <token id="19" string="," />
            <token id="20" string="untested" />
            <token id="21" string="and" />
            <token id="22" string="unqualified" />
          </tokens>
        </chunking>
        <chunking id="10" string="Democrats" type="NP">
          <tokens>
            <token id="1" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="11" string="unqualified" type="NP">
          <tokens>
            <token id="22" string="unqualified" />
          </tokens>
        </chunking>
        <chunking id="12" string="a heartbeat" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="heartbeat" />
          </tokens>
        </chunking>
        <chunking id="13" string="portrayed Quayle during the campaign as a lightweight , a man with little or no legislative accomplishments , untested and unqualified to be a heartbeat away from the presidency" type="VP">
          <tokens>
            <token id="2" string="portrayed" />
            <token id="3" string="Quayle" />
            <token id="4" string="during" />
            <token id="5" string="the" />
            <token id="6" string="campaign" />
            <token id="7" string="as" />
            <token id="8" string="a" />
            <token id="9" string="lightweight" />
            <token id="10" string="," />
            <token id="11" string="a" />
            <token id="12" string="man" />
            <token id="13" string="with" />
            <token id="14" string="little" />
            <token id="15" string="or" />
            <token id="16" string="no" />
            <token id="17" string="legislative" />
            <token id="18" string="accomplishments" />
            <token id="19" string="," />
            <token id="20" string="untested" />
            <token id="21" string="and" />
            <token id="22" string="unqualified" />
            <token id="23" string="to" />
            <token id="24" string="be" />
            <token id="25" string="a" />
            <token id="26" string="heartbeat" />
            <token id="27" string="away" />
            <token id="28" string="from" />
            <token id="29" string="the" />
            <token id="30" string="presidency" />
          </tokens>
        </chunking>
        <chunking id="14" string="a lightweight" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="lightweight" />
          </tokens>
        </chunking>
        <chunking id="15" string="the presidency" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="presidency" />
          </tokens>
        </chunking>
        <chunking id="16" string="little" type="NP">
          <tokens>
            <token id="14" string="little" />
          </tokens>
        </chunking>
        <chunking id="17" string="a man" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="man" />
          </tokens>
        </chunking>
        <chunking id="18" string="to be a heartbeat away from the presidency" type="VP">
          <tokens>
            <token id="23" string="to" />
            <token id="24" string="be" />
            <token id="25" string="a" />
            <token id="26" string="heartbeat" />
            <token id="27" string="away" />
            <token id="28" string="from" />
            <token id="29" string="the" />
            <token id="30" string="presidency" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">portrayed</governor>
          <dependent id="1">Democrats</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">portrayed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">portrayed</governor>
          <dependent id="3">Quayle</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">campaign</governor>
          <dependent id="4">during</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">campaign</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">portrayed</governor>
          <dependent id="6">campaign</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">lightweight</governor>
          <dependent id="7">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">lightweight</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">campaign</governor>
          <dependent id="9">lightweight</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">man</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">campaign</governor>
          <dependent id="12">man</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">little</governor>
          <dependent id="13">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">man</governor>
          <dependent id="14">little</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">campaign</governor>
          <dependent id="15">or</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="18">accomplishments</governor>
          <dependent id="16">no</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">accomplishments</governor>
          <dependent id="17">legislative</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">campaign</governor>
          <dependent id="18">accomplishments</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">accomplishments</governor>
          <dependent id="20">untested</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">accomplishments</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">accomplishments</governor>
          <dependent id="22">unqualified</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="30">presidency</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="30">presidency</governor>
          <dependent id="24">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">heartbeat</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="27">away</governor>
          <dependent id="26">heartbeat</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="30">presidency</governor>
          <dependent id="27">away</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">presidency</governor>
          <dependent id="28">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">presidency</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">portrayed</governor>
          <dependent id="30">presidency</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Democrats" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="1" string="Democrats" />
          </tokens>
        </entity>
        <entity id="2" string="Quayle" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Quayle" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>Even some members of Quayle&amp;apost;s own party were dismayed at Bush&amp;apost;s choice.</content>
      <tokens>
        <token id="1" string="Even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="members" lemma="member" stem="member" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Quayle" lemma="Quayle" stem="quayl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="6" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="7" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="party" lemma="party" stem="parti" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="dismayed" lemma="dismay" stem="dismai" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="choice" lemma="choice" stem="choic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (RB Even) (DT some) (NNS members)) (PP (IN of) (NP (NP (NNP Quayle) (POS 's)) (JJ own) (NN party)))) (VP (VBD were) (VP (VBN dismayed) (PP (IN at) (NP (NP (NNP Bush) (POS 's)) (NN choice))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Bush 's choice" type="NP">
          <tokens>
            <token id="12" string="Bush" />
            <token id="13" string="'s" />
            <token id="14" string="choice" />
          </tokens>
        </chunking>
        <chunking id="2" string="Even some members" type="NP">
          <tokens>
            <token id="1" string="Even" />
            <token id="2" string="some" />
            <token id="3" string="members" />
          </tokens>
        </chunking>
        <chunking id="3" string="Quayle 's" type="NP">
          <tokens>
            <token id="5" string="Quayle" />
            <token id="6" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="Bush 's" type="NP">
          <tokens>
            <token id="12" string="Bush" />
            <token id="13" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="Even some members of Quayle 's own party" type="NP">
          <tokens>
            <token id="1" string="Even" />
            <token id="2" string="some" />
            <token id="3" string="members" />
            <token id="4" string="of" />
            <token id="5" string="Quayle" />
            <token id="6" string="'s" />
            <token id="7" string="own" />
            <token id="8" string="party" />
          </tokens>
        </chunking>
        <chunking id="6" string="Quayle 's own party" type="NP">
          <tokens>
            <token id="5" string="Quayle" />
            <token id="6" string="'s" />
            <token id="7" string="own" />
            <token id="8" string="party" />
          </tokens>
        </chunking>
        <chunking id="7" string="were dismayed at Bush 's choice" type="VP">
          <tokens>
            <token id="9" string="were" />
            <token id="10" string="dismayed" />
            <token id="11" string="at" />
            <token id="12" string="Bush" />
            <token id="13" string="'s" />
            <token id="14" string="choice" />
          </tokens>
        </chunking>
        <chunking id="8" string="dismayed at Bush 's choice" type="VP">
          <tokens>
            <token id="10" string="dismayed" />
            <token id="11" string="at" />
            <token id="12" string="Bush" />
            <token id="13" string="'s" />
            <token id="14" string="choice" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">members</governor>
          <dependent id="1">Even</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">members</governor>
          <dependent id="2">some</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="10">dismayed</governor>
          <dependent id="3">members</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">party</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">party</governor>
          <dependent id="5">Quayle</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Quayle</governor>
          <dependent id="6">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">party</governor>
          <dependent id="7">own</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">members</governor>
          <dependent id="8">party</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">dismayed</governor>
          <dependent id="9">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">dismayed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">choice</governor>
          <dependent id="11">at</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">choice</governor>
          <dependent id="12">Bush</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Bush</governor>
          <dependent id="13">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">dismayed</governor>
          <dependent id="14">choice</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Quayle" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Quayle" />
          </tokens>
        </entity>
        <entity id="2" string="Bush" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Bush" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>Quayle didn&amp;apost;t help his case by making a number of celebrated gaffes during the campaign, perhaps the worst being his garbled explanation of the Holocaust and his declaration, ``I didn&amp;apost;t live in this century.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="Quayle" lemma="Quayle" stem="quayl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="help" lemma="help" stem="help" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="making" lemma="make" stem="make" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="number" lemma="number" stem="number" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="celebrated" lemma="celebrated" stem="celebr" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="gaffes" lemma="gaffe" stem="gaff" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="campaign" lemma="campaign" stem="campaign" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="perhaps" lemma="perhaps" stem="perhap" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="worst" lemma="worst" stem="worst" pos="JJS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="23" string="garbled" lemma="garbled" stem="garbl" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="explanation" lemma="explanation" stem="explan" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="Holocaust" lemma="Holocaust" stem="holocaust" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="30" string="declaration" lemma="declaration" stem="declar" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="32" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="34" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="35" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="36" string="live" lemma="live" stem="live" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="37" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="38" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="39" string="century" lemma="century" stem="centuri" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Quayle)) (VP (VBD did) (RB n't) (VP (VB help) (NP (PRP$ his) (NN case)) (PP (IN by) (S (VP (VBG making) (NP (NP (DT a) (NN number)) (PP (IN of) (NP (JJ celebrated) (NNS gaffes)))) (PP (IN during) (NP (NP (DT the) (NN campaign)) (, ,) (NP (NP (RB perhaps) (DT the) (JJS worst)) (SBAR (S (S (VP (VBG being) (NP (NP (PRP$ his) (JJ garbled) (NN explanation)) (PP (IN of) (NP (NP (DT the) (NNP Holocaust)) (CC and) (NP (PRP$ his) (NN declaration))))))) (, ,) (`` ``) (NP (PRP I)) (VP (VBD did) (RB n't) (VP (VB live) (PP (IN in) (NP (DT this) (NN century))))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="his garbled explanation" type="NP">
          <tokens>
            <token id="22" string="his" />
            <token id="23" string="garbled" />
            <token id="24" string="explanation" />
          </tokens>
        </chunking>
        <chunking id="2" string="this century" type="NP">
          <tokens>
            <token id="38" string="this" />
            <token id="39" string="century" />
          </tokens>
        </chunking>
        <chunking id="3" string="celebrated gaffes" type="NP">
          <tokens>
            <token id="12" string="celebrated" />
            <token id="13" string="gaffes" />
          </tokens>
        </chunking>
        <chunking id="4" string="Quayle" type="NP">
          <tokens>
            <token id="1" string="Quayle" />
          </tokens>
        </chunking>
        <chunking id="5" string="perhaps the worst being his garbled explanation of the Holocaust and his declaration , `` I did n't live in this century" type="NP">
          <tokens>
            <token id="18" string="perhaps" />
            <token id="19" string="the" />
            <token id="20" string="worst" />
            <token id="21" string="being" />
            <token id="22" string="his" />
            <token id="23" string="garbled" />
            <token id="24" string="explanation" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="Holocaust" />
            <token id="28" string="and" />
            <token id="29" string="his" />
            <token id="30" string="declaration" />
            <token id="31" string="," />
            <token id="32" string="``" />
            <token id="33" string="I" />
            <token id="34" string="did" />
            <token id="35" string="n't" />
            <token id="36" string="live" />
            <token id="37" string="in" />
            <token id="38" string="this" />
            <token id="39" string="century" />
          </tokens>
        </chunking>
        <chunking id="6" string="the campaign" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="campaign" />
          </tokens>
        </chunking>
        <chunking id="7" string="being his garbled explanation of the Holocaust and his declaration , `` I did n't live in this century" type="SBAR">
          <tokens>
            <token id="21" string="being" />
            <token id="22" string="his" />
            <token id="23" string="garbled" />
            <token id="24" string="explanation" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="Holocaust" />
            <token id="28" string="and" />
            <token id="29" string="his" />
            <token id="30" string="declaration" />
            <token id="31" string="," />
            <token id="32" string="``" />
            <token id="33" string="I" />
            <token id="34" string="did" />
            <token id="35" string="n't" />
            <token id="36" string="live" />
            <token id="37" string="in" />
            <token id="38" string="this" />
            <token id="39" string="century" />
          </tokens>
        </chunking>
        <chunking id="8" string="perhaps the worst" type="NP">
          <tokens>
            <token id="18" string="perhaps" />
            <token id="19" string="the" />
            <token id="20" string="worst" />
          </tokens>
        </chunking>
        <chunking id="9" string="I" type="NP">
          <tokens>
            <token id="33" string="I" />
          </tokens>
        </chunking>
        <chunking id="10" string="making a number of celebrated gaffes during the campaign , perhaps the worst being his garbled explanation of the Holocaust and his declaration , `` I did n't live in this century" type="VP">
          <tokens>
            <token id="8" string="making" />
            <token id="9" string="a" />
            <token id="10" string="number" />
            <token id="11" string="of" />
            <token id="12" string="celebrated" />
            <token id="13" string="gaffes" />
            <token id="14" string="during" />
            <token id="15" string="the" />
            <token id="16" string="campaign" />
            <token id="17" string="," />
            <token id="18" string="perhaps" />
            <token id="19" string="the" />
            <token id="20" string="worst" />
            <token id="21" string="being" />
            <token id="22" string="his" />
            <token id="23" string="garbled" />
            <token id="24" string="explanation" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="Holocaust" />
            <token id="28" string="and" />
            <token id="29" string="his" />
            <token id="30" string="declaration" />
            <token id="31" string="," />
            <token id="32" string="``" />
            <token id="33" string="I" />
            <token id="34" string="did" />
            <token id="35" string="n't" />
            <token id="36" string="live" />
            <token id="37" string="in" />
            <token id="38" string="this" />
            <token id="39" string="century" />
          </tokens>
        </chunking>
        <chunking id="11" string="his declaration" type="NP">
          <tokens>
            <token id="29" string="his" />
            <token id="30" string="declaration" />
          </tokens>
        </chunking>
        <chunking id="12" string="his case" type="NP">
          <tokens>
            <token id="5" string="his" />
            <token id="6" string="case" />
          </tokens>
        </chunking>
        <chunking id="13" string="a number of celebrated gaffes" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="number" />
            <token id="11" string="of" />
            <token id="12" string="celebrated" />
            <token id="13" string="gaffes" />
          </tokens>
        </chunking>
        <chunking id="14" string="did n't help his case by making a number of celebrated gaffes during the campaign , perhaps the worst being his garbled explanation of the Holocaust and his declaration , `` I did n't live in this century" type="VP">
          <tokens>
            <token id="2" string="did" />
            <token id="3" string="n't" />
            <token id="4" string="help" />
            <token id="5" string="his" />
            <token id="6" string="case" />
            <token id="7" string="by" />
            <token id="8" string="making" />
            <token id="9" string="a" />
            <token id="10" string="number" />
            <token id="11" string="of" />
            <token id="12" string="celebrated" />
            <token id="13" string="gaffes" />
            <token id="14" string="during" />
            <token id="15" string="the" />
            <token id="16" string="campaign" />
            <token id="17" string="," />
            <token id="18" string="perhaps" />
            <token id="19" string="the" />
            <token id="20" string="worst" />
            <token id="21" string="being" />
            <token id="22" string="his" />
            <token id="23" string="garbled" />
            <token id="24" string="explanation" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="Holocaust" />
            <token id="28" string="and" />
            <token id="29" string="his" />
            <token id="30" string="declaration" />
            <token id="31" string="," />
            <token id="32" string="``" />
            <token id="33" string="I" />
            <token id="34" string="did" />
            <token id="35" string="n't" />
            <token id="36" string="live" />
            <token id="37" string="in" />
            <token id="38" string="this" />
            <token id="39" string="century" />
          </tokens>
        </chunking>
        <chunking id="15" string="the campaign , perhaps the worst being his garbled explanation of the Holocaust and his declaration , `` I did n't live in this century" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="campaign" />
            <token id="17" string="," />
            <token id="18" string="perhaps" />
            <token id="19" string="the" />
            <token id="20" string="worst" />
            <token id="21" string="being" />
            <token id="22" string="his" />
            <token id="23" string="garbled" />
            <token id="24" string="explanation" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="Holocaust" />
            <token id="28" string="and" />
            <token id="29" string="his" />
            <token id="30" string="declaration" />
            <token id="31" string="," />
            <token id="32" string="``" />
            <token id="33" string="I" />
            <token id="34" string="did" />
            <token id="35" string="n't" />
            <token id="36" string="live" />
            <token id="37" string="in" />
            <token id="38" string="this" />
            <token id="39" string="century" />
          </tokens>
        </chunking>
        <chunking id="16" string="did n't live in this century" type="VP">
          <tokens>
            <token id="34" string="did" />
            <token id="35" string="n't" />
            <token id="36" string="live" />
            <token id="37" string="in" />
            <token id="38" string="this" />
            <token id="39" string="century" />
          </tokens>
        </chunking>
        <chunking id="17" string="a number" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="number" />
          </tokens>
        </chunking>
        <chunking id="18" string="the Holocaust and his declaration" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="Holocaust" />
            <token id="28" string="and" />
            <token id="29" string="his" />
            <token id="30" string="declaration" />
          </tokens>
        </chunking>
        <chunking id="19" string="being his garbled explanation of the Holocaust and his declaration" type="VP">
          <tokens>
            <token id="21" string="being" />
            <token id="22" string="his" />
            <token id="23" string="garbled" />
            <token id="24" string="explanation" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="Holocaust" />
            <token id="28" string="and" />
            <token id="29" string="his" />
            <token id="30" string="declaration" />
          </tokens>
        </chunking>
        <chunking id="20" string="live in this century" type="VP">
          <tokens>
            <token id="36" string="live" />
            <token id="37" string="in" />
            <token id="38" string="this" />
            <token id="39" string="century" />
          </tokens>
        </chunking>
        <chunking id="21" string="his garbled explanation of the Holocaust and his declaration" type="NP">
          <tokens>
            <token id="22" string="his" />
            <token id="23" string="garbled" />
            <token id="24" string="explanation" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="Holocaust" />
            <token id="28" string="and" />
            <token id="29" string="his" />
            <token id="30" string="declaration" />
          </tokens>
        </chunking>
        <chunking id="22" string="the Holocaust" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="Holocaust" />
          </tokens>
        </chunking>
        <chunking id="23" string="help his case by making a number of celebrated gaffes during the campaign , perhaps the worst being his garbled explanation of the Holocaust and his declaration , `` I did n't live in this century" type="VP">
          <tokens>
            <token id="4" string="help" />
            <token id="5" string="his" />
            <token id="6" string="case" />
            <token id="7" string="by" />
            <token id="8" string="making" />
            <token id="9" string="a" />
            <token id="10" string="number" />
            <token id="11" string="of" />
            <token id="12" string="celebrated" />
            <token id="13" string="gaffes" />
            <token id="14" string="during" />
            <token id="15" string="the" />
            <token id="16" string="campaign" />
            <token id="17" string="," />
            <token id="18" string="perhaps" />
            <token id="19" string="the" />
            <token id="20" string="worst" />
            <token id="21" string="being" />
            <token id="22" string="his" />
            <token id="23" string="garbled" />
            <token id="24" string="explanation" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="Holocaust" />
            <token id="28" string="and" />
            <token id="29" string="his" />
            <token id="30" string="declaration" />
            <token id="31" string="," />
            <token id="32" string="``" />
            <token id="33" string="I" />
            <token id="34" string="did" />
            <token id="35" string="n't" />
            <token id="36" string="live" />
            <token id="37" string="in" />
            <token id="38" string="this" />
            <token id="39" string="century" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">help</governor>
          <dependent id="1">Quayle</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">help</governor>
          <dependent id="2">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">help</governor>
          <dependent id="3">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">help</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">case</governor>
          <dependent id="5">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">help</governor>
          <dependent id="6">case</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">making</governor>
          <dependent id="7">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">help</governor>
          <dependent id="8">making</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">number</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">making</governor>
          <dependent id="10">number</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">gaffes</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">gaffes</governor>
          <dependent id="12">celebrated</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">number</governor>
          <dependent id="13">gaffes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">campaign</governor>
          <dependent id="14">during</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">campaign</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">making</governor>
          <dependent id="16">campaign</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">worst</governor>
          <dependent id="18">perhaps</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">worst</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="16">campaign</governor>
          <dependent id="20">worst</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="24">explanation</governor>
          <dependent id="21">being</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">explanation</governor>
          <dependent id="22">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">explanation</governor>
          <dependent id="23">garbled</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="36">live</governor>
          <dependent id="24">explanation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">Holocaust</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">Holocaust</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">explanation</governor>
          <dependent id="27">Holocaust</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="27">Holocaust</governor>
          <dependent id="28">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="30">declaration</governor>
          <dependent id="29">his</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="27">Holocaust</governor>
          <dependent id="30">declaration</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">live</governor>
          <dependent id="33">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="36">live</governor>
          <dependent id="34">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="36">live</governor>
          <dependent id="35">n't</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="20">worst</governor>
          <dependent id="36">live</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">century</governor>
          <dependent id="37">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">century</governor>
          <dependent id="38">this</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">live</governor>
          <dependent id="39">century</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="this century" type="DATE" score="0.0">
          <tokens>
            <token id="38" string="this" />
            <token id="39" string="century" />
          </tokens>
        </entity>
        <entity id="2" string="Quayle" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Quayle" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>Norman Ornstein, of the American Enterprise Institute, says Quayle, while ``not the world&amp;apost;s leading intellectual,&amp;apost;&amp;apost; is not ``a complete dummy.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="Norman" lemma="Norman" stem="norman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Ornstein" lemma="Ornstein" stem="ornstein" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="American" lemma="American" stem="american" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="7" string="Enterprise" lemma="Enterprise" stem="enterpris" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="8" string="Institute" lemma="Institute" stem="institut" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Quayle" lemma="Quayle" stem="quayl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="leading" lemma="lead" stem="lead" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="intellectual" lemma="intellectual" stem="intellectu" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="complete" lemma="complete" stem="complet" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="dummy" lemma="dummy" stem="dummi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Norman) (NNP Ornstein)) (, ,) (PP (IN of) (NP (DT the) (NNP American) (NNP Enterprise) (NNP Institute))) (, ,)) (VP (VBZ says) (SBAR (S (NP (NP (NNP Quayle)) (, ,) (SBAR (IN while) (S (`` ``) (RB not) (S (NP (DT the) (NN world) (POS 's)) (VP (VBG leading) (ADJP (JJ intellectual)))))) (, ,) ('' '')) (VP (VBZ is) (PP (RB not) (NP (`` ``) (DT a) (JJ complete) (NN dummy))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="says Quayle , while `` not the world 's leading intellectual , '' is not `` a complete dummy" type="VP">
          <tokens>
            <token id="10" string="says" />
            <token id="11" string="Quayle" />
            <token id="12" string="," />
            <token id="13" string="while" />
            <token id="14" string="``" />
            <token id="15" string="not" />
            <token id="16" string="the" />
            <token id="17" string="world" />
            <token id="18" string="'s" />
            <token id="19" string="leading" />
            <token id="20" string="intellectual" />
            <token id="21" string="," />
            <token id="22" string="''" />
            <token id="23" string="is" />
            <token id="24" string="not" />
            <token id="25" string="``" />
            <token id="26" string="a" />
            <token id="27" string="complete" />
            <token id="28" string="dummy" />
          </tokens>
        </chunking>
        <chunking id="2" string="Quayle , while `` not the world 's leading intellectual , '' is not `` a complete dummy" type="SBAR">
          <tokens>
            <token id="11" string="Quayle" />
            <token id="12" string="," />
            <token id="13" string="while" />
            <token id="14" string="``" />
            <token id="15" string="not" />
            <token id="16" string="the" />
            <token id="17" string="world" />
            <token id="18" string="'s" />
            <token id="19" string="leading" />
            <token id="20" string="intellectual" />
            <token id="21" string="," />
            <token id="22" string="''" />
            <token id="23" string="is" />
            <token id="24" string="not" />
            <token id="25" string="``" />
            <token id="26" string="a" />
            <token id="27" string="complete" />
            <token id="28" string="dummy" />
          </tokens>
        </chunking>
        <chunking id="3" string="Quayle" type="NP">
          <tokens>
            <token id="11" string="Quayle" />
          </tokens>
        </chunking>
        <chunking id="4" string="while `` not the world 's leading intellectual" type="SBAR">
          <tokens>
            <token id="13" string="while" />
            <token id="14" string="``" />
            <token id="15" string="not" />
            <token id="16" string="the" />
            <token id="17" string="world" />
            <token id="18" string="'s" />
            <token id="19" string="leading" />
            <token id="20" string="intellectual" />
          </tokens>
        </chunking>
        <chunking id="5" string="`` a complete dummy" type="NP">
          <tokens>
            <token id="25" string="``" />
            <token id="26" string="a" />
            <token id="27" string="complete" />
            <token id="28" string="dummy" />
          </tokens>
        </chunking>
        <chunking id="6" string="Quayle , while `` not the world 's leading intellectual , ''" type="NP">
          <tokens>
            <token id="11" string="Quayle" />
            <token id="12" string="," />
            <token id="13" string="while" />
            <token id="14" string="``" />
            <token id="15" string="not" />
            <token id="16" string="the" />
            <token id="17" string="world" />
            <token id="18" string="'s" />
            <token id="19" string="leading" />
            <token id="20" string="intellectual" />
            <token id="21" string="," />
            <token id="22" string="''" />
          </tokens>
        </chunking>
        <chunking id="7" string="is not `` a complete dummy" type="VP">
          <tokens>
            <token id="23" string="is" />
            <token id="24" string="not" />
            <token id="25" string="``" />
            <token id="26" string="a" />
            <token id="27" string="complete" />
            <token id="28" string="dummy" />
          </tokens>
        </chunking>
        <chunking id="8" string="Norman Ornstein , of the American Enterprise Institute ," type="NP">
          <tokens>
            <token id="1" string="Norman" />
            <token id="2" string="Ornstein" />
            <token id="3" string="," />
            <token id="4" string="of" />
            <token id="5" string="the" />
            <token id="6" string="American" />
            <token id="7" string="Enterprise" />
            <token id="8" string="Institute" />
            <token id="9" string="," />
          </tokens>
        </chunking>
        <chunking id="9" string="intellectual" type="ADJP">
          <tokens>
            <token id="20" string="intellectual" />
          </tokens>
        </chunking>
        <chunking id="10" string="the American Enterprise Institute" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="American" />
            <token id="7" string="Enterprise" />
            <token id="8" string="Institute" />
          </tokens>
        </chunking>
        <chunking id="11" string="Norman Ornstein" type="NP">
          <tokens>
            <token id="1" string="Norman" />
            <token id="2" string="Ornstein" />
          </tokens>
        </chunking>
        <chunking id="12" string="leading intellectual" type="VP">
          <tokens>
            <token id="19" string="leading" />
            <token id="20" string="intellectual" />
          </tokens>
        </chunking>
        <chunking id="13" string="the world 's" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="world" />
            <token id="18" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Ornstein</governor>
          <dependent id="1">Norman</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">says</governor>
          <dependent id="2">Ornstein</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Institute</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">Institute</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Institute</governor>
          <dependent id="6">American</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Institute</governor>
          <dependent id="7">Enterprise</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Ornstein</governor>
          <dependent id="8">Institute</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">says</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">dummy</governor>
          <dependent id="11">Quayle</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">leading</governor>
          <dependent id="13">while</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="19">leading</governor>
          <dependent id="15">not</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">world</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">leading</governor>
          <dependent id="17">world</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">world</governor>
          <dependent id="18">'s</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">Quayle</governor>
          <dependent id="19">leading</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="19">leading</governor>
          <dependent id="20">intellectual</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="28">dummy</governor>
          <dependent id="23">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="28">dummy</governor>
          <dependent id="24">not</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">dummy</governor>
          <dependent id="26">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">dummy</governor>
          <dependent id="27">complete</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">says</governor>
          <dependent id="28">dummy</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="American Enterprise Institute" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="6" string="American" />
            <token id="7" string="Enterprise" />
            <token id="8" string="Institute" />
          </tokens>
        </entity>
        <entity id="2" string="Quayle" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Quayle" />
          </tokens>
        </entity>
        <entity id="3" string="Norman Ornstein" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Norman" />
            <token id="2" string="Ornstein" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>He was simply thrust into a situation for which he was unprepared, Ornstein says.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="simply" lemma="simply" stem="simpli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="thrust" lemma="thrust" stem="thrust" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="situation" lemma="situation" stem="situat" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="unprepared" lemma="unprepared" stem="unprepar" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Ornstein" lemma="Ornstein" stem="ornstein" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP He)) (VP (VBD was) (ADVP (RB simply)) (VP (VBN thrust) (PP (IN into) (NP (NP (DT a) (NN situation)) (SBAR (WHPP (IN for) (WHNP (WDT which))) (S (NP (PRP he)) (VP (VBD was) (ADJP (JJ unprepared)))))))))) (, ,) (NP (NNP Ornstein)) (VP (VBZ says)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="says" type="VP">
          <tokens>
            <token id="15" string="says" />
          </tokens>
        </chunking>
        <chunking id="2" string="was simply thrust into a situation for which he was unprepared" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="simply" />
            <token id="4" string="thrust" />
            <token id="5" string="into" />
            <token id="6" string="a" />
            <token id="7" string="situation" />
            <token id="8" string="for" />
            <token id="9" string="which" />
            <token id="10" string="he" />
            <token id="11" string="was" />
            <token id="12" string="unprepared" />
          </tokens>
        </chunking>
        <chunking id="3" string="for which he was unprepared" type="SBAR">
          <tokens>
            <token id="8" string="for" />
            <token id="9" string="which" />
            <token id="10" string="he" />
            <token id="11" string="was" />
            <token id="12" string="unprepared" />
          </tokens>
        </chunking>
        <chunking id="4" string="thrust into a situation for which he was unprepared" type="VP">
          <tokens>
            <token id="4" string="thrust" />
            <token id="5" string="into" />
            <token id="6" string="a" />
            <token id="7" string="situation" />
            <token id="8" string="for" />
            <token id="9" string="which" />
            <token id="10" string="he" />
            <token id="11" string="was" />
            <token id="12" string="unprepared" />
          </tokens>
        </chunking>
        <chunking id="5" string="unprepared" type="ADJP">
          <tokens>
            <token id="12" string="unprepared" />
          </tokens>
        </chunking>
        <chunking id="6" string="a situation" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="situation" />
          </tokens>
        </chunking>
        <chunking id="7" string="was unprepared" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="unprepared" />
          </tokens>
        </chunking>
        <chunking id="8" string="a situation for which he was unprepared" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="situation" />
            <token id="8" string="for" />
            <token id="9" string="which" />
            <token id="10" string="he" />
            <token id="11" string="was" />
            <token id="12" string="unprepared" />
          </tokens>
        </chunking>
        <chunking id="9" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="10" string="he" type="NP">
          <tokens>
            <token id="10" string="he" />
          </tokens>
        </chunking>
        <chunking id="11" string="Ornstein" type="NP">
          <tokens>
            <token id="14" string="Ornstein" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="4">thrust</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">thrust</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">thrust</governor>
          <dependent id="3">simply</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">says</governor>
          <dependent id="4">thrust</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">situation</governor>
          <dependent id="5">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">situation</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">thrust</governor>
          <dependent id="7">situation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">which</governor>
          <dependent id="8">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">unprepared</governor>
          <dependent id="9">which</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">unprepared</governor>
          <dependent id="10">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">unprepared</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">situation</governor>
          <dependent id="12">unprepared</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">says</governor>
          <dependent id="14">Ornstein</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">says</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ornstein" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Ornstein" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>``I think he&amp;apost;s immature.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="immature" lemma="immature" stem="immatur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBP think) (SBAR (S (NP (PRP he)) (VP (VBZ 's) (ADJP (JJ immature)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="think he 's immature" type="VP">
          <tokens>
            <token id="3" string="think" />
            <token id="4" string="he" />
            <token id="5" string="'s" />
            <token id="6" string="immature" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="immature" type="ADJP">
          <tokens>
            <token id="6" string="immature" />
          </tokens>
        </chunking>
        <chunking id="4" string="he" type="NP">
          <tokens>
            <token id="4" string="he" />
          </tokens>
        </chunking>
        <chunking id="5" string="'s immature" type="VP">
          <tokens>
            <token id="5" string="'s" />
            <token id="6" string="immature" />
          </tokens>
        </chunking>
        <chunking id="6" string="he 's immature" type="SBAR">
          <tokens>
            <token id="4" string="he" />
            <token id="5" string="'s" />
            <token id="6" string="immature" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">think</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">think</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">immature</governor>
          <dependent id="4">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">immature</governor>
          <dependent id="5">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">think</governor>
          <dependent id="6">immature</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>He&amp;apost;s not stupid,&amp;apost;&amp;apost; Ornstein says.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="stupid" lemma="stupid" stem="stupid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Ornstein" lemma="Ornstein" stem="ornstein" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP He)) (VP (VBZ 's) (RB not) (ADJP (JJ stupid)))) (, ,) ('' '') (NP (NNP Ornstein)) (VP (VBZ says)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="stupid" type="ADJP">
          <tokens>
            <token id="4" string="stupid" />
          </tokens>
        </chunking>
        <chunking id="2" string="says" type="VP">
          <tokens>
            <token id="8" string="says" />
          </tokens>
        </chunking>
        <chunking id="3" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="4" string="'s not stupid" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="not" />
            <token id="4" string="stupid" />
          </tokens>
        </chunking>
        <chunking id="5" string="Ornstein" type="NP">
          <tokens>
            <token id="7" string="Ornstein" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">stupid</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">stupid</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">stupid</governor>
          <dependent id="3">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">says</governor>
          <dependent id="4">stupid</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">says</governor>
          <dependent id="7">Ornstein</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">says</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ornstein" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Ornstein" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>But Quayle comes to the White House with ``a very damaging stereotype that&amp;apost;s developed about him that&amp;apost;s widely believed in the political community and that&amp;apost;s believed by a large segment of the electorate,&amp;apost;&amp;apost; Ornstein says.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Quayle" lemma="Quayle" stem="quayl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="comes" lemma="come" stem="come" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="White" lemma="White" stem="white" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="7" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="8" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="damaging" lemma="damaging" stem="damag" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="stereotype" lemma="stereotype" stem="stereotyp" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="developed" lemma="develop" stem="develop" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="widely" lemma="widely" stem="wide" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="believed" lemma="believe" stem="believ" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="25" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="26" string="community" lemma="community" stem="commun" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="believed" lemma="believe" stem="believ" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="large" lemma="large" stem="larg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="segment" lemma="segment" stem="segment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="electorate" lemma="electorate" stem="elector" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="Ornstein" lemma="Ornstein" stem="ornstein" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="41" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (S (S (NP (NNP Quayle)) (VP (VBZ comes) (PP (TO to) (NP (DT the) (NNP White) (NNP House))) (PP (IN with) (`` ``) (NP (NP (DT a) (ADJP (RB very) (JJ damaging)) (NN stereotype)) (SBAR (WHNP (WDT that)) (S (VP (VBZ 's) (VP (VBN developed) (PP (IN about) (NP (NP (PRP him)) (SBAR (WHNP (DT that)) (S (VP (VBZ 's) (ADVP (RB widely)) (VP (VBN believed) (PP (IN in) (NP (DT the) (JJ political) (NN community))))))))))))))))) (CC and) (S (NP (DT that)) (VP (VBZ 's) (VP (VBN believed) (PP (IN by) (NP (NP (DT a) (JJ large) (NN segment)) (PP (IN of) (NP (DT the) (NN electorate))))))))) (, ,) ('' '') (NP (NNP Ornstein)) (VP (VBZ says)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="'s widely believed in the political community" type="VP">
          <tokens>
            <token id="20" string="'s" />
            <token id="21" string="widely" />
            <token id="22" string="believed" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="political" />
            <token id="26" string="community" />
          </tokens>
        </chunking>
        <chunking id="2" string="Quayle" type="NP">
          <tokens>
            <token id="2" string="Quayle" />
          </tokens>
        </chunking>
        <chunking id="3" string="a very damaging stereotype that 's developed about him that 's widely believed in the political community" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="very" />
            <token id="12" string="damaging" />
            <token id="13" string="stereotype" />
            <token id="14" string="that" />
            <token id="15" string="'s" />
            <token id="16" string="developed" />
            <token id="17" string="about" />
            <token id="18" string="him" />
            <token id="19" string="that" />
            <token id="20" string="'s" />
            <token id="21" string="widely" />
            <token id="22" string="believed" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="political" />
            <token id="26" string="community" />
          </tokens>
        </chunking>
        <chunking id="4" string="very damaging" type="ADJP">
          <tokens>
            <token id="11" string="very" />
            <token id="12" string="damaging" />
          </tokens>
        </chunking>
        <chunking id="5" string="'s developed about him that 's widely believed in the political community" type="VP">
          <tokens>
            <token id="15" string="'s" />
            <token id="16" string="developed" />
            <token id="17" string="about" />
            <token id="18" string="him" />
            <token id="19" string="that" />
            <token id="20" string="'s" />
            <token id="21" string="widely" />
            <token id="22" string="believed" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="political" />
            <token id="26" string="community" />
          </tokens>
        </chunking>
        <chunking id="6" string="comes to the White House with `` a very damaging stereotype that 's developed about him that 's widely believed in the political community" type="VP">
          <tokens>
            <token id="3" string="comes" />
            <token id="4" string="to" />
            <token id="5" string="the" />
            <token id="6" string="White" />
            <token id="7" string="House" />
            <token id="8" string="with" />
            <token id="9" string="``" />
            <token id="10" string="a" />
            <token id="11" string="very" />
            <token id="12" string="damaging" />
            <token id="13" string="stereotype" />
            <token id="14" string="that" />
            <token id="15" string="'s" />
            <token id="16" string="developed" />
            <token id="17" string="about" />
            <token id="18" string="him" />
            <token id="19" string="that" />
            <token id="20" string="'s" />
            <token id="21" string="widely" />
            <token id="22" string="believed" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="political" />
            <token id="26" string="community" />
          </tokens>
        </chunking>
        <chunking id="7" string="a very damaging stereotype" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="very" />
            <token id="12" string="damaging" />
            <token id="13" string="stereotype" />
          </tokens>
        </chunking>
        <chunking id="8" string="the White House" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="White" />
            <token id="7" string="House" />
          </tokens>
        </chunking>
        <chunking id="9" string="believed by a large segment of the electorate" type="VP">
          <tokens>
            <token id="30" string="believed" />
            <token id="31" string="by" />
            <token id="32" string="a" />
            <token id="33" string="large" />
            <token id="34" string="segment" />
            <token id="35" string="of" />
            <token id="36" string="the" />
            <token id="37" string="electorate" />
          </tokens>
        </chunking>
        <chunking id="10" string="him" type="NP">
          <tokens>
            <token id="18" string="him" />
          </tokens>
        </chunking>
        <chunking id="11" string="him that 's widely believed in the political community" type="NP">
          <tokens>
            <token id="18" string="him" />
            <token id="19" string="that" />
            <token id="20" string="'s" />
            <token id="21" string="widely" />
            <token id="22" string="believed" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="political" />
            <token id="26" string="community" />
          </tokens>
        </chunking>
        <chunking id="12" string="the electorate" type="NP">
          <tokens>
            <token id="36" string="the" />
            <token id="37" string="electorate" />
          </tokens>
        </chunking>
        <chunking id="13" string="'s believed by a large segment of the electorate" type="VP">
          <tokens>
            <token id="29" string="'s" />
            <token id="30" string="believed" />
            <token id="31" string="by" />
            <token id="32" string="a" />
            <token id="33" string="large" />
            <token id="34" string="segment" />
            <token id="35" string="of" />
            <token id="36" string="the" />
            <token id="37" string="electorate" />
          </tokens>
        </chunking>
        <chunking id="14" string="the political community" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="political" />
            <token id="26" string="community" />
          </tokens>
        </chunking>
        <chunking id="15" string="a large segment" type="NP">
          <tokens>
            <token id="32" string="a" />
            <token id="33" string="large" />
            <token id="34" string="segment" />
          </tokens>
        </chunking>
        <chunking id="16" string="that" type="NP">
          <tokens>
            <token id="28" string="that" />
          </tokens>
        </chunking>
        <chunking id="17" string="believed in the political community" type="VP">
          <tokens>
            <token id="22" string="believed" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="political" />
            <token id="26" string="community" />
          </tokens>
        </chunking>
        <chunking id="18" string="says" type="VP">
          <tokens>
            <token id="41" string="says" />
          </tokens>
        </chunking>
        <chunking id="19" string="that 's widely believed in the political community" type="SBAR">
          <tokens>
            <token id="19" string="that" />
            <token id="20" string="'s" />
            <token id="21" string="widely" />
            <token id="22" string="believed" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="political" />
            <token id="26" string="community" />
          </tokens>
        </chunking>
        <chunking id="20" string="developed about him that 's widely believed in the political community" type="VP">
          <tokens>
            <token id="16" string="developed" />
            <token id="17" string="about" />
            <token id="18" string="him" />
            <token id="19" string="that" />
            <token id="20" string="'s" />
            <token id="21" string="widely" />
            <token id="22" string="believed" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="political" />
            <token id="26" string="community" />
          </tokens>
        </chunking>
        <chunking id="21" string="that 's developed about him that 's widely believed in the political community" type="SBAR">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="'s" />
            <token id="16" string="developed" />
            <token id="17" string="about" />
            <token id="18" string="him" />
            <token id="19" string="that" />
            <token id="20" string="'s" />
            <token id="21" string="widely" />
            <token id="22" string="believed" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="political" />
            <token id="26" string="community" />
          </tokens>
        </chunking>
        <chunking id="22" string="Ornstein" type="NP">
          <tokens>
            <token id="40" string="Ornstein" />
          </tokens>
        </chunking>
        <chunking id="23" string="a large segment of the electorate" type="NP">
          <tokens>
            <token id="32" string="a" />
            <token id="33" string="large" />
            <token id="34" string="segment" />
            <token id="35" string="of" />
            <token id="36" string="the" />
            <token id="37" string="electorate" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="41">says</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">comes</governor>
          <dependent id="2">Quayle</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="41">says</governor>
          <dependent id="3">comes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">House</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">House</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">House</governor>
          <dependent id="6">White</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">comes</governor>
          <dependent id="7">House</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">stereotype</governor>
          <dependent id="8">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">stereotype</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">damaging</governor>
          <dependent id="11">very</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">stereotype</governor>
          <dependent id="12">damaging</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">comes</governor>
          <dependent id="13">stereotype</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="16">developed</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="16">developed</governor>
          <dependent id="15">'s</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">stereotype</governor>
          <dependent id="16">developed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">him</governor>
          <dependent id="17">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">developed</governor>
          <dependent id="18">him</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="22">believed</governor>
          <dependent id="19">that</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="22">believed</governor>
          <dependent id="20">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">believed</governor>
          <dependent id="21">widely</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="18">him</governor>
          <dependent id="22">believed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">community</governor>
          <dependent id="23">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">community</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">community</governor>
          <dependent id="25">political</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">believed</governor>
          <dependent id="26">community</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">comes</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="30">believed</governor>
          <dependent id="28">that</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="30">believed</governor>
          <dependent id="29">'s</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">comes</governor>
          <dependent id="30">believed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">segment</governor>
          <dependent id="31">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">segment</governor>
          <dependent id="32">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">segment</governor>
          <dependent id="33">large</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">believed</governor>
          <dependent id="34">segment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">electorate</governor>
          <dependent id="35">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">electorate</governor>
          <dependent id="36">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">segment</governor>
          <dependent id="37">electorate</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="41">says</governor>
          <dependent id="40">Ornstein</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="41">says</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Quayle" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Quayle" />
          </tokens>
        </entity>
        <entity id="2" string="White House" type="LOCATION" score="0.0">
          <tokens>
            <token id="6" string="White" />
            <token id="7" string="House" />
          </tokens>
        </entity>
        <entity id="3" string="Ornstein" type="PERSON" score="0.0">
          <tokens>
            <token id="40" string="Ornstein" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>``That&amp;apost;s going to give him a good deal to overcome.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="give" lemma="give" stem="give" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="deal" lemma="deal" stem="deal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="overcome" lemma="overcome" stem="overcom" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (DT That)) (VP (VBZ 's) (VP (VBG going) (S (VP (TO to) (VP (VB give) (NP (PRP him)) (NP (DT a) (JJ good) (NN deal) (S (VP (TO to) (VP (VB overcome)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="That" type="NP">
          <tokens>
            <token id="2" string="That" />
          </tokens>
        </chunking>
        <chunking id="2" string="'s going to give him a good deal to overcome" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="going" />
            <token id="5" string="to" />
            <token id="6" string="give" />
            <token id="7" string="him" />
            <token id="8" string="a" />
            <token id="9" string="good" />
            <token id="10" string="deal" />
            <token id="11" string="to" />
            <token id="12" string="overcome" />
          </tokens>
        </chunking>
        <chunking id="3" string="a good deal to overcome" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="good" />
            <token id="10" string="deal" />
            <token id="11" string="to" />
            <token id="12" string="overcome" />
          </tokens>
        </chunking>
        <chunking id="4" string="give him a good deal to overcome" type="VP">
          <tokens>
            <token id="6" string="give" />
            <token id="7" string="him" />
            <token id="8" string="a" />
            <token id="9" string="good" />
            <token id="10" string="deal" />
            <token id="11" string="to" />
            <token id="12" string="overcome" />
          </tokens>
        </chunking>
        <chunking id="5" string="overcome" type="VP">
          <tokens>
            <token id="12" string="overcome" />
          </tokens>
        </chunking>
        <chunking id="6" string="going to give him a good deal to overcome" type="VP">
          <tokens>
            <token id="4" string="going" />
            <token id="5" string="to" />
            <token id="6" string="give" />
            <token id="7" string="him" />
            <token id="8" string="a" />
            <token id="9" string="good" />
            <token id="10" string="deal" />
            <token id="11" string="to" />
            <token id="12" string="overcome" />
          </tokens>
        </chunking>
        <chunking id="7" string="him" type="NP">
          <tokens>
            <token id="7" string="him" />
          </tokens>
        </chunking>
        <chunking id="8" string="to overcome" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="overcome" />
          </tokens>
        </chunking>
        <chunking id="9" string="to give him a good deal to overcome" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="give" />
            <token id="7" string="him" />
            <token id="8" string="a" />
            <token id="9" string="good" />
            <token id="10" string="deal" />
            <token id="11" string="to" />
            <token id="12" string="overcome" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">going</governor>
          <dependent id="2">That</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">going</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">give</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">going</governor>
          <dependent id="6">give</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="6">give</governor>
          <dependent id="7">him</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">deal</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">deal</governor>
          <dependent id="9">good</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">give</governor>
          <dependent id="10">deal</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">overcome</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="10">deal</governor>
          <dependent id="12">overcome</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>It&amp;apost;s going to give him an enormous impetus to prove himself.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="give" lemma="give" stem="give" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="enormous" lemma="enormous" stem="enorm" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="impetus" lemma="impetus" stem="impetu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="prove" lemma="prove" stem="prove" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="himself" lemma="himself" stem="himself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ 's) (VP (VBG going) (S (VP (TO to) (VP (VB give) (NP (PRP him)) (NP (DT an) (JJ enormous) (NN impetus) (S (VP (TO to) (VP (VB prove) (NP (PRP himself))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="going to give him an enormous impetus to prove himself" type="VP">
          <tokens>
            <token id="3" string="going" />
            <token id="4" string="to" />
            <token id="5" string="give" />
            <token id="6" string="him" />
            <token id="7" string="an" />
            <token id="8" string="enormous" />
            <token id="9" string="impetus" />
            <token id="10" string="to" />
            <token id="11" string="prove" />
            <token id="12" string="himself" />
          </tokens>
        </chunking>
        <chunking id="2" string="to give him an enormous impetus to prove himself" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="give" />
            <token id="6" string="him" />
            <token id="7" string="an" />
            <token id="8" string="enormous" />
            <token id="9" string="impetus" />
            <token id="10" string="to" />
            <token id="11" string="prove" />
            <token id="12" string="himself" />
          </tokens>
        </chunking>
        <chunking id="3" string="prove himself" type="VP">
          <tokens>
            <token id="11" string="prove" />
            <token id="12" string="himself" />
          </tokens>
        </chunking>
        <chunking id="4" string="'s going to give him an enormous impetus to prove himself" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="going" />
            <token id="4" string="to" />
            <token id="5" string="give" />
            <token id="6" string="him" />
            <token id="7" string="an" />
            <token id="8" string="enormous" />
            <token id="9" string="impetus" />
            <token id="10" string="to" />
            <token id="11" string="prove" />
            <token id="12" string="himself" />
          </tokens>
        </chunking>
        <chunking id="5" string="give him an enormous impetus to prove himself" type="VP">
          <tokens>
            <token id="5" string="give" />
            <token id="6" string="him" />
            <token id="7" string="an" />
            <token id="8" string="enormous" />
            <token id="9" string="impetus" />
            <token id="10" string="to" />
            <token id="11" string="prove" />
            <token id="12" string="himself" />
          </tokens>
        </chunking>
        <chunking id="6" string="an enormous impetus to prove himself" type="NP">
          <tokens>
            <token id="7" string="an" />
            <token id="8" string="enormous" />
            <token id="9" string="impetus" />
            <token id="10" string="to" />
            <token id="11" string="prove" />
            <token id="12" string="himself" />
          </tokens>
        </chunking>
        <chunking id="7" string="to prove himself" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="prove" />
            <token id="12" string="himself" />
          </tokens>
        </chunking>
        <chunking id="8" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="9" string="him" type="NP">
          <tokens>
            <token id="6" string="him" />
          </tokens>
        </chunking>
        <chunking id="10" string="himself" type="NP">
          <tokens>
            <token id="12" string="himself" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">going</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">going</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">give</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">going</governor>
          <dependent id="5">give</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="5">give</governor>
          <dependent id="6">him</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">impetus</governor>
          <dependent id="7">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">impetus</governor>
          <dependent id="8">enormous</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">give</governor>
          <dependent id="9">impetus</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">prove</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="9">impetus</governor>
          <dependent id="11">prove</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">prove</governor>
          <dependent id="12">himself</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>That&amp;apost;s going to be difficult, given the office.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="difficult" lemma="difficult" stem="difficult" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="given" lemma="give" stem="given" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT That)) (VP (VBZ 's) (VP (VBG going) (S (VP (TO to) (VP (VB be) (ADJP (JJ difficult)) (, ,) (PP (VBN given) (NP (DT the) (NN office)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="That" type="NP">
          <tokens>
            <token id="1" string="That" />
          </tokens>
        </chunking>
        <chunking id="2" string="'s going to be difficult , given the office" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="going" />
            <token id="4" string="to" />
            <token id="5" string="be" />
            <token id="6" string="difficult" />
            <token id="7" string="," />
            <token id="8" string="given" />
            <token id="9" string="the" />
            <token id="10" string="office" />
          </tokens>
        </chunking>
        <chunking id="3" string="going to be difficult , given the office" type="VP">
          <tokens>
            <token id="3" string="going" />
            <token id="4" string="to" />
            <token id="5" string="be" />
            <token id="6" string="difficult" />
            <token id="7" string="," />
            <token id="8" string="given" />
            <token id="9" string="the" />
            <token id="10" string="office" />
          </tokens>
        </chunking>
        <chunking id="4" string="the office" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="office" />
          </tokens>
        </chunking>
        <chunking id="5" string="difficult" type="ADJP">
          <tokens>
            <token id="6" string="difficult" />
          </tokens>
        </chunking>
        <chunking id="6" string="be difficult , given the office" type="VP">
          <tokens>
            <token id="5" string="be" />
            <token id="6" string="difficult" />
            <token id="7" string="," />
            <token id="8" string="given" />
            <token id="9" string="the" />
            <token id="10" string="office" />
          </tokens>
        </chunking>
        <chunking id="7" string="to be difficult , given the office" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="be" />
            <token id="6" string="difficult" />
            <token id="7" string="," />
            <token id="8" string="given" />
            <token id="9" string="the" />
            <token id="10" string="office" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">going</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">going</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">difficult</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">difficult</governor>
          <dependent id="5">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">going</governor>
          <dependent id="6">difficult</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">office</governor>
          <dependent id="8">given</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">office</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">difficult</governor>
          <dependent id="10">office</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>Both Barilleaux and Stephen Hess of the Brookings Institution see parallels in Quayle&amp;apost;s vice presidency and those of Richard Nixon and Spiro Agnew.</content>
      <tokens>
        <token id="1" string="Both" lemma="both" stem="both" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="Barilleaux" lemma="Barilleaux" stem="barilleaux" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="Stephen" lemma="Stephen" stem="stephen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="Hess" lemma="Hess" stem="hess" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="Brookings" lemma="Brookings" stem="brook" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="9" string="Institution" lemma="Institution" stem="institut" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="10" string="see" lemma="see" stem="see" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="parallels" lemma="parallel" stem="parallel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Quayle" lemma="Quayle" stem="quayl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="vice" lemma="vice" stem="vice" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="presidency" lemma="presidency" stem="presid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Richard" lemma="Richard" stem="richard" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="21" string="Nixon" lemma="Nixon" stem="nixon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Spiro" lemma="Spiro" stem="spiro" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="24" string="Agnew" lemma="Agnew" stem="agnew" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT Both) (NNP Barilleaux) (CC and) (NNP Stephen) (NNP Hess)) (PP (IN of) (NP (DT the) (NNP Brookings) (NNP Institution)))) (VP (VB see) (NP (NP (NP (NNS parallels)) (PP (IN in) (NP (NP (NNP Quayle) (POS 's)) (NN vice) (NN presidency)))) (CC and) (NP (NP (DT those)) (PP (IN of) (NP (NP (NNP Richard) (NNP Nixon)) (CC and) (NP (NNP Spiro) (NNP Agnew))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Richard Nixon" type="NP">
          <tokens>
            <token id="20" string="Richard" />
            <token id="21" string="Nixon" />
          </tokens>
        </chunking>
        <chunking id="2" string="see parallels in Quayle 's vice presidency and those of Richard Nixon and Spiro Agnew" type="VP">
          <tokens>
            <token id="10" string="see" />
            <token id="11" string="parallels" />
            <token id="12" string="in" />
            <token id="13" string="Quayle" />
            <token id="14" string="'s" />
            <token id="15" string="vice" />
            <token id="16" string="presidency" />
            <token id="17" string="and" />
            <token id="18" string="those" />
            <token id="19" string="of" />
            <token id="20" string="Richard" />
            <token id="21" string="Nixon" />
            <token id="22" string="and" />
            <token id="23" string="Spiro" />
            <token id="24" string="Agnew" />
          </tokens>
        </chunking>
        <chunking id="3" string="Richard Nixon and Spiro Agnew" type="NP">
          <tokens>
            <token id="20" string="Richard" />
            <token id="21" string="Nixon" />
            <token id="22" string="and" />
            <token id="23" string="Spiro" />
            <token id="24" string="Agnew" />
          </tokens>
        </chunking>
        <chunking id="4" string="Both Barilleaux and Stephen Hess of the Brookings Institution" type="NP">
          <tokens>
            <token id="1" string="Both" />
            <token id="2" string="Barilleaux" />
            <token id="3" string="and" />
            <token id="4" string="Stephen" />
            <token id="5" string="Hess" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="Brookings" />
            <token id="9" string="Institution" />
          </tokens>
        </chunking>
        <chunking id="5" string="Spiro Agnew" type="NP">
          <tokens>
            <token id="23" string="Spiro" />
            <token id="24" string="Agnew" />
          </tokens>
        </chunking>
        <chunking id="6" string="Quayle 's" type="NP">
          <tokens>
            <token id="13" string="Quayle" />
            <token id="14" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="parallels in Quayle 's vice presidency and those of Richard Nixon and Spiro Agnew" type="NP">
          <tokens>
            <token id="11" string="parallels" />
            <token id="12" string="in" />
            <token id="13" string="Quayle" />
            <token id="14" string="'s" />
            <token id="15" string="vice" />
            <token id="16" string="presidency" />
            <token id="17" string="and" />
            <token id="18" string="those" />
            <token id="19" string="of" />
            <token id="20" string="Richard" />
            <token id="21" string="Nixon" />
            <token id="22" string="and" />
            <token id="23" string="Spiro" />
            <token id="24" string="Agnew" />
          </tokens>
        </chunking>
        <chunking id="8" string="Quayle 's vice presidency" type="NP">
          <tokens>
            <token id="13" string="Quayle" />
            <token id="14" string="'s" />
            <token id="15" string="vice" />
            <token id="16" string="presidency" />
          </tokens>
        </chunking>
        <chunking id="9" string="parallels in Quayle 's vice presidency" type="NP">
          <tokens>
            <token id="11" string="parallels" />
            <token id="12" string="in" />
            <token id="13" string="Quayle" />
            <token id="14" string="'s" />
            <token id="15" string="vice" />
            <token id="16" string="presidency" />
          </tokens>
        </chunking>
        <chunking id="10" string="Both Barilleaux and Stephen Hess" type="NP">
          <tokens>
            <token id="1" string="Both" />
            <token id="2" string="Barilleaux" />
            <token id="3" string="and" />
            <token id="4" string="Stephen" />
            <token id="5" string="Hess" />
          </tokens>
        </chunking>
        <chunking id="11" string="parallels" type="NP">
          <tokens>
            <token id="11" string="parallels" />
          </tokens>
        </chunking>
        <chunking id="12" string="those of Richard Nixon and Spiro Agnew" type="NP">
          <tokens>
            <token id="18" string="those" />
            <token id="19" string="of" />
            <token id="20" string="Richard" />
            <token id="21" string="Nixon" />
            <token id="22" string="and" />
            <token id="23" string="Spiro" />
            <token id="24" string="Agnew" />
          </tokens>
        </chunking>
        <chunking id="13" string="the Brookings Institution" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Brookings" />
            <token id="9" string="Institution" />
          </tokens>
        </chunking>
        <chunking id="14" string="those" type="NP">
          <tokens>
            <token id="18" string="those" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc:preconj">
          <governor id="5">Hess</governor>
          <dependent id="1">Both</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Hess</governor>
          <dependent id="2">Barilleaux</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">Barilleaux</governor>
          <dependent id="3">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">Barilleaux</governor>
          <dependent id="4">Stephen</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">see</governor>
          <dependent id="5">Hess</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Institution</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Institution</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Institution</governor>
          <dependent id="8">Brookings</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">Hess</governor>
          <dependent id="9">Institution</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">see</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">see</governor>
          <dependent id="11">parallels</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">presidency</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">presidency</governor>
          <dependent id="13">Quayle</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Quayle</governor>
          <dependent id="14">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">presidency</governor>
          <dependent id="15">vice</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">parallels</governor>
          <dependent id="16">presidency</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">parallels</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">parallels</governor>
          <dependent id="18">those</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Nixon</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Nixon</governor>
          <dependent id="20">Richard</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">those</governor>
          <dependent id="21">Nixon</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">Nixon</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Agnew</governor>
          <dependent id="23">Spiro</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">Nixon</governor>
          <dependent id="24">Agnew</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Spiro Agnew" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Spiro" />
            <token id="24" string="Agnew" />
          </tokens>
        </entity>
        <entity id="2" string="Quayle" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Quayle" />
          </tokens>
        </entity>
        <entity id="3" string="Richard Nixon" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Richard" />
            <token id="21" string="Nixon" />
          </tokens>
        </entity>
        <entity id="4" string="Barilleaux" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Barilleaux" />
          </tokens>
        </entity>
        <entity id="5" string="Stephen Hess" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Stephen" />
            <token id="5" string="Hess" />
          </tokens>
        </entity>
        <entity id="6" string="Brookings Institution" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="Brookings" />
            <token id="9" string="Institution" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>The choice of Nixon was viewed as a move by Dwight Eisenhower to appease the party&amp;apost;s right wing, and Agnew was seen as a political nonentity.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="choice" lemma="choice" stem="choic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Nixon" lemma="Nixon" stem="nixon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="viewed" lemma="view" stem="view" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="move" lemma="move" stem="move" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Dwight" lemma="Dwight" stem="dwight" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="Eisenhower" lemma="Eisenhower" stem="eisenhow" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="appease" lemma="appease" stem="appeas" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="party" lemma="party" stem="parti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="right" lemma="right" stem="right" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="19" string="wing" lemma="wing" stem="wing" pos="NN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Agnew" lemma="Agnew" stem="agnew" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="23" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="seen" lemma="see" stem="seen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="nonentity" lemma="nonentity" stem="nonent" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (DT The) (NN choice)) (PP (IN of) (NP (NNP Nixon)))) (VP (VBD was) (VP (VBN viewed) (PP (IN as) (NP (DT a) (NN move))) (PP (IN by) (NP (NNP Dwight) (NNP Eisenhower))) (S (VP (TO to) (VP (VB appease) (NP (NP (DT the) (NN party) (POS 's)) (JJ right) (NN wing)))))))) (, ,) (CC and) (S (NP (NNP Agnew)) (VP (VBD was) (VP (VBN seen) (PP (IN as) (NP (DT a) (JJ political) (NN nonentity)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was viewed as a move by Dwight Eisenhower to appease the party 's right wing" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="viewed" />
            <token id="7" string="as" />
            <token id="8" string="a" />
            <token id="9" string="move" />
            <token id="10" string="by" />
            <token id="11" string="Dwight" />
            <token id="12" string="Eisenhower" />
            <token id="13" string="to" />
            <token id="14" string="appease" />
            <token id="15" string="the" />
            <token id="16" string="party" />
            <token id="17" string="'s" />
            <token id="18" string="right" />
            <token id="19" string="wing" />
          </tokens>
        </chunking>
        <chunking id="2" string="the party 's" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="party" />
            <token id="17" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="was seen as a political nonentity" type="VP">
          <tokens>
            <token id="23" string="was" />
            <token id="24" string="seen" />
            <token id="25" string="as" />
            <token id="26" string="a" />
            <token id="27" string="political" />
            <token id="28" string="nonentity" />
          </tokens>
        </chunking>
        <chunking id="4" string="to appease the party 's right wing" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="appease" />
            <token id="15" string="the" />
            <token id="16" string="party" />
            <token id="17" string="'s" />
            <token id="18" string="right" />
            <token id="19" string="wing" />
          </tokens>
        </chunking>
        <chunking id="5" string="appease the party 's right wing" type="VP">
          <tokens>
            <token id="14" string="appease" />
            <token id="15" string="the" />
            <token id="16" string="party" />
            <token id="17" string="'s" />
            <token id="18" string="right" />
            <token id="19" string="wing" />
          </tokens>
        </chunking>
        <chunking id="6" string="Nixon" type="NP">
          <tokens>
            <token id="4" string="Nixon" />
          </tokens>
        </chunking>
        <chunking id="7" string="The choice" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="choice" />
          </tokens>
        </chunking>
        <chunking id="8" string="the party 's right wing" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="party" />
            <token id="17" string="'s" />
            <token id="18" string="right" />
            <token id="19" string="wing" />
          </tokens>
        </chunking>
        <chunking id="9" string="a move" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="move" />
          </tokens>
        </chunking>
        <chunking id="10" string="Dwight Eisenhower" type="NP">
          <tokens>
            <token id="11" string="Dwight" />
            <token id="12" string="Eisenhower" />
          </tokens>
        </chunking>
        <chunking id="11" string="seen as a political nonentity" type="VP">
          <tokens>
            <token id="24" string="seen" />
            <token id="25" string="as" />
            <token id="26" string="a" />
            <token id="27" string="political" />
            <token id="28" string="nonentity" />
          </tokens>
        </chunking>
        <chunking id="12" string="The choice of Nixon" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="choice" />
            <token id="3" string="of" />
            <token id="4" string="Nixon" />
          </tokens>
        </chunking>
        <chunking id="13" string="a political nonentity" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="political" />
            <token id="28" string="nonentity" />
          </tokens>
        </chunking>
        <chunking id="14" string="Agnew" type="NP">
          <tokens>
            <token id="22" string="Agnew" />
          </tokens>
        </chunking>
        <chunking id="15" string="viewed as a move by Dwight Eisenhower to appease the party 's right wing" type="VP">
          <tokens>
            <token id="6" string="viewed" />
            <token id="7" string="as" />
            <token id="8" string="a" />
            <token id="9" string="move" />
            <token id="10" string="by" />
            <token id="11" string="Dwight" />
            <token id="12" string="Eisenhower" />
            <token id="13" string="to" />
            <token id="14" string="appease" />
            <token id="15" string="the" />
            <token id="16" string="party" />
            <token id="17" string="'s" />
            <token id="18" string="right" />
            <token id="19" string="wing" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">choice</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">viewed</governor>
          <dependent id="2">choice</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Nixon</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">choice</governor>
          <dependent id="4">Nixon</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">viewed</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">viewed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">move</governor>
          <dependent id="7">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">move</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">viewed</governor>
          <dependent id="9">move</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Eisenhower</governor>
          <dependent id="10">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Eisenhower</governor>
          <dependent id="11">Dwight</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">viewed</governor>
          <dependent id="12">Eisenhower</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">appease</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">viewed</governor>
          <dependent id="14">appease</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">party</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">wing</governor>
          <dependent id="16">party</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">party</governor>
          <dependent id="17">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">wing</governor>
          <dependent id="18">right</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">appease</governor>
          <dependent id="19">wing</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">viewed</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="24">seen</governor>
          <dependent id="22">Agnew</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="24">seen</governor>
          <dependent id="23">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">viewed</governor>
          <dependent id="24">seen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">nonentity</governor>
          <dependent id="25">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">nonentity</governor>
          <dependent id="26">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">nonentity</governor>
          <dependent id="27">political</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">seen</governor>
          <dependent id="28">nonentity</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Dwight Eisenhower" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Dwight" />
            <token id="12" string="Eisenhower" />
          </tokens>
        </entity>
        <entity id="2" string="Nixon" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Nixon" />
          </tokens>
        </entity>
        <entity id="3" string="right wing" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="18" string="right" />
            <token id="19" string="wing" />
          </tokens>
        </entity>
        <entity id="4" string="Agnew" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Agnew" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>``The natural response is to use him (Quayle) sparingly, as Nixon did with Agnew in 1968,&amp;apost;&amp;apost; Hess says.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="natural" lemma="natural" stem="natur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="response" lemma="response" stem="respons" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="use" lemma="use" stem="us" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="Quayle" lemma="Quayle" stem="quayl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="sparingly" lemma="sparingly" stem="sparingli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Nixon" lemma="Nixon" stem="nixon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="16" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Agnew" lemma="Agnew" stem="agnew" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="1968" lemma="1968" stem="1968" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Hess" lemma="Hess" stem="hess" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="24" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (DT The) (JJ natural) (NN response)) (VP (VBZ is) (S (VP (TO to) (VP (VB use) (NP (NP (PRP him)) (PRN (-LRB- -LRB-) (NP (NNP Quayle)) (-RRB- -RRB-))) (ADVP (RB sparingly)) (, ,) (SBAR (IN as) (S (NP (NNP Nixon)) (VP (VBD did) (PP (IN with) (NP (NNP Agnew))) (PP (IN in) (NP (CD 1968))))))))))) (, ,) ('' '') (NP (NNP Hess)) (VP (VBZ says)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Quayle" type="NP">
          <tokens>
            <token id="10" string="Quayle" />
          </tokens>
        </chunking>
        <chunking id="2" string="Nixon" type="NP">
          <tokens>
            <token id="15" string="Nixon" />
          </tokens>
        </chunking>
        <chunking id="3" string="use him -LRB- Quayle -RRB- sparingly , as Nixon did with Agnew in 1968" type="VP">
          <tokens>
            <token id="7" string="use" />
            <token id="8" string="him" />
            <token id="9" string="(" />
            <token id="10" string="Quayle" />
            <token id="11" string=")" />
            <token id="12" string="sparingly" />
            <token id="13" string="," />
            <token id="14" string="as" />
            <token id="15" string="Nixon" />
            <token id="16" string="did" />
            <token id="17" string="with" />
            <token id="18" string="Agnew" />
            <token id="19" string="in" />
            <token id="20" string="1968" />
          </tokens>
        </chunking>
        <chunking id="4" string="as Nixon did with Agnew in 1968" type="SBAR">
          <tokens>
            <token id="14" string="as" />
            <token id="15" string="Nixon" />
            <token id="16" string="did" />
            <token id="17" string="with" />
            <token id="18" string="Agnew" />
            <token id="19" string="in" />
            <token id="20" string="1968" />
          </tokens>
        </chunking>
        <chunking id="5" string="is to use him -LRB- Quayle -RRB- sparingly , as Nixon did with Agnew in 1968" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="to" />
            <token id="7" string="use" />
            <token id="8" string="him" />
            <token id="9" string="(" />
            <token id="10" string="Quayle" />
            <token id="11" string=")" />
            <token id="12" string="sparingly" />
            <token id="13" string="," />
            <token id="14" string="as" />
            <token id="15" string="Nixon" />
            <token id="16" string="did" />
            <token id="17" string="with" />
            <token id="18" string="Agnew" />
            <token id="19" string="in" />
            <token id="20" string="1968" />
          </tokens>
        </chunking>
        <chunking id="6" string="him" type="NP">
          <tokens>
            <token id="8" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="to use him -LRB- Quayle -RRB- sparingly , as Nixon did with Agnew in 1968" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="use" />
            <token id="8" string="him" />
            <token id="9" string="(" />
            <token id="10" string="Quayle" />
            <token id="11" string=")" />
            <token id="12" string="sparingly" />
            <token id="13" string="," />
            <token id="14" string="as" />
            <token id="15" string="Nixon" />
            <token id="16" string="did" />
            <token id="17" string="with" />
            <token id="18" string="Agnew" />
            <token id="19" string="in" />
            <token id="20" string="1968" />
          </tokens>
        </chunking>
        <chunking id="8" string="says" type="VP">
          <tokens>
            <token id="24" string="says" />
          </tokens>
        </chunking>
        <chunking id="9" string="him -LRB- Quayle -RRB-" type="NP">
          <tokens>
            <token id="8" string="him" />
            <token id="9" string="(" />
            <token id="10" string="Quayle" />
            <token id="11" string=")" />
          </tokens>
        </chunking>
        <chunking id="10" string="The natural response" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="natural" />
            <token id="4" string="response" />
          </tokens>
        </chunking>
        <chunking id="11" string="did with Agnew in 1968" type="VP">
          <tokens>
            <token id="16" string="did" />
            <token id="17" string="with" />
            <token id="18" string="Agnew" />
            <token id="19" string="in" />
            <token id="20" string="1968" />
          </tokens>
        </chunking>
        <chunking id="12" string="Agnew" type="NP">
          <tokens>
            <token id="18" string="Agnew" />
          </tokens>
        </chunking>
        <chunking id="13" string="1968" type="NP">
          <tokens>
            <token id="20" string="1968" />
          </tokens>
        </chunking>
        <chunking id="14" string="Hess" type="NP">
          <tokens>
            <token id="23" string="Hess" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">response</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">response</governor>
          <dependent id="3">natural</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">is</governor>
          <dependent id="4">response</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="24">says</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">use</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">is</governor>
          <dependent id="7">use</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">use</governor>
          <dependent id="8">him</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">him</governor>
          <dependent id="10">Quayle</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">use</governor>
          <dependent id="12">sparingly</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">did</governor>
          <dependent id="14">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">did</governor>
          <dependent id="15">Nixon</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">use</governor>
          <dependent id="16">did</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Agnew</governor>
          <dependent id="17">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">did</governor>
          <dependent id="18">Agnew</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">1968</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">did</governor>
          <dependent id="20">1968</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">says</governor>
          <dependent id="23">Hess</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="24">says</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Quayle" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Quayle" />
          </tokens>
        </entity>
        <entity id="2" string="Nixon" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Nixon" />
          </tokens>
        </entity>
        <entity id="3" string="Agnew" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Agnew" />
          </tokens>
        </entity>
        <entity id="4" string="1968" type="DATE" score="0.0">
          <tokens>
            <token id="20" string="1968" />
          </tokens>
        </entity>
        <entity id="5" string="Hess" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Hess" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>``However, Quayle has four years to prove himself, and I think you&amp;apost;re going to see stories in two years about how much he&amp;apost;s learned, how much he&amp;apost;s acted responsibly, how far he&amp;apost;s come from the campaign of 1988.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="However" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Quayle" lemma="Quayle" stem="quayl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="5" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="four" lemma="four" stem="four" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="7" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="prove" lemma="prove" stem="prove" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="himself" lemma="himself" stem="himself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="see" lemma="see" stem="see" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="stories" lemma="story" stem="stori" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="23" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="24" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="much" lemma="much" stem="much" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="learned" lemma="learn" stem="learn" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="much" lemma="much" stem="much" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="acted" lemma="act" stem="act" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="responsibly" lemma="responsibly" stem="responsibli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="far" lemma="far" stem="far" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="41" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="come" lemma="come" stem="come" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="campaign" lemma="campaign" stem="campaign" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="1988" lemma="1988" stem="1988" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="48" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (ADVP (RB However)) (, ,) (S (NP (NNP Quayle)) (VP (VBZ has) (NP (NP (CD four) (NNS years)) (SBAR (S (VP (TO to) (VP (VB prove) (NP (PRP himself))))))))) (, ,) (CC and) (S (NP (PRP I)) (VP (VBP think) (SBAR (S (NP (PRP you)) (VP (VBP 're) (VP (VBG going) (S (VP (TO to) (VP (VB see) (NP (NNS stories)) (PP (IN in) (NP (NP (CD two) (NNS years)) (PP (IN about) (SBAR (WHADJP (WRB how) (JJ much)) (S (NP (PRP he)) (VP (VBZ 's) (VP (VBN learned) (, ,) (SBAR (WHADVP (WRB how) (RB much)) (S (NP (PRP he)) (VP (VBZ 's) (VP (VBN acted) (ADVP (RB responsibly)) (, ,) (SBAR (WHADVP (WRB how) (RB far)) (S (NP (PRP he)) (VP (VBZ 's) (VP (VBN come) (PP (IN from) (NP (NP (DT the) (NN campaign)) (PP (IN of) (NP (CD 1988))))))))))))))))))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="stories" type="NP">
          <tokens>
            <token id="20" string="stories" />
          </tokens>
        </chunking>
        <chunking id="2" string="Quayle" type="NP">
          <tokens>
            <token id="4" string="Quayle" />
          </tokens>
        </chunking>
        <chunking id="3" string="'s learned , how much he 's acted responsibly , how far he 's come from the campaign of 1988" type="VP">
          <tokens>
            <token id="28" string="'s" />
            <token id="29" string="learned" />
            <token id="30" string="," />
            <token id="31" string="how" />
            <token id="32" string="much" />
            <token id="33" string="he" />
            <token id="34" string="'s" />
            <token id="35" string="acted" />
            <token id="36" string="responsibly" />
            <token id="37" string="," />
            <token id="38" string="how" />
            <token id="39" string="far" />
            <token id="40" string="he" />
            <token id="41" string="'s" />
            <token id="42" string="come" />
            <token id="43" string="from" />
            <token id="44" string="the" />
            <token id="45" string="campaign" />
            <token id="46" string="of" />
            <token id="47" string="1988" />
          </tokens>
        </chunking>
        <chunking id="4" string="'s acted responsibly , how far he 's come from the campaign of 1988" type="VP">
          <tokens>
            <token id="34" string="'s" />
            <token id="35" string="acted" />
            <token id="36" string="responsibly" />
            <token id="37" string="," />
            <token id="38" string="how" />
            <token id="39" string="far" />
            <token id="40" string="he" />
            <token id="41" string="'s" />
            <token id="42" string="come" />
            <token id="43" string="from" />
            <token id="44" string="the" />
            <token id="45" string="campaign" />
            <token id="46" string="of" />
            <token id="47" string="1988" />
          </tokens>
        </chunking>
        <chunking id="5" string="acted responsibly , how far he 's come from the campaign of 1988" type="VP">
          <tokens>
            <token id="35" string="acted" />
            <token id="36" string="responsibly" />
            <token id="37" string="," />
            <token id="38" string="how" />
            <token id="39" string="far" />
            <token id="40" string="he" />
            <token id="41" string="'s" />
            <token id="42" string="come" />
            <token id="43" string="from" />
            <token id="44" string="the" />
            <token id="45" string="campaign" />
            <token id="46" string="of" />
            <token id="47" string="1988" />
          </tokens>
        </chunking>
        <chunking id="6" string="see stories in two years about how much he 's learned , how much he 's acted responsibly , how far he 's come from the campaign of 1988" type="VP">
          <tokens>
            <token id="19" string="see" />
            <token id="20" string="stories" />
            <token id="21" string="in" />
            <token id="22" string="two" />
            <token id="23" string="years" />
            <token id="24" string="about" />
            <token id="25" string="how" />
            <token id="26" string="much" />
            <token id="27" string="he" />
            <token id="28" string="'s" />
            <token id="29" string="learned" />
            <token id="30" string="," />
            <token id="31" string="how" />
            <token id="32" string="much" />
            <token id="33" string="he" />
            <token id="34" string="'s" />
            <token id="35" string="acted" />
            <token id="36" string="responsibly" />
            <token id="37" string="," />
            <token id="38" string="how" />
            <token id="39" string="far" />
            <token id="40" string="he" />
            <token id="41" string="'s" />
            <token id="42" string="come" />
            <token id="43" string="from" />
            <token id="44" string="the" />
            <token id="45" string="campaign" />
            <token id="46" string="of" />
            <token id="47" string="1988" />
          </tokens>
        </chunking>
        <chunking id="7" string="learned , how much he 's acted responsibly , how far he 's come from the campaign of 1988" type="VP">
          <tokens>
            <token id="29" string="learned" />
            <token id="30" string="," />
            <token id="31" string="how" />
            <token id="32" string="much" />
            <token id="33" string="he" />
            <token id="34" string="'s" />
            <token id="35" string="acted" />
            <token id="36" string="responsibly" />
            <token id="37" string="," />
            <token id="38" string="how" />
            <token id="39" string="far" />
            <token id="40" string="he" />
            <token id="41" string="'s" />
            <token id="42" string="come" />
            <token id="43" string="from" />
            <token id="44" string="the" />
            <token id="45" string="campaign" />
            <token id="46" string="of" />
            <token id="47" string="1988" />
          </tokens>
        </chunking>
        <chunking id="8" string="1988" type="NP">
          <tokens>
            <token id="47" string="1988" />
          </tokens>
        </chunking>
        <chunking id="9" string="how far he 's come from the campaign of 1988" type="SBAR">
          <tokens>
            <token id="38" string="how" />
            <token id="39" string="far" />
            <token id="40" string="he" />
            <token id="41" string="'s" />
            <token id="42" string="come" />
            <token id="43" string="from" />
            <token id="44" string="the" />
            <token id="45" string="campaign" />
            <token id="46" string="of" />
            <token id="47" string="1988" />
          </tokens>
        </chunking>
        <chunking id="10" string="two years" type="NP">
          <tokens>
            <token id="22" string="two" />
            <token id="23" string="years" />
          </tokens>
        </chunking>
        <chunking id="11" string="'re going to see stories in two years about how much he 's learned , how much he 's acted responsibly , how far he 's come from the campaign of 1988" type="VP">
          <tokens>
            <token id="16" string="'re" />
            <token id="17" string="going" />
            <token id="18" string="to" />
            <token id="19" string="see" />
            <token id="20" string="stories" />
            <token id="21" string="in" />
            <token id="22" string="two" />
            <token id="23" string="years" />
            <token id="24" string="about" />
            <token id="25" string="how" />
            <token id="26" string="much" />
            <token id="27" string="he" />
            <token id="28" string="'s" />
            <token id="29" string="learned" />
            <token id="30" string="," />
            <token id="31" string="how" />
            <token id="32" string="much" />
            <token id="33" string="he" />
            <token id="34" string="'s" />
            <token id="35" string="acted" />
            <token id="36" string="responsibly" />
            <token id="37" string="," />
            <token id="38" string="how" />
            <token id="39" string="far" />
            <token id="40" string="he" />
            <token id="41" string="'s" />
            <token id="42" string="come" />
            <token id="43" string="from" />
            <token id="44" string="the" />
            <token id="45" string="campaign" />
            <token id="46" string="of" />
            <token id="47" string="1988" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="27" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="himself" type="NP">
          <tokens>
            <token id="10" string="himself" />
          </tokens>
        </chunking>
        <chunking id="14" string="how much he 's acted responsibly , how far he 's come from the campaign of 1988" type="SBAR">
          <tokens>
            <token id="31" string="how" />
            <token id="32" string="much" />
            <token id="33" string="he" />
            <token id="34" string="'s" />
            <token id="35" string="acted" />
            <token id="36" string="responsibly" />
            <token id="37" string="," />
            <token id="38" string="how" />
            <token id="39" string="far" />
            <token id="40" string="he" />
            <token id="41" string="'s" />
            <token id="42" string="come" />
            <token id="43" string="from" />
            <token id="44" string="the" />
            <token id="45" string="campaign" />
            <token id="46" string="of" />
            <token id="47" string="1988" />
          </tokens>
        </chunking>
        <chunking id="15" string="to see stories in two years about how much he 's learned , how much he 's acted responsibly , how far he 's come from the campaign of 1988" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="see" />
            <token id="20" string="stories" />
            <token id="21" string="in" />
            <token id="22" string="two" />
            <token id="23" string="years" />
            <token id="24" string="about" />
            <token id="25" string="how" />
            <token id="26" string="much" />
            <token id="27" string="he" />
            <token id="28" string="'s" />
            <token id="29" string="learned" />
            <token id="30" string="," />
            <token id="31" string="how" />
            <token id="32" string="much" />
            <token id="33" string="he" />
            <token id="34" string="'s" />
            <token id="35" string="acted" />
            <token id="36" string="responsibly" />
            <token id="37" string="," />
            <token id="38" string="how" />
            <token id="39" string="far" />
            <token id="40" string="he" />
            <token id="41" string="'s" />
            <token id="42" string="come" />
            <token id="43" string="from" />
            <token id="44" string="the" />
            <token id="45" string="campaign" />
            <token id="46" string="of" />
            <token id="47" string="1988" />
          </tokens>
        </chunking>
        <chunking id="16" string="come from the campaign of 1988" type="VP">
          <tokens>
            <token id="42" string="come" />
            <token id="43" string="from" />
            <token id="44" string="the" />
            <token id="45" string="campaign" />
            <token id="46" string="of" />
            <token id="47" string="1988" />
          </tokens>
        </chunking>
        <chunking id="17" string="going to see stories in two years about how much he 's learned , how much he 's acted responsibly , how far he 's come from the campaign of 1988" type="VP">
          <tokens>
            <token id="17" string="going" />
            <token id="18" string="to" />
            <token id="19" string="see" />
            <token id="20" string="stories" />
            <token id="21" string="in" />
            <token id="22" string="two" />
            <token id="23" string="years" />
            <token id="24" string="about" />
            <token id="25" string="how" />
            <token id="26" string="much" />
            <token id="27" string="he" />
            <token id="28" string="'s" />
            <token id="29" string="learned" />
            <token id="30" string="," />
            <token id="31" string="how" />
            <token id="32" string="much" />
            <token id="33" string="he" />
            <token id="34" string="'s" />
            <token id="35" string="acted" />
            <token id="36" string="responsibly" />
            <token id="37" string="," />
            <token id="38" string="how" />
            <token id="39" string="far" />
            <token id="40" string="he" />
            <token id="41" string="'s" />
            <token id="42" string="come" />
            <token id="43" string="from" />
            <token id="44" string="the" />
            <token id="45" string="campaign" />
            <token id="46" string="of" />
            <token id="47" string="1988" />
          </tokens>
        </chunking>
        <chunking id="18" string="the campaign" type="NP">
          <tokens>
            <token id="44" string="the" />
            <token id="45" string="campaign" />
          </tokens>
        </chunking>
        <chunking id="19" string="how much he 's learned , how much he 's acted responsibly , how far he 's come from the campaign of 1988" type="SBAR">
          <tokens>
            <token id="25" string="how" />
            <token id="26" string="much" />
            <token id="27" string="he" />
            <token id="28" string="'s" />
            <token id="29" string="learned" />
            <token id="30" string="," />
            <token id="31" string="how" />
            <token id="32" string="much" />
            <token id="33" string="he" />
            <token id="34" string="'s" />
            <token id="35" string="acted" />
            <token id="36" string="responsibly" />
            <token id="37" string="," />
            <token id="38" string="how" />
            <token id="39" string="far" />
            <token id="40" string="he" />
            <token id="41" string="'s" />
            <token id="42" string="come" />
            <token id="43" string="from" />
            <token id="44" string="the" />
            <token id="45" string="campaign" />
            <token id="46" string="of" />
            <token id="47" string="1988" />
          </tokens>
        </chunking>
        <chunking id="20" string="four years to prove himself" type="NP">
          <tokens>
            <token id="6" string="four" />
            <token id="7" string="years" />
            <token id="8" string="to" />
            <token id="9" string="prove" />
            <token id="10" string="himself" />
          </tokens>
        </chunking>
        <chunking id="21" string="I" type="NP">
          <tokens>
            <token id="13" string="I" />
          </tokens>
        </chunking>
        <chunking id="22" string="how much" type="WHADVP">
          <tokens>
            <token id="31" string="how" />
            <token id="32" string="much" />
          </tokens>
        </chunking>
        <chunking id="23" string="four years" type="NP">
          <tokens>
            <token id="6" string="four" />
            <token id="7" string="years" />
          </tokens>
        </chunking>
        <chunking id="24" string="how far" type="WHADVP">
          <tokens>
            <token id="38" string="how" />
            <token id="39" string="far" />
          </tokens>
        </chunking>
        <chunking id="25" string="think you 're going to see stories in two years about how much he 's learned , how much he 's acted responsibly , how far he 's come from the campaign of 1988" type="VP">
          <tokens>
            <token id="14" string="think" />
            <token id="15" string="you" />
            <token id="16" string="'re" />
            <token id="17" string="going" />
            <token id="18" string="to" />
            <token id="19" string="see" />
            <token id="20" string="stories" />
            <token id="21" string="in" />
            <token id="22" string="two" />
            <token id="23" string="years" />
            <token id="24" string="about" />
            <token id="25" string="how" />
            <token id="26" string="much" />
            <token id="27" string="he" />
            <token id="28" string="'s" />
            <token id="29" string="learned" />
            <token id="30" string="," />
            <token id="31" string="how" />
            <token id="32" string="much" />
            <token id="33" string="he" />
            <token id="34" string="'s" />
            <token id="35" string="acted" />
            <token id="36" string="responsibly" />
            <token id="37" string="," />
            <token id="38" string="how" />
            <token id="39" string="far" />
            <token id="40" string="he" />
            <token id="41" string="'s" />
            <token id="42" string="come" />
            <token id="43" string="from" />
            <token id="44" string="the" />
            <token id="45" string="campaign" />
            <token id="46" string="of" />
            <token id="47" string="1988" />
          </tokens>
        </chunking>
        <chunking id="26" string="has four years to prove himself" type="VP">
          <tokens>
            <token id="5" string="has" />
            <token id="6" string="four" />
            <token id="7" string="years" />
            <token id="8" string="to" />
            <token id="9" string="prove" />
            <token id="10" string="himself" />
          </tokens>
        </chunking>
        <chunking id="27" string="prove himself" type="VP">
          <tokens>
            <token id="9" string="prove" />
            <token id="10" string="himself" />
          </tokens>
        </chunking>
        <chunking id="28" string="'s come from the campaign of 1988" type="VP">
          <tokens>
            <token id="41" string="'s" />
            <token id="42" string="come" />
            <token id="43" string="from" />
            <token id="44" string="the" />
            <token id="45" string="campaign" />
            <token id="46" string="of" />
            <token id="47" string="1988" />
          </tokens>
        </chunking>
        <chunking id="29" string="the campaign of 1988" type="NP">
          <tokens>
            <token id="44" string="the" />
            <token id="45" string="campaign" />
            <token id="46" string="of" />
            <token id="47" string="1988" />
          </tokens>
        </chunking>
        <chunking id="30" string="to prove himself" type="SBAR">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="prove" />
            <token id="10" string="himself" />
          </tokens>
        </chunking>
        <chunking id="31" string="you 're going to see stories in two years about how much he 's learned , how much he 's acted responsibly , how far he 's come from the campaign of 1988" type="SBAR">
          <tokens>
            <token id="15" string="you" />
            <token id="16" string="'re" />
            <token id="17" string="going" />
            <token id="18" string="to" />
            <token id="19" string="see" />
            <token id="20" string="stories" />
            <token id="21" string="in" />
            <token id="22" string="two" />
            <token id="23" string="years" />
            <token id="24" string="about" />
            <token id="25" string="how" />
            <token id="26" string="much" />
            <token id="27" string="he" />
            <token id="28" string="'s" />
            <token id="29" string="learned" />
            <token id="30" string="," />
            <token id="31" string="how" />
            <token id="32" string="much" />
            <token id="33" string="he" />
            <token id="34" string="'s" />
            <token id="35" string="acted" />
            <token id="36" string="responsibly" />
            <token id="37" string="," />
            <token id="38" string="how" />
            <token id="39" string="far" />
            <token id="40" string="he" />
            <token id="41" string="'s" />
            <token id="42" string="come" />
            <token id="43" string="from" />
            <token id="44" string="the" />
            <token id="45" string="campaign" />
            <token id="46" string="of" />
            <token id="47" string="1988" />
          </tokens>
        </chunking>
        <chunking id="32" string="two years about how much he 's learned , how much he 's acted responsibly , how far he 's come from the campaign of 1988" type="NP">
          <tokens>
            <token id="22" string="two" />
            <token id="23" string="years" />
            <token id="24" string="about" />
            <token id="25" string="how" />
            <token id="26" string="much" />
            <token id="27" string="he" />
            <token id="28" string="'s" />
            <token id="29" string="learned" />
            <token id="30" string="," />
            <token id="31" string="how" />
            <token id="32" string="much" />
            <token id="33" string="he" />
            <token id="34" string="'s" />
            <token id="35" string="acted" />
            <token id="36" string="responsibly" />
            <token id="37" string="," />
            <token id="38" string="how" />
            <token id="39" string="far" />
            <token id="40" string="he" />
            <token id="41" string="'s" />
            <token id="42" string="come" />
            <token id="43" string="from" />
            <token id="44" string="the" />
            <token id="45" string="campaign" />
            <token id="46" string="of" />
            <token id="47" string="1988" />
          </tokens>
        </chunking>
        <chunking id="33" string="you" type="NP">
          <tokens>
            <token id="15" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">has</governor>
          <dependent id="2">However</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">has</governor>
          <dependent id="4">Quayle</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">has</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">years</governor>
          <dependent id="6">four</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">has</governor>
          <dependent id="7">years</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">prove</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="7">years</governor>
          <dependent id="9">prove</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">prove</governor>
          <dependent id="10">himself</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">has</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">think</governor>
          <dependent id="13">I</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">has</governor>
          <dependent id="14">think</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">going</governor>
          <dependent id="15">you</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">going</governor>
          <dependent id="16">'re</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">think</governor>
          <dependent id="17">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">see</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">going</governor>
          <dependent id="19">see</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">see</governor>
          <dependent id="20">stories</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">years</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="23">years</governor>
          <dependent id="22">two</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">see</governor>
          <dependent id="23">years</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">learned</governor>
          <dependent id="24">about</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">much</governor>
          <dependent id="25">how</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="29">learned</governor>
          <dependent id="26">much</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="29">learned</governor>
          <dependent id="27">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="29">learned</governor>
          <dependent id="28">'s</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="23">years</governor>
          <dependent id="29">learned</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="32">much</governor>
          <dependent id="31">how</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="35">acted</governor>
          <dependent id="32">much</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="35">acted</governor>
          <dependent id="33">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="35">acted</governor>
          <dependent id="34">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="29">learned</governor>
          <dependent id="35">acted</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="35">acted</governor>
          <dependent id="36">responsibly</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="39">far</governor>
          <dependent id="38">how</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="42">come</governor>
          <dependent id="39">far</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="42">come</governor>
          <dependent id="40">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="42">come</governor>
          <dependent id="41">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="35">acted</governor>
          <dependent id="42">come</dependent>
        </dependency>
        <dependency type="case">
          <governor id="45">campaign</governor>
          <dependent id="43">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="45">campaign</governor>
          <dependent id="44">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="42">come</governor>
          <dependent id="45">campaign</dependent>
        </dependency>
        <dependency type="case">
          <governor id="47">1988</governor>
          <dependent id="46">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="45">campaign</governor>
          <dependent id="47">1988</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1988" type="DATE" score="0.0">
          <tokens>
            <token id="47" string="1988" />
          </tokens>
        </entity>
        <entity id="2" string="Quayle" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Quayle" />
          </tokens>
        </entity>
        <entity id="3" string="two years" type="DURATION" score="0.0">
          <tokens>
            <token id="22" string="two" />
            <token id="23" string="years" />
          </tokens>
        </entity>
        <entity id="4" string="four years" type="DURATION" score="0.0">
          <tokens>
            <token id="6" string="four" />
            <token id="7" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>Quayle admits the campaign was a learning process.</content>
      <tokens>
        <token id="1" string="Quayle" lemma="Quayle" stem="quayl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="admits" lemma="admit" stem="admit" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="campaign" lemma="campaign" stem="campaign" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="learning" lemma="learning" stem="learn" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="process" lemma="process" stem="process" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Quayle)) (VP (VBZ admits) (SBAR (S (NP (DT the) (NN campaign)) (VP (VBD was) (NP (DT a) (NN learning) (NN process)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a learning process" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="learning" />
            <token id="8" string="process" />
          </tokens>
        </chunking>
        <chunking id="2" string="Quayle" type="NP">
          <tokens>
            <token id="1" string="Quayle" />
          </tokens>
        </chunking>
        <chunking id="3" string="the campaign" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="campaign" />
          </tokens>
        </chunking>
        <chunking id="4" string="admits the campaign was a learning process" type="VP">
          <tokens>
            <token id="2" string="admits" />
            <token id="3" string="the" />
            <token id="4" string="campaign" />
            <token id="5" string="was" />
            <token id="6" string="a" />
            <token id="7" string="learning" />
            <token id="8" string="process" />
          </tokens>
        </chunking>
        <chunking id="5" string="was a learning process" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="a" />
            <token id="7" string="learning" />
            <token id="8" string="process" />
          </tokens>
        </chunking>
        <chunking id="6" string="the campaign was a learning process" type="SBAR">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="campaign" />
            <token id="5" string="was" />
            <token id="6" string="a" />
            <token id="7" string="learning" />
            <token id="8" string="process" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">admits</governor>
          <dependent id="1">Quayle</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">admits</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">campaign</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">process</governor>
          <dependent id="4">campaign</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">process</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">process</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">process</governor>
          <dependent id="7">learning</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">admits</governor>
          <dependent id="8">process</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Quayle" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Quayle" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>After the controversies subsided, Quayle declared his independence from his Bush handlers, saying he would be his own man.</content>
      <tokens>
        <token id="1" string="After" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="controversies" lemma="controversy" stem="controversi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="subsided" lemma="subside" stem="subsid" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Quayle" lemma="Quayle" stem="quayl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="declared" lemma="declare" stem="declar" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="independence" lemma="independence" stem="independ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="handlers" lemma="handler" stem="handler" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN After) (S (NP (DT the) (NNS controversies)) (VP (VBD subsided)))) (, ,) (NP (NNP Quayle)) (VP (VBD declared) (NP (PRP$ his) (NN independence)) (PP (IN from) (NP (PRP$ his) (NNP Bush) (NNS handlers))) (, ,) (S (VP (VBG saying) (SBAR (S (NP (PRP he)) (VP (MD would) (VP (VB be) (NP (PRP$ his) (JJ own) (NN man))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Quayle" type="NP">
          <tokens>
            <token id="6" string="Quayle" />
          </tokens>
        </chunking>
        <chunking id="2" string="his Bush handlers" type="NP">
          <tokens>
            <token id="11" string="his" />
            <token id="12" string="Bush" />
            <token id="13" string="handlers" />
          </tokens>
        </chunking>
        <chunking id="3" string="would be his own man" type="VP">
          <tokens>
            <token id="17" string="would" />
            <token id="18" string="be" />
            <token id="19" string="his" />
            <token id="20" string="own" />
            <token id="21" string="man" />
          </tokens>
        </chunking>
        <chunking id="4" string="subsided" type="VP">
          <tokens>
            <token id="4" string="subsided" />
          </tokens>
        </chunking>
        <chunking id="5" string="declared his independence from his Bush handlers , saying he would be his own man" type="VP">
          <tokens>
            <token id="7" string="declared" />
            <token id="8" string="his" />
            <token id="9" string="independence" />
            <token id="10" string="from" />
            <token id="11" string="his" />
            <token id="12" string="Bush" />
            <token id="13" string="handlers" />
            <token id="14" string="," />
            <token id="15" string="saying" />
            <token id="16" string="he" />
            <token id="17" string="would" />
            <token id="18" string="be" />
            <token id="19" string="his" />
            <token id="20" string="own" />
            <token id="21" string="man" />
          </tokens>
        </chunking>
        <chunking id="6" string="be his own man" type="VP">
          <tokens>
            <token id="18" string="be" />
            <token id="19" string="his" />
            <token id="20" string="own" />
            <token id="21" string="man" />
          </tokens>
        </chunking>
        <chunking id="7" string="saying he would be his own man" type="VP">
          <tokens>
            <token id="15" string="saying" />
            <token id="16" string="he" />
            <token id="17" string="would" />
            <token id="18" string="be" />
            <token id="19" string="his" />
            <token id="20" string="own" />
            <token id="21" string="man" />
          </tokens>
        </chunking>
        <chunking id="8" string="his independence" type="NP">
          <tokens>
            <token id="8" string="his" />
            <token id="9" string="independence" />
          </tokens>
        </chunking>
        <chunking id="9" string="the controversies" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="controversies" />
          </tokens>
        </chunking>
        <chunking id="10" string="he" type="NP">
          <tokens>
            <token id="16" string="he" />
          </tokens>
        </chunking>
        <chunking id="11" string="After the controversies subsided" type="SBAR">
          <tokens>
            <token id="1" string="After" />
            <token id="2" string="the" />
            <token id="3" string="controversies" />
            <token id="4" string="subsided" />
          </tokens>
        </chunking>
        <chunking id="12" string="he would be his own man" type="SBAR">
          <tokens>
            <token id="16" string="he" />
            <token id="17" string="would" />
            <token id="18" string="be" />
            <token id="19" string="his" />
            <token id="20" string="own" />
            <token id="21" string="man" />
          </tokens>
        </chunking>
        <chunking id="13" string="his own man" type="NP">
          <tokens>
            <token id="19" string="his" />
            <token id="20" string="own" />
            <token id="21" string="man" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="4">subsided</governor>
          <dependent id="1">After</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">controversies</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">subsided</governor>
          <dependent id="3">controversies</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">declared</governor>
          <dependent id="4">subsided</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">declared</governor>
          <dependent id="6">Quayle</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">declared</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">independence</governor>
          <dependent id="8">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">declared</governor>
          <dependent id="9">independence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">handlers</governor>
          <dependent id="10">from</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">handlers</governor>
          <dependent id="11">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">handlers</governor>
          <dependent id="12">Bush</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">declared</governor>
          <dependent id="13">handlers</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">declared</governor>
          <dependent id="15">saying</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">man</governor>
          <dependent id="16">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">man</governor>
          <dependent id="17">would</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">man</governor>
          <dependent id="18">be</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">man</governor>
          <dependent id="19">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">man</governor>
          <dependent id="20">own</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">saying</governor>
          <dependent id="21">man</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Quayle" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Quayle" />
          </tokens>
        </entity>
        <entity id="2" string="Bush" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Bush" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>He became more accessible to the media but continued to adhere to the schedule handed down from Washington and to deliver the party&amp;apost;s scripted message.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="became" lemma="become" stem="becam" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="accessible" lemma="accessible" stem="access" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="media" lemma="media" stem="media" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="continued" lemma="continue" stem="continu" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="adhere" lemma="adhere" stem="adher" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="schedule" lemma="schedule" stem="schedul" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="handed" lemma="hand" stem="hand" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="down" lemma="down" stem="down" pos="RP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="Washington" lemma="Washington" stem="washington" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="deliver" lemma="deliver" stem="deliv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="party" lemma="party" stem="parti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="scripted" lemma="script" stem="script" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="message" lemma="message" stem="messag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VP (VBD became) (S (ADJP (RBR more) (JJ accessible) (PP (TO to) (NP (DT the) (NNS media)))))) (CC but) (VP (VBD continued) (S (VP (VP (TO to) (VP (VB adhere) (PP (TO to) (NP (NP (DT the) (NN schedule)) (VP (VBD handed) (PRT (RP down)) (PP (IN from) (NP (NNP Washington)))))))) (CC and) (VP (TO to) (VP (VB deliver) (NP (NP (DT the) (NN party) (POS 's)) (VBN scripted) (NN message)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="continued to adhere to the schedule handed down from Washington and to deliver the party 's scripted message" type="VP">
          <tokens>
            <token id="9" string="continued" />
            <token id="10" string="to" />
            <token id="11" string="adhere" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="schedule" />
            <token id="15" string="handed" />
            <token id="16" string="down" />
            <token id="17" string="from" />
            <token id="18" string="Washington" />
            <token id="19" string="and" />
            <token id="20" string="to" />
            <token id="21" string="deliver" />
            <token id="22" string="the" />
            <token id="23" string="party" />
            <token id="24" string="'s" />
            <token id="25" string="scripted" />
            <token id="26" string="message" />
          </tokens>
        </chunking>
        <chunking id="2" string="became more accessible to the media but continued to adhere to the schedule handed down from Washington and to deliver the party 's scripted message" type="VP">
          <tokens>
            <token id="2" string="became" />
            <token id="3" string="more" />
            <token id="4" string="accessible" />
            <token id="5" string="to" />
            <token id="6" string="the" />
            <token id="7" string="media" />
            <token id="8" string="but" />
            <token id="9" string="continued" />
            <token id="10" string="to" />
            <token id="11" string="adhere" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="schedule" />
            <token id="15" string="handed" />
            <token id="16" string="down" />
            <token id="17" string="from" />
            <token id="18" string="Washington" />
            <token id="19" string="and" />
            <token id="20" string="to" />
            <token id="21" string="deliver" />
            <token id="22" string="the" />
            <token id="23" string="party" />
            <token id="24" string="'s" />
            <token id="25" string="scripted" />
            <token id="26" string="message" />
          </tokens>
        </chunking>
        <chunking id="3" string="more accessible to the media" type="ADJP">
          <tokens>
            <token id="3" string="more" />
            <token id="4" string="accessible" />
            <token id="5" string="to" />
            <token id="6" string="the" />
            <token id="7" string="media" />
          </tokens>
        </chunking>
        <chunking id="4" string="the party 's" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="party" />
            <token id="24" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="the media" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="media" />
          </tokens>
        </chunking>
        <chunking id="6" string="became more accessible to the media" type="VP">
          <tokens>
            <token id="2" string="became" />
            <token id="3" string="more" />
            <token id="4" string="accessible" />
            <token id="5" string="to" />
            <token id="6" string="the" />
            <token id="7" string="media" />
          </tokens>
        </chunking>
        <chunking id="7" string="adhere to the schedule handed down from Washington" type="VP">
          <tokens>
            <token id="11" string="adhere" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="schedule" />
            <token id="15" string="handed" />
            <token id="16" string="down" />
            <token id="17" string="from" />
            <token id="18" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="8" string="the schedule" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="schedule" />
          </tokens>
        </chunking>
        <chunking id="9" string="Washington" type="NP">
          <tokens>
            <token id="18" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="10" string="handed down from Washington" type="VP">
          <tokens>
            <token id="15" string="handed" />
            <token id="16" string="down" />
            <token id="17" string="from" />
            <token id="18" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="11" string="the schedule handed down from Washington" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="schedule" />
            <token id="15" string="handed" />
            <token id="16" string="down" />
            <token id="17" string="from" />
            <token id="18" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="12" string="to deliver the party 's scripted message" type="VP">
          <tokens>
            <token id="20" string="to" />
            <token id="21" string="deliver" />
            <token id="22" string="the" />
            <token id="23" string="party" />
            <token id="24" string="'s" />
            <token id="25" string="scripted" />
            <token id="26" string="message" />
          </tokens>
        </chunking>
        <chunking id="13" string="the party 's scripted message" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="party" />
            <token id="24" string="'s" />
            <token id="25" string="scripted" />
            <token id="26" string="message" />
          </tokens>
        </chunking>
        <chunking id="14" string="to adhere to the schedule handed down from Washington and to deliver the party 's scripted message" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="adhere" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="schedule" />
            <token id="15" string="handed" />
            <token id="16" string="down" />
            <token id="17" string="from" />
            <token id="18" string="Washington" />
            <token id="19" string="and" />
            <token id="20" string="to" />
            <token id="21" string="deliver" />
            <token id="22" string="the" />
            <token id="23" string="party" />
            <token id="24" string="'s" />
            <token id="25" string="scripted" />
            <token id="26" string="message" />
          </tokens>
        </chunking>
        <chunking id="15" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="16" string="to adhere to the schedule handed down from Washington" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="adhere" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="schedule" />
            <token id="15" string="handed" />
            <token id="16" string="down" />
            <token id="17" string="from" />
            <token id="18" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="17" string="deliver the party 's scripted message" type="VP">
          <tokens>
            <token id="21" string="deliver" />
            <token id="22" string="the" />
            <token id="23" string="party" />
            <token id="24" string="'s" />
            <token id="25" string="scripted" />
            <token id="26" string="message" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">became</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">became</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">accessible</governor>
          <dependent id="3">more</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">became</governor>
          <dependent id="4">accessible</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">media</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">media</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">accessible</governor>
          <dependent id="7">media</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">became</governor>
          <dependent id="8">but</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">became</governor>
          <dependent id="9">continued</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">adhere</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">continued</governor>
          <dependent id="11">adhere</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">schedule</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">schedule</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">adhere</governor>
          <dependent id="14">schedule</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">schedule</governor>
          <dependent id="15">handed</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="15">handed</governor>
          <dependent id="16">down</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Washington</governor>
          <dependent id="17">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">handed</governor>
          <dependent id="18">Washington</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">adhere</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">deliver</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">adhere</governor>
          <dependent id="21">deliver</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">party</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="26">message</governor>
          <dependent id="23">party</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">party</governor>
          <dependent id="24">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">message</governor>
          <dependent id="25">scripted</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">deliver</governor>
          <dependent id="26">message</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Washington" type="LOCATION" score="0.0">
          <tokens>
            <token id="18" string="Washington" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>Soon, he dropped off the front pages.</content>
      <tokens>
        <token id="1" string="Soon" lemma="soon" stem="soon" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="dropped" lemma="drop" stem="drop" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="off" lemma="off" stem="off" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="front" lemma="front" stem="front" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="pages" lemma="page" stem="page" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Soon)) (, ,) (NP (PRP he)) (VP (VBD dropped) (PRT (RP off)) (NP (DT the) (JJ front) (NNS pages))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="dropped off the front pages" type="VP">
          <tokens>
            <token id="4" string="dropped" />
            <token id="5" string="off" />
            <token id="6" string="the" />
            <token id="7" string="front" />
            <token id="8" string="pages" />
          </tokens>
        </chunking>
        <chunking id="2" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
        <chunking id="3" string="the front pages" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="front" />
            <token id="8" string="pages" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">dropped</governor>
          <dependent id="1">Soon</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">dropped</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">dropped</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="4">dropped</governor>
          <dependent id="5">off</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">pages</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">pages</governor>
          <dependent id="7">front</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">dropped</governor>
          <dependent id="8">pages</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>And although he occasionally spoke out in frustration at having little control over his schedule and at ceasing to make national news, he played the role of loyal No. 2 and even trumpeted his new anonymity.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="although" lemma="although" stem="although" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="occasionally" lemma="occasionally" stem="occasion" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="spoke" lemma="speak" stem="spoke" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="frustration" lemma="frustration" stem="frustrat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="having" lemma="have" stem="have" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="little" lemma="little" stem="littl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="control" lemma="control" stem="control" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="schedule" lemma="schedule" stem="schedul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="ceasing" lemma="cease" stem="ceas" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="national" lemma="national" stem="nation" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="news" lemma="news" stem="new" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="played" lemma="play" stem="plai" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="role" lemma="role" stem="role" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="loyal" lemma="loyal" stem="loyal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="No." lemma="no." stem="no." pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="2" lemma="2" stem="2" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="32" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="trumpeted" lemma="trumpet" stem="trumpet" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="anonymity" lemma="anonymity" stem="anonym" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (SBAR (IN although) (S (NP (PRP he)) (ADVP (RB occasionally)) (VP (VBD spoke) (PRT (RP out)) (PP (IN in) (NP (NN frustration))) (PP (PP (IN at) (S (VP (VBG having) (NP (JJ little) (NN control)) (PP (IN over) (NP (PRP$ his) (NN schedule)))))) (CC and) (PP (IN at) (S (VP (VBG ceasing) (S (VP (TO to) (VP (VB make) (NP (JJ national) (NN news)))))))))))) (, ,) (NP (PRP he)) (VP (VP (VBD played) (NP (NP (DT the) (NN role)) (PP (IN of) (NP (JJ loyal) (NN No.)))) (NP (CD 2))) (CC and) (VP (ADVP (RB even)) (VBD trumpeted) (NP (PRP$ his) (JJ new) (NN anonymity)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="spoke out in frustration at having little control over his schedule and at ceasing to make national news" type="VP">
          <tokens>
            <token id="5" string="spoke" />
            <token id="6" string="out" />
            <token id="7" string="in" />
            <token id="8" string="frustration" />
            <token id="9" string="at" />
            <token id="10" string="having" />
            <token id="11" string="little" />
            <token id="12" string="control" />
            <token id="13" string="over" />
            <token id="14" string="his" />
            <token id="15" string="schedule" />
            <token id="16" string="and" />
            <token id="17" string="at" />
            <token id="18" string="ceasing" />
            <token id="19" string="to" />
            <token id="20" string="make" />
            <token id="21" string="national" />
            <token id="22" string="news" />
          </tokens>
        </chunking>
        <chunking id="2" string="frustration" type="NP">
          <tokens>
            <token id="8" string="frustration" />
          </tokens>
        </chunking>
        <chunking id="3" string="played the role of loyal No. 2" type="VP">
          <tokens>
            <token id="25" string="played" />
            <token id="26" string="the" />
            <token id="27" string="role" />
            <token id="28" string="of" />
            <token id="29" string="loyal" />
            <token id="30" string="No." />
            <token id="31" string="2" />
          </tokens>
        </chunking>
        <chunking id="4" string="the role" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="role" />
          </tokens>
        </chunking>
        <chunking id="5" string="even trumpeted his new anonymity" type="VP">
          <tokens>
            <token id="33" string="even" />
            <token id="34" string="trumpeted" />
            <token id="35" string="his" />
            <token id="36" string="new" />
            <token id="37" string="anonymity" />
          </tokens>
        </chunking>
        <chunking id="6" string="although he occasionally spoke out in frustration at having little control over his schedule and at ceasing to make national news" type="SBAR">
          <tokens>
            <token id="2" string="although" />
            <token id="3" string="he" />
            <token id="4" string="occasionally" />
            <token id="5" string="spoke" />
            <token id="6" string="out" />
            <token id="7" string="in" />
            <token id="8" string="frustration" />
            <token id="9" string="at" />
            <token id="10" string="having" />
            <token id="11" string="little" />
            <token id="12" string="control" />
            <token id="13" string="over" />
            <token id="14" string="his" />
            <token id="15" string="schedule" />
            <token id="16" string="and" />
            <token id="17" string="at" />
            <token id="18" string="ceasing" />
            <token id="19" string="to" />
            <token id="20" string="make" />
            <token id="21" string="national" />
            <token id="22" string="news" />
          </tokens>
        </chunking>
        <chunking id="7" string="national news" type="NP">
          <tokens>
            <token id="21" string="national" />
            <token id="22" string="news" />
          </tokens>
        </chunking>
        <chunking id="8" string="ceasing to make national news" type="VP">
          <tokens>
            <token id="18" string="ceasing" />
            <token id="19" string="to" />
            <token id="20" string="make" />
            <token id="21" string="national" />
            <token id="22" string="news" />
          </tokens>
        </chunking>
        <chunking id="9" string="make national news" type="VP">
          <tokens>
            <token id="20" string="make" />
            <token id="21" string="national" />
            <token id="22" string="news" />
          </tokens>
        </chunking>
        <chunking id="10" string="his new anonymity" type="NP">
          <tokens>
            <token id="35" string="his" />
            <token id="36" string="new" />
            <token id="37" string="anonymity" />
          </tokens>
        </chunking>
        <chunking id="11" string="his schedule" type="NP">
          <tokens>
            <token id="14" string="his" />
            <token id="15" string="schedule" />
          </tokens>
        </chunking>
        <chunking id="12" string="2" type="NP">
          <tokens>
            <token id="31" string="2" />
          </tokens>
        </chunking>
        <chunking id="13" string="played the role of loyal No. 2 and even trumpeted his new anonymity" type="VP">
          <tokens>
            <token id="25" string="played" />
            <token id="26" string="the" />
            <token id="27" string="role" />
            <token id="28" string="of" />
            <token id="29" string="loyal" />
            <token id="30" string="No." />
            <token id="31" string="2" />
            <token id="32" string="and" />
            <token id="33" string="even" />
            <token id="34" string="trumpeted" />
            <token id="35" string="his" />
            <token id="36" string="new" />
            <token id="37" string="anonymity" />
          </tokens>
        </chunking>
        <chunking id="14" string="little control" type="NP">
          <tokens>
            <token id="11" string="little" />
            <token id="12" string="control" />
          </tokens>
        </chunking>
        <chunking id="15" string="loyal No." type="NP">
          <tokens>
            <token id="29" string="loyal" />
            <token id="30" string="No." />
          </tokens>
        </chunking>
        <chunking id="16" string="the role of loyal No." type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="role" />
            <token id="28" string="of" />
            <token id="29" string="loyal" />
            <token id="30" string="No." />
          </tokens>
        </chunking>
        <chunking id="17" string="having little control over his schedule" type="VP">
          <tokens>
            <token id="10" string="having" />
            <token id="11" string="little" />
            <token id="12" string="control" />
            <token id="13" string="over" />
            <token id="14" string="his" />
            <token id="15" string="schedule" />
          </tokens>
        </chunking>
        <chunking id="18" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
        <chunking id="19" string="to make national news" type="VP">
          <tokens>
            <token id="19" string="to" />
            <token id="20" string="make" />
            <token id="21" string="national" />
            <token id="22" string="news" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="25">played</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">spoke</governor>
          <dependent id="2">although</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">spoke</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">spoke</governor>
          <dependent id="4">occasionally</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="25">played</governor>
          <dependent id="5">spoke</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="5">spoke</governor>
          <dependent id="6">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">frustration</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">spoke</governor>
          <dependent id="8">frustration</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">having</governor>
          <dependent id="9">at</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">spoke</governor>
          <dependent id="10">having</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">control</governor>
          <dependent id="11">little</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">having</governor>
          <dependent id="12">control</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">schedule</governor>
          <dependent id="13">over</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">schedule</governor>
          <dependent id="14">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">having</governor>
          <dependent id="15">schedule</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">having</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">ceasing</governor>
          <dependent id="17">at</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">having</governor>
          <dependent id="18">ceasing</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">make</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">ceasing</governor>
          <dependent id="20">make</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">news</governor>
          <dependent id="21">national</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">make</governor>
          <dependent id="22">news</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">played</governor>
          <dependent id="24">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="25">played</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">role</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="25">played</governor>
          <dependent id="27">role</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">No.</governor>
          <dependent id="28">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">No.</governor>
          <dependent id="29">loyal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">role</governor>
          <dependent id="30">No.</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">played</governor>
          <dependent id="31">2</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="25">played</governor>
          <dependent id="32">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="34">trumpeted</governor>
          <dependent id="33">even</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="25">played</governor>
          <dependent id="34">trumpeted</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="37">anonymity</governor>
          <dependent id="35">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="37">anonymity</governor>
          <dependent id="36">new</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="34">trumpeted</governor>
          <dependent id="37">anonymity</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="2" type="NUMBER" score="0.0">
          <tokens>
            <token id="31" string="2" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>``We have arrived as being a traditional vice presidential nominee because we are either on the back pages or either not on the pages at all.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="arrived" lemma="arrive" stem="arriv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="traditional" lemma="traditional" stem="tradit" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="vice" lemma="vice" stem="vice" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="presidential" lemma="presidential" stem="presidenti" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="nominee" lemma="nominee" stem="nomine" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="either" lemma="either" stem="either" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="back" lemma="back" stem="back" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="pages" lemma="page" stem="page" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="either" lemma="either" stem="either" pos="CC" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="pages" lemma="page" stem="page" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP We)) (VP (VBP have) (VP (VP (VBN arrived) (PP (IN as) (S (VP (VBG being) (NP (DT a) (JJ traditional) (NN vice) (JJ presidential) (NN nominee))))) (SBAR (IN because) (S (NP (PRP we)) (VP (VBP are) (ADVP (RB either)) (PP (IN on) (NP (DT the) (JJ back) (NNS pages))))))) (CC or) (VP (PP (CC either) (PP (RB not) (IN on) (NP (DT the) (NNS pages)))) (ADVP (IN at) (DT all))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the pages" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="pages" />
          </tokens>
        </chunking>
        <chunking id="2" string="have arrived as being a traditional vice presidential nominee because we are either on the back pages or either not on the pages at all" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="arrived" />
            <token id="5" string="as" />
            <token id="6" string="being" />
            <token id="7" string="a" />
            <token id="8" string="traditional" />
            <token id="9" string="vice" />
            <token id="10" string="presidential" />
            <token id="11" string="nominee" />
            <token id="12" string="because" />
            <token id="13" string="we" />
            <token id="14" string="are" />
            <token id="15" string="either" />
            <token id="16" string="on" />
            <token id="17" string="the" />
            <token id="18" string="back" />
            <token id="19" string="pages" />
            <token id="20" string="or" />
            <token id="21" string="either" />
            <token id="22" string="not" />
            <token id="23" string="on" />
            <token id="24" string="the" />
            <token id="25" string="pages" />
            <token id="26" string="at" />
            <token id="27" string="all" />
          </tokens>
        </chunking>
        <chunking id="3" string="arrived as being a traditional vice presidential nominee because we are either on the back pages or either not on the pages at all" type="VP">
          <tokens>
            <token id="4" string="arrived" />
            <token id="5" string="as" />
            <token id="6" string="being" />
            <token id="7" string="a" />
            <token id="8" string="traditional" />
            <token id="9" string="vice" />
            <token id="10" string="presidential" />
            <token id="11" string="nominee" />
            <token id="12" string="because" />
            <token id="13" string="we" />
            <token id="14" string="are" />
            <token id="15" string="either" />
            <token id="16" string="on" />
            <token id="17" string="the" />
            <token id="18" string="back" />
            <token id="19" string="pages" />
            <token id="20" string="or" />
            <token id="21" string="either" />
            <token id="22" string="not" />
            <token id="23" string="on" />
            <token id="24" string="the" />
            <token id="25" string="pages" />
            <token id="26" string="at" />
            <token id="27" string="all" />
          </tokens>
        </chunking>
        <chunking id="4" string="either not on the pages at all" type="VP">
          <tokens>
            <token id="21" string="either" />
            <token id="22" string="not" />
            <token id="23" string="on" />
            <token id="24" string="the" />
            <token id="25" string="pages" />
            <token id="26" string="at" />
            <token id="27" string="all" />
          </tokens>
        </chunking>
        <chunking id="5" string="being a traditional vice presidential nominee" type="VP">
          <tokens>
            <token id="6" string="being" />
            <token id="7" string="a" />
            <token id="8" string="traditional" />
            <token id="9" string="vice" />
            <token id="10" string="presidential" />
            <token id="11" string="nominee" />
          </tokens>
        </chunking>
        <chunking id="6" string="are either on the back pages" type="VP">
          <tokens>
            <token id="14" string="are" />
            <token id="15" string="either" />
            <token id="16" string="on" />
            <token id="17" string="the" />
            <token id="18" string="back" />
            <token id="19" string="pages" />
          </tokens>
        </chunking>
        <chunking id="7" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="8" string="arrived as being a traditional vice presidential nominee because we are either on the back pages" type="VP">
          <tokens>
            <token id="4" string="arrived" />
            <token id="5" string="as" />
            <token id="6" string="being" />
            <token id="7" string="a" />
            <token id="8" string="traditional" />
            <token id="9" string="vice" />
            <token id="10" string="presidential" />
            <token id="11" string="nominee" />
            <token id="12" string="because" />
            <token id="13" string="we" />
            <token id="14" string="are" />
            <token id="15" string="either" />
            <token id="16" string="on" />
            <token id="17" string="the" />
            <token id="18" string="back" />
            <token id="19" string="pages" />
          </tokens>
        </chunking>
        <chunking id="9" string="because we are either on the back pages" type="SBAR">
          <tokens>
            <token id="12" string="because" />
            <token id="13" string="we" />
            <token id="14" string="are" />
            <token id="15" string="either" />
            <token id="16" string="on" />
            <token id="17" string="the" />
            <token id="18" string="back" />
            <token id="19" string="pages" />
          </tokens>
        </chunking>
        <chunking id="10" string="we" type="NP">
          <tokens>
            <token id="13" string="we" />
          </tokens>
        </chunking>
        <chunking id="11" string="the back pages" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="back" />
            <token id="19" string="pages" />
          </tokens>
        </chunking>
        <chunking id="12" string="a traditional vice presidential nominee" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="traditional" />
            <token id="9" string="vice" />
            <token id="10" string="presidential" />
            <token id="11" string="nominee" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">arrived</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">arrived</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">arrived</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">nominee</governor>
          <dependent id="5">as</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">nominee</governor>
          <dependent id="6">being</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">nominee</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">nominee</governor>
          <dependent id="8">traditional</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">nominee</governor>
          <dependent id="9">vice</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">nominee</governor>
          <dependent id="10">presidential</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">arrived</governor>
          <dependent id="11">nominee</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">pages</governor>
          <dependent id="12">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">pages</governor>
          <dependent id="13">we</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">pages</governor>
          <dependent id="14">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">pages</governor>
          <dependent id="15">either</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">pages</governor>
          <dependent id="16">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">pages</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">pages</governor>
          <dependent id="18">back</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">arrived</governor>
          <dependent id="19">pages</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">arrived</governor>
          <dependent id="20">or</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="25">pages</governor>
          <dependent id="21">either</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="25">pages</governor>
          <dependent id="22">not</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">pages</governor>
          <dependent id="23">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">pages</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">arrived</governor>
          <dependent id="25">pages</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">all</governor>
          <dependent id="26">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">pages</governor>
          <dependent id="27">all</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>That&amp;apost;s what we&amp;apost;re supposed to be,&amp;apost;&amp;apost; he told reporters.</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="supposed" lemma="suppose" stem="suppos" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="reporters" lemma="reporter" stem="report" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT That)) (VP (VBZ 's) (SBAR (WHNP (WP what)) (S (NP (PRP we)) (VP (VBP 're) (VP (VBN supposed) (S (VP (TO to) (VP (VB be)))))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD told) (NP (NNS reporters))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="That" type="NP">
          <tokens>
            <token id="1" string="That" />
          </tokens>
        </chunking>
        <chunking id="2" string="told reporters" type="VP">
          <tokens>
            <token id="12" string="told" />
            <token id="13" string="reporters" />
          </tokens>
        </chunking>
        <chunking id="3" string="reporters" type="NP">
          <tokens>
            <token id="13" string="reporters" />
          </tokens>
        </chunking>
        <chunking id="4" string="to be" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="be" />
          </tokens>
        </chunking>
        <chunking id="5" string="be" type="VP">
          <tokens>
            <token id="8" string="be" />
          </tokens>
        </chunking>
        <chunking id="6" string="'s what we 're supposed to be" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="what" />
            <token id="4" string="we" />
            <token id="5" string="'re" />
            <token id="6" string="supposed" />
            <token id="7" string="to" />
            <token id="8" string="be" />
          </tokens>
        </chunking>
        <chunking id="7" string="what we 're supposed to be" type="SBAR">
          <tokens>
            <token id="3" string="what" />
            <token id="4" string="we" />
            <token id="5" string="'re" />
            <token id="6" string="supposed" />
            <token id="7" string="to" />
            <token id="8" string="be" />
          </tokens>
        </chunking>
        <chunking id="8" string="supposed to be" type="VP">
          <tokens>
            <token id="6" string="supposed" />
            <token id="7" string="to" />
            <token id="8" string="be" />
          </tokens>
        </chunking>
        <chunking id="9" string="'re supposed to be" type="VP">
          <tokens>
            <token id="5" string="'re" />
            <token id="6" string="supposed" />
            <token id="7" string="to" />
            <token id="8" string="be" />
          </tokens>
        </chunking>
        <chunking id="10" string="he" type="NP">
          <tokens>
            <token id="11" string="he" />
          </tokens>
        </chunking>
        <chunking id="11" string="we" type="NP">
          <tokens>
            <token id="4" string="we" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">'s</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">told</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">be</governor>
          <dependent id="3">what</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">supposed</governor>
          <dependent id="4">we</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">supposed</governor>
          <dependent id="5">'re</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">'s</governor>
          <dependent id="6">supposed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">be</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">supposed</governor>
          <dependent id="8">be</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">told</governor>
          <dependent id="11">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">told</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">told</governor>
          <dependent id="13">reporters</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>That willingness to be a team player could serve him well in a Bush White House, Mahe feels, since Bush wants ``a private adviser, whose experience and opinion he respected ... (who) has never had another agenda.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="willingness" lemma="willingness" stem="willing" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="team" lemma="team" stem="team" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="player" lemma="player" stem="player" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="serve" lemma="serve" stem="serv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="White" lemma="White" stem="white" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="16" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Mahe" lemma="Mahe" stem="mahe" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="feels" lemma="feel" stem="feel" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="23" string="wants" lemma="want" stem="want" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="private" lemma="private" stem="privat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="adviser" lemma="adviser" stem="advis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="whose" lemma="whose" stem="whose" pos="WP$" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="experience" lemma="experience" stem="experi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="opinion" lemma="opinion" stem="opinion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="respected" lemma="respect" stem="respect" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="..." lemma="..." stem="..." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="38" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="agenda" lemma="agenda" stem="agenda" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT That) (NN willingness) (S (VP (TO to) (VP (VB be) (NP (DT a) (NN team) (NN player)))))) (VP (MD could) (VP (VB serve) (NP (PRP him)) (ADVP (RB well) (PP (IN in) (NP (DT a) (NNP Bush) (NNP White) (NNP House)))) (PRN (, ,) (S (NP (NNP Mahe)) (VP (VBZ feels))) (, ,)) (SBAR (IN since) (S (NP (NNP Bush)) (VP (VBZ wants) (`` ``) (NP (NP (DT a) (JJ private) (NN adviser)) (, ,) (SBAR (WHNP (WP$ whose) (NP (NN experience) (CC and) (NN opinion))) (S (NP (PRP he)) (VP (VBD respected))))))))))) (: ...) (S (-LRB- -LRB-) (NP (WP who)) (-RRB- -RRB-) (VP (VBZ has) (ADVP (RB never)) (VP (VBD had) (NP (DT another) (NN agenda))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="feels" type="VP">
          <tokens>
            <token id="19" string="feels" />
          </tokens>
        </chunking>
        <chunking id="2" string="experience and opinion" type="NP">
          <tokens>
            <token id="30" string="experience" />
            <token id="31" string="and" />
            <token id="32" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="3" string="since Bush wants `` a private adviser , whose experience and opinion he respected" type="SBAR">
          <tokens>
            <token id="21" string="since" />
            <token id="22" string="Bush" />
            <token id="23" string="wants" />
            <token id="24" string="``" />
            <token id="25" string="a" />
            <token id="26" string="private" />
            <token id="27" string="adviser" />
            <token id="28" string="," />
            <token id="29" string="whose" />
            <token id="30" string="experience" />
            <token id="31" string="and" />
            <token id="32" string="opinion" />
            <token id="33" string="he" />
            <token id="34" string="respected" />
          </tokens>
        </chunking>
        <chunking id="4" string="a private adviser , whose experience and opinion he respected" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="private" />
            <token id="27" string="adviser" />
            <token id="28" string="," />
            <token id="29" string="whose" />
            <token id="30" string="experience" />
            <token id="31" string="and" />
            <token id="32" string="opinion" />
            <token id="33" string="he" />
            <token id="34" string="respected" />
          </tokens>
        </chunking>
        <chunking id="5" string="whose experience and opinion he respected" type="SBAR">
          <tokens>
            <token id="29" string="whose" />
            <token id="30" string="experience" />
            <token id="31" string="and" />
            <token id="32" string="opinion" />
            <token id="33" string="he" />
            <token id="34" string="respected" />
          </tokens>
        </chunking>
        <chunking id="6" string="him" type="NP">
          <tokens>
            <token id="10" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="another agenda" type="NP">
          <tokens>
            <token id="42" string="another" />
            <token id="43" string="agenda" />
          </tokens>
        </chunking>
        <chunking id="8" string="That willingness to be a team player" type="NP">
          <tokens>
            <token id="1" string="That" />
            <token id="2" string="willingness" />
            <token id="3" string="to" />
            <token id="4" string="be" />
            <token id="5" string="a" />
            <token id="6" string="team" />
            <token id="7" string="player" />
          </tokens>
        </chunking>
        <chunking id="9" string="a team player" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="team" />
            <token id="7" string="player" />
          </tokens>
        </chunking>
        <chunking id="10" string="a private adviser" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="private" />
            <token id="27" string="adviser" />
          </tokens>
        </chunking>
        <chunking id="11" string="be a team player" type="VP">
          <tokens>
            <token id="4" string="be" />
            <token id="5" string="a" />
            <token id="6" string="team" />
            <token id="7" string="player" />
          </tokens>
        </chunking>
        <chunking id="12" string="serve him well in a Bush White House , Mahe feels , since Bush wants `` a private adviser , whose experience and opinion he respected" type="VP">
          <tokens>
            <token id="9" string="serve" />
            <token id="10" string="him" />
            <token id="11" string="well" />
            <token id="12" string="in" />
            <token id="13" string="a" />
            <token id="14" string="Bush" />
            <token id="15" string="White" />
            <token id="16" string="House" />
            <token id="17" string="," />
            <token id="18" string="Mahe" />
            <token id="19" string="feels" />
            <token id="20" string="," />
            <token id="21" string="since" />
            <token id="22" string="Bush" />
            <token id="23" string="wants" />
            <token id="24" string="``" />
            <token id="25" string="a" />
            <token id="26" string="private" />
            <token id="27" string="adviser" />
            <token id="28" string="," />
            <token id="29" string="whose" />
            <token id="30" string="experience" />
            <token id="31" string="and" />
            <token id="32" string="opinion" />
            <token id="33" string="he" />
            <token id="34" string="respected" />
          </tokens>
        </chunking>
        <chunking id="13" string="Mahe" type="NP">
          <tokens>
            <token id="18" string="Mahe" />
          </tokens>
        </chunking>
        <chunking id="14" string="a Bush White House" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="Bush" />
            <token id="15" string="White" />
            <token id="16" string="House" />
          </tokens>
        </chunking>
        <chunking id="15" string="had another agenda" type="VP">
          <tokens>
            <token id="41" string="had" />
            <token id="42" string="another" />
            <token id="43" string="agenda" />
          </tokens>
        </chunking>
        <chunking id="16" string="to be a team player" type="VP">
          <tokens>
            <token id="3" string="to" />
            <token id="4" string="be" />
            <token id="5" string="a" />
            <token id="6" string="team" />
            <token id="7" string="player" />
          </tokens>
        </chunking>
        <chunking id="17" string="Bush" type="NP">
          <tokens>
            <token id="22" string="Bush" />
          </tokens>
        </chunking>
        <chunking id="18" string="could serve him well in a Bush White House , Mahe feels , since Bush wants `` a private adviser , whose experience and opinion he respected" type="VP">
          <tokens>
            <token id="8" string="could" />
            <token id="9" string="serve" />
            <token id="10" string="him" />
            <token id="11" string="well" />
            <token id="12" string="in" />
            <token id="13" string="a" />
            <token id="14" string="Bush" />
            <token id="15" string="White" />
            <token id="16" string="House" />
            <token id="17" string="," />
            <token id="18" string="Mahe" />
            <token id="19" string="feels" />
            <token id="20" string="," />
            <token id="21" string="since" />
            <token id="22" string="Bush" />
            <token id="23" string="wants" />
            <token id="24" string="``" />
            <token id="25" string="a" />
            <token id="26" string="private" />
            <token id="27" string="adviser" />
            <token id="28" string="," />
            <token id="29" string="whose" />
            <token id="30" string="experience" />
            <token id="31" string="and" />
            <token id="32" string="opinion" />
            <token id="33" string="he" />
            <token id="34" string="respected" />
          </tokens>
        </chunking>
        <chunking id="19" string="wants `` a private adviser , whose experience and opinion he respected" type="VP">
          <tokens>
            <token id="23" string="wants" />
            <token id="24" string="``" />
            <token id="25" string="a" />
            <token id="26" string="private" />
            <token id="27" string="adviser" />
            <token id="28" string="," />
            <token id="29" string="whose" />
            <token id="30" string="experience" />
            <token id="31" string="and" />
            <token id="32" string="opinion" />
            <token id="33" string="he" />
            <token id="34" string="respected" />
          </tokens>
        </chunking>
        <chunking id="20" string="has never had another agenda" type="VP">
          <tokens>
            <token id="39" string="has" />
            <token id="40" string="never" />
            <token id="41" string="had" />
            <token id="42" string="another" />
            <token id="43" string="agenda" />
          </tokens>
        </chunking>
        <chunking id="21" string="he" type="NP">
          <tokens>
            <token id="33" string="he" />
          </tokens>
        </chunking>
        <chunking id="22" string="who" type="NP">
          <tokens>
            <token id="37" string="who" />
          </tokens>
        </chunking>
        <chunking id="23" string="respected" type="VP">
          <tokens>
            <token id="34" string="respected" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">willingness</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">serve</governor>
          <dependent id="2">willingness</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">player</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">player</governor>
          <dependent id="4">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">player</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">player</governor>
          <dependent id="6">team</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="2">willingness</governor>
          <dependent id="7">player</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">serve</governor>
          <dependent id="8">could</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">serve</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">serve</governor>
          <dependent id="10">him</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">serve</governor>
          <dependent id="11">well</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">House</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">House</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">House</governor>
          <dependent id="14">Bush</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">House</governor>
          <dependent id="15">White</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">well</governor>
          <dependent id="16">House</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">feels</governor>
          <dependent id="18">Mahe</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="9">serve</governor>
          <dependent id="19">feels</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">wants</governor>
          <dependent id="21">since</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">wants</governor>
          <dependent id="22">Bush</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">serve</governor>
          <dependent id="23">wants</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">adviser</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">adviser</governor>
          <dependent id="26">private</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">wants</governor>
          <dependent id="27">adviser</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="30">experience</governor>
          <dependent id="29">whose</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="34">respected</governor>
          <dependent id="30">experience</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="30">experience</governor>
          <dependent id="31">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="30">experience</governor>
          <dependent id="32">opinion</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">respected</governor>
          <dependent id="33">he</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="27">adviser</governor>
          <dependent id="34">respected</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="41">had</governor>
          <dependent id="37">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="41">had</governor>
          <dependent id="39">has</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="41">had</governor>
          <dependent id="40">never</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="9">serve</governor>
          <dependent id="41">had</dependent>
        </dependency>
        <dependency type="det">
          <governor id="43">agenda</governor>
          <dependent id="42">another</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="41">had</governor>
          <dependent id="43">agenda</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mahe" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Mahe" />
          </tokens>
        </entity>
        <entity id="2" string="Bush" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Bush" />
          </tokens>
        </entity>
        <entity id="3" string="White House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="15" string="White" />
            <token id="16" string="House" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="45" has_coreference="true">
      <content>``Dan Quayle owes his political life to one man and one man alone,&amp;apost;&amp;apost; Mahe says.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Dan" lemma="Dan" stem="dan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="Quayle" lemma="Quayle" stem="quayl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="owes" lemma="owe" stem="ow" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="10" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="13" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="alone" lemma="alone" stem="alon" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Mahe" lemma="Mahe" stem="mahe" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="18" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (NNP Dan) (NNP Quayle)) (VP (VBZ owes) (NP (PRP$ his) (JJ political) (NN life)) (PP (TO to) (NP (NP (CD one) (NN man)) (CC and) (NP (CD one) (NN man) (RB alone)))))) (, ,) ('' '') (NP (NNP Mahe)) (VP (VBZ says)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="says" type="VP">
          <tokens>
            <token id="18" string="says" />
          </tokens>
        </chunking>
        <chunking id="2" string="Mahe" type="NP">
          <tokens>
            <token id="17" string="Mahe" />
          </tokens>
        </chunking>
        <chunking id="3" string="owes his political life to one man and one man alone" type="VP">
          <tokens>
            <token id="4" string="owes" />
            <token id="5" string="his" />
            <token id="6" string="political" />
            <token id="7" string="life" />
            <token id="8" string="to" />
            <token id="9" string="one" />
            <token id="10" string="man" />
            <token id="11" string="and" />
            <token id="12" string="one" />
            <token id="13" string="man" />
            <token id="14" string="alone" />
          </tokens>
        </chunking>
        <chunking id="4" string="one man" type="NP">
          <tokens>
            <token id="9" string="one" />
            <token id="10" string="man" />
          </tokens>
        </chunking>
        <chunking id="5" string="his political life" type="NP">
          <tokens>
            <token id="5" string="his" />
            <token id="6" string="political" />
            <token id="7" string="life" />
          </tokens>
        </chunking>
        <chunking id="6" string="one man and one man alone" type="NP">
          <tokens>
            <token id="9" string="one" />
            <token id="10" string="man" />
            <token id="11" string="and" />
            <token id="12" string="one" />
            <token id="13" string="man" />
            <token id="14" string="alone" />
          </tokens>
        </chunking>
        <chunking id="7" string="Dan Quayle" type="NP">
          <tokens>
            <token id="2" string="Dan" />
            <token id="3" string="Quayle" />
          </tokens>
        </chunking>
        <chunking id="8" string="one man alone" type="NP">
          <tokens>
            <token id="12" string="one" />
            <token id="13" string="man" />
            <token id="14" string="alone" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Quayle</governor>
          <dependent id="2">Dan</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">owes</governor>
          <dependent id="3">Quayle</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">says</governor>
          <dependent id="4">owes</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">life</governor>
          <dependent id="5">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">life</governor>
          <dependent id="6">political</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">owes</governor>
          <dependent id="7">life</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">man</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">man</governor>
          <dependent id="9">one</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">owes</governor>
          <dependent id="10">man</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">man</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">man</governor>
          <dependent id="12">one</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">man</governor>
          <dependent id="13">man</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">man</governor>
          <dependent id="14">alone</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">says</governor>
          <dependent id="17">Mahe</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">says</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="Mahe" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Mahe" />
          </tokens>
        </entity>
        <entity id="3" string="Dan Quayle" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Dan" />
            <token id="3" string="Quayle" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="46" has_coreference="false">
      <content>``You&amp;apost;re never going to see Dan Quayle telling tales out of school.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="You" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="see" lemma="see" stem="see" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Dan" lemma="Dan" stem="dan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="9" string="Quayle" lemma="Quayle" stem="quayl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="10" string="telling" lemma="tell" stem="tell" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="tales" lemma="tale" stem="tale" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP You)) (VP (VBP 're) (ADVP (RB never)) (VP (VBG going) (S (VP (TO to) (VP (VB see) (S (NP (NNP Dan) (NNP Quayle)) (VP (VBG telling) (NP (NNS tales)) (PRT (IN out)) (PP (IN of) (NP (NN school)))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="'re never going to see Dan Quayle telling tales out of school" type="VP">
          <tokens>
            <token id="3" string="'re" />
            <token id="4" string="never" />
            <token id="5" string="going" />
            <token id="6" string="to" />
            <token id="7" string="see" />
            <token id="8" string="Dan" />
            <token id="9" string="Quayle" />
            <token id="10" string="telling" />
            <token id="11" string="tales" />
            <token id="12" string="out" />
            <token id="13" string="of" />
            <token id="14" string="school" />
          </tokens>
        </chunking>
        <chunking id="2" string="going to see Dan Quayle telling tales out of school" type="VP">
          <tokens>
            <token id="5" string="going" />
            <token id="6" string="to" />
            <token id="7" string="see" />
            <token id="8" string="Dan" />
            <token id="9" string="Quayle" />
            <token id="10" string="telling" />
            <token id="11" string="tales" />
            <token id="12" string="out" />
            <token id="13" string="of" />
            <token id="14" string="school" />
          </tokens>
        </chunking>
        <chunking id="3" string="school" type="NP">
          <tokens>
            <token id="14" string="school" />
          </tokens>
        </chunking>
        <chunking id="4" string="telling tales out of school" type="VP">
          <tokens>
            <token id="10" string="telling" />
            <token id="11" string="tales" />
            <token id="12" string="out" />
            <token id="13" string="of" />
            <token id="14" string="school" />
          </tokens>
        </chunking>
        <chunking id="5" string="to see Dan Quayle telling tales out of school" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="see" />
            <token id="8" string="Dan" />
            <token id="9" string="Quayle" />
            <token id="10" string="telling" />
            <token id="11" string="tales" />
            <token id="12" string="out" />
            <token id="13" string="of" />
            <token id="14" string="school" />
          </tokens>
        </chunking>
        <chunking id="6" string="see Dan Quayle telling tales out of school" type="VP">
          <tokens>
            <token id="7" string="see" />
            <token id="8" string="Dan" />
            <token id="9" string="Quayle" />
            <token id="10" string="telling" />
            <token id="11" string="tales" />
            <token id="12" string="out" />
            <token id="13" string="of" />
            <token id="14" string="school" />
          </tokens>
        </chunking>
        <chunking id="7" string="Dan Quayle" type="NP">
          <tokens>
            <token id="8" string="Dan" />
            <token id="9" string="Quayle" />
          </tokens>
        </chunking>
        <chunking id="8" string="tales" type="NP">
          <tokens>
            <token id="11" string="tales" />
          </tokens>
        </chunking>
        <chunking id="9" string="You" type="NP">
          <tokens>
            <token id="2" string="You" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">going</governor>
          <dependent id="2">You</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">going</governor>
          <dependent id="3">'re</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">going</governor>
          <dependent id="4">never</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">see</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">going</governor>
          <dependent id="7">see</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Quayle</governor>
          <dependent id="8">Dan</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">telling</governor>
          <dependent id="9">Quayle</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">see</governor>
          <dependent id="10">telling</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">telling</governor>
          <dependent id="11">tales</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="10">telling</governor>
          <dependent id="12">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">school</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">telling</governor>
          <dependent id="14">school</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Dan Quayle" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Dan" />
            <token id="9" string="Quayle" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="1-2" string="Dan Quayle" id_sentence="1" />
      <mentions>
        <mention ids_tokens="3" string="his" id_sentence="2" />
        <mention ids_tokens="29" string="he" id_sentence="2" />
        <mention ids_tokens="1" string="He" id_sentence="16" />
        <mention ids_tokens="5" string="his" id_sentence="16" />
        <mention ids_tokens="7" string="him" id_sentence="18" />
        <mention ids_tokens="23" string="he" id_sentence="18" />
        <mention ids_tokens="5" string="his" id_sentence="45" />
      </mentions>
    </coreference>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="15-16-17" string="George Bush 's" id_sentence="1" />
      <mentions>
        <mention ids_tokens="13-14" string="George Bush" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="15-16-17-18-19" string="George Bush 's White House" id_sentence="1" />
      <mentions>
        <mention ids_tokens="10-11" string="White House" id_sentence="17" />
        <mention ids_tokens="5-7" string="the White House" id_sentence="29" />
        <mention ids_tokens="2" string="That" id_sentence="30" />
        <mention ids_tokens="1" string="It" id_sentence="31" />
        <mention ids_tokens="1" string="That" id_sentence="32" />
        <mention ids_tokens="15-16" string="White House" id_sentence="44" />
      </mentions>
    </coreference>
    <coreference id="4" type="PROPER">
      <referenced ids_tokens="22" string="Quayle" id_sentence="2" />
      <mentions>
        <mention ids_tokens="5-6" string="Quayle's" id_sentence="23" />
        <mention ids_tokens="5" string="his" id_sentence="24" />
        <mention ids_tokens="22" string="his" id_sentence="24" />
        <mention ids_tokens="29" string="his" id_sentence="24" />
        <mention ids_tokens="11-22" string="Quayle , while `` not the world's leading intellectual ,''" id_sentence="25" />
        <mention ids_tokens="18-26" string="him that's widely believed in the political community" id_sentence="29" />
        <mention ids_tokens="7" string="him" id_sentence="30" />
        <mention ids_tokens="6" string="him" id_sentence="31" />
        <mention ids_tokens="12" string="himself" id_sentence="31" />
        <mention ids_tokens="13-14" string="Quayle's" id_sentence="33" />
        <mention ids_tokens="10" string="himself" id_sentence="36" />
        <mention ids_tokens="27" string="he" id_sentence="36" />
        <mention ids_tokens="33" string="he" id_sentence="36" />
        <mention ids_tokens="40" string="he" id_sentence="36" />
        <mention ids_tokens="8" string="his" id_sentence="38" />
        <mention ids_tokens="11" string="his" id_sentence="38" />
        <mention ids_tokens="16" string="he" id_sentence="38" />
        <mention ids_tokens="19-21" string="his own man" id_sentence="38" />
        <mention ids_tokens="19" string="his" id_sentence="38" />
        <mention ids_tokens="1" string="He" id_sentence="39" />
        <mention ids_tokens="3" string="he" id_sentence="40" />
        <mention ids_tokens="3" string="he" id_sentence="41" />
        <mention ids_tokens="14" string="his" id_sentence="41" />
        <mention ids_tokens="24" string="he" id_sentence="41" />
        <mention ids_tokens="35" string="his" id_sentence="41" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="44-45" string="even Bush" id_sentence="3" />
      <mentions>
        <mention ids_tokens="25" string="Bush" id_sentence="2" />
        <mention ids_tokens="1" string="Bush" id_sentence="7" />
        <mention ids_tokens="4" string="his" id_sentence="7" />
        <mention ids_tokens="4" string="Bush" id_sentence="8" />
        <mention ids_tokens="28" string="he" id_sentence="8" />
        <mention ids_tokens="34" string="his" id_sentence="8" />
        <mention ids_tokens="3" string="Bush" id_sentence="11" />
        <mention ids_tokens="7" string="him" id_sentence="11" />
        <mention ids_tokens="16" string="he" id_sentence="11" />
        <mention ids_tokens="18" string="he" id_sentence="11" />
        <mention ids_tokens="2" string="Bush" id_sentence="14" />
        <mention ids_tokens="14" string="Bush" id_sentence="15" />
        <mention ids_tokens="9" string="Bush" id_sentence="17" />
        <mention ids_tokens="13" string="Bush" id_sentence="19" />
        <mention ids_tokens="17" string="Bush" id_sentence="19" />
        <mention ids_tokens="31" string="he" id_sentence="19" />
        <mention ids_tokens="12-13" string="Bush's" id_sentence="23" />
        <mention ids_tokens="12" string="Bush" id_sentence="38" />
        <mention ids_tokens="14" string="Bush" id_sentence="44" />
        <mention ids_tokens="22" string="Bush" id_sentence="44" />
        <mention ids_tokens="33" string="he" id_sentence="44" />
        <mention ids_tokens="37" string="who" id_sentence="44" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="18-19-20" string="early campaign controversies" id_sentence="2" />
      <mentions>
        <mention ids_tokens="2-3" string="the controversies" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="24-25-26-27-28-29-30-31-32-33-34" string="a Bush administration in which he has few intimates or allies" id_sentence="2" />
      <mentions>
        <mention ids_tokens="24-26" string="the administration's" id_sentence="11" />
        <mention ids_tokens="2" string="I" id_sentence="12" />
        <mention ids_tokens="2" string="that" id_sentence="13" />
        <mention ids_tokens="5-9" string="the way everyone sees it" id_sentence="13" />
        <mention ids_tokens="9" string="it" id_sentence="13" />
        <mention ids_tokens="28-29" string="the administration" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="8" type="NOMINAL">
      <referenced ids_tokens="13-14-15-16-17-18" string="the schedule handed down from Washington" id_sentence="39" />
      <mentions>
        <mention ids_tokens="14-15" string="his schedule" id_sentence="41" />
      </mentions>
    </coreference>
    <coreference id="10" type="PROPER">
      <referenced ids_tokens="41-42" string="Walter Mondale" id_sentence="3" />
      <mentions>
        <mention ids_tokens="4" string="Mondale" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="6-7-8" string="the front pages" id_sentence="40" />
      <mentions>
        <mention ids_tokens="24-25" string="the pages" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="12" type="NOMINAL">
      <referenced ids_tokens="18-19-20-21-22-23-24-25-26-27-28-29-30-31-32-33-34-35-36-37-38-39" string="perhaps the worst being his garbled explanation of the Holocaust and his declaration , `` I did n't live in this century" id_sentence="24" />
      <mentions>
        <mention ids_tokens="3-4" string="the campaign" id_sentence="3" />
        <mention ids_tokens="9-10" string="the campaign" id_sentence="7" />
        <mention ids_tokens="34-35" string="the campaign" id_sentence="19" />
        <mention ids_tokens="3-4" string="the campaign" id_sentence="37" />
        <mention ids_tokens="6-8" string="a learning process" id_sentence="37" />
      </mentions>
    </coreference>
    <coreference id="13" type="PRONOMINAL">
      <referenced ids_tokens="2" string="We" id_sentence="42" />
      <mentions>
        <mention ids_tokens="1" string="That" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="14" type="NOMINAL">
      <referenced ids_tokens="7-8-9-10-11" string="a traditional vice presidential nominee" id_sentence="42" />
      <mentions>
        <mention ids_tokens="11" string="he" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="16" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9" string="One thing that political scientists have been talking about" id_sentence="5" />
      <mentions>
        <mention ids_tokens="5" string="it" id_sentence="6" />
      </mentions>
    </coreference>
    <coreference id="17" type="PROPER">
      <referenced ids_tokens="22-23" string="Ryan Barilleaux" id_sentence="6" />
      <mentions>
        <mention ids_tokens="30" string="Barilleaux" id_sentence="14" />
        <mention ids_tokens="17" string="Barilleaux" id_sentence="17" />
        <mention ids_tokens="2" string="Barilleaux" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="19" type="NOMINAL">
      <referenced ids_tokens="40-41-42" string="the American presidency" id_sentence="6" />
      <mentions>
        <mention ids_tokens="29-30" string="the presidency" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="20" type="NOMINAL">
      <referenced ids_tokens="14-15-16-17" string="an outstanding vice president" id_sentence="8" />
      <mentions>
        <mention ids_tokens="21-22" string="the president" id_sentence="9" />
        <mention ids_tokens="10-11" string="the president" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="21" type="NOMINAL">
      <referenced ids_tokens="1-2" string="The president-elect" id_sentence="9" />
      <mentions>
        <mention ids_tokens="2" string="he" id_sentence="10" />
        <mention ids_tokens="11" string="he" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="22" type="NOMINAL">
      <referenced ids_tokens="4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22" string="reporters Quayle would have access to the same papers , information and intelligence that is available to the president" id_sentence="9" />
      <mentions>
        <mention ids_tokens="13" string="reporters" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="23" type="NOMINAL">
      <referenced ids_tokens="10-11-12" string="a space council" id_sentence="11" />
      <mentions>
        <mention ids_tokens="14-20" string="a space council , drug task force" id_sentence="18" />
        <mention ids_tokens="18-20" string="drug task force" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="27" type="NOMINAL">
      <referenced ids_tokens="5-6-7-8-9-10-11-12-13-14" string="no friends in a Bush White House except George Bush" id_sentence="17" />
      <mentions>
        <mention ids_tokens="2" string="They" id_sentence="18" />
        <mention ids_tokens="3" string="them" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="28" type="PROPER">
      <referenced ids_tokens="2-3-4" string="Eddie Mahe Jr." id_sentence="19" />
      <mentions>
        <mention ids_tokens="15" string="Mahe" id_sentence="21" />
        <mention ids_tokens="18" string="Mahe" id_sentence="44" />
        <mention ids_tokens="17" string="Mahe" id_sentence="45" />
      </mentions>
    </coreference>
    <coreference id="29" type="NOMINAL">
      <referenced ids_tokens="5-6-7-8" string="Quayle 's own party" id_sentence="23" />
      <mentions>
        <mention ids_tokens="15-17" string="the party's" id_sentence="34" />
        <mention ids_tokens="22-24" string="the party's" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="31" type="PROPER">
      <referenced ids_tokens="1-2" string="Norman Ornstein" id_sentence="25" />
      <mentions>
        <mention ids_tokens="1" string="He" id_sentence="26" />
        <mention ids_tokens="10" string="he" id_sentence="26" />
        <mention ids_tokens="14" string="Ornstein" id_sentence="26" />
        <mention ids_tokens="4" string="he" id_sentence="27" />
        <mention ids_tokens="1" string="He" id_sentence="28" />
        <mention ids_tokens="7" string="Ornstein" id_sentence="28" />
        <mention ids_tokens="40" string="Ornstein" id_sentence="29" />
      </mentions>
    </coreference>
    <coreference id="32" type="NOMINAL">
      <referenced ids_tokens="6-7-8-9-10-11-12" string="a situation for which he was unprepared" id_sentence="26" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="34" type="PROPER">
      <referenced ids_tokens="20-21" string="Richard Nixon" id_sentence="33" />
      <mentions>
        <mention ids_tokens="4" string="Nixon" id_sentence="34" />
        <mention ids_tokens="8-11" string="him ( Quayle )" id_sentence="35" />
        <mention ids_tokens="15" string="Nixon" id_sentence="35" />
      </mentions>
    </coreference>
    <coreference id="35" type="PROPER">
      <referenced ids_tokens="23-24" string="Spiro Agnew" id_sentence="33" />
      <mentions>
        <mention ids_tokens="22" string="Agnew" id_sentence="34" />
        <mention ids_tokens="18" string="Agnew" id_sentence="35" />
      </mentions>
    </coreference>
    <coreference id="36" type="PROPER">
      <referenced ids_tokens="23" string="Hess" id_sentence="35" />
      <mentions>
        <mention ids_tokens="1-9" string="Both Barilleaux and Stephen Hess of the Brookings Institution" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="37" type="NOMINAL">
      <referenced ids_tokens="26-27-28" string="a political nonentity" id_sentence="34" />
      <mentions>
        <mention ids_tokens="13" string="I" id_sentence="36" />
      </mentions>
    </coreference>
  </coreferences>
</document>
