<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP900119-0051">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>``Ray Will Die&amp;apost;&amp;apost; is scrawled in big black letters on the faded green paint of the McMartin Pre-School, testimony to the rage inflamed by the notorious child-molesting case.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Ray" lemma="Ray" stem="rai" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Will" lemma="Will" stem="will" pos="NNP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Die" lemma="die" stem="die" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="scrawled" lemma="scrawl" stem="scrawl" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="big" lemma="big" stem="big" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="letters" lemma="letter" stem="letter" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="faded" lemma="fade" stem="fade" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="green" lemma="green" stem="green" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="paint" lemma="paint" stem="paint" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="20" string="Pre-School" lemma="Pre-School" stem="pre-school" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="testimony" lemma="testimony" stem="testimoni" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="rage" lemma="rage" stem="rage" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="inflamed" lemma="inflamed" stem="inflam" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="notorious" lemma="notorious" stem="notori" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="child-molesting" lemma="child-molesting" stem="child-molest" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (NNP Ray) (NNP Will)) (VP (VB Die))) ('' '') (VP (VBZ is) (VP (VBN scrawled) (PP (IN in) (NP (JJ big) (JJ black) (NNS letters))) (PP (IN on) (NP (NP (DT the) (ADJP (VBN faded) (JJ green)) (NN paint)) (PP (IN of) (NP (DT the) (NNP McMartin))))))) (NP (NP (NNP Pre-School)) (, ,) (NP (NP (NN testimony)) (PP (TO to) (NP (NP (DT the) (NN rage)) (ADJP (JJ inflamed) (PP (IN by) (NP (DT the) (JJ notorious) (JJ child-molesting) (NN case)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Ray Will" type="NP">
          <tokens>
            <token id="2" string="Ray" />
            <token id="3" string="Will" />
          </tokens>
        </chunking>
        <chunking id="2" string="the faded green paint" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="faded" />
            <token id="15" string="green" />
            <token id="16" string="paint" />
          </tokens>
        </chunking>
        <chunking id="3" string="scrawled in big black letters on the faded green paint of the McMartin" type="VP">
          <tokens>
            <token id="7" string="scrawled" />
            <token id="8" string="in" />
            <token id="9" string="big" />
            <token id="10" string="black" />
            <token id="11" string="letters" />
            <token id="12" string="on" />
            <token id="13" string="the" />
            <token id="14" string="faded" />
            <token id="15" string="green" />
            <token id="16" string="paint" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="McMartin" />
          </tokens>
        </chunking>
        <chunking id="4" string="is scrawled in big black letters on the faded green paint of the McMartin" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="scrawled" />
            <token id="8" string="in" />
            <token id="9" string="big" />
            <token id="10" string="black" />
            <token id="11" string="letters" />
            <token id="12" string="on" />
            <token id="13" string="the" />
            <token id="14" string="faded" />
            <token id="15" string="green" />
            <token id="16" string="paint" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="McMartin" />
          </tokens>
        </chunking>
        <chunking id="5" string="the rage inflamed by the notorious child-molesting case" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="rage" />
            <token id="26" string="inflamed" />
            <token id="27" string="by" />
            <token id="28" string="the" />
            <token id="29" string="notorious" />
            <token id="30" string="child-molesting" />
            <token id="31" string="case" />
          </tokens>
        </chunking>
        <chunking id="6" string="Pre-School , testimony to the rage inflamed by the notorious child-molesting case" type="NP">
          <tokens>
            <token id="20" string="Pre-School" />
            <token id="21" string="," />
            <token id="22" string="testimony" />
            <token id="23" string="to" />
            <token id="24" string="the" />
            <token id="25" string="rage" />
            <token id="26" string="inflamed" />
            <token id="27" string="by" />
            <token id="28" string="the" />
            <token id="29" string="notorious" />
            <token id="30" string="child-molesting" />
            <token id="31" string="case" />
          </tokens>
        </chunking>
        <chunking id="7" string="the notorious child-molesting case" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="notorious" />
            <token id="30" string="child-molesting" />
            <token id="31" string="case" />
          </tokens>
        </chunking>
        <chunking id="8" string="testimony to the rage inflamed by the notorious child-molesting case" type="NP">
          <tokens>
            <token id="22" string="testimony" />
            <token id="23" string="to" />
            <token id="24" string="the" />
            <token id="25" string="rage" />
            <token id="26" string="inflamed" />
            <token id="27" string="by" />
            <token id="28" string="the" />
            <token id="29" string="notorious" />
            <token id="30" string="child-molesting" />
            <token id="31" string="case" />
          </tokens>
        </chunking>
        <chunking id="9" string="testimony" type="NP">
          <tokens>
            <token id="22" string="testimony" />
          </tokens>
        </chunking>
        <chunking id="10" string="big black letters" type="NP">
          <tokens>
            <token id="9" string="big" />
            <token id="10" string="black" />
            <token id="11" string="letters" />
          </tokens>
        </chunking>
        <chunking id="11" string="the rage" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="rage" />
          </tokens>
        </chunking>
        <chunking id="12" string="faded green" type="ADJP">
          <tokens>
            <token id="14" string="faded" />
            <token id="15" string="green" />
          </tokens>
        </chunking>
        <chunking id="13" string="the faded green paint of the McMartin" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="faded" />
            <token id="15" string="green" />
            <token id="16" string="paint" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="McMartin" />
          </tokens>
        </chunking>
        <chunking id="14" string="the McMartin" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="McMartin" />
          </tokens>
        </chunking>
        <chunking id="15" string="inflamed by the notorious child-molesting case" type="ADJP">
          <tokens>
            <token id="26" string="inflamed" />
            <token id="27" string="by" />
            <token id="28" string="the" />
            <token id="29" string="notorious" />
            <token id="30" string="child-molesting" />
            <token id="31" string="case" />
          </tokens>
        </chunking>
        <chunking id="16" string="Die" type="VP">
          <tokens>
            <token id="4" string="Die" />
          </tokens>
        </chunking>
        <chunking id="17" string="Pre-School" type="NP">
          <tokens>
            <token id="20" string="Pre-School" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Will</governor>
          <dependent id="2">Ray</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">Die</governor>
          <dependent id="3">Will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">scrawled</governor>
          <dependent id="4">Die</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">scrawled</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">scrawled</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">letters</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">letters</governor>
          <dependent id="9">big</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">letters</governor>
          <dependent id="10">black</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">scrawled</governor>
          <dependent id="11">letters</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">paint</governor>
          <dependent id="12">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">paint</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="15">green</governor>
          <dependent id="14">faded</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">paint</governor>
          <dependent id="15">green</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">scrawled</governor>
          <dependent id="16">paint</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">McMartin</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">McMartin</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">paint</governor>
          <dependent id="19">McMartin</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">scrawled</governor>
          <dependent id="20">Pre-School</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="20">Pre-School</governor>
          <dependent id="22">testimony</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">rage</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">rage</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">testimony</governor>
          <dependent id="25">rage</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">rage</governor>
          <dependent id="26">inflamed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">case</governor>
          <dependent id="27">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">case</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">case</governor>
          <dependent id="29">notorious</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">case</governor>
          <dependent id="30">child-molesting</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">inflamed</governor>
          <dependent id="31">case</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="McMartin Pre-School" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="19" string="McMartin" />
            <token id="20" string="Pre-School" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>Former McMartin teachers Raymond Buckey and his mother, Peggy McMartin Buckey, were acquitted Thursday of 52 charges of molesting students.</content>
      <tokens>
        <token id="1" string="Former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="McMartin" lemma="mcmartin" stem="mcmartin" pos="NN" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="teachers" lemma="teacher" stem="teacher" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Raymond" lemma="Raymond" stem="raymond" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="mother" lemma="mother" stem="mother" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Peggy" lemma="Peggy" stem="peggi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="acquitted" lemma="acquit" stem="acquit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="Thursday" lemma="Thursday" stem="thursdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="52" lemma="52" stem="52" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="19" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="molesting" lemma="molest" stem="molest" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="students" lemma="student" stem="student" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (JJ Former) (NN McMartin) (NNS teachers)) (NP (NP (NNP Raymond) (NNP Buckey)) (CC and) (NP (PRP$ his) (NN mother)))) (, ,) (NP (NNP Peggy) (NNP McMartin) (NNP Buckey)) (, ,)) (VP (VBD were) (VP (VBN acquitted) (NP-TMP (NNP Thursday)) (PP (IN of) (NP (NP (CD 52) (NNS charges)) (PP (IN of) (NP (VBG molesting) (NNS students))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Peggy McMartin Buckey" type="NP">
          <tokens>
            <token id="10" string="Peggy" />
            <token id="11" string="McMartin" />
            <token id="12" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="2" string="Former McMartin teachers Raymond Buckey and his mother , Peggy McMartin Buckey ," type="NP">
          <tokens>
            <token id="1" string="Former" />
            <token id="2" string="McMartin" />
            <token id="3" string="teachers" />
            <token id="4" string="Raymond" />
            <token id="5" string="Buckey" />
            <token id="6" string="and" />
            <token id="7" string="his" />
            <token id="8" string="mother" />
            <token id="9" string="," />
            <token id="10" string="Peggy" />
            <token id="11" string="McMartin" />
            <token id="12" string="Buckey" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="Former McMartin teachers" type="NP">
          <tokens>
            <token id="1" string="Former" />
            <token id="2" string="McMartin" />
            <token id="3" string="teachers" />
          </tokens>
        </chunking>
        <chunking id="4" string="Raymond Buckey and his mother" type="NP">
          <tokens>
            <token id="4" string="Raymond" />
            <token id="5" string="Buckey" />
            <token id="6" string="and" />
            <token id="7" string="his" />
            <token id="8" string="mother" />
          </tokens>
        </chunking>
        <chunking id="5" string="his mother" type="NP">
          <tokens>
            <token id="7" string="his" />
            <token id="8" string="mother" />
          </tokens>
        </chunking>
        <chunking id="6" string="Former McMartin teachers Raymond Buckey and his mother" type="NP">
          <tokens>
            <token id="1" string="Former" />
            <token id="2" string="McMartin" />
            <token id="3" string="teachers" />
            <token id="4" string="Raymond" />
            <token id="5" string="Buckey" />
            <token id="6" string="and" />
            <token id="7" string="his" />
            <token id="8" string="mother" />
          </tokens>
        </chunking>
        <chunking id="7" string="were acquitted Thursday of 52 charges of molesting students" type="VP">
          <tokens>
            <token id="14" string="were" />
            <token id="15" string="acquitted" />
            <token id="16" string="Thursday" />
            <token id="17" string="of" />
            <token id="18" string="52" />
            <token id="19" string="charges" />
            <token id="20" string="of" />
            <token id="21" string="molesting" />
            <token id="22" string="students" />
          </tokens>
        </chunking>
        <chunking id="8" string="molesting students" type="NP">
          <tokens>
            <token id="21" string="molesting" />
            <token id="22" string="students" />
          </tokens>
        </chunking>
        <chunking id="9" string="52 charges of molesting students" type="NP">
          <tokens>
            <token id="18" string="52" />
            <token id="19" string="charges" />
            <token id="20" string="of" />
            <token id="21" string="molesting" />
            <token id="22" string="students" />
          </tokens>
        </chunking>
        <chunking id="10" string="Raymond Buckey" type="NP">
          <tokens>
            <token id="4" string="Raymond" />
            <token id="5" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="11" string="acquitted Thursday of 52 charges of molesting students" type="VP">
          <tokens>
            <token id="15" string="acquitted" />
            <token id="16" string="Thursday" />
            <token id="17" string="of" />
            <token id="18" string="52" />
            <token id="19" string="charges" />
            <token id="20" string="of" />
            <token id="21" string="molesting" />
            <token id="22" string="students" />
          </tokens>
        </chunking>
        <chunking id="12" string="52 charges" type="NP">
          <tokens>
            <token id="18" string="52" />
            <token id="19" string="charges" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="3">teachers</governor>
          <dependent id="1">Former</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">teachers</governor>
          <dependent id="2">McMartin</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="15">acquitted</governor>
          <dependent id="3">teachers</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Buckey</governor>
          <dependent id="4">Raymond</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">teachers</governor>
          <dependent id="5">Buckey</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">Buckey</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">mother</governor>
          <dependent id="7">his</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">Buckey</governor>
          <dependent id="8">mother</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Buckey</governor>
          <dependent id="10">Peggy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Buckey</governor>
          <dependent id="11">McMartin</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">teachers</governor>
          <dependent id="12">Buckey</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="15">acquitted</governor>
          <dependent id="14">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">acquitted</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="15">acquitted</governor>
          <dependent id="16">Thursday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">charges</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">charges</governor>
          <dependent id="18">52</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">acquitted</governor>
          <dependent id="19">charges</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">students</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">students</governor>
          <dependent id="21">molesting</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">charges</governor>
          <dependent id="22">students</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Peggy McMartin Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Peggy" />
            <token id="11" string="McMartin" />
            <token id="12" string="Buckey" />
          </tokens>
        </entity>
        <entity id="2" string="McMartin" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="McMartin" />
          </tokens>
        </entity>
        <entity id="3" string="Thursday" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="Thursday" />
          </tokens>
        </entity>
        <entity id="4" string="52" type="NUMBER" score="0.0">
          <tokens>
            <token id="18" string="52" />
          </tokens>
        </entity>
        <entity id="5" string="Raymond Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Raymond" />
            <token id="5" string="Buckey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>Jurors were deadlocked on 13 other counts.</content>
      <tokens>
        <token id="1" string="Jurors" lemma="Jurors" stem="juror" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="deadlocked" lemma="deadlock" stem="deadlock" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="13" lemma="13" stem="13" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="6" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="counts" lemma="count" stem="count" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Jurors)) (VP (VBD were) (VP (VBN deadlocked) (PP (IN on) (NP (CD 13) (JJ other) (NNS counts))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Jurors" type="NP">
          <tokens>
            <token id="1" string="Jurors" />
          </tokens>
        </chunking>
        <chunking id="2" string="were deadlocked on 13 other counts" type="VP">
          <tokens>
            <token id="2" string="were" />
            <token id="3" string="deadlocked" />
            <token id="4" string="on" />
            <token id="5" string="13" />
            <token id="6" string="other" />
            <token id="7" string="counts" />
          </tokens>
        </chunking>
        <chunking id="3" string="13 other counts" type="NP">
          <tokens>
            <token id="5" string="13" />
            <token id="6" string="other" />
            <token id="7" string="counts" />
          </tokens>
        </chunking>
        <chunking id="4" string="deadlocked on 13 other counts" type="VP">
          <tokens>
            <token id="3" string="deadlocked" />
            <token id="4" string="on" />
            <token id="5" string="13" />
            <token id="6" string="other" />
            <token id="7" string="counts" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="3">deadlocked</governor>
          <dependent id="1">Jurors</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="3">deadlocked</governor>
          <dependent id="2">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">deadlocked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">counts</governor>
          <dependent id="4">on</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">counts</governor>
          <dependent id="5">13</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">counts</governor>
          <dependent id="6">other</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">deadlocked</governor>
          <dependent id="7">counts</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="13" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="13" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>Whatever happens on those charges, few in this upper-middle-class Los Angeles suburb would disagree with the judge in the trial, William Pounders, who once said, ``The case has poisoned everyone who had contact with it.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="Whatever" lemma="whatever" stem="whatev" pos="WDT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="happens" lemma="happen" stem="happen" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="upper-middle-class" lemma="upper-middle-class" stem="upper-middle-class" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="12" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="13" string="suburb" lemma="suburb" stem="suburb" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="disagree" lemma="disagree" stem="disagre" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="judge" lemma="judge" stem="judg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="William" lemma="William" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="24" string="Pounders" lemma="Pounders" stem="pounder" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="once" lemma="once" stem="onc" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="28" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="33" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="poisoned" lemma="poison" stem="poison" pos="VBN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="35" string="everyone" lemma="everyone" stem="everyon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="contact" lemma="contact" stem="contact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHNP (WDT Whatever)) (S (VP (VBZ happens) (PP (IN on) (NP (DT those) (NNS charges)))))) (PRN (, ,) (S (NP (NP (JJ few)) (PP (IN in) (NP (DT this) (JJ upper-middle-class) (NNP Los) (NNP Angeles) (NN suburb)))) (VP (MD would) (VP (VB disagree) (PP (IN with) (NP (NP (DT the) (NN judge)) (PP (IN in) (NP (NP (DT the) (NN trial)) (, ,) (NP (NNP William) (NNP Pounders)) (, ,) (SBAR (WHNP (WP who)) (S (ADVP (RB once)) (VP (VBD said))))))))))) (, ,)) (`` ``) (NP (DT The) (NN case)) (VP (VBZ has) (NP (NP (VBN poisoned) (NN everyone)) (SBAR (WHNP (WP who)) (S (VP (VBD had) (NP (NP (NN contact)) (PP (IN with) (NP (PRP it))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="William Pounders" type="NP">
          <tokens>
            <token id="23" string="William" />
            <token id="24" string="Pounders" />
          </tokens>
        </chunking>
        <chunking id="2" string="who had contact with it" type="SBAR">
          <tokens>
            <token id="36" string="who" />
            <token id="37" string="had" />
            <token id="38" string="contact" />
            <token id="39" string="with" />
            <token id="40" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="the trial" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="trial" />
          </tokens>
        </chunking>
        <chunking id="4" string="the judge in the trial , William Pounders , who once said" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="judge" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="trial" />
            <token id="22" string="," />
            <token id="23" string="William" />
            <token id="24" string="Pounders" />
            <token id="25" string="," />
            <token id="26" string="who" />
            <token id="27" string="once" />
            <token id="28" string="said" />
          </tokens>
        </chunking>
        <chunking id="5" string="disagree with the judge in the trial , William Pounders , who once said" type="VP">
          <tokens>
            <token id="15" string="disagree" />
            <token id="16" string="with" />
            <token id="17" string="the" />
            <token id="18" string="judge" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="trial" />
            <token id="22" string="," />
            <token id="23" string="William" />
            <token id="24" string="Pounders" />
            <token id="25" string="," />
            <token id="26" string="who" />
            <token id="27" string="once" />
            <token id="28" string="said" />
          </tokens>
        </chunking>
        <chunking id="6" string="contact" type="NP">
          <tokens>
            <token id="38" string="contact" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="40" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="happens on those charges" type="VP">
          <tokens>
            <token id="2" string="happens" />
            <token id="3" string="on" />
            <token id="4" string="those" />
            <token id="5" string="charges" />
          </tokens>
        </chunking>
        <chunking id="9" string="The case" type="NP">
          <tokens>
            <token id="31" string="The" />
            <token id="32" string="case" />
          </tokens>
        </chunking>
        <chunking id="10" string="Whatever happens on those charges" type="SBAR">
          <tokens>
            <token id="1" string="Whatever" />
            <token id="2" string="happens" />
            <token id="3" string="on" />
            <token id="4" string="those" />
            <token id="5" string="charges" />
          </tokens>
        </chunking>
        <chunking id="11" string="those charges" type="NP">
          <tokens>
            <token id="4" string="those" />
            <token id="5" string="charges" />
          </tokens>
        </chunking>
        <chunking id="12" string="had contact with it" type="VP">
          <tokens>
            <token id="37" string="had" />
            <token id="38" string="contact" />
            <token id="39" string="with" />
            <token id="40" string="it" />
          </tokens>
        </chunking>
        <chunking id="13" string="contact with it" type="NP">
          <tokens>
            <token id="38" string="contact" />
            <token id="39" string="with" />
            <token id="40" string="it" />
          </tokens>
        </chunking>
        <chunking id="14" string="has poisoned everyone who had contact with it" type="VP">
          <tokens>
            <token id="33" string="has" />
            <token id="34" string="poisoned" />
            <token id="35" string="everyone" />
            <token id="36" string="who" />
            <token id="37" string="had" />
            <token id="38" string="contact" />
            <token id="39" string="with" />
            <token id="40" string="it" />
          </tokens>
        </chunking>
        <chunking id="15" string="few" type="NP">
          <tokens>
            <token id="7" string="few" />
          </tokens>
        </chunking>
        <chunking id="16" string="who once said" type="SBAR">
          <tokens>
            <token id="26" string="who" />
            <token id="27" string="once" />
            <token id="28" string="said" />
          </tokens>
        </chunking>
        <chunking id="17" string="few in this upper-middle-class Los Angeles suburb" type="NP">
          <tokens>
            <token id="7" string="few" />
            <token id="8" string="in" />
            <token id="9" string="this" />
            <token id="10" string="upper-middle-class" />
            <token id="11" string="Los" />
            <token id="12" string="Angeles" />
            <token id="13" string="suburb" />
          </tokens>
        </chunking>
        <chunking id="18" string="the trial , William Pounders , who once said" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="trial" />
            <token id="22" string="," />
            <token id="23" string="William" />
            <token id="24" string="Pounders" />
            <token id="25" string="," />
            <token id="26" string="who" />
            <token id="27" string="once" />
            <token id="28" string="said" />
          </tokens>
        </chunking>
        <chunking id="19" string="this upper-middle-class Los Angeles suburb" type="NP">
          <tokens>
            <token id="9" string="this" />
            <token id="10" string="upper-middle-class" />
            <token id="11" string="Los" />
            <token id="12" string="Angeles" />
            <token id="13" string="suburb" />
          </tokens>
        </chunking>
        <chunking id="20" string="would disagree with the judge in the trial , William Pounders , who once said" type="VP">
          <tokens>
            <token id="14" string="would" />
            <token id="15" string="disagree" />
            <token id="16" string="with" />
            <token id="17" string="the" />
            <token id="18" string="judge" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="trial" />
            <token id="22" string="," />
            <token id="23" string="William" />
            <token id="24" string="Pounders" />
            <token id="25" string="," />
            <token id="26" string="who" />
            <token id="27" string="once" />
            <token id="28" string="said" />
          </tokens>
        </chunking>
        <chunking id="21" string="said" type="VP">
          <tokens>
            <token id="28" string="said" />
          </tokens>
        </chunking>
        <chunking id="22" string="the judge" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="judge" />
          </tokens>
        </chunking>
        <chunking id="23" string="poisoned everyone who had contact with it" type="NP">
          <tokens>
            <token id="34" string="poisoned" />
            <token id="35" string="everyone" />
            <token id="36" string="who" />
            <token id="37" string="had" />
            <token id="38" string="contact" />
            <token id="39" string="with" />
            <token id="40" string="it" />
          </tokens>
        </chunking>
        <chunking id="24" string="poisoned everyone" type="NP">
          <tokens>
            <token id="34" string="poisoned" />
            <token id="35" string="everyone" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">happens</governor>
          <dependent id="1">Whatever</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="33">has</governor>
          <dependent id="2">happens</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">charges</governor>
          <dependent id="3">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">charges</governor>
          <dependent id="4">those</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">happens</governor>
          <dependent id="5">charges</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">disagree</governor>
          <dependent id="7">few</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">suburb</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">suburb</governor>
          <dependent id="9">this</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">suburb</governor>
          <dependent id="10">upper-middle-class</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">suburb</governor>
          <dependent id="11">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">suburb</governor>
          <dependent id="12">Angeles</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">few</governor>
          <dependent id="13">suburb</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">disagree</governor>
          <dependent id="14">would</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="33">has</governor>
          <dependent id="15">disagree</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">judge</governor>
          <dependent id="16">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">judge</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">disagree</governor>
          <dependent id="18">judge</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">trial</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">trial</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">judge</governor>
          <dependent id="21">trial</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Pounders</governor>
          <dependent id="23">William</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="21">trial</governor>
          <dependent id="24">Pounders</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">said</governor>
          <dependent id="26">who</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">said</governor>
          <dependent id="27">once</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="21">trial</governor>
          <dependent id="28">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">case</governor>
          <dependent id="31">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">has</governor>
          <dependent id="32">case</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="33">has</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">everyone</governor>
          <dependent id="34">poisoned</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="33">has</governor>
          <dependent id="35">everyone</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="37">had</governor>
          <dependent id="36">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="35">everyone</governor>
          <dependent id="37">had</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="37">had</governor>
          <dependent id="38">contact</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">it</governor>
          <dependent id="39">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">contact</governor>
          <dependent id="40">it</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="William Pounders" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="William" />
            <token id="24" string="Pounders" />
          </tokens>
        </entity>
        <entity id="2" string="once" type="DATE" score="0.0">
          <tokens>
            <token id="27" string="once" />
          </tokens>
        </entity>
        <entity id="3" string="poisoned" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="34" string="poisoned" />
          </tokens>
        </entity>
        <entity id="4" string="Los Angeles" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="Los" />
            <token id="12" string="Angeles" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>Sue Brown, a receptionist at a medical office across the street from the school, said she had two friends who were involved in the case and had been convinced of the Buckeys&amp;apost; guilt.</content>
      <tokens>
        <token id="1" string="Sue" lemma="sue" stem="sue" pos="VB" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Brown" lemma="Brown" stem="brown" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="receptionist" lemma="receptionist" stem="receptionist" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="medical" lemma="medical" stem="medic" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="across" lemma="across" stem="across" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="street" lemma="street" stem="street" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="21" string="friends" lemma="friend" stem="friend" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="involved" lemma="involve" stem="involv" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="27" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="28" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="convinced" lemma="convince" stem="convinc" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="Buckeys" lemma="Buckeys" stem="buckei" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="35" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="guilt" lemma="guilt" stem="guilt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (VP (VB Sue) (SBAR (S (NP (NP (NNP Brown)) (, ,) (NP (NP (DT a) (NN receptionist)) (PP (IN at) (NP (NP (DT a) (JJ medical) (NN office)) (PP (IN across) (NP (NP (DT the) (NN street)) (PP (IN from) (NP (DT the) (NN school)))))))) (, ,)) (VP (VBD said) (SBAR (S (NP (PRP she)) (VP (VP (VBD had) (NP (NP (CD two) (NNS friends)) (SBAR (WHNP (WP who)) (S (VP (VBD were) (VP (VBN involved) (PP (IN in) (NP (DT the) (NN case))))))))) (CC and) (VP (VBD had) (VP (VBN been) (VP (VBN convinced) (PP (IN of) (NP (NP (DT the) (NNPS Buckeys) (POS ')) (NN guilt))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="two friends who were involved in the case" type="NP">
          <tokens>
            <token id="20" string="two" />
            <token id="21" string="friends" />
            <token id="22" string="who" />
            <token id="23" string="were" />
            <token id="24" string="involved" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="case" />
          </tokens>
        </chunking>
        <chunking id="2" string="who were involved in the case" type="SBAR">
          <tokens>
            <token id="22" string="who" />
            <token id="23" string="were" />
            <token id="24" string="involved" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="case" />
          </tokens>
        </chunking>
        <chunking id="3" string="were involved in the case" type="VP">
          <tokens>
            <token id="23" string="were" />
            <token id="24" string="involved" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="case" />
          </tokens>
        </chunking>
        <chunking id="4" string="the case" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="case" />
          </tokens>
        </chunking>
        <chunking id="5" string="said she had two friends who were involved in the case and had been convinced of the Buckeys ' guilt" type="VP">
          <tokens>
            <token id="17" string="said" />
            <token id="18" string="she" />
            <token id="19" string="had" />
            <token id="20" string="two" />
            <token id="21" string="friends" />
            <token id="22" string="who" />
            <token id="23" string="were" />
            <token id="24" string="involved" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="case" />
            <token id="28" string="and" />
            <token id="29" string="had" />
            <token id="30" string="been" />
            <token id="31" string="convinced" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="Buckeys" />
            <token id="35" string="'" />
            <token id="36" string="guilt" />
          </tokens>
        </chunking>
        <chunking id="6" string="been convinced of the Buckeys ' guilt" type="VP">
          <tokens>
            <token id="30" string="been" />
            <token id="31" string="convinced" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="Buckeys" />
            <token id="35" string="'" />
            <token id="36" string="guilt" />
          </tokens>
        </chunking>
        <chunking id="7" string="Brown , a receptionist at a medical office across the street from the school ," type="NP">
          <tokens>
            <token id="2" string="Brown" />
            <token id="3" string="," />
            <token id="4" string="a" />
            <token id="5" string="receptionist" />
            <token id="6" string="at" />
            <token id="7" string="a" />
            <token id="8" string="medical" />
            <token id="9" string="office" />
            <token id="10" string="across" />
            <token id="11" string="the" />
            <token id="12" string="street" />
            <token id="13" string="from" />
            <token id="14" string="the" />
            <token id="15" string="school" />
            <token id="16" string="," />
          </tokens>
        </chunking>
        <chunking id="8" string="Brown , a receptionist at a medical office across the street from the school , said she had two friends who were involved in the case and had been convinced of the Buckeys ' guilt" type="SBAR">
          <tokens>
            <token id="2" string="Brown" />
            <token id="3" string="," />
            <token id="4" string="a" />
            <token id="5" string="receptionist" />
            <token id="6" string="at" />
            <token id="7" string="a" />
            <token id="8" string="medical" />
            <token id="9" string="office" />
            <token id="10" string="across" />
            <token id="11" string="the" />
            <token id="12" string="street" />
            <token id="13" string="from" />
            <token id="14" string="the" />
            <token id="15" string="school" />
            <token id="16" string="," />
            <token id="17" string="said" />
            <token id="18" string="she" />
            <token id="19" string="had" />
            <token id="20" string="two" />
            <token id="21" string="friends" />
            <token id="22" string="who" />
            <token id="23" string="were" />
            <token id="24" string="involved" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="case" />
            <token id="28" string="and" />
            <token id="29" string="had" />
            <token id="30" string="been" />
            <token id="31" string="convinced" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="Buckeys" />
            <token id="35" string="'" />
            <token id="36" string="guilt" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="18" string="she" />
          </tokens>
        </chunking>
        <chunking id="10" string="had been convinced of the Buckeys ' guilt" type="VP">
          <tokens>
            <token id="29" string="had" />
            <token id="30" string="been" />
            <token id="31" string="convinced" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="Buckeys" />
            <token id="35" string="'" />
            <token id="36" string="guilt" />
          </tokens>
        </chunking>
        <chunking id="11" string="the Buckeys '" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="Buckeys" />
            <token id="35" string="'" />
          </tokens>
        </chunking>
        <chunking id="12" string="had two friends who were involved in the case and had been convinced of the Buckeys ' guilt" type="VP">
          <tokens>
            <token id="19" string="had" />
            <token id="20" string="two" />
            <token id="21" string="friends" />
            <token id="22" string="who" />
            <token id="23" string="were" />
            <token id="24" string="involved" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="case" />
            <token id="28" string="and" />
            <token id="29" string="had" />
            <token id="30" string="been" />
            <token id="31" string="convinced" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="Buckeys" />
            <token id="35" string="'" />
            <token id="36" string="guilt" />
          </tokens>
        </chunking>
        <chunking id="13" string="Brown" type="NP">
          <tokens>
            <token id="2" string="Brown" />
          </tokens>
        </chunking>
        <chunking id="14" string="a receptionist" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="receptionist" />
          </tokens>
        </chunking>
        <chunking id="15" string="a medical office across the street from the school" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="medical" />
            <token id="9" string="office" />
            <token id="10" string="across" />
            <token id="11" string="the" />
            <token id="12" string="street" />
            <token id="13" string="from" />
            <token id="14" string="the" />
            <token id="15" string="school" />
          </tokens>
        </chunking>
        <chunking id="16" string="the Buckeys ' guilt" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="Buckeys" />
            <token id="35" string="'" />
            <token id="36" string="guilt" />
          </tokens>
        </chunking>
        <chunking id="17" string="Sue Brown , a receptionist at a medical office across the street from the school , said she had two friends who were involved in the case and had been convinced of the Buckeys ' guilt" type="VP">
          <tokens>
            <token id="1" string="Sue" />
            <token id="2" string="Brown" />
            <token id="3" string="," />
            <token id="4" string="a" />
            <token id="5" string="receptionist" />
            <token id="6" string="at" />
            <token id="7" string="a" />
            <token id="8" string="medical" />
            <token id="9" string="office" />
            <token id="10" string="across" />
            <token id="11" string="the" />
            <token id="12" string="street" />
            <token id="13" string="from" />
            <token id="14" string="the" />
            <token id="15" string="school" />
            <token id="16" string="," />
            <token id="17" string="said" />
            <token id="18" string="she" />
            <token id="19" string="had" />
            <token id="20" string="two" />
            <token id="21" string="friends" />
            <token id="22" string="who" />
            <token id="23" string="were" />
            <token id="24" string="involved" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="case" />
            <token id="28" string="and" />
            <token id="29" string="had" />
            <token id="30" string="been" />
            <token id="31" string="convinced" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="Buckeys" />
            <token id="35" string="'" />
            <token id="36" string="guilt" />
          </tokens>
        </chunking>
        <chunking id="18" string="a receptionist at a medical office across the street from the school" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="receptionist" />
            <token id="6" string="at" />
            <token id="7" string="a" />
            <token id="8" string="medical" />
            <token id="9" string="office" />
            <token id="10" string="across" />
            <token id="11" string="the" />
            <token id="12" string="street" />
            <token id="13" string="from" />
            <token id="14" string="the" />
            <token id="15" string="school" />
          </tokens>
        </chunking>
        <chunking id="19" string="the street from the school" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="street" />
            <token id="13" string="from" />
            <token id="14" string="the" />
            <token id="15" string="school" />
          </tokens>
        </chunking>
        <chunking id="20" string="the school" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="school" />
          </tokens>
        </chunking>
        <chunking id="21" string="two friends" type="NP">
          <tokens>
            <token id="20" string="two" />
            <token id="21" string="friends" />
          </tokens>
        </chunking>
        <chunking id="22" string="involved in the case" type="VP">
          <tokens>
            <token id="24" string="involved" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="case" />
          </tokens>
        </chunking>
        <chunking id="23" string="she had two friends who were involved in the case and had been convinced of the Buckeys ' guilt" type="SBAR">
          <tokens>
            <token id="18" string="she" />
            <token id="19" string="had" />
            <token id="20" string="two" />
            <token id="21" string="friends" />
            <token id="22" string="who" />
            <token id="23" string="were" />
            <token id="24" string="involved" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="case" />
            <token id="28" string="and" />
            <token id="29" string="had" />
            <token id="30" string="been" />
            <token id="31" string="convinced" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="Buckeys" />
            <token id="35" string="'" />
            <token id="36" string="guilt" />
          </tokens>
        </chunking>
        <chunking id="24" string="the street" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="street" />
          </tokens>
        </chunking>
        <chunking id="25" string="convinced of the Buckeys ' guilt" type="VP">
          <tokens>
            <token id="31" string="convinced" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="Buckeys" />
            <token id="35" string="'" />
            <token id="36" string="guilt" />
          </tokens>
        </chunking>
        <chunking id="26" string="a medical office" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="medical" />
            <token id="9" string="office" />
          </tokens>
        </chunking>
        <chunking id="27" string="had two friends who were involved in the case" type="VP">
          <tokens>
            <token id="19" string="had" />
            <token id="20" string="two" />
            <token id="21" string="friends" />
            <token id="22" string="who" />
            <token id="23" string="were" />
            <token id="24" string="involved" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="case" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">Sue</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">said</governor>
          <dependent id="2">Brown</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">receptionist</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Brown</governor>
          <dependent id="5">receptionist</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">office</governor>
          <dependent id="6">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">office</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">office</governor>
          <dependent id="8">medical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">receptionist</governor>
          <dependent id="9">office</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">street</governor>
          <dependent id="10">across</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">street</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">office</governor>
          <dependent id="12">street</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">school</governor>
          <dependent id="13">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">school</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">street</governor>
          <dependent id="15">school</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="1">Sue</governor>
          <dependent id="17">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">had</governor>
          <dependent id="18">she</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">said</governor>
          <dependent id="19">had</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="21">friends</governor>
          <dependent id="20">two</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">had</governor>
          <dependent id="21">friends</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="24">involved</governor>
          <dependent id="22">who</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="24">involved</governor>
          <dependent id="23">were</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="21">friends</governor>
          <dependent id="24">involved</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">case</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">case</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">involved</governor>
          <dependent id="27">case</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">had</governor>
          <dependent id="28">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="31">convinced</governor>
          <dependent id="29">had</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="31">convinced</governor>
          <dependent id="30">been</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">had</governor>
          <dependent id="31">convinced</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">guilt</governor>
          <dependent id="32">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">Buckeys</governor>
          <dependent id="33">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="36">guilt</governor>
          <dependent id="34">Buckeys</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">Buckeys</governor>
          <dependent id="35">'</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">convinced</governor>
          <dependent id="36">guilt</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Sue Brown" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Sue" />
            <token id="2" string="Brown" />
          </tokens>
        </entity>
        <entity id="2" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="20" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>``I think they got off scot-free,&amp;apost;&amp;apost; Brown said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="off" lemma="off" stem="off" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="scot-free" lemma="scot-free" stem="scot-fre" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Brown" lemma="Brown" stem="brown" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBP think) (SBAR (S (NP (PRP they)) (VP (VBD got) (PRT (RP off)) (S (ADJP (JJ scot-free)))))))) (, ,) ('' '') (NP (NNP Brown)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="4" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="scot-free" type="ADJP">
          <tokens>
            <token id="7" string="scot-free" />
          </tokens>
        </chunking>
        <chunking id="3" string="Brown" type="NP">
          <tokens>
            <token id="10" string="Brown" />
          </tokens>
        </chunking>
        <chunking id="4" string="think they got off scot-free" type="VP">
          <tokens>
            <token id="3" string="think" />
            <token id="4" string="they" />
            <token id="5" string="got" />
            <token id="6" string="off" />
            <token id="7" string="scot-free" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="they got off scot-free" type="SBAR">
          <tokens>
            <token id="4" string="they" />
            <token id="5" string="got" />
            <token id="6" string="off" />
            <token id="7" string="scot-free" />
          </tokens>
        </chunking>
        <chunking id="7" string="got off scot-free" type="VP">
          <tokens>
            <token id="5" string="got" />
            <token id="6" string="off" />
            <token id="7" string="scot-free" />
          </tokens>
        </chunking>
        <chunking id="8" string="said" type="VP">
          <tokens>
            <token id="11" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">think</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">said</governor>
          <dependent id="3">think</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">got</governor>
          <dependent id="4">they</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">think</governor>
          <dependent id="5">got</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="5">got</governor>
          <dependent id="6">off</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">got</governor>
          <dependent id="7">scot-free</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">said</governor>
          <dependent id="10">Brown</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Brown" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Brown" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>``I&amp;apost;m really sick about it.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="sick" lemma="sick" stem="sick" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBP 'm) (ADJP (RB really) (JJ sick) (PP (IN about) (NP (PRP it))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="2" string="'m really sick about it" type="VP">
          <tokens>
            <token id="3" string="'m" />
            <token id="4" string="really" />
            <token id="5" string="sick" />
            <token id="6" string="about" />
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="it" type="NP">
          <tokens>
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="really sick about it" type="ADJP">
          <tokens>
            <token id="4" string="really" />
            <token id="5" string="sick" />
            <token id="6" string="about" />
            <token id="7" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">sick</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">sick</governor>
          <dependent id="3">'m</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">sick</governor>
          <dependent id="4">really</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">sick</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">it</governor>
          <dependent id="6">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">sick</governor>
          <dependent id="7">it</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>Alan Lagunoff, whose son, now 10, testified against the Buckeys, stood in front of the run-down, long-closed nursery school and talked about his disappointment.</content>
      <tokens>
        <token id="1" string="Alan" lemma="Alan" stem="alan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Lagunoff" lemma="Lagunoff" stem="lagunoff" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="whose" lemma="whose" stem="whose" pos="WP$" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="son" lemma="son" stem="son" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="10" lemma="10" stem="10" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="testified" lemma="testify" stem="testifi" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="Buckeys" lemma="Buckeys" stem="buckei" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="stood" lemma="stand" stem="stood" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="front" lemma="front" stem="front" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="run-down" lemma="run-down" stem="run-down" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="long-closed" lemma="long-closed" stem="long-clos" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="nursery" lemma="nursery" stem="nurseri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="talked" lemma="talk" stem="talk" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="disappointment" lemma="disappointment" stem="disappoint" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Alan) (NNP Lagunoff)) (, ,) (SBAR (WHNP (WHNP (WP$ whose) (NN son)) (PRN (, ,) (ADVP (RB now) (NP (CD 10))) (, ,))) (S (VP (VBD testified) (PP (IN against) (NP (DT the) (NNPS Buckeys)))))) (, ,)) (VP (VP (VBD stood) (PP (IN in) (NP (NP (NN front)) (PP (IN of) (NP (DT the) (JJ run-down) (, ,) (JJ long-closed) (NN nursery) (NN school)))))) (CC and) (VP (VBD talked) (PP (IN about) (NP (PRP$ his) (NN disappointment))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="talked about his disappointment" type="VP">
          <tokens>
            <token id="26" string="talked" />
            <token id="27" string="about" />
            <token id="28" string="his" />
            <token id="29" string="disappointment" />
          </tokens>
        </chunking>
        <chunking id="2" string="stood in front of the run-down , long-closed nursery school" type="VP">
          <tokens>
            <token id="15" string="stood" />
            <token id="16" string="in" />
            <token id="17" string="front" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="run-down" />
            <token id="21" string="," />
            <token id="22" string="long-closed" />
            <token id="23" string="nursery" />
            <token id="24" string="school" />
          </tokens>
        </chunking>
        <chunking id="3" string="testified against the Buckeys" type="VP">
          <tokens>
            <token id="10" string="testified" />
            <token id="11" string="against" />
            <token id="12" string="the" />
            <token id="13" string="Buckeys" />
          </tokens>
        </chunking>
        <chunking id="4" string="Alan Lagunoff , whose son , now 10 , testified against the Buckeys ," type="NP">
          <tokens>
            <token id="1" string="Alan" />
            <token id="2" string="Lagunoff" />
            <token id="3" string="," />
            <token id="4" string="whose" />
            <token id="5" string="son" />
            <token id="6" string="," />
            <token id="7" string="now" />
            <token id="8" string="10" />
            <token id="9" string="," />
            <token id="10" string="testified" />
            <token id="11" string="against" />
            <token id="12" string="the" />
            <token id="13" string="Buckeys" />
            <token id="14" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="whose son , now 10 , testified against the Buckeys" type="SBAR">
          <tokens>
            <token id="4" string="whose" />
            <token id="5" string="son" />
            <token id="6" string="," />
            <token id="7" string="now" />
            <token id="8" string="10" />
            <token id="9" string="," />
            <token id="10" string="testified" />
            <token id="11" string="against" />
            <token id="12" string="the" />
            <token id="13" string="Buckeys" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Buckeys" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="Buckeys" />
          </tokens>
        </chunking>
        <chunking id="7" string="the run-down , long-closed nursery school" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="run-down" />
            <token id="21" string="," />
            <token id="22" string="long-closed" />
            <token id="23" string="nursery" />
            <token id="24" string="school" />
          </tokens>
        </chunking>
        <chunking id="8" string="his disappointment" type="NP">
          <tokens>
            <token id="28" string="his" />
            <token id="29" string="disappointment" />
          </tokens>
        </chunking>
        <chunking id="9" string="stood in front of the run-down , long-closed nursery school and talked about his disappointment" type="VP">
          <tokens>
            <token id="15" string="stood" />
            <token id="16" string="in" />
            <token id="17" string="front" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="run-down" />
            <token id="21" string="," />
            <token id="22" string="long-closed" />
            <token id="23" string="nursery" />
            <token id="24" string="school" />
            <token id="25" string="and" />
            <token id="26" string="talked" />
            <token id="27" string="about" />
            <token id="28" string="his" />
            <token id="29" string="disappointment" />
          </tokens>
        </chunking>
        <chunking id="10" string="front of the run-down , long-closed nursery school" type="NP">
          <tokens>
            <token id="17" string="front" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="run-down" />
            <token id="21" string="," />
            <token id="22" string="long-closed" />
            <token id="23" string="nursery" />
            <token id="24" string="school" />
          </tokens>
        </chunking>
        <chunking id="11" string="front" type="NP">
          <tokens>
            <token id="17" string="front" />
          </tokens>
        </chunking>
        <chunking id="12" string="Alan Lagunoff" type="NP">
          <tokens>
            <token id="1" string="Alan" />
            <token id="2" string="Lagunoff" />
          </tokens>
        </chunking>
        <chunking id="13" string="10" type="NP">
          <tokens>
            <token id="8" string="10" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Lagunoff</governor>
          <dependent id="1">Alan</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">stood</governor>
          <dependent id="2">Lagunoff</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">son</governor>
          <dependent id="4">whose</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">testified</governor>
          <dependent id="5">son</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">son</governor>
          <dependent id="7">now</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="7">now</governor>
          <dependent id="8">10</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">Lagunoff</governor>
          <dependent id="10">testified</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Buckeys</governor>
          <dependent id="11">against</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">Buckeys</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">testified</governor>
          <dependent id="13">Buckeys</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">stood</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">school</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="16">in</governor>
          <dependent id="17">front</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="16">in</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">school</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">school</governor>
          <dependent id="20">run-down</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">school</governor>
          <dependent id="22">long-closed</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">school</governor>
          <dependent id="23">nursery</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">stood</governor>
          <dependent id="24">school</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">stood</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">stood</governor>
          <dependent id="26">talked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">disappointment</governor>
          <dependent id="27">about</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="29">disappointment</governor>
          <dependent id="28">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">talked</governor>
          <dependent id="29">disappointment</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="now" />
          </tokens>
        </entity>
        <entity id="2" string="Buckeys" type="MISC" score="0.0">
          <tokens>
            <token id="13" string="Buckeys" />
          </tokens>
        </entity>
        <entity id="3" string="Alan Lagunoff" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Alan" />
            <token id="2" string="Lagunoff" />
          </tokens>
        </entity>
        <entity id="4" string="10" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="10" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>``The defense did everything to prolong the case and the prosecution did not do enough research to prosecute the case properly,&amp;apost;&amp;apost; he said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="defense" lemma="defense" stem="defens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="everything" lemma="everything" stem="everyth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="prolong" lemma="prolong" stem="prolong" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="prosecution" lemma="prosecution" stem="prosecut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="enough" lemma="enough" stem="enough" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="research" lemma="research" stem="research" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="prosecute" lemma="prosecute" stem="prosecut" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="properly" lemma="properly" stem="properli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (NP (DT The) (NN defense)) (VP (VBD did) (NP (NN everything)) (S (VP (TO to) (VP (VB prolong) (NP (DT the) (NN case))))))) (CC and) (S (NP (DT the) (NN prosecution)) (VP (VBD did) (RB not) (VP (VB do) (NP (JJ enough) (NN research)) (S (VP (TO to) (VP (VB prosecute) (NP (DT the) (NN case)) (ADVP (RB properly))))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="do enough research to prosecute the case properly" type="VP">
          <tokens>
            <token id="15" string="do" />
            <token id="16" string="enough" />
            <token id="17" string="research" />
            <token id="18" string="to" />
            <token id="19" string="prosecute" />
            <token id="20" string="the" />
            <token id="21" string="case" />
            <token id="22" string="properly" />
          </tokens>
        </chunking>
        <chunking id="2" string="the case" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="case" />
          </tokens>
        </chunking>
        <chunking id="3" string="to prosecute the case properly" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="prosecute" />
            <token id="20" string="the" />
            <token id="21" string="case" />
            <token id="22" string="properly" />
          </tokens>
        </chunking>
        <chunking id="4" string="The defense" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="defense" />
          </tokens>
        </chunking>
        <chunking id="5" string="prolong the case" type="VP">
          <tokens>
            <token id="7" string="prolong" />
            <token id="8" string="the" />
            <token id="9" string="case" />
          </tokens>
        </chunking>
        <chunking id="6" string="prosecute the case properly" type="VP">
          <tokens>
            <token id="19" string="prosecute" />
            <token id="20" string="the" />
            <token id="21" string="case" />
            <token id="22" string="properly" />
          </tokens>
        </chunking>
        <chunking id="7" string="enough research" type="NP">
          <tokens>
            <token id="16" string="enough" />
            <token id="17" string="research" />
          </tokens>
        </chunking>
        <chunking id="8" string="to prolong the case" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="prolong" />
            <token id="8" string="the" />
            <token id="9" string="case" />
          </tokens>
        </chunking>
        <chunking id="9" string="did not do enough research to prosecute the case properly" type="VP">
          <tokens>
            <token id="13" string="did" />
            <token id="14" string="not" />
            <token id="15" string="do" />
            <token id="16" string="enough" />
            <token id="17" string="research" />
            <token id="18" string="to" />
            <token id="19" string="prosecute" />
            <token id="20" string="the" />
            <token id="21" string="case" />
            <token id="22" string="properly" />
          </tokens>
        </chunking>
        <chunking id="10" string="did everything to prolong the case" type="VP">
          <tokens>
            <token id="4" string="did" />
            <token id="5" string="everything" />
            <token id="6" string="to" />
            <token id="7" string="prolong" />
            <token id="8" string="the" />
            <token id="9" string="case" />
          </tokens>
        </chunking>
        <chunking id="11" string="the prosecution" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="prosecution" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="25" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="everything" type="NP">
          <tokens>
            <token id="5" string="everything" />
          </tokens>
        </chunking>
        <chunking id="14" string="said" type="VP">
          <tokens>
            <token id="26" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">defense</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">did</governor>
          <dependent id="3">defense</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="26">said</governor>
          <dependent id="4">did</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">did</governor>
          <dependent id="5">everything</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">prolong</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">did</governor>
          <dependent id="7">prolong</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">case</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">prolong</governor>
          <dependent id="9">case</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">did</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">prosecution</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">do</governor>
          <dependent id="12">prosecution</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">do</governor>
          <dependent id="13">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="15">do</governor>
          <dependent id="14">not</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">did</governor>
          <dependent id="15">do</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">research</governor>
          <dependent id="16">enough</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">do</governor>
          <dependent id="17">research</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">prosecute</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">do</governor>
          <dependent id="19">prosecute</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">case</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">prosecute</governor>
          <dependent id="21">case</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">prosecute</governor>
          <dependent id="22">properly</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">said</governor>
          <dependent id="25">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="26">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="10" has_coreference="false">
      <content>A cold wind blasted leaves across the schoolyard as Lagunoff leaned on the rusted chain-link fence surrounding the dilapidated L-shaped building.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="cold" lemma="cold" stem="cold" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="wind" lemma="wind" stem="wind" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="blasted" lemma="blast" stem="blast" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="leaves" lemma="leave" stem="leav" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="across" lemma="across" stem="across" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="schoolyard" lemma="schoolyard" stem="schoolyard" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Lagunoff" lemma="lagunoff" stem="lagunoff" pos="NN" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="leaned" lemma="lean" stem="lean" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="rusted" lemma="rust" stem="rust" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="chain-link" lemma="chain-link" stem="chain-link" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="fence" lemma="fence" stem="fenc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="surrounding" lemma="surround" stem="surround" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="dilapidated" lemma="dilapidated" stem="dilapid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="L-shaped" lemma="l-shaped" stem="l-shape" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="21" string="building" lemma="building" stem="build" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT A) (JJ cold) (NN wind)) (VP (VBD blasted) (SBAR (S (VP (VBZ leaves) (PP (IN across) (NP (DT the) (NN schoolyard))) (SBAR (IN as) (S (NP (NN Lagunoff)) (VP (VBD leaned) (PP (IN on) (NP (NP (DT the)) (VP (VBN rusted) (NP (JJ chain-link) (NN fence)) (S (VP (VBG surrounding) (NP (DT the) (JJ dilapidated) (JJ L-shaped) (NN building)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the schoolyard" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="schoolyard" />
          </tokens>
        </chunking>
        <chunking id="2" string="leaned on the rusted chain-link fence surrounding the dilapidated L-shaped building" type="VP">
          <tokens>
            <token id="11" string="leaned" />
            <token id="12" string="on" />
            <token id="13" string="the" />
            <token id="14" string="rusted" />
            <token id="15" string="chain-link" />
            <token id="16" string="fence" />
            <token id="17" string="surrounding" />
            <token id="18" string="the" />
            <token id="19" string="dilapidated" />
            <token id="20" string="L-shaped" />
            <token id="21" string="building" />
          </tokens>
        </chunking>
        <chunking id="3" string="as Lagunoff leaned on the rusted chain-link fence surrounding the dilapidated L-shaped building" type="SBAR">
          <tokens>
            <token id="9" string="as" />
            <token id="10" string="Lagunoff" />
            <token id="11" string="leaned" />
            <token id="12" string="on" />
            <token id="13" string="the" />
            <token id="14" string="rusted" />
            <token id="15" string="chain-link" />
            <token id="16" string="fence" />
            <token id="17" string="surrounding" />
            <token id="18" string="the" />
            <token id="19" string="dilapidated" />
            <token id="20" string="L-shaped" />
            <token id="21" string="building" />
          </tokens>
        </chunking>
        <chunking id="4" string="blasted leaves across the schoolyard as Lagunoff leaned on the rusted chain-link fence surrounding the dilapidated L-shaped building" type="VP">
          <tokens>
            <token id="4" string="blasted" />
            <token id="5" string="leaves" />
            <token id="6" string="across" />
            <token id="7" string="the" />
            <token id="8" string="schoolyard" />
            <token id="9" string="as" />
            <token id="10" string="Lagunoff" />
            <token id="11" string="leaned" />
            <token id="12" string="on" />
            <token id="13" string="the" />
            <token id="14" string="rusted" />
            <token id="15" string="chain-link" />
            <token id="16" string="fence" />
            <token id="17" string="surrounding" />
            <token id="18" string="the" />
            <token id="19" string="dilapidated" />
            <token id="20" string="L-shaped" />
            <token id="21" string="building" />
          </tokens>
        </chunking>
        <chunking id="5" string="surrounding the dilapidated L-shaped building" type="VP">
          <tokens>
            <token id="17" string="surrounding" />
            <token id="18" string="the" />
            <token id="19" string="dilapidated" />
            <token id="20" string="L-shaped" />
            <token id="21" string="building" />
          </tokens>
        </chunking>
        <chunking id="6" string="rusted chain-link fence surrounding the dilapidated L-shaped building" type="VP">
          <tokens>
            <token id="14" string="rusted" />
            <token id="15" string="chain-link" />
            <token id="16" string="fence" />
            <token id="17" string="surrounding" />
            <token id="18" string="the" />
            <token id="19" string="dilapidated" />
            <token id="20" string="L-shaped" />
            <token id="21" string="building" />
          </tokens>
        </chunking>
        <chunking id="7" string="the" type="NP">
          <tokens>
            <token id="13" string="the" />
          </tokens>
        </chunking>
        <chunking id="8" string="the rusted chain-link fence surrounding the dilapidated L-shaped building" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="rusted" />
            <token id="15" string="chain-link" />
            <token id="16" string="fence" />
            <token id="17" string="surrounding" />
            <token id="18" string="the" />
            <token id="19" string="dilapidated" />
            <token id="20" string="L-shaped" />
            <token id="21" string="building" />
          </tokens>
        </chunking>
        <chunking id="9" string="the dilapidated L-shaped building" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="dilapidated" />
            <token id="20" string="L-shaped" />
            <token id="21" string="building" />
          </tokens>
        </chunking>
        <chunking id="10" string="chain-link fence" type="NP">
          <tokens>
            <token id="15" string="chain-link" />
            <token id="16" string="fence" />
          </tokens>
        </chunking>
        <chunking id="11" string="A cold wind" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="cold" />
            <token id="3" string="wind" />
          </tokens>
        </chunking>
        <chunking id="12" string="leaves across the schoolyard as Lagunoff leaned on the rusted chain-link fence surrounding the dilapidated L-shaped building" type="SBAR">
          <tokens>
            <token id="5" string="leaves" />
            <token id="6" string="across" />
            <token id="7" string="the" />
            <token id="8" string="schoolyard" />
            <token id="9" string="as" />
            <token id="10" string="Lagunoff" />
            <token id="11" string="leaned" />
            <token id="12" string="on" />
            <token id="13" string="the" />
            <token id="14" string="rusted" />
            <token id="15" string="chain-link" />
            <token id="16" string="fence" />
            <token id="17" string="surrounding" />
            <token id="18" string="the" />
            <token id="19" string="dilapidated" />
            <token id="20" string="L-shaped" />
            <token id="21" string="building" />
          </tokens>
        </chunking>
        <chunking id="13" string="Lagunoff" type="NP">
          <tokens>
            <token id="10" string="Lagunoff" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">wind</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">wind</governor>
          <dependent id="2">cold</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">blasted</governor>
          <dependent id="3">wind</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">blasted</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">blasted</governor>
          <dependent id="5">leaves</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">schoolyard</governor>
          <dependent id="6">across</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">schoolyard</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">leaves</governor>
          <dependent id="8">schoolyard</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">leaned</governor>
          <dependent id="9">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">leaned</governor>
          <dependent id="10">Lagunoff</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">leaves</governor>
          <dependent id="11">leaned</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">the</governor>
          <dependent id="12">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">leaned</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="13">the</governor>
          <dependent id="14">rusted</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">fence</governor>
          <dependent id="15">chain-link</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">rusted</governor>
          <dependent id="16">fence</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">rusted</governor>
          <dependent id="17">surrounding</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">building</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">building</governor>
          <dependent id="19">dilapidated</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">building</governor>
          <dependent id="20">L-shaped</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">surrounding</governor>
          <dependent id="21">building</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="L-shaped" type="MISC" score="0.0">
          <tokens>
            <token id="20" string="L-shaped" />
          </tokens>
        </entity>
        <entity id="2" string="Lagunoff" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Lagunoff" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="false">
      <content>``I&amp;apost;d like to see the school become a center for abused children,&amp;apost;&amp;apost; he said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="'d" lemma="would" stem="'d" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="like" lemma="like" stem="like" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="see" lemma="see" stem="see" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="become" lemma="become" stem="becom" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="center" lemma="center" stem="center" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="abused" lemma="abused" stem="abus" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (MD 'd) (VP (VB like) (S (VP (TO to) (VP (VB see) (S (NP (DT the) (NN school)) (VP (VB become) (NP (NP (DT a) (NN center)) (PP (IN for) (NP (JJ abused) (NNS children)))))))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the school" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="school" />
          </tokens>
        </chunking>
        <chunking id="2" string="become a center for abused children" type="VP">
          <tokens>
            <token id="9" string="become" />
            <token id="10" string="a" />
            <token id="11" string="center" />
            <token id="12" string="for" />
            <token id="13" string="abused" />
            <token id="14" string="children" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="like to see the school become a center for abused children" type="VP">
          <tokens>
            <token id="4" string="like" />
            <token id="5" string="to" />
            <token id="6" string="see" />
            <token id="7" string="the" />
            <token id="8" string="school" />
            <token id="9" string="become" />
            <token id="10" string="a" />
            <token id="11" string="center" />
            <token id="12" string="for" />
            <token id="13" string="abused" />
            <token id="14" string="children" />
          </tokens>
        </chunking>
        <chunking id="5" string="to see the school become a center for abused children" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="see" />
            <token id="7" string="the" />
            <token id="8" string="school" />
            <token id="9" string="become" />
            <token id="10" string="a" />
            <token id="11" string="center" />
            <token id="12" string="for" />
            <token id="13" string="abused" />
            <token id="14" string="children" />
          </tokens>
        </chunking>
        <chunking id="6" string="see the school become a center for abused children" type="VP">
          <tokens>
            <token id="6" string="see" />
            <token id="7" string="the" />
            <token id="8" string="school" />
            <token id="9" string="become" />
            <token id="10" string="a" />
            <token id="11" string="center" />
            <token id="12" string="for" />
            <token id="13" string="abused" />
            <token id="14" string="children" />
          </tokens>
        </chunking>
        <chunking id="7" string="abused children" type="NP">
          <tokens>
            <token id="13" string="abused" />
            <token id="14" string="children" />
          </tokens>
        </chunking>
        <chunking id="8" string="he" type="NP">
          <tokens>
            <token id="17" string="he" />
          </tokens>
        </chunking>
        <chunking id="9" string="a center for abused children" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="center" />
            <token id="12" string="for" />
            <token id="13" string="abused" />
            <token id="14" string="children" />
          </tokens>
        </chunking>
        <chunking id="10" string="said" type="VP">
          <tokens>
            <token id="18" string="said" />
          </tokens>
        </chunking>
        <chunking id="11" string="'d like to see the school become a center for abused children" type="VP">
          <tokens>
            <token id="3" string="'d" />
            <token id="4" string="like" />
            <token id="5" string="to" />
            <token id="6" string="see" />
            <token id="7" string="the" />
            <token id="8" string="school" />
            <token id="9" string="become" />
            <token id="10" string="a" />
            <token id="11" string="center" />
            <token id="12" string="for" />
            <token id="13" string="abused" />
            <token id="14" string="children" />
          </tokens>
        </chunking>
        <chunking id="12" string="a center" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="center" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">like</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">like</governor>
          <dependent id="3">'d</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">said</governor>
          <dependent id="4">like</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">see</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">like</governor>
          <dependent id="6">see</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">school</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">become</governor>
          <dependent id="8">school</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">see</governor>
          <dependent id="9">become</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">center</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">become</governor>
          <dependent id="11">center</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">children</governor>
          <dependent id="12">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">children</governor>
          <dependent id="13">abused</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">center</governor>
          <dependent id="14">children</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">said</governor>
          <dependent id="17">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>``It should be put to some good use rather than tear it down.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="put" lemma="put" stem="put" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="use" lemma="use" stem="us" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="rather" lemma="rather" stem="rather" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="tear" lemma="tear" stem="tear" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="down" lemma="down" stem="down" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP It)) (VP (MD should) (VP (VP (VB be) (VP (VBN put) (PP (TO to) (NP (DT some) (JJ good) (NN use))))) (CONJP (RB rather) (IN than)) (VP (VB tear) (NP (PRP it)) (PRT (RP down))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="should be put to some good use rather than tear it down" type="VP">
          <tokens>
            <token id="3" string="should" />
            <token id="4" string="be" />
            <token id="5" string="put" />
            <token id="6" string="to" />
            <token id="7" string="some" />
            <token id="8" string="good" />
            <token id="9" string="use" />
            <token id="10" string="rather" />
            <token id="11" string="than" />
            <token id="12" string="tear" />
            <token id="13" string="it" />
            <token id="14" string="down" />
          </tokens>
        </chunking>
        <chunking id="2" string="put to some good use" type="VP">
          <tokens>
            <token id="5" string="put" />
            <token id="6" string="to" />
            <token id="7" string="some" />
            <token id="8" string="good" />
            <token id="9" string="use" />
          </tokens>
        </chunking>
        <chunking id="3" string="tear it down" type="VP">
          <tokens>
            <token id="12" string="tear" />
            <token id="13" string="it" />
            <token id="14" string="down" />
          </tokens>
        </chunking>
        <chunking id="4" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="13" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="be put to some good use rather than tear it down" type="VP">
          <tokens>
            <token id="4" string="be" />
            <token id="5" string="put" />
            <token id="6" string="to" />
            <token id="7" string="some" />
            <token id="8" string="good" />
            <token id="9" string="use" />
            <token id="10" string="rather" />
            <token id="11" string="than" />
            <token id="12" string="tear" />
            <token id="13" string="it" />
            <token id="14" string="down" />
          </tokens>
        </chunking>
        <chunking id="7" string="some good use" type="NP">
          <tokens>
            <token id="7" string="some" />
            <token id="8" string="good" />
            <token id="9" string="use" />
          </tokens>
        </chunking>
        <chunking id="8" string="be put to some good use" type="VP">
          <tokens>
            <token id="4" string="be" />
            <token id="5" string="put" />
            <token id="6" string="to" />
            <token id="7" string="some" />
            <token id="8" string="good" />
            <token id="9" string="use" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="5">put</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">put</governor>
          <dependent id="3">should</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">put</governor>
          <dependent id="4">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">put</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">use</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">use</governor>
          <dependent id="7">some</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">use</governor>
          <dependent id="8">good</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">put</governor>
          <dependent id="9">use</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">put</governor>
          <dependent id="10">rather</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="10">rather</governor>
          <dependent id="11">than</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">put</governor>
          <dependent id="12">tear</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">tear</governor>
          <dependent id="13">it</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="12">tear</governor>
          <dependent id="14">down</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>But another longtime Manhattan Beach resident disagreed.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="longtime" lemma="longtime" stem="longtim" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="Manhattan" lemma="Manhattan" stem="manhattan" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="5" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="6" string="resident" lemma="resident" stem="resid" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="disagreed" lemma="disagree" stem="disagre" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NP (DT another) (JJ longtime) (NNP Manhattan) (NNP Beach)) (JJ resident)) (VP (VBD disagreed)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="another longtime Manhattan Beach resident" type="NP">
          <tokens>
            <token id="2" string="another" />
            <token id="3" string="longtime" />
            <token id="4" string="Manhattan" />
            <token id="5" string="Beach" />
            <token id="6" string="resident" />
          </tokens>
        </chunking>
        <chunking id="2" string="another longtime Manhattan Beach" type="NP">
          <tokens>
            <token id="2" string="another" />
            <token id="3" string="longtime" />
            <token id="4" string="Manhattan" />
            <token id="5" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="3" string="disagreed" type="VP">
          <tokens>
            <token id="7" string="disagreed" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="7">disagreed</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">Beach</governor>
          <dependent id="2">another</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">Beach</governor>
          <dependent id="3">longtime</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Beach</governor>
          <dependent id="4">Manhattan</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">disagreed</governor>
          <dependent id="5">Beach</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">Beach</governor>
          <dependent id="6">resident</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">disagreed</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Manhattan Beach" type="LOCATION" score="0.0">
          <tokens>
            <token id="4" string="Manhattan" />
            <token id="5" string="Beach" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>``I&amp;apost;d like to see it torn down,&amp;apost;&amp;apost; said Brenda Platt.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'d" lemma="would" stem="'d" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="like" lemma="like" stem="like" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="see" lemma="see" stem="see" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="torn" lemma="tear" stem="torn" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="down" lemma="down" stem="down" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="Brenda" lemma="Brenda" stem="brenda" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="Platt" lemma="Platt" stem="platt" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP I)) (VP (MD 'd) (VP (VB like) (S (VP (TO to) (VP (VB see) (S (NP (PRP it)) (VP (VBN torn) (ADVP (RB down)))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NNP Brenda) (NNP Platt)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="see it torn down" type="VP">
          <tokens>
            <token id="6" string="see" />
            <token id="7" string="it" />
            <token id="8" string="torn" />
            <token id="9" string="down" />
          </tokens>
        </chunking>
        <chunking id="2" string="Brenda Platt" type="NP">
          <tokens>
            <token id="13" string="Brenda" />
            <token id="14" string="Platt" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="torn down" type="VP">
          <tokens>
            <token id="8" string="torn" />
            <token id="9" string="down" />
          </tokens>
        </chunking>
        <chunking id="5" string="'d like to see it torn down" type="VP">
          <tokens>
            <token id="3" string="'d" />
            <token id="4" string="like" />
            <token id="5" string="to" />
            <token id="6" string="see" />
            <token id="7" string="it" />
            <token id="8" string="torn" />
            <token id="9" string="down" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="said" type="VP">
          <tokens>
            <token id="12" string="said" />
          </tokens>
        </chunking>
        <chunking id="8" string="like to see it torn down" type="VP">
          <tokens>
            <token id="4" string="like" />
            <token id="5" string="to" />
            <token id="6" string="see" />
            <token id="7" string="it" />
            <token id="8" string="torn" />
            <token id="9" string="down" />
          </tokens>
        </chunking>
        <chunking id="9" string="to see it torn down" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="see" />
            <token id="7" string="it" />
            <token id="8" string="torn" />
            <token id="9" string="down" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">like</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">like</governor>
          <dependent id="3">'d</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">said</governor>
          <dependent id="4">like</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">see</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">like</governor>
          <dependent id="6">see</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">torn</governor>
          <dependent id="7">it</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">see</governor>
          <dependent id="8">torn</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">torn</governor>
          <dependent id="9">down</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Platt</governor>
          <dependent id="13">Brenda</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">said</governor>
          <dependent id="14">Platt</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Brenda Platt" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Brenda" />
            <token id="14" string="Platt" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>``I&amp;apost;d like to have no memories of this.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'d" lemma="would" stem="'d" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="like" lemma="like" stem="like" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="memories" lemma="memory" stem="memori" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (MD 'd) (VP (VB like) (S (VP (TO to) (VP (VB have) (NP (NP (DT no) (NNS memories)) (PP (IN of) (NP (DT this))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="like to have no memories of this" type="VP">
          <tokens>
            <token id="4" string="like" />
            <token id="5" string="to" />
            <token id="6" string="have" />
            <token id="7" string="no" />
            <token id="8" string="memories" />
            <token id="9" string="of" />
            <token id="10" string="this" />
          </tokens>
        </chunking>
        <chunking id="2" string="to have no memories of this" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="have" />
            <token id="7" string="no" />
            <token id="8" string="memories" />
            <token id="9" string="of" />
            <token id="10" string="this" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="'d like to have no memories of this" type="VP">
          <tokens>
            <token id="3" string="'d" />
            <token id="4" string="like" />
            <token id="5" string="to" />
            <token id="6" string="have" />
            <token id="7" string="no" />
            <token id="8" string="memories" />
            <token id="9" string="of" />
            <token id="10" string="this" />
          </tokens>
        </chunking>
        <chunking id="5" string="no memories of this" type="NP">
          <tokens>
            <token id="7" string="no" />
            <token id="8" string="memories" />
            <token id="9" string="of" />
            <token id="10" string="this" />
          </tokens>
        </chunking>
        <chunking id="6" string="this" type="NP">
          <tokens>
            <token id="10" string="this" />
          </tokens>
        </chunking>
        <chunking id="7" string="have no memories of this" type="VP">
          <tokens>
            <token id="6" string="have" />
            <token id="7" string="no" />
            <token id="8" string="memories" />
            <token id="9" string="of" />
            <token id="10" string="this" />
          </tokens>
        </chunking>
        <chunking id="8" string="no memories" type="NP">
          <tokens>
            <token id="7" string="no" />
            <token id="8" string="memories" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">like</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">like</governor>
          <dependent id="3">'d</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">like</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">have</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">like</governor>
          <dependent id="6">have</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="8">memories</governor>
          <dependent id="7">no</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">have</governor>
          <dependent id="8">memories</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">this</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">memories</governor>
          <dependent id="10">this</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>Platt, who has two children aged 1 and 3, said she has serious doubts about placing them in a day-care center because of the McMartin trial.</content>
      <tokens>
        <token id="1" string="Platt" lemma="Platt" stem="platt" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="6" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="aged" lemma="aged" stem="ag" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="1" lemma="1" stem="1" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="3" lemma="3" stem="3" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="serious" lemma="serious" stem="seriou" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="doubts" lemma="doubt" stem="doubt" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="placing" lemma="place" stem="place" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="day-care" lemma="day-care" stem="day-car" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="center" lemma="center" stem="center" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Platt)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBZ has) (NP (NP (CD two) (NNS children)) (ADJP (JJ aged) (NP-TMP (CD 1) (CC and) (CD 3))))))) (, ,)) (VP (VBD said) (SBAR (S (NP (PRP she)) (VP (VBZ has) (NP (NP (JJ serious) (NNS doubts)) (PP (IN about) (S (VP (VBG placing) (NP (PRP them)) (PP (IN in) (NP (DT a) (JJ day-care) (NN center))) (PP (IN because) (PP (IN of) (NP (DT the) (NNP McMartin) (NN trial)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="she has serious doubts about placing them in a day-care center because of the McMartin trial" type="SBAR">
          <tokens>
            <token id="13" string="she" />
            <token id="14" string="has" />
            <token id="15" string="serious" />
            <token id="16" string="doubts" />
            <token id="17" string="about" />
            <token id="18" string="placing" />
            <token id="19" string="them" />
            <token id="20" string="in" />
            <token id="21" string="a" />
            <token id="22" string="day-care" />
            <token id="23" string="center" />
            <token id="24" string="because" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="McMartin" />
            <token id="28" string="trial" />
          </tokens>
        </chunking>
        <chunking id="2" string="two children" type="NP">
          <tokens>
            <token id="5" string="two" />
            <token id="6" string="children" />
          </tokens>
        </chunking>
        <chunking id="3" string="them" type="NP">
          <tokens>
            <token id="19" string="them" />
          </tokens>
        </chunking>
        <chunking id="4" string="she" type="NP">
          <tokens>
            <token id="13" string="she" />
          </tokens>
        </chunking>
        <chunking id="5" string="has serious doubts about placing them in a day-care center because of the McMartin trial" type="VP">
          <tokens>
            <token id="14" string="has" />
            <token id="15" string="serious" />
            <token id="16" string="doubts" />
            <token id="17" string="about" />
            <token id="18" string="placing" />
            <token id="19" string="them" />
            <token id="20" string="in" />
            <token id="21" string="a" />
            <token id="22" string="day-care" />
            <token id="23" string="center" />
            <token id="24" string="because" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="McMartin" />
            <token id="28" string="trial" />
          </tokens>
        </chunking>
        <chunking id="6" string="Platt , who has two children aged 1 and 3 ," type="NP">
          <tokens>
            <token id="1" string="Platt" />
            <token id="2" string="," />
            <token id="3" string="who" />
            <token id="4" string="has" />
            <token id="5" string="two" />
            <token id="6" string="children" />
            <token id="7" string="aged" />
            <token id="8" string="1" />
            <token id="9" string="and" />
            <token id="10" string="3" />
            <token id="11" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="serious doubts about placing them in a day-care center because of the McMartin trial" type="NP">
          <tokens>
            <token id="15" string="serious" />
            <token id="16" string="doubts" />
            <token id="17" string="about" />
            <token id="18" string="placing" />
            <token id="19" string="them" />
            <token id="20" string="in" />
            <token id="21" string="a" />
            <token id="22" string="day-care" />
            <token id="23" string="center" />
            <token id="24" string="because" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="McMartin" />
            <token id="28" string="trial" />
          </tokens>
        </chunking>
        <chunking id="8" string="serious doubts" type="NP">
          <tokens>
            <token id="15" string="serious" />
            <token id="16" string="doubts" />
          </tokens>
        </chunking>
        <chunking id="9" string="said she has serious doubts about placing them in a day-care center because of the McMartin trial" type="VP">
          <tokens>
            <token id="12" string="said" />
            <token id="13" string="she" />
            <token id="14" string="has" />
            <token id="15" string="serious" />
            <token id="16" string="doubts" />
            <token id="17" string="about" />
            <token id="18" string="placing" />
            <token id="19" string="them" />
            <token id="20" string="in" />
            <token id="21" string="a" />
            <token id="22" string="day-care" />
            <token id="23" string="center" />
            <token id="24" string="because" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="McMartin" />
            <token id="28" string="trial" />
          </tokens>
        </chunking>
        <chunking id="10" string="placing them in a day-care center because of the McMartin trial" type="VP">
          <tokens>
            <token id="18" string="placing" />
            <token id="19" string="them" />
            <token id="20" string="in" />
            <token id="21" string="a" />
            <token id="22" string="day-care" />
            <token id="23" string="center" />
            <token id="24" string="because" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="McMartin" />
            <token id="28" string="trial" />
          </tokens>
        </chunking>
        <chunking id="11" string="the McMartin trial" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="McMartin" />
            <token id="28" string="trial" />
          </tokens>
        </chunking>
        <chunking id="12" string="two children aged 1 and 3" type="NP">
          <tokens>
            <token id="5" string="two" />
            <token id="6" string="children" />
            <token id="7" string="aged" />
            <token id="8" string="1" />
            <token id="9" string="and" />
            <token id="10" string="3" />
          </tokens>
        </chunking>
        <chunking id="13" string="who has two children aged 1 and 3" type="SBAR">
          <tokens>
            <token id="3" string="who" />
            <token id="4" string="has" />
            <token id="5" string="two" />
            <token id="6" string="children" />
            <token id="7" string="aged" />
            <token id="8" string="1" />
            <token id="9" string="and" />
            <token id="10" string="3" />
          </tokens>
        </chunking>
        <chunking id="14" string="aged 1 and 3" type="ADJP">
          <tokens>
            <token id="7" string="aged" />
            <token id="8" string="1" />
            <token id="9" string="and" />
            <token id="10" string="3" />
          </tokens>
        </chunking>
        <chunking id="15" string="a day-care center" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="day-care" />
            <token id="23" string="center" />
          </tokens>
        </chunking>
        <chunking id="16" string="Platt" type="NP">
          <tokens>
            <token id="1" string="Platt" />
          </tokens>
        </chunking>
        <chunking id="17" string="has two children aged 1 and 3" type="VP">
          <tokens>
            <token id="4" string="has" />
            <token id="5" string="two" />
            <token id="6" string="children" />
            <token id="7" string="aged" />
            <token id="8" string="1" />
            <token id="9" string="and" />
            <token id="10" string="3" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="12">said</governor>
          <dependent id="1">Platt</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">has</governor>
          <dependent id="3">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="1">Platt</governor>
          <dependent id="4">has</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">children</governor>
          <dependent id="5">two</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">has</governor>
          <dependent id="6">children</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">children</governor>
          <dependent id="7">aged</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="7">aged</governor>
          <dependent id="8">1</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">1</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">1</governor>
          <dependent id="10">3</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">has</governor>
          <dependent id="13">she</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">said</governor>
          <dependent id="14">has</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">doubts</governor>
          <dependent id="15">serious</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">has</governor>
          <dependent id="16">doubts</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">placing</governor>
          <dependent id="17">about</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="16">doubts</governor>
          <dependent id="18">placing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">placing</governor>
          <dependent id="19">them</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">center</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">center</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">center</governor>
          <dependent id="22">day-care</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">placing</governor>
          <dependent id="23">center</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">trial</governor>
          <dependent id="24">because</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">trial</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">trial</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">trial</governor>
          <dependent id="27">McMartin</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">placing</governor>
          <dependent id="28">trial</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="1" />
          </tokens>
        </entity>
        <entity id="2" string="3" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="3" />
          </tokens>
        </entity>
        <entity id="3" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="two" />
          </tokens>
        </entity>
        <entity id="4" string="Platt" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Platt" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>``I think (the McMartin case) is a disgrace to Manhattan Beach and society.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="disgrace" lemma="disgrace" stem="disgrac" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="Manhattan" lemma="Manhattan" stem="manhattan" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="14" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="16" string="society" lemma="society" stem="societi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBP think) (SBAR (S (-LRB- -LRB-) (NP (DT the) (NNP McMartin) (NN case)) (-RRB- -RRB-) (VP (VBZ is) (NP (NP (DT a) (NN disgrace)) (PP (TO to) (NP (NP (NNP Manhattan) (NNP Beach)) (CC and) (NP (NN society))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is a disgrace to Manhattan Beach and society" type="VP">
          <tokens>
            <token id="9" string="is" />
            <token id="10" string="a" />
            <token id="11" string="disgrace" />
            <token id="12" string="to" />
            <token id="13" string="Manhattan" />
            <token id="14" string="Beach" />
            <token id="15" string="and" />
            <token id="16" string="society" />
          </tokens>
        </chunking>
        <chunking id="2" string="Manhattan Beach and society" type="NP">
          <tokens>
            <token id="13" string="Manhattan" />
            <token id="14" string="Beach" />
            <token id="15" string="and" />
            <token id="16" string="society" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="think -LRB- the McMartin case -RRB- is a disgrace to Manhattan Beach and society" type="VP">
          <tokens>
            <token id="3" string="think" />
            <token id="4" string="(" />
            <token id="5" string="the" />
            <token id="6" string="McMartin" />
            <token id="7" string="case" />
            <token id="8" string=")" />
            <token id="9" string="is" />
            <token id="10" string="a" />
            <token id="11" string="disgrace" />
            <token id="12" string="to" />
            <token id="13" string="Manhattan" />
            <token id="14" string="Beach" />
            <token id="15" string="and" />
            <token id="16" string="society" />
          </tokens>
        </chunking>
        <chunking id="5" string="-LRB- the McMartin case -RRB- is a disgrace to Manhattan Beach and society" type="SBAR">
          <tokens>
            <token id="4" string="(" />
            <token id="5" string="the" />
            <token id="6" string="McMartin" />
            <token id="7" string="case" />
            <token id="8" string=")" />
            <token id="9" string="is" />
            <token id="10" string="a" />
            <token id="11" string="disgrace" />
            <token id="12" string="to" />
            <token id="13" string="Manhattan" />
            <token id="14" string="Beach" />
            <token id="15" string="and" />
            <token id="16" string="society" />
          </tokens>
        </chunking>
        <chunking id="6" string="the McMartin case" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="McMartin" />
            <token id="7" string="case" />
          </tokens>
        </chunking>
        <chunking id="7" string="a disgrace" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="disgrace" />
          </tokens>
        </chunking>
        <chunking id="8" string="society" type="NP">
          <tokens>
            <token id="16" string="society" />
          </tokens>
        </chunking>
        <chunking id="9" string="a disgrace to Manhattan Beach and society" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="disgrace" />
            <token id="12" string="to" />
            <token id="13" string="Manhattan" />
            <token id="14" string="Beach" />
            <token id="15" string="and" />
            <token id="16" string="society" />
          </tokens>
        </chunking>
        <chunking id="10" string="Manhattan Beach" type="NP">
          <tokens>
            <token id="13" string="Manhattan" />
            <token id="14" string="Beach" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">think</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">think</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">case</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">case</governor>
          <dependent id="6">McMartin</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">disgrace</governor>
          <dependent id="7">case</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">disgrace</governor>
          <dependent id="9">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">disgrace</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">think</governor>
          <dependent id="11">disgrace</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Beach</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Beach</governor>
          <dependent id="13">Manhattan</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">disgrace</governor>
          <dependent id="14">Beach</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">Beach</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">Beach</governor>
          <dependent id="16">society</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Manhattan Beach" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Manhattan" />
            <token id="14" string="Beach" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>It&amp;apost;s totally upsetting,&amp;apost;&amp;apost; Platt said.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="totally" lemma="totally" stem="total" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="upsetting" lemma="upset" stem="upset" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Platt" lemma="Platt" stem="platt" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP It)) (VP (VBZ 's) (ADVP (RB totally)) (VP (VBG upsetting)))) (, ,) ('' '') (NP (NNP Platt)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="'s totally upsetting" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="totally" />
            <token id="4" string="upsetting" />
          </tokens>
        </chunking>
        <chunking id="2" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="3" string="upsetting" type="VP">
          <tokens>
            <token id="4" string="upsetting" />
          </tokens>
        </chunking>
        <chunking id="4" string="Platt" type="NP">
          <tokens>
            <token id="7" string="Platt" />
          </tokens>
        </chunking>
        <chunking id="5" string="said" type="VP">
          <tokens>
            <token id="8" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">upsetting</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">upsetting</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">upsetting</governor>
          <dependent id="3">totally</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">said</governor>
          <dependent id="4">upsetting</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">said</governor>
          <dependent id="7">Platt</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Platt" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Platt" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>Linda Geisert, another resident of the beach city, was also upset.</content>
      <tokens>
        <token id="1" string="Linda" lemma="Linda" stem="linda" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Geisert" lemma="Geisert" stem="geisert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="resident" lemma="resident" stem="resid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="beach" lemma="beach" stem="beach" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="upset" lemma="upset" stem="upset" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Linda) (NNP Geisert)) (, ,) (NP (NP (DT another) (NN resident)) (PP (IN of) (NP (DT the) (NN beach) (NN city)))) (, ,)) (VP (VBD was) (ADVP (RB also)) (ADJP (VBN upset))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Linda Geisert" type="NP">
          <tokens>
            <token id="1" string="Linda" />
            <token id="2" string="Geisert" />
          </tokens>
        </chunking>
        <chunking id="2" string="another resident" type="NP">
          <tokens>
            <token id="4" string="another" />
            <token id="5" string="resident" />
          </tokens>
        </chunking>
        <chunking id="3" string="upset" type="ADJP">
          <tokens>
            <token id="13" string="upset" />
          </tokens>
        </chunking>
        <chunking id="4" string="Linda Geisert , another resident of the beach city ," type="NP">
          <tokens>
            <token id="1" string="Linda" />
            <token id="2" string="Geisert" />
            <token id="3" string="," />
            <token id="4" string="another" />
            <token id="5" string="resident" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="beach" />
            <token id="9" string="city" />
            <token id="10" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="was also upset" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="also" />
            <token id="13" string="upset" />
          </tokens>
        </chunking>
        <chunking id="6" string="another resident of the beach city" type="NP">
          <tokens>
            <token id="4" string="another" />
            <token id="5" string="resident" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="beach" />
            <token id="9" string="city" />
          </tokens>
        </chunking>
        <chunking id="7" string="the beach city" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="beach" />
            <token id="9" string="city" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Geisert</governor>
          <dependent id="1">Linda</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">upset</governor>
          <dependent id="2">Geisert</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">resident</governor>
          <dependent id="4">another</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Geisert</governor>
          <dependent id="5">resident</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">city</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">city</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">city</governor>
          <dependent id="8">beach</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">resident</governor>
          <dependent id="9">city</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">upset</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">upset</governor>
          <dependent id="12">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">upset</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Linda Geisert" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Linda" />
            <token id="2" string="Geisert" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>``I&amp;apost;m greatly disappointed in the legal system and quite frankly in the jurors,&amp;apost;&amp;apost; Geisert said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="greatly" lemma="greatly" stem="greatli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="disappointed" lemma="disappoint" stem="disappoint" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="legal" lemma="legal" stem="legal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="system" lemma="system" stem="system" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="quite" lemma="quite" stem="quit" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="frankly" lemma="frankly" stem="frankli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="jurors" lemma="juror" stem="juror" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Geisert" lemma="Geisert" stem="geisert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBP 'm) (ADJP (ADJP (RB greatly) (VBN disappointed) (PP (IN in) (NP (DT the) (JJ legal) (NN system)))) (CC and) (ADJP (ADJP (RB quite) (RB frankly)) (PP (IN in) (NP (DT the) (NNS jurors))))))) (, ,) ('' '') (NP (NNP Geisert)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the legal system" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="legal" />
            <token id="9" string="system" />
          </tokens>
        </chunking>
        <chunking id="2" string="quite frankly in the jurors" type="ADJP">
          <tokens>
            <token id="11" string="quite" />
            <token id="12" string="frankly" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="jurors" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="greatly disappointed in the legal system" type="ADJP">
          <tokens>
            <token id="4" string="greatly" />
            <token id="5" string="disappointed" />
            <token id="6" string="in" />
            <token id="7" string="the" />
            <token id="8" string="legal" />
            <token id="9" string="system" />
          </tokens>
        </chunking>
        <chunking id="5" string="'m greatly disappointed in the legal system and quite frankly in the jurors" type="VP">
          <tokens>
            <token id="3" string="'m" />
            <token id="4" string="greatly" />
            <token id="5" string="disappointed" />
            <token id="6" string="in" />
            <token id="7" string="the" />
            <token id="8" string="legal" />
            <token id="9" string="system" />
            <token id="10" string="and" />
            <token id="11" string="quite" />
            <token id="12" string="frankly" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="jurors" />
          </tokens>
        </chunking>
        <chunking id="6" string="quite frankly" type="ADJP">
          <tokens>
            <token id="11" string="quite" />
            <token id="12" string="frankly" />
          </tokens>
        </chunking>
        <chunking id="7" string="greatly disappointed in the legal system and quite frankly in the jurors" type="ADJP">
          <tokens>
            <token id="4" string="greatly" />
            <token id="5" string="disappointed" />
            <token id="6" string="in" />
            <token id="7" string="the" />
            <token id="8" string="legal" />
            <token id="9" string="system" />
            <token id="10" string="and" />
            <token id="11" string="quite" />
            <token id="12" string="frankly" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="jurors" />
          </tokens>
        </chunking>
        <chunking id="8" string="the jurors" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="jurors" />
          </tokens>
        </chunking>
        <chunking id="9" string="said" type="VP">
          <tokens>
            <token id="19" string="said" />
          </tokens>
        </chunking>
        <chunking id="10" string="Geisert" type="NP">
          <tokens>
            <token id="18" string="Geisert" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="5">disappointed</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">disappointed</governor>
          <dependent id="3">'m</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">disappointed</governor>
          <dependent id="4">greatly</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">said</governor>
          <dependent id="5">disappointed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">system</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">system</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">system</governor>
          <dependent id="8">legal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">disappointed</governor>
          <dependent id="9">system</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">disappointed</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">frankly</governor>
          <dependent id="11">quite</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">disappointed</governor>
          <dependent id="12">frankly</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">jurors</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">jurors</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">frankly</governor>
          <dependent id="15">jurors</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">said</governor>
          <dependent id="18">Geisert</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Geisert" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Geisert" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>For all his disappointment, Lagunoff said he did not feel the prosecutors should retry the remaining 13 counts.</content>
      <tokens>
        <token id="1" string="For" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="all" lemma="all" stem="all" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="disappointment" lemma="disappointment" stem="disappoint" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Lagunoff" lemma="Lagunoff" stem="lagunoff" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="feel" lemma="feel" stem="feel" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="prosecutors" lemma="prosecutor" stem="prosecutor" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="retry" lemma="retry" stem="retri" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="remaining" lemma="remain" stem="remain" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="13" lemma="13" stem="13" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="19" string="counts" lemma="count" stem="count" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN For) (NP (PDT all) (PRP$ his) (NN disappointment))) (, ,) (NP (NNP Lagunoff)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBD did) (RB not) (VP (VB feel) (SBAR (S (NP (DT the) (NNS prosecutors)) (VP (MD should) (VP (VB retry) (S (NP (DT the) (VBG remaining) (CD 13) (NNS counts)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="did not feel the prosecutors should retry the remaining 13 counts" type="VP">
          <tokens>
            <token id="9" string="did" />
            <token id="10" string="not" />
            <token id="11" string="feel" />
            <token id="12" string="the" />
            <token id="13" string="prosecutors" />
            <token id="14" string="should" />
            <token id="15" string="retry" />
            <token id="16" string="the" />
            <token id="17" string="remaining" />
            <token id="18" string="13" />
            <token id="19" string="counts" />
          </tokens>
        </chunking>
        <chunking id="2" string="all his disappointment" type="NP">
          <tokens>
            <token id="2" string="all" />
            <token id="3" string="his" />
            <token id="4" string="disappointment" />
          </tokens>
        </chunking>
        <chunking id="3" string="the prosecutors" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="prosecutors" />
          </tokens>
        </chunking>
        <chunking id="4" string="feel the prosecutors should retry the remaining 13 counts" type="VP">
          <tokens>
            <token id="11" string="feel" />
            <token id="12" string="the" />
            <token id="13" string="prosecutors" />
            <token id="14" string="should" />
            <token id="15" string="retry" />
            <token id="16" string="the" />
            <token id="17" string="remaining" />
            <token id="18" string="13" />
            <token id="19" string="counts" />
          </tokens>
        </chunking>
        <chunking id="5" string="said he did not feel the prosecutors should retry the remaining 13 counts" type="VP">
          <tokens>
            <token id="7" string="said" />
            <token id="8" string="he" />
            <token id="9" string="did" />
            <token id="10" string="not" />
            <token id="11" string="feel" />
            <token id="12" string="the" />
            <token id="13" string="prosecutors" />
            <token id="14" string="should" />
            <token id="15" string="retry" />
            <token id="16" string="the" />
            <token id="17" string="remaining" />
            <token id="18" string="13" />
            <token id="19" string="counts" />
          </tokens>
        </chunking>
        <chunking id="6" string="he did not feel the prosecutors should retry the remaining 13 counts" type="SBAR">
          <tokens>
            <token id="8" string="he" />
            <token id="9" string="did" />
            <token id="10" string="not" />
            <token id="11" string="feel" />
            <token id="12" string="the" />
            <token id="13" string="prosecutors" />
            <token id="14" string="should" />
            <token id="15" string="retry" />
            <token id="16" string="the" />
            <token id="17" string="remaining" />
            <token id="18" string="13" />
            <token id="19" string="counts" />
          </tokens>
        </chunking>
        <chunking id="7" string="retry the remaining 13 counts" type="VP">
          <tokens>
            <token id="15" string="retry" />
            <token id="16" string="the" />
            <token id="17" string="remaining" />
            <token id="18" string="13" />
            <token id="19" string="counts" />
          </tokens>
        </chunking>
        <chunking id="8" string="he" type="NP">
          <tokens>
            <token id="8" string="he" />
          </tokens>
        </chunking>
        <chunking id="9" string="Lagunoff" type="NP">
          <tokens>
            <token id="6" string="Lagunoff" />
          </tokens>
        </chunking>
        <chunking id="10" string="the remaining 13 counts" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="remaining" />
            <token id="18" string="13" />
            <token id="19" string="counts" />
          </tokens>
        </chunking>
        <chunking id="11" string="the prosecutors should retry the remaining 13 counts" type="SBAR">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="prosecutors" />
            <token id="14" string="should" />
            <token id="15" string="retry" />
            <token id="16" string="the" />
            <token id="17" string="remaining" />
            <token id="18" string="13" />
            <token id="19" string="counts" />
          </tokens>
        </chunking>
        <chunking id="12" string="should retry the remaining 13 counts" type="VP">
          <tokens>
            <token id="14" string="should" />
            <token id="15" string="retry" />
            <token id="16" string="the" />
            <token id="17" string="remaining" />
            <token id="18" string="13" />
            <token id="19" string="counts" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">disappointment</governor>
          <dependent id="1">For</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="4">disappointment</governor>
          <dependent id="2">all</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">disappointment</governor>
          <dependent id="3">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">said</governor>
          <dependent id="4">disappointment</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">said</governor>
          <dependent id="6">Lagunoff</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">feel</governor>
          <dependent id="8">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">feel</governor>
          <dependent id="9">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">feel</governor>
          <dependent id="10">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">said</governor>
          <dependent id="11">feel</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">prosecutors</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">retry</governor>
          <dependent id="13">prosecutors</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">retry</governor>
          <dependent id="14">should</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">feel</governor>
          <dependent id="15">retry</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">counts</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">counts</governor>
          <dependent id="17">remaining</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">counts</governor>
          <dependent id="18">13</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">retry</governor>
          <dependent id="19">counts</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="13" type="NUMBER" score="0.0">
          <tokens>
            <token id="18" string="13" />
          </tokens>
        </entity>
        <entity id="2" string="Lagunoff" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Lagunoff" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>``It would be just more of the same circus,&amp;apost;&amp;apost; he said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="same" lemma="same" stem="same" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="circus" lemma="circus" stem="circu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP It)) (VP (MD would) (VP (VB be) (NP (NP (RB just) (JJR more)) (PP (IN of) (NP (DT the) (JJ same) (NN circus))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="be just more of the same circus" type="VP">
          <tokens>
            <token id="4" string="be" />
            <token id="5" string="just" />
            <token id="6" string="more" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="same" />
            <token id="10" string="circus" />
          </tokens>
        </chunking>
        <chunking id="2" string="would be just more of the same circus" type="VP">
          <tokens>
            <token id="3" string="would" />
            <token id="4" string="be" />
            <token id="5" string="just" />
            <token id="6" string="more" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="same" />
            <token id="10" string="circus" />
          </tokens>
        </chunking>
        <chunking id="3" string="the same circus" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="same" />
            <token id="10" string="circus" />
          </tokens>
        </chunking>
        <chunking id="4" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="5" string="just more of the same circus" type="NP">
          <tokens>
            <token id="5" string="just" />
            <token id="6" string="more" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="same" />
            <token id="10" string="circus" />
          </tokens>
        </chunking>
        <chunking id="6" string="just more" type="NP">
          <tokens>
            <token id="5" string="just" />
            <token id="6" string="more" />
          </tokens>
        </chunking>
        <chunking id="7" string="he" type="NP">
          <tokens>
            <token id="13" string="he" />
          </tokens>
        </chunking>
        <chunking id="8" string="said" type="VP">
          <tokens>
            <token id="14" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">more</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">more</governor>
          <dependent id="3">would</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">more</governor>
          <dependent id="4">be</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">more</governor>
          <dependent id="5">just</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">said</governor>
          <dependent id="6">more</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">circus</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">circus</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">circus</governor>
          <dependent id="9">same</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">more</governor>
          <dependent id="10">circus</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">said</governor>
          <dependent id="13">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>``We put so much faith and hope in our courts,&amp;apost;&amp;apost; said Robert Canter, 74.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="put" lemma="put" stem="put" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="much" lemma="much" stem="much" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="faith" lemma="faith" stem="faith" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="hope" lemma="hope" stem="hope" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="courts" lemma="court" stem="court" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Robert" lemma="Robert" stem="robert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="16" string="Canter" lemma="Canter" stem="canter" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="74" lemma="74" stem="74" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP We)) (VP (VBD put) (NP (ADJP (RB so) (JJ much)) (NN faith) (CC and) (NN hope)) (PP (IN in) (NP (PRP$ our) (NNS courts))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Robert) (NNP Canter)) (, ,) (NP (CD 74))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Robert Canter" type="NP">
          <tokens>
            <token id="15" string="Robert" />
            <token id="16" string="Canter" />
          </tokens>
        </chunking>
        <chunking id="2" string="so much faith and hope" type="NP">
          <tokens>
            <token id="4" string="so" />
            <token id="5" string="much" />
            <token id="6" string="faith" />
            <token id="7" string="and" />
            <token id="8" string="hope" />
          </tokens>
        </chunking>
        <chunking id="3" string="our courts" type="NP">
          <tokens>
            <token id="10" string="our" />
            <token id="11" string="courts" />
          </tokens>
        </chunking>
        <chunking id="4" string="Robert Canter , 74" type="NP">
          <tokens>
            <token id="15" string="Robert" />
            <token id="16" string="Canter" />
            <token id="17" string="," />
            <token id="18" string="74" />
          </tokens>
        </chunking>
        <chunking id="5" string="put so much faith and hope in our courts" type="VP">
          <tokens>
            <token id="3" string="put" />
            <token id="4" string="so" />
            <token id="5" string="much" />
            <token id="6" string="faith" />
            <token id="7" string="and" />
            <token id="8" string="hope" />
            <token id="9" string="in" />
            <token id="10" string="our" />
            <token id="11" string="courts" />
          </tokens>
        </chunking>
        <chunking id="6" string="so much" type="ADJP">
          <tokens>
            <token id="4" string="so" />
            <token id="5" string="much" />
          </tokens>
        </chunking>
        <chunking id="7" string="74" type="NP">
          <tokens>
            <token id="18" string="74" />
          </tokens>
        </chunking>
        <chunking id="8" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="9" string="said" type="VP">
          <tokens>
            <token id="14" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">put</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">said</governor>
          <dependent id="3">put</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">much</governor>
          <dependent id="4">so</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">faith</governor>
          <dependent id="5">much</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">put</governor>
          <dependent id="6">faith</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">faith</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">faith</governor>
          <dependent id="8">hope</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">courts</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">courts</governor>
          <dependent id="10">our</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">put</governor>
          <dependent id="11">courts</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Canter</governor>
          <dependent id="15">Robert</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">said</governor>
          <dependent id="16">Canter</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">Canter</governor>
          <dependent id="18">74</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Robert Canter" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Robert" />
            <token id="16" string="Canter" />
          </tokens>
        </entity>
        <entity id="2" string="74" type="NUMBER" score="0.0">
          <tokens>
            <token id="18" string="74" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>``And this is what we get _ frustration.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="get" lemma="get" stem="get" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="_" lemma="_" stem="_" pos="CD" type="Symbol" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="9" string="frustration" lemma="frustration" stem="frustrat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (CC And) (NP (DT this)) (VP (VBZ is) (SBAR (WHNP (WP what)) (S (NP (PRP we)) (VP (VBP get) (NP (CD _) (NN frustration)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="what we get _ frustration" type="SBAR">
          <tokens>
            <token id="5" string="what" />
            <token id="6" string="we" />
            <token id="7" string="get" />
            <token id="8" string="_" />
            <token id="9" string="frustration" />
          </tokens>
        </chunking>
        <chunking id="2" string="is what we get _ frustration" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="what" />
            <token id="6" string="we" />
            <token id="7" string="get" />
            <token id="8" string="_" />
            <token id="9" string="frustration" />
          </tokens>
        </chunking>
        <chunking id="3" string="_ frustration" type="NP">
          <tokens>
            <token id="8" string="_" />
            <token id="9" string="frustration" />
          </tokens>
        </chunking>
        <chunking id="4" string="get _ frustration" type="VP">
          <tokens>
            <token id="7" string="get" />
            <token id="8" string="_" />
            <token id="9" string="frustration" />
          </tokens>
        </chunking>
        <chunking id="5" string="this" type="NP">
          <tokens>
            <token id="3" string="this" />
          </tokens>
        </chunking>
        <chunking id="6" string="we" type="NP">
          <tokens>
            <token id="6" string="we" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">is</governor>
          <dependent id="2">And</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">is</governor>
          <dependent id="3">this</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">get</governor>
          <dependent id="5">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">get</governor>
          <dependent id="6">we</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">is</governor>
          <dependent id="7">get</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">frustration</governor>
          <dependent id="8">_</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">get</governor>
          <dependent id="9">frustration</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="_" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="_" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="2" type="NOMINAL">
      <referenced ids_tokens="28-29-30-31" string="the notorious child-molesting case" id_sentence="1" />
      <mentions>
        <mention ids_tokens="31-32" string="The case" id_sentence="4" />
        <mention ids_tokens="26-27" string="the case" id_sentence="5" />
        <mention ids_tokens="8-9" string="the case" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="18-19-20-21-22" string="52 charges of molesting students" id_sentence="2" />
      <mentions>
        <mention ids_tokens="4-5" string="those charges" id_sentence="4" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="5" string="13" id_sentence="3" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="22" />
        <mention ids_tokens="5-10" string="just more of the same circus" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="6" type="PROPER">
      <referenced ids_tokens="1" string="Jurors" id_sentence="3" />
      <mentions>
        <mention ids_tokens="14-15" string="the jurors" id_sentence="20" />
        <mention ids_tokens="3" string="his" id_sentence="21" />
        <mention ids_tokens="8" string="he" id_sentence="21" />
        <mention ids_tokens="13" string="he" id_sentence="22" />
        <mention ids_tokens="2" string="We" id_sentence="23" />
        <mention ids_tokens="6" string="we" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="10" type="PROPER">
      <referenced ids_tokens="2-3-4-5-6-7-8-9-10-11-12-13-14-15" string="Brown , a receptionist at a medical office across the street from the school" id_sentence="5" />
      <mentions>
        <mention ids_tokens="10" string="Brown" id_sentence="6" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="7-8-9-10-11-12-13-14-15" string="a medical office across the street from the school" id_sentence="5" />
      <mentions>
        <mention ids_tokens="7" string="it" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="12" type="NOMINAL">
      <referenced ids_tokens="14-15" string="the school" id_sentence="5" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="12" />
        <mention ids_tokens="13" string="it" id_sentence="12" />
        <mention ids_tokens="7" string="it" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="13" type="NOMINAL">
      <referenced ids_tokens="20-21-22-23-24-25-26-27" string="two friends who were involved in the case" id_sentence="5" />
      <mentions>
        <mention ids_tokens="4" string="they" id_sentence="6" />
      </mentions>
    </coreference>
    <coreference id="14" type="PROPER">
      <referenced ids_tokens="12-13" string="the Buckeys" id_sentence="8" />
      <mentions>
        <mention ids_tokens="33-35" string="the Buckeys'" id_sentence="5" />
        <mention ids_tokens="2" string="I" id_sentence="6" />
        <mention ids_tokens="2" string="I" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="15" type="PROPER">
      <referenced ids_tokens="1-2" string="Alan Lagunoff" id_sentence="8" />
      <mentions>
        <mention ids_tokens="25" string="he" id_sentence="9" />
        <mention ids_tokens="6" string="Lagunoff" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="17" type="PROPER">
      <referenced ids_tokens="2-3-4-5-6" string="another longtime Manhattan Beach resident" id_sentence="13" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="14" />
        <mention ids_tokens="2" string="I" id_sentence="15" />
        <mention ids_tokens="13-16" string="Manhattan Beach and society" id_sentence="17" />
        <mention ids_tokens="13-14" string="Manhattan Beach" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="18" type="PROPER">
      <referenced ids_tokens="13-14" string="Brenda Platt" id_sentence="14" />
      <mentions>
        <mention ids_tokens="1" string="Platt" id_sentence="16" />
        <mention ids_tokens="13" string="she" id_sentence="16" />
        <mention ids_tokens="7" string="Platt" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="21" type="NOMINAL">
      <referenced ids_tokens="5-6-7" string="the McMartin case" id_sentence="17" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="22" type="PROPER">
      <referenced ids_tokens="1-2" string="Linda Geisert" id_sentence="19" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="20" />
        <mention ids_tokens="18" string="Geisert" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="23" type="NOMINAL">
      <referenced ids_tokens="12-13" string="the prosecutors" id_sentence="21" />
      <mentions>
        <mention ids_tokens="10" string="our" id_sentence="23" />
      </mentions>
    </coreference>
  </coreferences>
</document>
