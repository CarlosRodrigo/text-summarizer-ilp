<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP900119-0024">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>A therapist defended her interviews of alleged victims in the McMartin Pre-School molestation trial, despite criticism by several jurors who said leading questions undermined the prosecution&amp;apost;s case.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="therapist" lemma="therapist" stem="therapist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="defended" lemma="defend" stem="defend" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="interviews" lemma="interview" stem="interview" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="alleged" lemma="allege" stem="alleg" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="victims" lemma="victim" stem="victim" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="12" string="Pre-School" lemma="Pre-School" stem="pre-school" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="13" string="molestation" lemma="molestation" stem="molest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="despite" lemma="despite" stem="despit" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="criticism" lemma="criticism" stem="critic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="several" lemma="several" stem="sever" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="jurors" lemma="juror" stem="juror" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="leading" lemma="lead" stem="lead" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="questions" lemma="question" stem="question" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="undermined" lemma="undermine" stem="undermin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="prosecution" lemma="prosecution" stem="prosecut" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT A) (NN therapist)) (VP (VBD defended) (NP (NP (PRP$ her) (NNS interviews)) (PP (IN of) (NP (NP (VBN alleged) (NNS victims)) (PP (IN in) (NP (DT the) (NNP McMartin) (NNP Pre-School) (NN molestation) (NN trial)))))) (, ,) (PP (IN despite) (NP (NP (NN criticism)) (PP (IN by) (NP (JJ several) (NNS jurors))) (SBAR (WHNP (WP who)) (S (VP (VBD said) (NP (NP (VBG leading) (NNS questions)) (VP (VBN undermined) (NP (NP (DT the) (NN prosecution) (POS 's)) (NN case)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the prosecution 's case" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="prosecution" />
            <token id="28" string="'s" />
            <token id="29" string="case" />
          </tokens>
        </chunking>
        <chunking id="2" string="who said leading questions undermined the prosecution 's case" type="SBAR">
          <tokens>
            <token id="21" string="who" />
            <token id="22" string="said" />
            <token id="23" string="leading" />
            <token id="24" string="questions" />
            <token id="25" string="undermined" />
            <token id="26" string="the" />
            <token id="27" string="prosecution" />
            <token id="28" string="'s" />
            <token id="29" string="case" />
          </tokens>
        </chunking>
        <chunking id="3" string="alleged victims in the McMartin Pre-School molestation trial" type="NP">
          <tokens>
            <token id="7" string="alleged" />
            <token id="8" string="victims" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="McMartin" />
            <token id="12" string="Pre-School" />
            <token id="13" string="molestation" />
            <token id="14" string="trial" />
          </tokens>
        </chunking>
        <chunking id="4" string="criticism by several jurors who said leading questions undermined the prosecution 's case" type="NP">
          <tokens>
            <token id="17" string="criticism" />
            <token id="18" string="by" />
            <token id="19" string="several" />
            <token id="20" string="jurors" />
            <token id="21" string="who" />
            <token id="22" string="said" />
            <token id="23" string="leading" />
            <token id="24" string="questions" />
            <token id="25" string="undermined" />
            <token id="26" string="the" />
            <token id="27" string="prosecution" />
            <token id="28" string="'s" />
            <token id="29" string="case" />
          </tokens>
        </chunking>
        <chunking id="5" string="her interviews" type="NP">
          <tokens>
            <token id="4" string="her" />
            <token id="5" string="interviews" />
          </tokens>
        </chunking>
        <chunking id="6" string="alleged victims" type="NP">
          <tokens>
            <token id="7" string="alleged" />
            <token id="8" string="victims" />
          </tokens>
        </chunking>
        <chunking id="7" string="several jurors" type="NP">
          <tokens>
            <token id="19" string="several" />
            <token id="20" string="jurors" />
          </tokens>
        </chunking>
        <chunking id="8" string="her interviews of alleged victims in the McMartin Pre-School molestation trial" type="NP">
          <tokens>
            <token id="4" string="her" />
            <token id="5" string="interviews" />
            <token id="6" string="of" />
            <token id="7" string="alleged" />
            <token id="8" string="victims" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="McMartin" />
            <token id="12" string="Pre-School" />
            <token id="13" string="molestation" />
            <token id="14" string="trial" />
          </tokens>
        </chunking>
        <chunking id="9" string="defended her interviews of alleged victims in the McMartin Pre-School molestation trial , despite criticism by several jurors who said leading questions undermined the prosecution 's case" type="VP">
          <tokens>
            <token id="3" string="defended" />
            <token id="4" string="her" />
            <token id="5" string="interviews" />
            <token id="6" string="of" />
            <token id="7" string="alleged" />
            <token id="8" string="victims" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="McMartin" />
            <token id="12" string="Pre-School" />
            <token id="13" string="molestation" />
            <token id="14" string="trial" />
            <token id="15" string="," />
            <token id="16" string="despite" />
            <token id="17" string="criticism" />
            <token id="18" string="by" />
            <token id="19" string="several" />
            <token id="20" string="jurors" />
            <token id="21" string="who" />
            <token id="22" string="said" />
            <token id="23" string="leading" />
            <token id="24" string="questions" />
            <token id="25" string="undermined" />
            <token id="26" string="the" />
            <token id="27" string="prosecution" />
            <token id="28" string="'s" />
            <token id="29" string="case" />
          </tokens>
        </chunking>
        <chunking id="10" string="leading questions" type="NP">
          <tokens>
            <token id="23" string="leading" />
            <token id="24" string="questions" />
          </tokens>
        </chunking>
        <chunking id="11" string="the McMartin Pre-School molestation trial" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="McMartin" />
            <token id="12" string="Pre-School" />
            <token id="13" string="molestation" />
            <token id="14" string="trial" />
          </tokens>
        </chunking>
        <chunking id="12" string="the prosecution 's" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="prosecution" />
            <token id="28" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="leading questions undermined the prosecution 's case" type="NP">
          <tokens>
            <token id="23" string="leading" />
            <token id="24" string="questions" />
            <token id="25" string="undermined" />
            <token id="26" string="the" />
            <token id="27" string="prosecution" />
            <token id="28" string="'s" />
            <token id="29" string="case" />
          </tokens>
        </chunking>
        <chunking id="14" string="undermined the prosecution 's case" type="VP">
          <tokens>
            <token id="25" string="undermined" />
            <token id="26" string="the" />
            <token id="27" string="prosecution" />
            <token id="28" string="'s" />
            <token id="29" string="case" />
          </tokens>
        </chunking>
        <chunking id="15" string="criticism" type="NP">
          <tokens>
            <token id="17" string="criticism" />
          </tokens>
        </chunking>
        <chunking id="16" string="said leading questions undermined the prosecution 's case" type="VP">
          <tokens>
            <token id="22" string="said" />
            <token id="23" string="leading" />
            <token id="24" string="questions" />
            <token id="25" string="undermined" />
            <token id="26" string="the" />
            <token id="27" string="prosecution" />
            <token id="28" string="'s" />
            <token id="29" string="case" />
          </tokens>
        </chunking>
        <chunking id="17" string="A therapist" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="therapist" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">therapist</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">defended</governor>
          <dependent id="2">therapist</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">defended</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">interviews</governor>
          <dependent id="4">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">defended</governor>
          <dependent id="5">interviews</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">victims</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">victims</governor>
          <dependent id="7">alleged</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">interviews</governor>
          <dependent id="8">victims</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">trial</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">trial</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">trial</governor>
          <dependent id="11">McMartin</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">trial</governor>
          <dependent id="12">Pre-School</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">trial</governor>
          <dependent id="13">molestation</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">victims</governor>
          <dependent id="14">trial</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">criticism</governor>
          <dependent id="16">despite</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">defended</governor>
          <dependent id="17">criticism</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">jurors</governor>
          <dependent id="18">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">jurors</governor>
          <dependent id="19">several</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">criticism</governor>
          <dependent id="20">jurors</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">said</governor>
          <dependent id="21">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="17">criticism</governor>
          <dependent id="22">said</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">questions</governor>
          <dependent id="23">leading</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">said</governor>
          <dependent id="24">questions</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="24">questions</governor>
          <dependent id="25">undermined</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">prosecution</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="29">case</governor>
          <dependent id="27">prosecution</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">prosecution</governor>
          <dependent id="28">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">undermined</governor>
          <dependent id="29">case</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="McMartin Pre-School" type="MISC" score="0.0">
          <tokens>
            <token id="11" string="McMartin" />
            <token id="12" string="Pre-School" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="false">
      <content>The jury on Thursday acquitted Raymond Buckey and his mother, Peggy McMartin Buckey, of 52 child molestation counts and deadlocked on 13 other counts.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="jury" lemma="jury" stem="juri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Thursday" lemma="Thursday" stem="thursdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="5" string="acquitted" lemma="acquit" stem="acquit" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Raymond" lemma="Raymond" stem="raymond" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="mother" lemma="mother" stem="mother" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Peggy" lemma="Peggy" stem="peggi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="13" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="14" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="52" lemma="52" stem="52" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="18" string="child" lemma="child" stem="child" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="molestation" lemma="molestation" stem="molest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="counts" lemma="count" stem="count" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="deadlocked" lemma="deadlock" stem="deadlock" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="13" lemma="13" stem="13" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="25" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="counts" lemma="count" stem="count" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN jury)) (PP (IN on) (NP (NNP Thursday)))) (VP (VBD acquitted) (NP (NP (NNP Raymond) (NNP Buckey)) (CC and) (NP (NP (NP (PRP$ his) (NN mother)) (, ,) (NP (NNP Peggy) (NNP McMartin) (NNP Buckey)) (, ,)) (PP (IN of) (NP (CD 52) (NN child) (NN molestation) (NNS counts)))) (CC and) (NP (ADJP (VBN deadlocked) (PP (IN on) (NP (CD 13)))) (JJ other) (NNS counts)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="acquitted Raymond Buckey and his mother , Peggy McMartin Buckey , of 52 child molestation counts and deadlocked on 13 other counts" type="VP">
          <tokens>
            <token id="5" string="acquitted" />
            <token id="6" string="Raymond" />
            <token id="7" string="Buckey" />
            <token id="8" string="and" />
            <token id="9" string="his" />
            <token id="10" string="mother" />
            <token id="11" string="," />
            <token id="12" string="Peggy" />
            <token id="13" string="McMartin" />
            <token id="14" string="Buckey" />
            <token id="15" string="," />
            <token id="16" string="of" />
            <token id="17" string="52" />
            <token id="18" string="child" />
            <token id="19" string="molestation" />
            <token id="20" string="counts" />
            <token id="21" string="and" />
            <token id="22" string="deadlocked" />
            <token id="23" string="on" />
            <token id="24" string="13" />
            <token id="25" string="other" />
            <token id="26" string="counts" />
          </tokens>
        </chunking>
        <chunking id="2" string="52 child molestation counts" type="NP">
          <tokens>
            <token id="17" string="52" />
            <token id="18" string="child" />
            <token id="19" string="molestation" />
            <token id="20" string="counts" />
          </tokens>
        </chunking>
        <chunking id="3" string="Peggy McMartin Buckey" type="NP">
          <tokens>
            <token id="12" string="Peggy" />
            <token id="13" string="McMartin" />
            <token id="14" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="4" string="13" type="NP">
          <tokens>
            <token id="24" string="13" />
          </tokens>
        </chunking>
        <chunking id="5" string="his mother , Peggy McMartin Buckey , of 52 child molestation counts" type="NP">
          <tokens>
            <token id="9" string="his" />
            <token id="10" string="mother" />
            <token id="11" string="," />
            <token id="12" string="Peggy" />
            <token id="13" string="McMartin" />
            <token id="14" string="Buckey" />
            <token id="15" string="," />
            <token id="16" string="of" />
            <token id="17" string="52" />
            <token id="18" string="child" />
            <token id="19" string="molestation" />
            <token id="20" string="counts" />
          </tokens>
        </chunking>
        <chunking id="6" string="Raymond Buckey" type="NP">
          <tokens>
            <token id="6" string="Raymond" />
            <token id="7" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="7" string="Thursday" type="NP">
          <tokens>
            <token id="4" string="Thursday" />
          </tokens>
        </chunking>
        <chunking id="8" string="his mother , Peggy McMartin Buckey ," type="NP">
          <tokens>
            <token id="9" string="his" />
            <token id="10" string="mother" />
            <token id="11" string="," />
            <token id="12" string="Peggy" />
            <token id="13" string="McMartin" />
            <token id="14" string="Buckey" />
            <token id="15" string="," />
          </tokens>
        </chunking>
        <chunking id="9" string="Raymond Buckey and his mother , Peggy McMartin Buckey , of 52 child molestation counts and deadlocked on 13 other counts" type="NP">
          <tokens>
            <token id="6" string="Raymond" />
            <token id="7" string="Buckey" />
            <token id="8" string="and" />
            <token id="9" string="his" />
            <token id="10" string="mother" />
            <token id="11" string="," />
            <token id="12" string="Peggy" />
            <token id="13" string="McMartin" />
            <token id="14" string="Buckey" />
            <token id="15" string="," />
            <token id="16" string="of" />
            <token id="17" string="52" />
            <token id="18" string="child" />
            <token id="19" string="molestation" />
            <token id="20" string="counts" />
            <token id="21" string="and" />
            <token id="22" string="deadlocked" />
            <token id="23" string="on" />
            <token id="24" string="13" />
            <token id="25" string="other" />
            <token id="26" string="counts" />
          </tokens>
        </chunking>
        <chunking id="10" string="his mother" type="NP">
          <tokens>
            <token id="9" string="his" />
            <token id="10" string="mother" />
          </tokens>
        </chunking>
        <chunking id="11" string="The jury" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="jury" />
          </tokens>
        </chunking>
        <chunking id="12" string="The jury on Thursday" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="jury" />
            <token id="3" string="on" />
            <token id="4" string="Thursday" />
          </tokens>
        </chunking>
        <chunking id="13" string="deadlocked on 13 other counts" type="NP">
          <tokens>
            <token id="22" string="deadlocked" />
            <token id="23" string="on" />
            <token id="24" string="13" />
            <token id="25" string="other" />
            <token id="26" string="counts" />
          </tokens>
        </chunking>
        <chunking id="14" string="deadlocked on 13" type="ADJP">
          <tokens>
            <token id="22" string="deadlocked" />
            <token id="23" string="on" />
            <token id="24" string="13" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">jury</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">acquitted</governor>
          <dependent id="2">jury</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Thursday</governor>
          <dependent id="3">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">jury</governor>
          <dependent id="4">Thursday</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">acquitted</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Buckey</governor>
          <dependent id="6">Raymond</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">acquitted</governor>
          <dependent id="7">Buckey</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">Buckey</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">mother</governor>
          <dependent id="9">his</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">Buckey</governor>
          <dependent id="10">mother</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Buckey</governor>
          <dependent id="12">Peggy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Buckey</governor>
          <dependent id="13">McMartin</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="10">mother</governor>
          <dependent id="14">Buckey</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">counts</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="20">counts</governor>
          <dependent id="17">52</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">counts</governor>
          <dependent id="18">child</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">counts</governor>
          <dependent id="19">molestation</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">mother</governor>
          <dependent id="20">counts</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">Buckey</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">counts</governor>
          <dependent id="22">deadlocked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">13</governor>
          <dependent id="23">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">deadlocked</governor>
          <dependent id="24">13</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">counts</governor>
          <dependent id="25">other</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">Buckey</governor>
          <dependent id="26">counts</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Peggy McMartin Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Peggy" />
            <token id="13" string="McMartin" />
            <token id="14" string="Buckey" />
          </tokens>
        </entity>
        <entity id="2" string="13" type="NUMBER" score="0.0">
          <tokens>
            <token id="24" string="13" />
          </tokens>
        </entity>
        <entity id="3" string="Thursday" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="Thursday" />
          </tokens>
        </entity>
        <entity id="4" string="52" type="NUMBER" score="0.0">
          <tokens>
            <token id="17" string="52" />
          </tokens>
        </entity>
        <entity id="5" string="Raymond Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Raymond" />
            <token id="7" string="Buckey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>Therapist Kee McFarlane later defended her work with hundreds of McMartin students, and suggested that the goals of therapy are at odds with the legal standards required for a successful criminal prosecution.</content>
      <tokens>
        <token id="1" string="Therapist" lemma="Therapist" stem="therapist" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="2" string="Kee" lemma="Kee" stem="kee" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="McFarlane" lemma="McFarlane" stem="mcfarlan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="defended" lemma="defend" stem="defend" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="work" lemma="work" stem="work" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="hundreds" lemma="hundred" stem="hundr" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="12" string="students" lemma="student" stem="student" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="suggested" lemma="suggest" stem="suggest" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="goals" lemma="goal" stem="goal" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="therapy" lemma="therapy" stem="therapi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="odds" lemma="odds" stem="odd" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="legal" lemma="legal" stem="legal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="standards" lemma="standard" stem="standard" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="required" lemma="require" stem="requir" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="successful" lemma="successful" stem="success" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="prosecution" lemma="prosecution" stem="prosecut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Therapist) (NNP Kee) (NNP McFarlane)) (ADVP (RB later)) (VP (VP (VBD defended) (NP (PRP$ her) (NN work)) (PP (IN with) (NP (NP (NNS hundreds)) (PP (IN of) (NP (NNP McMartin) (NNS students)))))) (, ,) (CC and) (VP (VBD suggested) (SBAR (IN that) (S (NP (NP (DT the) (NNS goals)) (PP (IN of) (NP (NN therapy)))) (VP (VBP are) (PP (IN at) (NP (NP (NNS odds)) (PP (IN with) (NP (NP (DT the) (JJ legal) (NNS standards)) (VP (VBN required) (PP (IN for) (NP (DT a) (JJ successful) (JJ criminal) (NN prosecution))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the goals of therapy" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="goals" />
            <token id="19" string="of" />
            <token id="20" string="therapy" />
          </tokens>
        </chunking>
        <chunking id="2" string="therapy" type="NP">
          <tokens>
            <token id="20" string="therapy" />
          </tokens>
        </chunking>
        <chunking id="3" string="the legal standards required for a successful criminal prosecution" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="legal" />
            <token id="27" string="standards" />
            <token id="28" string="required" />
            <token id="29" string="for" />
            <token id="30" string="a" />
            <token id="31" string="successful" />
            <token id="32" string="criminal" />
            <token id="33" string="prosecution" />
          </tokens>
        </chunking>
        <chunking id="4" string="her work" type="NP">
          <tokens>
            <token id="6" string="her" />
            <token id="7" string="work" />
          </tokens>
        </chunking>
        <chunking id="5" string="Therapist Kee McFarlane" type="NP">
          <tokens>
            <token id="1" string="Therapist" />
            <token id="2" string="Kee" />
            <token id="3" string="McFarlane" />
          </tokens>
        </chunking>
        <chunking id="6" string="defended her work with hundreds of McMartin students" type="VP">
          <tokens>
            <token id="5" string="defended" />
            <token id="6" string="her" />
            <token id="7" string="work" />
            <token id="8" string="with" />
            <token id="9" string="hundreds" />
            <token id="10" string="of" />
            <token id="11" string="McMartin" />
            <token id="12" string="students" />
          </tokens>
        </chunking>
        <chunking id="7" string="defended her work with hundreds of McMartin students , and suggested that the goals of therapy are at odds with the legal standards required for a successful criminal prosecution" type="VP">
          <tokens>
            <token id="5" string="defended" />
            <token id="6" string="her" />
            <token id="7" string="work" />
            <token id="8" string="with" />
            <token id="9" string="hundreds" />
            <token id="10" string="of" />
            <token id="11" string="McMartin" />
            <token id="12" string="students" />
            <token id="13" string="," />
            <token id="14" string="and" />
            <token id="15" string="suggested" />
            <token id="16" string="that" />
            <token id="17" string="the" />
            <token id="18" string="goals" />
            <token id="19" string="of" />
            <token id="20" string="therapy" />
            <token id="21" string="are" />
            <token id="22" string="at" />
            <token id="23" string="odds" />
            <token id="24" string="with" />
            <token id="25" string="the" />
            <token id="26" string="legal" />
            <token id="27" string="standards" />
            <token id="28" string="required" />
            <token id="29" string="for" />
            <token id="30" string="a" />
            <token id="31" string="successful" />
            <token id="32" string="criminal" />
            <token id="33" string="prosecution" />
          </tokens>
        </chunking>
        <chunking id="8" string="a successful criminal prosecution" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="successful" />
            <token id="32" string="criminal" />
            <token id="33" string="prosecution" />
          </tokens>
        </chunking>
        <chunking id="9" string="odds" type="NP">
          <tokens>
            <token id="23" string="odds" />
          </tokens>
        </chunking>
        <chunking id="10" string="suggested that the goals of therapy are at odds with the legal standards required for a successful criminal prosecution" type="VP">
          <tokens>
            <token id="15" string="suggested" />
            <token id="16" string="that" />
            <token id="17" string="the" />
            <token id="18" string="goals" />
            <token id="19" string="of" />
            <token id="20" string="therapy" />
            <token id="21" string="are" />
            <token id="22" string="at" />
            <token id="23" string="odds" />
            <token id="24" string="with" />
            <token id="25" string="the" />
            <token id="26" string="legal" />
            <token id="27" string="standards" />
            <token id="28" string="required" />
            <token id="29" string="for" />
            <token id="30" string="a" />
            <token id="31" string="successful" />
            <token id="32" string="criminal" />
            <token id="33" string="prosecution" />
          </tokens>
        </chunking>
        <chunking id="11" string="are at odds with the legal standards required for a successful criminal prosecution" type="VP">
          <tokens>
            <token id="21" string="are" />
            <token id="22" string="at" />
            <token id="23" string="odds" />
            <token id="24" string="with" />
            <token id="25" string="the" />
            <token id="26" string="legal" />
            <token id="27" string="standards" />
            <token id="28" string="required" />
            <token id="29" string="for" />
            <token id="30" string="a" />
            <token id="31" string="successful" />
            <token id="32" string="criminal" />
            <token id="33" string="prosecution" />
          </tokens>
        </chunking>
        <chunking id="12" string="odds with the legal standards required for a successful criminal prosecution" type="NP">
          <tokens>
            <token id="23" string="odds" />
            <token id="24" string="with" />
            <token id="25" string="the" />
            <token id="26" string="legal" />
            <token id="27" string="standards" />
            <token id="28" string="required" />
            <token id="29" string="for" />
            <token id="30" string="a" />
            <token id="31" string="successful" />
            <token id="32" string="criminal" />
            <token id="33" string="prosecution" />
          </tokens>
        </chunking>
        <chunking id="13" string="hundreds of McMartin students" type="NP">
          <tokens>
            <token id="9" string="hundreds" />
            <token id="10" string="of" />
            <token id="11" string="McMartin" />
            <token id="12" string="students" />
          </tokens>
        </chunking>
        <chunking id="14" string="hundreds" type="NP">
          <tokens>
            <token id="9" string="hundreds" />
          </tokens>
        </chunking>
        <chunking id="15" string="McMartin students" type="NP">
          <tokens>
            <token id="11" string="McMartin" />
            <token id="12" string="students" />
          </tokens>
        </chunking>
        <chunking id="16" string="required for a successful criminal prosecution" type="VP">
          <tokens>
            <token id="28" string="required" />
            <token id="29" string="for" />
            <token id="30" string="a" />
            <token id="31" string="successful" />
            <token id="32" string="criminal" />
            <token id="33" string="prosecution" />
          </tokens>
        </chunking>
        <chunking id="17" string="the goals" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="goals" />
          </tokens>
        </chunking>
        <chunking id="18" string="that the goals of therapy are at odds with the legal standards required for a successful criminal prosecution" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="the" />
            <token id="18" string="goals" />
            <token id="19" string="of" />
            <token id="20" string="therapy" />
            <token id="21" string="are" />
            <token id="22" string="at" />
            <token id="23" string="odds" />
            <token id="24" string="with" />
            <token id="25" string="the" />
            <token id="26" string="legal" />
            <token id="27" string="standards" />
            <token id="28" string="required" />
            <token id="29" string="for" />
            <token id="30" string="a" />
            <token id="31" string="successful" />
            <token id="32" string="criminal" />
            <token id="33" string="prosecution" />
          </tokens>
        </chunking>
        <chunking id="19" string="the legal standards" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="legal" />
            <token id="27" string="standards" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">McFarlane</governor>
          <dependent id="1">Therapist</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">McFarlane</governor>
          <dependent id="2">Kee</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">defended</governor>
          <dependent id="3">McFarlane</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">defended</governor>
          <dependent id="4">later</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">defended</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">work</governor>
          <dependent id="6">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">defended</governor>
          <dependent id="7">work</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">hundreds</governor>
          <dependent id="8">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">defended</governor>
          <dependent id="9">hundreds</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">students</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">students</governor>
          <dependent id="11">McMartin</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">hundreds</governor>
          <dependent id="12">students</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">defended</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">defended</governor>
          <dependent id="15">suggested</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">odds</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">goals</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">odds</governor>
          <dependent id="18">goals</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">therapy</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">goals</governor>
          <dependent id="20">therapy</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="23">odds</governor>
          <dependent id="21">are</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">odds</governor>
          <dependent id="22">at</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">suggested</governor>
          <dependent id="23">odds</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">standards</governor>
          <dependent id="24">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">standards</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">standards</governor>
          <dependent id="26">legal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">odds</governor>
          <dependent id="27">standards</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="27">standards</governor>
          <dependent id="28">required</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">prosecution</governor>
          <dependent id="29">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">prosecution</governor>
          <dependent id="30">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">prosecution</governor>
          <dependent id="31">successful</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">prosecution</governor>
          <dependent id="32">criminal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">required</governor>
          <dependent id="33">prosecution</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="McMartin" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="11" string="McMartin" />
          </tokens>
        </entity>
        <entity id="2" string="Kee McFarlane" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Kee" />
            <token id="3" string="McFarlane" />
          </tokens>
        </entity>
        <entity id="3" string="Therapist" type="TITLE" score="0.0">
          <tokens>
            <token id="1" string="Therapist" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>``What is in the interest of children is not always in the interest of the legal system,&amp;apost;&amp;apost; she said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="What" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="interest" lemma="interest" stem="interest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="always" lemma="always" stem="alwai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="interest" lemma="interest" stem="interest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="legal" lemma="legal" stem="legal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="system" lemma="system" stem="system" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (SBAR (WHNP (WP What)) (S (VP (VBZ is) (PP (IN in) (NP (NP (DT the) (NN interest)) (PP (IN of) (NP (NNS children)))))))) (VP (VBZ is) (RB not) (ADVP (RB always)) (PP (IN in) (NP (NP (DT the) (NN interest)) (PP (IN of) (NP (DT the) (JJ legal) (NN system))))))) (, ,) ('' '') (NP (PRP she)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the interest of the legal system" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="interest" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="legal" />
            <token id="18" string="system" />
          </tokens>
        </chunking>
        <chunking id="2" string="is in the interest of children" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="in" />
            <token id="5" string="the" />
            <token id="6" string="interest" />
            <token id="7" string="of" />
            <token id="8" string="children" />
          </tokens>
        </chunking>
        <chunking id="3" string="is not always in the interest of the legal system" type="VP">
          <tokens>
            <token id="9" string="is" />
            <token id="10" string="not" />
            <token id="11" string="always" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="interest" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="legal" />
            <token id="18" string="system" />
          </tokens>
        </chunking>
        <chunking id="4" string="the interest of children" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="interest" />
            <token id="7" string="of" />
            <token id="8" string="children" />
          </tokens>
        </chunking>
        <chunking id="5" string="the legal system" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="legal" />
            <token id="18" string="system" />
          </tokens>
        </chunking>
        <chunking id="6" string="children" type="NP">
          <tokens>
            <token id="8" string="children" />
          </tokens>
        </chunking>
        <chunking id="7" string="the interest" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="interest" />
          </tokens>
        </chunking>
        <chunking id="8" string="What is in the interest of children" type="SBAR">
          <tokens>
            <token id="2" string="What" />
            <token id="3" string="is" />
            <token id="4" string="in" />
            <token id="5" string="the" />
            <token id="6" string="interest" />
            <token id="7" string="of" />
            <token id="8" string="children" />
          </tokens>
        </chunking>
        <chunking id="9" string="said" type="VP">
          <tokens>
            <token id="22" string="said" />
          </tokens>
        </chunking>
        <chunking id="10" string="she" type="NP">
          <tokens>
            <token id="21" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">interest</governor>
          <dependent id="2">What</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">interest</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">interest</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">interest</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="14">interest</governor>
          <dependent id="6">interest</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">children</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">interest</governor>
          <dependent id="8">children</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">interest</governor>
          <dependent id="9">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="14">interest</governor>
          <dependent id="10">not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">interest</governor>
          <dependent id="11">always</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">interest</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">interest</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">said</governor>
          <dependent id="14">interest</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">system</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">system</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">system</governor>
          <dependent id="17">legal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">interest</governor>
          <dependent id="18">system</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">said</governor>
          <dependent id="21">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="22">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>Evidence introduced by prosecutors in what became the longest and most expensive criminal trial in U.S. history included videotaped interviews of the alleged victims.</content>
      <tokens>
        <token id="1" string="Evidence" lemma="evidence" stem="evidenc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="introduced" lemma="introduce" stem="introduc" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="prosecutors" lemma="prosecutor" stem="prosecutor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="became" lemma="become" stem="becam" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="longest" lemma="longest" stem="longest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="expensive" lemma="expensive" stem="expens" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="17" string="history" lemma="history" stem="histori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="included" lemma="include" stem="includ" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="videotaped" lemma="videotaped" stem="videotap" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="interviews" lemma="interview" stem="interview" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="alleged" lemma="allege" stem="alleg" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="victims" lemma="victim" stem="victim" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NN Evidence)) (VP (VBN introduced) (PP (IN by) (NP (NP (NNS prosecutors)) (PP (IN in) (SBAR (WHNP (WP what)) (S (VP (VBD became) (NP (DT the) (ADJP (JJS longest) (CC and) (ADJP (RBS most) (JJ expensive))) (JJ criminal) (NN trial)) (PP (IN in) (NP (NNP U.S.) (NN history))))))))))) (VP (VBD included) (NP (NP (JJ videotaped) (NNS interviews)) (PP (IN of) (NP (DT the) (VBN alleged) (NNS victims))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the longest and most expensive criminal trial" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="longest" />
            <token id="10" string="and" />
            <token id="11" string="most" />
            <token id="12" string="expensive" />
            <token id="13" string="criminal" />
            <token id="14" string="trial" />
          </tokens>
        </chunking>
        <chunking id="2" string="the alleged victims" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="alleged" />
            <token id="24" string="victims" />
          </tokens>
        </chunking>
        <chunking id="3" string="included videotaped interviews of the alleged victims" type="VP">
          <tokens>
            <token id="18" string="included" />
            <token id="19" string="videotaped" />
            <token id="20" string="interviews" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="alleged" />
            <token id="24" string="victims" />
          </tokens>
        </chunking>
        <chunking id="4" string="introduced by prosecutors in what became the longest and most expensive criminal trial in U.S. history" type="VP">
          <tokens>
            <token id="2" string="introduced" />
            <token id="3" string="by" />
            <token id="4" string="prosecutors" />
            <token id="5" string="in" />
            <token id="6" string="what" />
            <token id="7" string="became" />
            <token id="8" string="the" />
            <token id="9" string="longest" />
            <token id="10" string="and" />
            <token id="11" string="most" />
            <token id="12" string="expensive" />
            <token id="13" string="criminal" />
            <token id="14" string="trial" />
            <token id="15" string="in" />
            <token id="16" string="U.S." />
            <token id="17" string="history" />
          </tokens>
        </chunking>
        <chunking id="5" string="videotaped interviews of the alleged victims" type="NP">
          <tokens>
            <token id="19" string="videotaped" />
            <token id="20" string="interviews" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="alleged" />
            <token id="24" string="victims" />
          </tokens>
        </chunking>
        <chunking id="6" string="longest and most expensive" type="ADJP">
          <tokens>
            <token id="9" string="longest" />
            <token id="10" string="and" />
            <token id="11" string="most" />
            <token id="12" string="expensive" />
          </tokens>
        </chunking>
        <chunking id="7" string="Evidence introduced by prosecutors in what became the longest and most expensive criminal trial in U.S. history" type="NP">
          <tokens>
            <token id="1" string="Evidence" />
            <token id="2" string="introduced" />
            <token id="3" string="by" />
            <token id="4" string="prosecutors" />
            <token id="5" string="in" />
            <token id="6" string="what" />
            <token id="7" string="became" />
            <token id="8" string="the" />
            <token id="9" string="longest" />
            <token id="10" string="and" />
            <token id="11" string="most" />
            <token id="12" string="expensive" />
            <token id="13" string="criminal" />
            <token id="14" string="trial" />
            <token id="15" string="in" />
            <token id="16" string="U.S." />
            <token id="17" string="history" />
          </tokens>
        </chunking>
        <chunking id="8" string="became the longest and most expensive criminal trial in U.S. history" type="VP">
          <tokens>
            <token id="7" string="became" />
            <token id="8" string="the" />
            <token id="9" string="longest" />
            <token id="10" string="and" />
            <token id="11" string="most" />
            <token id="12" string="expensive" />
            <token id="13" string="criminal" />
            <token id="14" string="trial" />
            <token id="15" string="in" />
            <token id="16" string="U.S." />
            <token id="17" string="history" />
          </tokens>
        </chunking>
        <chunking id="9" string="prosecutors" type="NP">
          <tokens>
            <token id="4" string="prosecutors" />
          </tokens>
        </chunking>
        <chunking id="10" string="most expensive" type="ADJP">
          <tokens>
            <token id="11" string="most" />
            <token id="12" string="expensive" />
          </tokens>
        </chunking>
        <chunking id="11" string="U.S. history" type="NP">
          <tokens>
            <token id="16" string="U.S." />
            <token id="17" string="history" />
          </tokens>
        </chunking>
        <chunking id="12" string="what became the longest and most expensive criminal trial in U.S. history" type="SBAR">
          <tokens>
            <token id="6" string="what" />
            <token id="7" string="became" />
            <token id="8" string="the" />
            <token id="9" string="longest" />
            <token id="10" string="and" />
            <token id="11" string="most" />
            <token id="12" string="expensive" />
            <token id="13" string="criminal" />
            <token id="14" string="trial" />
            <token id="15" string="in" />
            <token id="16" string="U.S." />
            <token id="17" string="history" />
          </tokens>
        </chunking>
        <chunking id="13" string="Evidence" type="NP">
          <tokens>
            <token id="1" string="Evidence" />
          </tokens>
        </chunking>
        <chunking id="14" string="prosecutors in what became the longest and most expensive criminal trial in U.S. history" type="NP">
          <tokens>
            <token id="4" string="prosecutors" />
            <token id="5" string="in" />
            <token id="6" string="what" />
            <token id="7" string="became" />
            <token id="8" string="the" />
            <token id="9" string="longest" />
            <token id="10" string="and" />
            <token id="11" string="most" />
            <token id="12" string="expensive" />
            <token id="13" string="criminal" />
            <token id="14" string="trial" />
            <token id="15" string="in" />
            <token id="16" string="U.S." />
            <token id="17" string="history" />
          </tokens>
        </chunking>
        <chunking id="15" string="videotaped interviews" type="NP">
          <tokens>
            <token id="19" string="videotaped" />
            <token id="20" string="interviews" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="18">included</governor>
          <dependent id="1">Evidence</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="1">Evidence</governor>
          <dependent id="2">introduced</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">prosecutors</governor>
          <dependent id="3">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">introduced</governor>
          <dependent id="4">prosecutors</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">became</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">became</governor>
          <dependent id="6">what</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="4">prosecutors</governor>
          <dependent id="7">became</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">trial</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">trial</governor>
          <dependent id="9">longest</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">longest</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">expensive</governor>
          <dependent id="11">most</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">longest</governor>
          <dependent id="12">expensive</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">trial</governor>
          <dependent id="13">criminal</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">became</governor>
          <dependent id="14">trial</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">history</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">history</governor>
          <dependent id="16">U.S.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">became</governor>
          <dependent id="17">history</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">included</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">interviews</governor>
          <dependent id="19">videotaped</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">included</governor>
          <dependent id="20">interviews</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">victims</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">victims</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">victims</governor>
          <dependent id="23">alleged</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">interviews</governor>
          <dependent id="24">victims</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="U.S." type="LOCATION" score="0.0">
          <tokens>
            <token id="16" string="U.S." />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>Many of the interviews were conducted at an early stage of the sexual abuse investigation by MacFarlane, a social worker and director of the Child Sexual Abuse Center at Children&amp;apost;s Institute International.</content>
      <tokens>
        <token id="1" string="Many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="interviews" lemma="interview" stem="interview" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="5" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="conducted" lemma="conduct" stem="conduct" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="early" lemma="early" stem="earli" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="stage" lemma="stage" stem="stage" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="sexual" lemma="sexual" stem="sexual" pos="JJ" type="Word" isStopWord="false" ner="CRIMINAL_CHARGE" is_referenced="false" is_refers="false" />
        <token id="14" string="abuse" lemma="abuse" stem="abus" pos="NN" type="Word" isStopWord="false" ner="CRIMINAL_CHARGE" is_referenced="false" is_refers="false" />
        <token id="15" string="investigation" lemma="investigation" stem="investig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="MacFarlane" lemma="MacFarlane" stem="macfarlan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="social" lemma="social" stem="social" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="worker" lemma="worker" stem="worker" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="director" lemma="director" stem="director" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="Child" lemma="Child" stem="child" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="27" string="Sexual" lemma="Sexual" stem="sexual" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="28" string="Abuse" lemma="abuse" stem="abuse" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="29" string="Center" lemma="Center" stem="center" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="30" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="31" string="Children" lemma="Children" stem="children" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="32" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="33" string="Institute" lemma="Institute" stem="institut" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="34" string="International" lemma="International" stem="internat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (JJ Many)) (PP (IN of) (NP (DT the) (NNS interviews)))) (VP (VBD were) (VP (VBN conducted) (PP (IN at) (NP (NP (DT an) (JJ early) (NN stage)) (PP (IN of) (NP (DT the) (JJ sexual) (NN abuse) (NN investigation))))) (PP (IN by) (NP (NP (NNP MacFarlane)) (, ,) (NP (DT a) (JJ social) (NN worker)) (CC and) (NP (NP (NN director)) (PP (IN of) (NP (DT the) (NNP Child) (NNP Sexual) (NN Abuse) (NNP Center)))))) (PP (IN at) (NP (NP (NNP Children) (POS 's)) (NNP Institute) (NNP International))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="director" type="NP">
          <tokens>
            <token id="23" string="director" />
          </tokens>
        </chunking>
        <chunking id="2" string="the interviews" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="interviews" />
          </tokens>
        </chunking>
        <chunking id="3" string="an early stage" type="NP">
          <tokens>
            <token id="8" string="an" />
            <token id="9" string="early" />
            <token id="10" string="stage" />
          </tokens>
        </chunking>
        <chunking id="4" string="MacFarlane , a social worker and director of the Child Sexual Abuse Center" type="NP">
          <tokens>
            <token id="17" string="MacFarlane" />
            <token id="18" string="," />
            <token id="19" string="a" />
            <token id="20" string="social" />
            <token id="21" string="worker" />
            <token id="22" string="and" />
            <token id="23" string="director" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="Child" />
            <token id="27" string="Sexual" />
            <token id="28" string="Abuse" />
            <token id="29" string="Center" />
          </tokens>
        </chunking>
        <chunking id="5" string="an early stage of the sexual abuse investigation" type="NP">
          <tokens>
            <token id="8" string="an" />
            <token id="9" string="early" />
            <token id="10" string="stage" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="sexual" />
            <token id="14" string="abuse" />
            <token id="15" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="6" string="conducted at an early stage of the sexual abuse investigation by MacFarlane , a social worker and director of the Child Sexual Abuse Center at Children 's Institute International" type="VP">
          <tokens>
            <token id="6" string="conducted" />
            <token id="7" string="at" />
            <token id="8" string="an" />
            <token id="9" string="early" />
            <token id="10" string="stage" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="sexual" />
            <token id="14" string="abuse" />
            <token id="15" string="investigation" />
            <token id="16" string="by" />
            <token id="17" string="MacFarlane" />
            <token id="18" string="," />
            <token id="19" string="a" />
            <token id="20" string="social" />
            <token id="21" string="worker" />
            <token id="22" string="and" />
            <token id="23" string="director" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="Child" />
            <token id="27" string="Sexual" />
            <token id="28" string="Abuse" />
            <token id="29" string="Center" />
            <token id="30" string="at" />
            <token id="31" string="Children" />
            <token id="32" string="'s" />
            <token id="33" string="Institute" />
            <token id="34" string="International" />
          </tokens>
        </chunking>
        <chunking id="7" string="were conducted at an early stage of the sexual abuse investigation by MacFarlane , a social worker and director of the Child Sexual Abuse Center at Children 's Institute International" type="VP">
          <tokens>
            <token id="5" string="were" />
            <token id="6" string="conducted" />
            <token id="7" string="at" />
            <token id="8" string="an" />
            <token id="9" string="early" />
            <token id="10" string="stage" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="sexual" />
            <token id="14" string="abuse" />
            <token id="15" string="investigation" />
            <token id="16" string="by" />
            <token id="17" string="MacFarlane" />
            <token id="18" string="," />
            <token id="19" string="a" />
            <token id="20" string="social" />
            <token id="21" string="worker" />
            <token id="22" string="and" />
            <token id="23" string="director" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="Child" />
            <token id="27" string="Sexual" />
            <token id="28" string="Abuse" />
            <token id="29" string="Center" />
            <token id="30" string="at" />
            <token id="31" string="Children" />
            <token id="32" string="'s" />
            <token id="33" string="Institute" />
            <token id="34" string="International" />
          </tokens>
        </chunking>
        <chunking id="8" string="director of the Child Sexual Abuse Center" type="NP">
          <tokens>
            <token id="23" string="director" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="Child" />
            <token id="27" string="Sexual" />
            <token id="28" string="Abuse" />
            <token id="29" string="Center" />
          </tokens>
        </chunking>
        <chunking id="9" string="Children 's Institute International" type="NP">
          <tokens>
            <token id="31" string="Children" />
            <token id="32" string="'s" />
            <token id="33" string="Institute" />
            <token id="34" string="International" />
          </tokens>
        </chunking>
        <chunking id="10" string="the sexual abuse investigation" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="sexual" />
            <token id="14" string="abuse" />
            <token id="15" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="11" string="Children 's" type="NP">
          <tokens>
            <token id="31" string="Children" />
            <token id="32" string="'s" />
          </tokens>
        </chunking>
        <chunking id="12" string="a social worker" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="social" />
            <token id="21" string="worker" />
          </tokens>
        </chunking>
        <chunking id="13" string="Many" type="NP">
          <tokens>
            <token id="1" string="Many" />
          </tokens>
        </chunking>
        <chunking id="14" string="Many of the interviews" type="NP">
          <tokens>
            <token id="1" string="Many" />
            <token id="2" string="of" />
            <token id="3" string="the" />
            <token id="4" string="interviews" />
          </tokens>
        </chunking>
        <chunking id="15" string="the Child Sexual Abuse Center" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="Child" />
            <token id="27" string="Sexual" />
            <token id="28" string="Abuse" />
            <token id="29" string="Center" />
          </tokens>
        </chunking>
        <chunking id="16" string="MacFarlane" type="NP">
          <tokens>
            <token id="17" string="MacFarlane" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="6">conducted</governor>
          <dependent id="1">Many</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">interviews</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">interviews</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Many</governor>
          <dependent id="4">interviews</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">conducted</governor>
          <dependent id="5">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">conducted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">stage</governor>
          <dependent id="7">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">stage</governor>
          <dependent id="8">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">stage</governor>
          <dependent id="9">early</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">conducted</governor>
          <dependent id="10">stage</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">investigation</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">investigation</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">investigation</governor>
          <dependent id="13">sexual</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">investigation</governor>
          <dependent id="14">abuse</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">stage</governor>
          <dependent id="15">investigation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">MacFarlane</governor>
          <dependent id="16">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">conducted</governor>
          <dependent id="17">MacFarlane</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">worker</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">worker</governor>
          <dependent id="20">social</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">MacFarlane</governor>
          <dependent id="21">worker</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">MacFarlane</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">MacFarlane</governor>
          <dependent id="23">director</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">Center</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">Center</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Center</governor>
          <dependent id="26">Child</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Center</governor>
          <dependent id="27">Sexual</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Center</governor>
          <dependent id="28">Abuse</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">director</governor>
          <dependent id="29">Center</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">International</governor>
          <dependent id="30">at</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="34">International</governor>
          <dependent id="31">Children</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">Children</governor>
          <dependent id="32">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">International</governor>
          <dependent id="33">Institute</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">conducted</governor>
          <dependent id="34">International</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Child Sexual Abuse Center at Children 's Institute International" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="26" string="Child" />
            <token id="27" string="Sexual" />
            <token id="28" string="Abuse" />
            <token id="29" string="Center" />
            <token id="30" string="at" />
            <token id="31" string="Children" />
            <token id="32" string="'s" />
            <token id="33" string="Institute" />
            <token id="34" string="International" />
          </tokens>
        </entity>
        <entity id="2" string="sexual abuse" type="CRIMINAL_CHARGE" score="0.0">
          <tokens>
            <token id="13" string="sexual" />
            <token id="14" string="abuse" />
          </tokens>
        </entity>
        <entity id="3" string="MacFarlane" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="MacFarlane" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>MacFarlane said Thursday she still believes children from the school had been molested and that they had not fabricated their accounts of abuse.</content>
      <tokens>
        <token id="1" string="MacFarlane" lemma="MacFarlane" stem="macfarlan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Thursday" lemma="Thursday" stem="thursdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="believes" lemma="believe" stem="believ" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="molested" lemma="molest" stem="molest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="fabricated" lemma="fabricate" stem="fabric" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="accounts" lemma="account" stem="account" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="abuse" lemma="abuse" stem="abus" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP MacFarlane)) (VP (VBD said) (NP-TMP (NNP Thursday)) (SBAR (SBAR (S (NP (PRP she)) (ADVP (RB still)) (VP (VBZ believes) (SBAR (S (NP (NP (NNS children)) (PP (IN from) (NP (DT the) (NN school)))) (VP (VBD had) (VP (VBN been) (VP (VBN molested))))))))) (CC and) (SBAR (IN that) (S (NP (PRP they)) (VP (VBD had) (RB not) (VP (VBN fabricated) (NP (NP (PRP$ their) (NNS accounts)) (PP (IN of) (NP (NN abuse)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="abuse" type="NP">
          <tokens>
            <token id="23" string="abuse" />
          </tokens>
        </chunking>
        <chunking id="2" string="believes children from the school had been molested" type="VP">
          <tokens>
            <token id="6" string="believes" />
            <token id="7" string="children" />
            <token id="8" string="from" />
            <token id="9" string="the" />
            <token id="10" string="school" />
            <token id="11" string="had" />
            <token id="12" string="been" />
            <token id="13" string="molested" />
          </tokens>
        </chunking>
        <chunking id="3" string="had not fabricated their accounts of abuse" type="VP">
          <tokens>
            <token id="17" string="had" />
            <token id="18" string="not" />
            <token id="19" string="fabricated" />
            <token id="20" string="their" />
            <token id="21" string="accounts" />
            <token id="22" string="of" />
            <token id="23" string="abuse" />
          </tokens>
        </chunking>
        <chunking id="4" string="that they had not fabricated their accounts of abuse" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="they" />
            <token id="17" string="had" />
            <token id="18" string="not" />
            <token id="19" string="fabricated" />
            <token id="20" string="their" />
            <token id="21" string="accounts" />
            <token id="22" string="of" />
            <token id="23" string="abuse" />
          </tokens>
        </chunking>
        <chunking id="5" string="had been molested" type="VP">
          <tokens>
            <token id="11" string="had" />
            <token id="12" string="been" />
            <token id="13" string="molested" />
          </tokens>
        </chunking>
        <chunking id="6" string="fabricated their accounts of abuse" type="VP">
          <tokens>
            <token id="19" string="fabricated" />
            <token id="20" string="their" />
            <token id="21" string="accounts" />
            <token id="22" string="of" />
            <token id="23" string="abuse" />
          </tokens>
        </chunking>
        <chunking id="7" string="said Thursday she still believes children from the school had been molested and that they had not fabricated their accounts of abuse" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="Thursday" />
            <token id="4" string="she" />
            <token id="5" string="still" />
            <token id="6" string="believes" />
            <token id="7" string="children" />
            <token id="8" string="from" />
            <token id="9" string="the" />
            <token id="10" string="school" />
            <token id="11" string="had" />
            <token id="12" string="been" />
            <token id="13" string="molested" />
            <token id="14" string="and" />
            <token id="15" string="that" />
            <token id="16" string="they" />
            <token id="17" string="had" />
            <token id="18" string="not" />
            <token id="19" string="fabricated" />
            <token id="20" string="their" />
            <token id="21" string="accounts" />
            <token id="22" string="of" />
            <token id="23" string="abuse" />
          </tokens>
        </chunking>
        <chunking id="8" string="she" type="NP">
          <tokens>
            <token id="4" string="she" />
          </tokens>
        </chunking>
        <chunking id="9" string="she still believes children from the school had been molested and that they had not fabricated their accounts of abuse" type="SBAR">
          <tokens>
            <token id="4" string="she" />
            <token id="5" string="still" />
            <token id="6" string="believes" />
            <token id="7" string="children" />
            <token id="8" string="from" />
            <token id="9" string="the" />
            <token id="10" string="school" />
            <token id="11" string="had" />
            <token id="12" string="been" />
            <token id="13" string="molested" />
            <token id="14" string="and" />
            <token id="15" string="that" />
            <token id="16" string="they" />
            <token id="17" string="had" />
            <token id="18" string="not" />
            <token id="19" string="fabricated" />
            <token id="20" string="their" />
            <token id="21" string="accounts" />
            <token id="22" string="of" />
            <token id="23" string="abuse" />
          </tokens>
        </chunking>
        <chunking id="10" string="the school" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="school" />
          </tokens>
        </chunking>
        <chunking id="11" string="they" type="NP">
          <tokens>
            <token id="16" string="they" />
          </tokens>
        </chunking>
        <chunking id="12" string="children from the school had been molested" type="SBAR">
          <tokens>
            <token id="7" string="children" />
            <token id="8" string="from" />
            <token id="9" string="the" />
            <token id="10" string="school" />
            <token id="11" string="had" />
            <token id="12" string="been" />
            <token id="13" string="molested" />
          </tokens>
        </chunking>
        <chunking id="13" string="she still believes children from the school had been molested" type="SBAR">
          <tokens>
            <token id="4" string="she" />
            <token id="5" string="still" />
            <token id="6" string="believes" />
            <token id="7" string="children" />
            <token id="8" string="from" />
            <token id="9" string="the" />
            <token id="10" string="school" />
            <token id="11" string="had" />
            <token id="12" string="been" />
            <token id="13" string="molested" />
          </tokens>
        </chunking>
        <chunking id="14" string="children" type="NP">
          <tokens>
            <token id="7" string="children" />
          </tokens>
        </chunking>
        <chunking id="15" string="been molested" type="VP">
          <tokens>
            <token id="12" string="been" />
            <token id="13" string="molested" />
          </tokens>
        </chunking>
        <chunking id="16" string="their accounts" type="NP">
          <tokens>
            <token id="20" string="their" />
            <token id="21" string="accounts" />
          </tokens>
        </chunking>
        <chunking id="17" string="children from the school" type="NP">
          <tokens>
            <token id="7" string="children" />
            <token id="8" string="from" />
            <token id="9" string="the" />
            <token id="10" string="school" />
          </tokens>
        </chunking>
        <chunking id="18" string="molested" type="VP">
          <tokens>
            <token id="13" string="molested" />
          </tokens>
        </chunking>
        <chunking id="19" string="MacFarlane" type="NP">
          <tokens>
            <token id="1" string="MacFarlane" />
          </tokens>
        </chunking>
        <chunking id="20" string="their accounts of abuse" type="NP">
          <tokens>
            <token id="20" string="their" />
            <token id="21" string="accounts" />
            <token id="22" string="of" />
            <token id="23" string="abuse" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">MacFarlane</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="2">said</governor>
          <dependent id="3">Thursday</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">believes</governor>
          <dependent id="4">she</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">believes</governor>
          <dependent id="5">still</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="6">believes</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">molested</governor>
          <dependent id="7">children</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">school</governor>
          <dependent id="8">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">school</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">children</governor>
          <dependent id="10">school</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">molested</governor>
          <dependent id="11">had</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">molested</governor>
          <dependent id="12">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">believes</governor>
          <dependent id="13">molested</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">believes</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">fabricated</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">fabricated</governor>
          <dependent id="16">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">fabricated</governor>
          <dependent id="17">had</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="19">fabricated</governor>
          <dependent id="18">not</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">believes</governor>
          <dependent id="19">fabricated</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">accounts</governor>
          <dependent id="20">their</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">fabricated</governor>
          <dependent id="21">accounts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">abuse</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">accounts</governor>
          <dependent id="23">abuse</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thursday" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="Thursday" />
          </tokens>
        </entity>
        <entity id="2" string="MacFarlane" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="MacFarlane" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>``This agency would never have gone all the way through what we have if we did not believe these children,&amp;apost;&amp;apost; she said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="agency" lemma="agency" stem="agenc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="gone" lemma="go" stem="gone" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="all" lemma="all" stem="all" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="believe" lemma="believe" stem="believ" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="these" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (DT This) (NN agency)) (VP (MD would) (ADVP (RB never)) (VP (VB have) (VP (VBN gone) (NP (PDT all) (DT the) (NN way)) (PP (IN through) (SBAR (WHNP (WP what)) (S (NP (PRP we)) (VP (VBP have) (SBAR (IN if) (S (NP (PRP we)) (VP (VBD did) (RB not) (VP (VB believe) (NP (DT these) (NNS children)))))))))))))) (, ,) ('' '') (NP (PRP she)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="have if we did not believe these children" type="VP">
          <tokens>
            <token id="14" string="have" />
            <token id="15" string="if" />
            <token id="16" string="we" />
            <token id="17" string="did" />
            <token id="18" string="not" />
            <token id="19" string="believe" />
            <token id="20" string="these" />
            <token id="21" string="children" />
          </tokens>
        </chunking>
        <chunking id="2" string="believe these children" type="VP">
          <tokens>
            <token id="19" string="believe" />
            <token id="20" string="these" />
            <token id="21" string="children" />
          </tokens>
        </chunking>
        <chunking id="3" string="these children" type="NP">
          <tokens>
            <token id="20" string="these" />
            <token id="21" string="children" />
          </tokens>
        </chunking>
        <chunking id="4" string="This agency" type="NP">
          <tokens>
            <token id="2" string="This" />
            <token id="3" string="agency" />
          </tokens>
        </chunking>
        <chunking id="5" string="what we have if we did not believe these children" type="SBAR">
          <tokens>
            <token id="12" string="what" />
            <token id="13" string="we" />
            <token id="14" string="have" />
            <token id="15" string="if" />
            <token id="16" string="we" />
            <token id="17" string="did" />
            <token id="18" string="not" />
            <token id="19" string="believe" />
            <token id="20" string="these" />
            <token id="21" string="children" />
          </tokens>
        </chunking>
        <chunking id="6" string="if we did not believe these children" type="SBAR">
          <tokens>
            <token id="15" string="if" />
            <token id="16" string="we" />
            <token id="17" string="did" />
            <token id="18" string="not" />
            <token id="19" string="believe" />
            <token id="20" string="these" />
            <token id="21" string="children" />
          </tokens>
        </chunking>
        <chunking id="7" string="gone all the way through what we have if we did not believe these children" type="VP">
          <tokens>
            <token id="7" string="gone" />
            <token id="8" string="all" />
            <token id="9" string="the" />
            <token id="10" string="way" />
            <token id="11" string="through" />
            <token id="12" string="what" />
            <token id="13" string="we" />
            <token id="14" string="have" />
            <token id="15" string="if" />
            <token id="16" string="we" />
            <token id="17" string="did" />
            <token id="18" string="not" />
            <token id="19" string="believe" />
            <token id="20" string="these" />
            <token id="21" string="children" />
          </tokens>
        </chunking>
        <chunking id="8" string="we" type="NP">
          <tokens>
            <token id="13" string="we" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="24" string="she" />
          </tokens>
        </chunking>
        <chunking id="10" string="all the way" type="NP">
          <tokens>
            <token id="8" string="all" />
            <token id="9" string="the" />
            <token id="10" string="way" />
          </tokens>
        </chunking>
        <chunking id="11" string="would never have gone all the way through what we have if we did not believe these children" type="VP">
          <tokens>
            <token id="4" string="would" />
            <token id="5" string="never" />
            <token id="6" string="have" />
            <token id="7" string="gone" />
            <token id="8" string="all" />
            <token id="9" string="the" />
            <token id="10" string="way" />
            <token id="11" string="through" />
            <token id="12" string="what" />
            <token id="13" string="we" />
            <token id="14" string="have" />
            <token id="15" string="if" />
            <token id="16" string="we" />
            <token id="17" string="did" />
            <token id="18" string="not" />
            <token id="19" string="believe" />
            <token id="20" string="these" />
            <token id="21" string="children" />
          </tokens>
        </chunking>
        <chunking id="12" string="did not believe these children" type="VP">
          <tokens>
            <token id="17" string="did" />
            <token id="18" string="not" />
            <token id="19" string="believe" />
            <token id="20" string="these" />
            <token id="21" string="children" />
          </tokens>
        </chunking>
        <chunking id="13" string="said" type="VP">
          <tokens>
            <token id="25" string="said" />
          </tokens>
        </chunking>
        <chunking id="14" string="have gone all the way through what we have if we did not believe these children" type="VP">
          <tokens>
            <token id="6" string="have" />
            <token id="7" string="gone" />
            <token id="8" string="all" />
            <token id="9" string="the" />
            <token id="10" string="way" />
            <token id="11" string="through" />
            <token id="12" string="what" />
            <token id="13" string="we" />
            <token id="14" string="have" />
            <token id="15" string="if" />
            <token id="16" string="we" />
            <token id="17" string="did" />
            <token id="18" string="not" />
            <token id="19" string="believe" />
            <token id="20" string="these" />
            <token id="21" string="children" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">agency</governor>
          <dependent id="2">This</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">gone</governor>
          <dependent id="3">agency</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">gone</governor>
          <dependent id="4">would</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">gone</governor>
          <dependent id="5">never</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">gone</governor>
          <dependent id="6">have</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="25">said</governor>
          <dependent id="7">gone</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="10">way</governor>
          <dependent id="8">all</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">way</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">gone</governor>
          <dependent id="10">way</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">have</governor>
          <dependent id="11">through</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">have</governor>
          <dependent id="12">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">have</governor>
          <dependent id="13">we</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">gone</governor>
          <dependent id="14">have</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">believe</governor>
          <dependent id="15">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">believe</governor>
          <dependent id="16">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">believe</governor>
          <dependent id="17">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="19">believe</governor>
          <dependent id="18">not</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">have</governor>
          <dependent id="19">believe</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">children</governor>
          <dependent id="20">these</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">believe</governor>
          <dependent id="21">children</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">said</governor>
          <dependent id="24">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="25">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>At least seven jurors who attended a news conference agreed the evidence showed children had been molested.</content>
      <tokens>
        <token id="1" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="least" lemma="least" stem="least" pos="JJS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="seven" lemma="seven" stem="seven" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="4" string="jurors" lemma="juror" stem="juror" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="attended" lemma="attend" stem="attend" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="news" lemma="news" stem="new" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="conference" lemma="conference" stem="confer" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="agreed" lemma="agree" stem="agre" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="evidence" lemma="evidence" stem="evid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="showed" lemma="show" stem="show" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="molested" lemma="molest" stem="molest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (QP (IN At) (JJS least) (CD seven)) (NNS jurors)) (SBAR (WHNP (WP who)) (S (VP (VBD attended) (NP (DT a) (NN news) (NN conference)))))) (VP (VBD agreed) (SBAR (S (NP (DT the) (NN evidence)) (VP (VBD showed) (SBAR (S (NP (NNS children)) (VP (VBD had) (VP (VBN been) (VP (VBN molested)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="who attended a news conference" type="SBAR">
          <tokens>
            <token id="5" string="who" />
            <token id="6" string="attended" />
            <token id="7" string="a" />
            <token id="8" string="news" />
            <token id="9" string="conference" />
          </tokens>
        </chunking>
        <chunking id="2" string="a news conference" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="news" />
            <token id="9" string="conference" />
          </tokens>
        </chunking>
        <chunking id="3" string="attended a news conference" type="VP">
          <tokens>
            <token id="6" string="attended" />
            <token id="7" string="a" />
            <token id="8" string="news" />
            <token id="9" string="conference" />
          </tokens>
        </chunking>
        <chunking id="4" string="agreed the evidence showed children had been molested" type="VP">
          <tokens>
            <token id="10" string="agreed" />
            <token id="11" string="the" />
            <token id="12" string="evidence" />
            <token id="13" string="showed" />
            <token id="14" string="children" />
            <token id="15" string="had" />
            <token id="16" string="been" />
            <token id="17" string="molested" />
          </tokens>
        </chunking>
        <chunking id="5" string="the evidence" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="6" string="children had been molested" type="SBAR">
          <tokens>
            <token id="14" string="children" />
            <token id="15" string="had" />
            <token id="16" string="been" />
            <token id="17" string="molested" />
          </tokens>
        </chunking>
        <chunking id="7" string="showed children had been molested" type="VP">
          <tokens>
            <token id="13" string="showed" />
            <token id="14" string="children" />
            <token id="15" string="had" />
            <token id="16" string="been" />
            <token id="17" string="molested" />
          </tokens>
        </chunking>
        <chunking id="8" string="had been molested" type="VP">
          <tokens>
            <token id="15" string="had" />
            <token id="16" string="been" />
            <token id="17" string="molested" />
          </tokens>
        </chunking>
        <chunking id="9" string="At least seven jurors" type="NP">
          <tokens>
            <token id="1" string="At" />
            <token id="2" string="least" />
            <token id="3" string="seven" />
            <token id="4" string="jurors" />
          </tokens>
        </chunking>
        <chunking id="10" string="the evidence showed children had been molested" type="SBAR">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="evidence" />
            <token id="13" string="showed" />
            <token id="14" string="children" />
            <token id="15" string="had" />
            <token id="16" string="been" />
            <token id="17" string="molested" />
          </tokens>
        </chunking>
        <chunking id="11" string="children" type="NP">
          <tokens>
            <token id="14" string="children" />
          </tokens>
        </chunking>
        <chunking id="12" string="been molested" type="VP">
          <tokens>
            <token id="16" string="been" />
            <token id="17" string="molested" />
          </tokens>
        </chunking>
        <chunking id="13" string="At least seven jurors who attended a news conference" type="NP">
          <tokens>
            <token id="1" string="At" />
            <token id="2" string="least" />
            <token id="3" string="seven" />
            <token id="4" string="jurors" />
            <token id="5" string="who" />
            <token id="6" string="attended" />
            <token id="7" string="a" />
            <token id="8" string="news" />
            <token id="9" string="conference" />
          </tokens>
        </chunking>
        <chunking id="14" string="molested" type="VP">
          <tokens>
            <token id="17" string="molested" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">least</governor>
          <dependent id="1">At</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="3">seven</governor>
          <dependent id="2">least</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">jurors</governor>
          <dependent id="3">seven</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">agreed</governor>
          <dependent id="4">jurors</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">attended</governor>
          <dependent id="5">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">jurors</governor>
          <dependent id="6">attended</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">conference</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">conference</governor>
          <dependent id="8">news</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">attended</governor>
          <dependent id="9">conference</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">agreed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">evidence</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">showed</governor>
          <dependent id="12">evidence</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">agreed</governor>
          <dependent id="13">showed</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="17">molested</governor>
          <dependent id="14">children</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">molested</governor>
          <dependent id="15">had</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="17">molested</governor>
          <dependent id="16">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">showed</governor>
          <dependent id="17">molested</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="seven" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="seven" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>But the jurors were sharply critical of the interviewers&amp;apost; technique at the institute.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="jurors" lemma="juror" stem="juror" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="sharply" lemma="sharply" stem="sharpli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="critical" lemma="critical" stem="critic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="interviewers" lemma="interviewer" stem="interview" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="technique" lemma="technique" stem="techniqu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="institute" lemma="institute" stem="institut" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (DT the) (NNS jurors)) (VP (VBD were) (ADJP (RB sharply) (JJ critical) (PP (IN of) (NP (NP (DT the) (NNS interviewers) (POS ')) (NN technique)))) (PP (IN at) (NP (DT the) (NN institute)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the interviewers '" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="interviewers" />
            <token id="10" string="'" />
          </tokens>
        </chunking>
        <chunking id="2" string="the interviewers ' technique" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="interviewers" />
            <token id="10" string="'" />
            <token id="11" string="technique" />
          </tokens>
        </chunking>
        <chunking id="3" string="the institute" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="institute" />
          </tokens>
        </chunking>
        <chunking id="4" string="the jurors" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="jurors" />
          </tokens>
        </chunking>
        <chunking id="5" string="were sharply critical of the interviewers ' technique at the institute" type="VP">
          <tokens>
            <token id="4" string="were" />
            <token id="5" string="sharply" />
            <token id="6" string="critical" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="interviewers" />
            <token id="10" string="'" />
            <token id="11" string="technique" />
            <token id="12" string="at" />
            <token id="13" string="the" />
            <token id="14" string="institute" />
          </tokens>
        </chunking>
        <chunking id="6" string="sharply critical of the interviewers ' technique" type="ADJP">
          <tokens>
            <token id="5" string="sharply" />
            <token id="6" string="critical" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="interviewers" />
            <token id="10" string="'" />
            <token id="11" string="technique" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="6">critical</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">jurors</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">critical</governor>
          <dependent id="3">jurors</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">critical</governor>
          <dependent id="4">were</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">critical</governor>
          <dependent id="5">sharply</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">critical</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">technique</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">interviewers</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">technique</governor>
          <dependent id="9">interviewers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">interviewers</governor>
          <dependent id="10">'</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">critical</governor>
          <dependent id="11">technique</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">institute</governor>
          <dependent id="12">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">institute</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">critical</governor>
          <dependent id="14">institute</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>``The children were never allowed to say in their own words what happened to them,&amp;apost;&amp;apost; said juror John Breese.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="allowed" lemma="allow" stem="allow" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="words" lemma="word" stem="word" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="happened" lemma="happen" stem="happen" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="juror" lemma="juror" stem="juror" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="22" string="Breese" lemma="Breese" stem="brees" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (DT The) (NNS children)) (VP (VBD were) (ADVP (RB never)) (VP (VBN allowed) (S (VP (TO to) (VP (VB say) (PP (IN in) (NP (NP (PRP$ their) (JJ own) (NNS words)) (SBAR (WHNP (WP what)) (S (VP (VBD happened) (PP (TO to) (NP (PRP them)))))))))))))) (, ,) ('' '') (VP (VBD said) (NP (NN juror))) (NP (NNP John) (NNP Breese)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="allowed to say in their own words what happened to them" type="VP">
          <tokens>
            <token id="6" string="allowed" />
            <token id="7" string="to" />
            <token id="8" string="say" />
            <token id="9" string="in" />
            <token id="10" string="their" />
            <token id="11" string="own" />
            <token id="12" string="words" />
            <token id="13" string="what" />
            <token id="14" string="happened" />
            <token id="15" string="to" />
            <token id="16" string="them" />
          </tokens>
        </chunking>
        <chunking id="2" string="to say in their own words what happened to them" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="say" />
            <token id="9" string="in" />
            <token id="10" string="their" />
            <token id="11" string="own" />
            <token id="12" string="words" />
            <token id="13" string="what" />
            <token id="14" string="happened" />
            <token id="15" string="to" />
            <token id="16" string="them" />
          </tokens>
        </chunking>
        <chunking id="3" string="juror" type="NP">
          <tokens>
            <token id="20" string="juror" />
          </tokens>
        </chunking>
        <chunking id="4" string="The children" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="children" />
          </tokens>
        </chunking>
        <chunking id="5" string="John Breese" type="NP">
          <tokens>
            <token id="21" string="John" />
            <token id="22" string="Breese" />
          </tokens>
        </chunking>
        <chunking id="6" string="said juror" type="VP">
          <tokens>
            <token id="19" string="said" />
            <token id="20" string="juror" />
          </tokens>
        </chunking>
        <chunking id="7" string="happened to them" type="VP">
          <tokens>
            <token id="14" string="happened" />
            <token id="15" string="to" />
            <token id="16" string="them" />
          </tokens>
        </chunking>
        <chunking id="8" string="them" type="NP">
          <tokens>
            <token id="16" string="them" />
          </tokens>
        </chunking>
        <chunking id="9" string="their own words" type="NP">
          <tokens>
            <token id="10" string="their" />
            <token id="11" string="own" />
            <token id="12" string="words" />
          </tokens>
        </chunking>
        <chunking id="10" string="what happened to them" type="SBAR">
          <tokens>
            <token id="13" string="what" />
            <token id="14" string="happened" />
            <token id="15" string="to" />
            <token id="16" string="them" />
          </tokens>
        </chunking>
        <chunking id="11" string="say in their own words what happened to them" type="VP">
          <tokens>
            <token id="8" string="say" />
            <token id="9" string="in" />
            <token id="10" string="their" />
            <token id="11" string="own" />
            <token id="12" string="words" />
            <token id="13" string="what" />
            <token id="14" string="happened" />
            <token id="15" string="to" />
            <token id="16" string="them" />
          </tokens>
        </chunking>
        <chunking id="12" string="were never allowed to say in their own words what happened to them" type="VP">
          <tokens>
            <token id="4" string="were" />
            <token id="5" string="never" />
            <token id="6" string="allowed" />
            <token id="7" string="to" />
            <token id="8" string="say" />
            <token id="9" string="in" />
            <token id="10" string="their" />
            <token id="11" string="own" />
            <token id="12" string="words" />
            <token id="13" string="what" />
            <token id="14" string="happened" />
            <token id="15" string="to" />
            <token id="16" string="them" />
          </tokens>
        </chunking>
        <chunking id="13" string="their own words what happened to them" type="NP">
          <tokens>
            <token id="10" string="their" />
            <token id="11" string="own" />
            <token id="12" string="words" />
            <token id="13" string="what" />
            <token id="14" string="happened" />
            <token id="15" string="to" />
            <token id="16" string="them" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">children</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">allowed</governor>
          <dependent id="3">children</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">allowed</governor>
          <dependent id="4">were</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">allowed</governor>
          <dependent id="5">never</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">said</governor>
          <dependent id="6">allowed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">say</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">allowed</governor>
          <dependent id="8">say</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">words</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">words</governor>
          <dependent id="10">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">words</governor>
          <dependent id="11">own</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">say</governor>
          <dependent id="12">words</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">happened</governor>
          <dependent id="13">what</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">words</governor>
          <dependent id="14">happened</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">them</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">happened</governor>
          <dependent id="16">them</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">said</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">said</governor>
          <dependent id="20">juror</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Breese</governor>
          <dependent id="21">John</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">said</governor>
          <dependent id="22">Breese</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Breese" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="John" />
            <token id="22" string="Breese" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="false">
      <content>``All the questions were leading.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="All" lemma="all" stem="all" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="questions" lemma="question" stem="question" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="leading" lemma="lead" stem="lead" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PDT All) (DT the) (NNS questions)) (VP (VBD were) (VP (VBG leading))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="All the questions" type="NP">
          <tokens>
            <token id="2" string="All" />
            <token id="3" string="the" />
            <token id="4" string="questions" />
          </tokens>
        </chunking>
        <chunking id="2" string="leading" type="VP">
          <tokens>
            <token id="6" string="leading" />
          </tokens>
        </chunking>
        <chunking id="3" string="were leading" type="VP">
          <tokens>
            <token id="5" string="were" />
            <token id="6" string="leading" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det:predet">
          <governor id="4">questions</governor>
          <dependent id="2">All</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">questions</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">leading</governor>
          <dependent id="4">questions</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">leading</governor>
          <dependent id="5">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">leading</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>``If the CII tapes had not been entered into evidence and I had not seen them, I could have believed the children a little more,&amp;apost;&amp;apost; juror Brenda Williams said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="CII" lemma="cii" stem="cii" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="5" string="tapes" lemma="tape" stem="tape" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="entered" lemma="enter" stem="enter" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="evidence" lemma="evidence" stem="evid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="seen" lemma="see" stem="seen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="believed" lemma="believe" stem="believ" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="little" lemma="little" stem="littl" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="juror" lemma="juror" stem="juror" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="Brenda" lemma="Brenda" stem="brenda" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="32" string="Williams" lemma="Williams" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="33" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (SBAR (IN If) (S (S (NP (DT the) (NN CII) (NNS tapes)) (VP (VBD had) (RB not) (VP (VBN been) (VP (VBN entered) (PP (IN into) (NP (NN evidence))))))) (CC and) (S (NP (PRP I)) (VP (VBD had) (RB not) (VP (VBN seen) (NP (PRP them))))))) (, ,) (NP (PRP I)) (VP (MD could) (VP (VB have) (VP (VBN believed) (NP (DT the) (NNS children)) (ADVP (NP (DT a) (RB little)) (RBR more)))))) (, ,) ('' '') (NP (NN juror) (NNP Brenda) (NNP Williams)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="If the CII tapes had not been entered into evidence and I had not seen them" type="SBAR">
          <tokens>
            <token id="2" string="If" />
            <token id="3" string="the" />
            <token id="4" string="CII" />
            <token id="5" string="tapes" />
            <token id="6" string="had" />
            <token id="7" string="not" />
            <token id="8" string="been" />
            <token id="9" string="entered" />
            <token id="10" string="into" />
            <token id="11" string="evidence" />
            <token id="12" string="and" />
            <token id="13" string="I" />
            <token id="14" string="had" />
            <token id="15" string="not" />
            <token id="16" string="seen" />
            <token id="17" string="them" />
          </tokens>
        </chunking>
        <chunking id="2" string="the CII tapes" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="CII" />
            <token id="5" string="tapes" />
          </tokens>
        </chunking>
        <chunking id="3" string="had not been entered into evidence" type="VP">
          <tokens>
            <token id="6" string="had" />
            <token id="7" string="not" />
            <token id="8" string="been" />
            <token id="9" string="entered" />
            <token id="10" string="into" />
            <token id="11" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="4" string="evidence" type="NP">
          <tokens>
            <token id="11" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="5" string="juror Brenda Williams" type="NP">
          <tokens>
            <token id="30" string="juror" />
            <token id="31" string="Brenda" />
            <token id="32" string="Williams" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="13" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="could have believed the children a little more" type="VP">
          <tokens>
            <token id="20" string="could" />
            <token id="21" string="have" />
            <token id="22" string="believed" />
            <token id="23" string="the" />
            <token id="24" string="children" />
            <token id="25" string="a" />
            <token id="26" string="little" />
            <token id="27" string="more" />
          </tokens>
        </chunking>
        <chunking id="8" string="them" type="NP">
          <tokens>
            <token id="17" string="them" />
          </tokens>
        </chunking>
        <chunking id="9" string="believed the children a little more" type="VP">
          <tokens>
            <token id="22" string="believed" />
            <token id="23" string="the" />
            <token id="24" string="children" />
            <token id="25" string="a" />
            <token id="26" string="little" />
            <token id="27" string="more" />
          </tokens>
        </chunking>
        <chunking id="10" string="been entered into evidence" type="VP">
          <tokens>
            <token id="8" string="been" />
            <token id="9" string="entered" />
            <token id="10" string="into" />
            <token id="11" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="11" string="had not seen them" type="VP">
          <tokens>
            <token id="14" string="had" />
            <token id="15" string="not" />
            <token id="16" string="seen" />
            <token id="17" string="them" />
          </tokens>
        </chunking>
        <chunking id="12" string="have believed the children a little more" type="VP">
          <tokens>
            <token id="21" string="have" />
            <token id="22" string="believed" />
            <token id="23" string="the" />
            <token id="24" string="children" />
            <token id="25" string="a" />
            <token id="26" string="little" />
            <token id="27" string="more" />
          </tokens>
        </chunking>
        <chunking id="13" string="the children" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="children" />
          </tokens>
        </chunking>
        <chunking id="14" string="a little" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="little" />
          </tokens>
        </chunking>
        <chunking id="15" string="seen them" type="VP">
          <tokens>
            <token id="16" string="seen" />
            <token id="17" string="them" />
          </tokens>
        </chunking>
        <chunking id="16" string="said" type="VP">
          <tokens>
            <token id="33" string="said" />
          </tokens>
        </chunking>
        <chunking id="17" string="entered into evidence" type="VP">
          <tokens>
            <token id="9" string="entered" />
            <token id="10" string="into" />
            <token id="11" string="evidence" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="9">entered</governor>
          <dependent id="2">If</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">tapes</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">tapes</governor>
          <dependent id="4">CII</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">entered</governor>
          <dependent id="5">tapes</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">entered</governor>
          <dependent id="6">had</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="9">entered</governor>
          <dependent id="7">not</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">entered</governor>
          <dependent id="8">been</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="22">believed</governor>
          <dependent id="9">entered</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">evidence</governor>
          <dependent id="10">into</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">entered</governor>
          <dependent id="11">evidence</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">entered</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">seen</governor>
          <dependent id="13">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">seen</governor>
          <dependent id="14">had</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="16">seen</governor>
          <dependent id="15">not</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">entered</governor>
          <dependent id="16">seen</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">seen</governor>
          <dependent id="17">them</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">believed</governor>
          <dependent id="19">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">believed</governor>
          <dependent id="20">could</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">believed</governor>
          <dependent id="21">have</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="33">said</governor>
          <dependent id="22">believed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">children</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">believed</governor>
          <dependent id="24">children</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">little</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="27">more</governor>
          <dependent id="26">little</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">believed</governor>
          <dependent id="27">more</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">Williams</governor>
          <dependent id="30">juror</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">Williams</governor>
          <dependent id="31">Brenda</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">said</governor>
          <dependent id="32">Williams</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="33">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="CII" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="4" string="CII" />
          </tokens>
        </entity>
        <entity id="2" string="Brenda Williams" type="PERSON" score="0.0">
          <tokens>
            <token id="31" string="Brenda" />
            <token id="32" string="Williams" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>But MacFarlane said that the interviewing techniques were sound, noting that small children must be interviewed differently than adults.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="MacFarlane" lemma="MacFarlane" stem="macfarlan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="interviewing" lemma="interview" stem="interview" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="techniques" lemma="technique" stem="techniqu" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="sound" lemma="sound" stem="sound" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="noting" lemma="note" stem="note" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="small" lemma="small" stem="small" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="must" lemma="must" stem="must" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="interviewed" lemma="interview" stem="interview" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="differently" lemma="differently" stem="differ" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="adults" lemma="adult" stem="adult" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NNP MacFarlane)) (VP (VBD said) (SBAR (IN that) (S (NP (DT the) (VBG interviewing) (NNS techniques)) (VP (VBD were) (ADJP (JJ sound)) (, ,) (S (VP (VBG noting) (SBAR (IN that) (S (NP (JJ small) (NNS children)) (VP (MD must) (VP (VB be) (VP (VBN interviewed) (ADVP (RB differently)) (PP (IN than) (NP (NNS adults)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="be interviewed differently than adults" type="VP">
          <tokens>
            <token id="16" string="be" />
            <token id="17" string="interviewed" />
            <token id="18" string="differently" />
            <token id="19" string="than" />
            <token id="20" string="adults" />
          </tokens>
        </chunking>
        <chunking id="2" string="said that the interviewing techniques were sound , noting that small children must be interviewed differently than adults" type="VP">
          <tokens>
            <token id="3" string="said" />
            <token id="4" string="that" />
            <token id="5" string="the" />
            <token id="6" string="interviewing" />
            <token id="7" string="techniques" />
            <token id="8" string="were" />
            <token id="9" string="sound" />
            <token id="10" string="," />
            <token id="11" string="noting" />
            <token id="12" string="that" />
            <token id="13" string="small" />
            <token id="14" string="children" />
            <token id="15" string="must" />
            <token id="16" string="be" />
            <token id="17" string="interviewed" />
            <token id="18" string="differently" />
            <token id="19" string="than" />
            <token id="20" string="adults" />
          </tokens>
        </chunking>
        <chunking id="3" string="sound" type="ADJP">
          <tokens>
            <token id="9" string="sound" />
          </tokens>
        </chunking>
        <chunking id="4" string="adults" type="NP">
          <tokens>
            <token id="20" string="adults" />
          </tokens>
        </chunking>
        <chunking id="5" string="that the interviewing techniques were sound , noting that small children must be interviewed differently than adults" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="the" />
            <token id="6" string="interviewing" />
            <token id="7" string="techniques" />
            <token id="8" string="were" />
            <token id="9" string="sound" />
            <token id="10" string="," />
            <token id="11" string="noting" />
            <token id="12" string="that" />
            <token id="13" string="small" />
            <token id="14" string="children" />
            <token id="15" string="must" />
            <token id="16" string="be" />
            <token id="17" string="interviewed" />
            <token id="18" string="differently" />
            <token id="19" string="than" />
            <token id="20" string="adults" />
          </tokens>
        </chunking>
        <chunking id="6" string="that small children must be interviewed differently than adults" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="small" />
            <token id="14" string="children" />
            <token id="15" string="must" />
            <token id="16" string="be" />
            <token id="17" string="interviewed" />
            <token id="18" string="differently" />
            <token id="19" string="than" />
            <token id="20" string="adults" />
          </tokens>
        </chunking>
        <chunking id="7" string="the interviewing techniques" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="interviewing" />
            <token id="7" string="techniques" />
          </tokens>
        </chunking>
        <chunking id="8" string="noting that small children must be interviewed differently than adults" type="VP">
          <tokens>
            <token id="11" string="noting" />
            <token id="12" string="that" />
            <token id="13" string="small" />
            <token id="14" string="children" />
            <token id="15" string="must" />
            <token id="16" string="be" />
            <token id="17" string="interviewed" />
            <token id="18" string="differently" />
            <token id="19" string="than" />
            <token id="20" string="adults" />
          </tokens>
        </chunking>
        <chunking id="9" string="were sound , noting that small children must be interviewed differently than adults" type="VP">
          <tokens>
            <token id="8" string="were" />
            <token id="9" string="sound" />
            <token id="10" string="," />
            <token id="11" string="noting" />
            <token id="12" string="that" />
            <token id="13" string="small" />
            <token id="14" string="children" />
            <token id="15" string="must" />
            <token id="16" string="be" />
            <token id="17" string="interviewed" />
            <token id="18" string="differently" />
            <token id="19" string="than" />
            <token id="20" string="adults" />
          </tokens>
        </chunking>
        <chunking id="10" string="must be interviewed differently than adults" type="VP">
          <tokens>
            <token id="15" string="must" />
            <token id="16" string="be" />
            <token id="17" string="interviewed" />
            <token id="18" string="differently" />
            <token id="19" string="than" />
            <token id="20" string="adults" />
          </tokens>
        </chunking>
        <chunking id="11" string="interviewed differently than adults" type="VP">
          <tokens>
            <token id="17" string="interviewed" />
            <token id="18" string="differently" />
            <token id="19" string="than" />
            <token id="20" string="adults" />
          </tokens>
        </chunking>
        <chunking id="12" string="small children" type="NP">
          <tokens>
            <token id="13" string="small" />
            <token id="14" string="children" />
          </tokens>
        </chunking>
        <chunking id="13" string="MacFarlane" type="NP">
          <tokens>
            <token id="2" string="MacFarlane" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">said</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">said</governor>
          <dependent id="2">MacFarlane</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">sound</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">techniques</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">techniques</governor>
          <dependent id="6">interviewing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">sound</governor>
          <dependent id="7">techniques</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">sound</governor>
          <dependent id="8">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">said</governor>
          <dependent id="9">sound</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">sound</governor>
          <dependent id="11">noting</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">interviewed</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">children</governor>
          <dependent id="13">small</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="17">interviewed</governor>
          <dependent id="14">children</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">interviewed</governor>
          <dependent id="15">must</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="17">interviewed</governor>
          <dependent id="16">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">noting</governor>
          <dependent id="17">interviewed</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">interviewed</governor>
          <dependent id="18">differently</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">adults</governor>
          <dependent id="19">than</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">interviewed</governor>
          <dependent id="20">adults</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="MacFarlane" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="MacFarlane" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>``I didn&amp;apost;t put words into their mouths,&amp;apost;&amp;apost; she said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="put" lemma="put" stem="put" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="words" lemma="word" stem="word" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="mouths" lemma="mouth" stem="mouth" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBD did) (RB n't) (VP (VB put) (NP (NNS words)) (PP (IN into) (NP (PRP$ their) (NNS mouths)))))) (, ,) ('' '') (NP (PRP she)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="put words into their mouths" type="VP">
          <tokens>
            <token id="5" string="put" />
            <token id="6" string="words" />
            <token id="7" string="into" />
            <token id="8" string="their" />
            <token id="9" string="mouths" />
          </tokens>
        </chunking>
        <chunking id="2" string="did n't put words into their mouths" type="VP">
          <tokens>
            <token id="3" string="did" />
            <token id="4" string="n't" />
            <token id="5" string="put" />
            <token id="6" string="words" />
            <token id="7" string="into" />
            <token id="8" string="their" />
            <token id="9" string="mouths" />
          </tokens>
        </chunking>
        <chunking id="3" string="their mouths" type="NP">
          <tokens>
            <token id="8" string="their" />
            <token id="9" string="mouths" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="words" type="NP">
          <tokens>
            <token id="6" string="words" />
          </tokens>
        </chunking>
        <chunking id="6" string="said" type="VP">
          <tokens>
            <token id="13" string="said" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="12" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">put</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">put</governor>
          <dependent id="3">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">put</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">said</governor>
          <dependent id="5">put</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">put</governor>
          <dependent id="6">words</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">mouths</governor>
          <dependent id="7">into</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">mouths</governor>
          <dependent id="8">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">put</governor>
          <dependent id="9">mouths</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">said</governor>
          <dependent id="12">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>``I tried to enable them to get over their fears.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="tried" lemma="try" stem="tri" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="enable" lemma="enable" stem="enabl" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="get" lemma="get" stem="get" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="fears" lemma="fear" stem="fear" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBD tried) (S (VP (TO to) (VP (VB enable) (S (NP (PRP them)) (VP (TO to) (VP (VB get) (PP (IN over) (NP (PRP$ their) (NNS fears)))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="to enable them to get over their fears" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="enable" />
            <token id="6" string="them" />
            <token id="7" string="to" />
            <token id="8" string="get" />
            <token id="9" string="over" />
            <token id="10" string="their" />
            <token id="11" string="fears" />
          </tokens>
        </chunking>
        <chunking id="2" string="enable them to get over their fears" type="VP">
          <tokens>
            <token id="5" string="enable" />
            <token id="6" string="them" />
            <token id="7" string="to" />
            <token id="8" string="get" />
            <token id="9" string="over" />
            <token id="10" string="their" />
            <token id="11" string="fears" />
          </tokens>
        </chunking>
        <chunking id="3" string="tried to enable them to get over their fears" type="VP">
          <tokens>
            <token id="3" string="tried" />
            <token id="4" string="to" />
            <token id="5" string="enable" />
            <token id="6" string="them" />
            <token id="7" string="to" />
            <token id="8" string="get" />
            <token id="9" string="over" />
            <token id="10" string="their" />
            <token id="11" string="fears" />
          </tokens>
        </chunking>
        <chunking id="4" string="get over their fears" type="VP">
          <tokens>
            <token id="8" string="get" />
            <token id="9" string="over" />
            <token id="10" string="their" />
            <token id="11" string="fears" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="their fears" type="NP">
          <tokens>
            <token id="10" string="their" />
            <token id="11" string="fears" />
          </tokens>
        </chunking>
        <chunking id="7" string="them" type="NP">
          <tokens>
            <token id="6" string="them" />
          </tokens>
        </chunking>
        <chunking id="8" string="to get over their fears" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="get" />
            <token id="9" string="over" />
            <token id="10" string="their" />
            <token id="11" string="fears" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">tried</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">tried</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">enable</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">tried</governor>
          <dependent id="5">enable</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">enable</governor>
          <dependent id="6">them</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">get</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">enable</governor>
          <dependent id="8">get</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">fears</governor>
          <dependent id="9">over</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">fears</governor>
          <dependent id="10">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">get</governor>
          <dependent id="11">fears</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="17" has_coreference="false">
      <content>MacFarlane acknowledged that some procedures could have been done differently, including conducting more interviews over a longer period of time.</content>
      <tokens>
        <token id="1" string="MacFarlane" lemma="MacFarlane" stem="macfarlan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="acknowledged" lemma="acknowledge" stem="acknowledg" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="procedures" lemma="procedure" stem="procedur" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="done" lemma="do" stem="done" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="differently" lemma="differently" stem="differ" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="conducting" lemma="conduct" stem="conduct" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="interviews" lemma="interview" stem="interview" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="longer" lemma="longer" stem="longer" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="period" lemma="period" stem="period" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP MacFarlane)) (VP (VBD acknowledged) (SBAR (IN that) (S (NP (DT some) (NNS procedures)) (VP (MD could) (VP (VB have) (VP (VBN been) (VP (VBN done) (ADVP (RB differently)) (, ,) (PP (VBG including) (S (VP (VBG conducting) (NP (JJR more) (NNS interviews)) (PP (IN over) (NP (NP (DT a) (JJR longer) (NN period)) (PP (IN of) (NP (NN time))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="some procedures" type="NP">
          <tokens>
            <token id="4" string="some" />
            <token id="5" string="procedures" />
          </tokens>
        </chunking>
        <chunking id="2" string="more interviews" type="NP">
          <tokens>
            <token id="14" string="more" />
            <token id="15" string="interviews" />
          </tokens>
        </chunking>
        <chunking id="3" string="acknowledged that some procedures could have been done differently , including conducting more interviews over a longer period of time" type="VP">
          <tokens>
            <token id="2" string="acknowledged" />
            <token id="3" string="that" />
            <token id="4" string="some" />
            <token id="5" string="procedures" />
            <token id="6" string="could" />
            <token id="7" string="have" />
            <token id="8" string="been" />
            <token id="9" string="done" />
            <token id="10" string="differently" />
            <token id="11" string="," />
            <token id="12" string="including" />
            <token id="13" string="conducting" />
            <token id="14" string="more" />
            <token id="15" string="interviews" />
            <token id="16" string="over" />
            <token id="17" string="a" />
            <token id="18" string="longer" />
            <token id="19" string="period" />
            <token id="20" string="of" />
            <token id="21" string="time" />
          </tokens>
        </chunking>
        <chunking id="4" string="have been done differently , including conducting more interviews over a longer period of time" type="VP">
          <tokens>
            <token id="7" string="have" />
            <token id="8" string="been" />
            <token id="9" string="done" />
            <token id="10" string="differently" />
            <token id="11" string="," />
            <token id="12" string="including" />
            <token id="13" string="conducting" />
            <token id="14" string="more" />
            <token id="15" string="interviews" />
            <token id="16" string="over" />
            <token id="17" string="a" />
            <token id="18" string="longer" />
            <token id="19" string="period" />
            <token id="20" string="of" />
            <token id="21" string="time" />
          </tokens>
        </chunking>
        <chunking id="5" string="been done differently , including conducting more interviews over a longer period of time" type="VP">
          <tokens>
            <token id="8" string="been" />
            <token id="9" string="done" />
            <token id="10" string="differently" />
            <token id="11" string="," />
            <token id="12" string="including" />
            <token id="13" string="conducting" />
            <token id="14" string="more" />
            <token id="15" string="interviews" />
            <token id="16" string="over" />
            <token id="17" string="a" />
            <token id="18" string="longer" />
            <token id="19" string="period" />
            <token id="20" string="of" />
            <token id="21" string="time" />
          </tokens>
        </chunking>
        <chunking id="6" string="a longer period" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="longer" />
            <token id="19" string="period" />
          </tokens>
        </chunking>
        <chunking id="7" string="a longer period of time" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="longer" />
            <token id="19" string="period" />
            <token id="20" string="of" />
            <token id="21" string="time" />
          </tokens>
        </chunking>
        <chunking id="8" string="could have been done differently , including conducting more interviews over a longer period of time" type="VP">
          <tokens>
            <token id="6" string="could" />
            <token id="7" string="have" />
            <token id="8" string="been" />
            <token id="9" string="done" />
            <token id="10" string="differently" />
            <token id="11" string="," />
            <token id="12" string="including" />
            <token id="13" string="conducting" />
            <token id="14" string="more" />
            <token id="15" string="interviews" />
            <token id="16" string="over" />
            <token id="17" string="a" />
            <token id="18" string="longer" />
            <token id="19" string="period" />
            <token id="20" string="of" />
            <token id="21" string="time" />
          </tokens>
        </chunking>
        <chunking id="9" string="done differently , including conducting more interviews over a longer period of time" type="VP">
          <tokens>
            <token id="9" string="done" />
            <token id="10" string="differently" />
            <token id="11" string="," />
            <token id="12" string="including" />
            <token id="13" string="conducting" />
            <token id="14" string="more" />
            <token id="15" string="interviews" />
            <token id="16" string="over" />
            <token id="17" string="a" />
            <token id="18" string="longer" />
            <token id="19" string="period" />
            <token id="20" string="of" />
            <token id="21" string="time" />
          </tokens>
        </chunking>
        <chunking id="10" string="time" type="NP">
          <tokens>
            <token id="21" string="time" />
          </tokens>
        </chunking>
        <chunking id="11" string="that some procedures could have been done differently , including conducting more interviews over a longer period of time" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="some" />
            <token id="5" string="procedures" />
            <token id="6" string="could" />
            <token id="7" string="have" />
            <token id="8" string="been" />
            <token id="9" string="done" />
            <token id="10" string="differently" />
            <token id="11" string="," />
            <token id="12" string="including" />
            <token id="13" string="conducting" />
            <token id="14" string="more" />
            <token id="15" string="interviews" />
            <token id="16" string="over" />
            <token id="17" string="a" />
            <token id="18" string="longer" />
            <token id="19" string="period" />
            <token id="20" string="of" />
            <token id="21" string="time" />
          </tokens>
        </chunking>
        <chunking id="12" string="conducting more interviews over a longer period of time" type="VP">
          <tokens>
            <token id="13" string="conducting" />
            <token id="14" string="more" />
            <token id="15" string="interviews" />
            <token id="16" string="over" />
            <token id="17" string="a" />
            <token id="18" string="longer" />
            <token id="19" string="period" />
            <token id="20" string="of" />
            <token id="21" string="time" />
          </tokens>
        </chunking>
        <chunking id="13" string="MacFarlane" type="NP">
          <tokens>
            <token id="1" string="MacFarlane" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">acknowledged</governor>
          <dependent id="1">MacFarlane</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">acknowledged</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">done</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">procedures</governor>
          <dependent id="4">some</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">done</governor>
          <dependent id="5">procedures</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">done</governor>
          <dependent id="6">could</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">done</governor>
          <dependent id="7">have</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">done</governor>
          <dependent id="8">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">acknowledged</governor>
          <dependent id="9">done</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">done</governor>
          <dependent id="10">differently</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">conducting</governor>
          <dependent id="12">including</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">done</governor>
          <dependent id="13">conducting</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">interviews</governor>
          <dependent id="14">more</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">conducting</governor>
          <dependent id="15">interviews</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">period</governor>
          <dependent id="16">over</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">period</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">period</governor>
          <dependent id="18">longer</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">conducting</governor>
          <dependent id="19">period</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">time</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">period</governor>
          <dependent id="21">time</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="MacFarlane" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="MacFarlane" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>She called the outcome of the case a ``tragic consequence of an attempt to prevent trauma to these children.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="called" lemma="call" stem="call" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="outcome" lemma="outcome" stem="outcom" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="tragic" lemma="tragic" stem="tragic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="consequence" lemma="consequence" stem="consequ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="attempt" lemma="attempt" stem="attempt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="prevent" lemma="prevent" stem="prevent" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="trauma" lemma="trauma" stem="trauma" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="these" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VBD called) (S (NP (NP (DT the) (NN outcome)) (PP (IN of) (NP (DT the) (NN case)))) (NP (NP (DT a) (`` ``) (JJ tragic) (NN consequence)) (PP (IN of) (NP (DT an) (NN attempt) (S (VP (TO to) (VP (VB prevent) (NP (NN trauma)) (PP (TO to) (NP (DT these) (NNS children))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="a `` tragic consequence of an attempt to prevent trauma to these children" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="``" />
            <token id="10" string="tragic" />
            <token id="11" string="consequence" />
            <token id="12" string="of" />
            <token id="13" string="an" />
            <token id="14" string="attempt" />
            <token id="15" string="to" />
            <token id="16" string="prevent" />
            <token id="17" string="trauma" />
            <token id="18" string="to" />
            <token id="19" string="these" />
            <token id="20" string="children" />
          </tokens>
        </chunking>
        <chunking id="2" string="prevent trauma to these children" type="VP">
          <tokens>
            <token id="16" string="prevent" />
            <token id="17" string="trauma" />
            <token id="18" string="to" />
            <token id="19" string="these" />
            <token id="20" string="children" />
          </tokens>
        </chunking>
        <chunking id="3" string="a `` tragic consequence" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="``" />
            <token id="10" string="tragic" />
            <token id="11" string="consequence" />
          </tokens>
        </chunking>
        <chunking id="4" string="to prevent trauma to these children" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="prevent" />
            <token id="17" string="trauma" />
            <token id="18" string="to" />
            <token id="19" string="these" />
            <token id="20" string="children" />
          </tokens>
        </chunking>
        <chunking id="5" string="called the outcome of the case a `` tragic consequence of an attempt to prevent trauma to these children" type="VP">
          <tokens>
            <token id="2" string="called" />
            <token id="3" string="the" />
            <token id="4" string="outcome" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="case" />
            <token id="8" string="a" />
            <token id="9" string="``" />
            <token id="10" string="tragic" />
            <token id="11" string="consequence" />
            <token id="12" string="of" />
            <token id="13" string="an" />
            <token id="14" string="attempt" />
            <token id="15" string="to" />
            <token id="16" string="prevent" />
            <token id="17" string="trauma" />
            <token id="18" string="to" />
            <token id="19" string="these" />
            <token id="20" string="children" />
          </tokens>
        </chunking>
        <chunking id="6" string="trauma" type="NP">
          <tokens>
            <token id="17" string="trauma" />
          </tokens>
        </chunking>
        <chunking id="7" string="the case" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="case" />
          </tokens>
        </chunking>
        <chunking id="8" string="these children" type="NP">
          <tokens>
            <token id="19" string="these" />
            <token id="20" string="children" />
          </tokens>
        </chunking>
        <chunking id="9" string="the outcome of the case" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="outcome" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="case" />
          </tokens>
        </chunking>
        <chunking id="10" string="an attempt to prevent trauma to these children" type="NP">
          <tokens>
            <token id="13" string="an" />
            <token id="14" string="attempt" />
            <token id="15" string="to" />
            <token id="16" string="prevent" />
            <token id="17" string="trauma" />
            <token id="18" string="to" />
            <token id="19" string="these" />
            <token id="20" string="children" />
          </tokens>
        </chunking>
        <chunking id="11" string="the outcome" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="outcome" />
          </tokens>
        </chunking>
        <chunking id="12" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">called</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">called</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">outcome</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">consequence</governor>
          <dependent id="4">outcome</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">case</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">case</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">outcome</governor>
          <dependent id="7">case</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">consequence</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">consequence</governor>
          <dependent id="10">tragic</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">called</governor>
          <dependent id="11">consequence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">attempt</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">attempt</governor>
          <dependent id="13">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">consequence</governor>
          <dependent id="14">attempt</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">prevent</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">attempt</governor>
          <dependent id="16">prevent</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">prevent</governor>
          <dependent id="17">trauma</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">children</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">children</governor>
          <dependent id="19">these</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">prevent</governor>
          <dependent id="20">children</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>But the institute&amp;apost;s executive director, Mary M. Emmons, said some good may come out of the case.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="institute" lemma="institute" stem="institut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="executive" lemma="executive" stem="execut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="director" lemma="director" stem="director" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Mary" lemma="Mary" stem="mari" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="M." lemma="M." stem="m." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="Emmons" lemma="Emmons" stem="emmon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="come" lemma="come" stem="come" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="out" lemma="out" stem="out" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NP (NP (DT the) (NN institute) (POS 's)) (NN executive) (NN director)) (, ,) (NP (NNP Mary) (NNP M.) (NNP Emmons)) (, ,)) (VP (VBD said) (SBAR (S (NP (DT some) (JJ good)) (VP (MD may) (VP (VB come) (PRT (RB out)) (PP (IN of) (NP (DT the) (NN case)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the institute 's" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="institute" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="some good may come out of the case" type="SBAR">
          <tokens>
            <token id="13" string="some" />
            <token id="14" string="good" />
            <token id="15" string="may" />
            <token id="16" string="come" />
            <token id="17" string="out" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="case" />
          </tokens>
        </chunking>
        <chunking id="3" string="may come out of the case" type="VP">
          <tokens>
            <token id="15" string="may" />
            <token id="16" string="come" />
            <token id="17" string="out" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="case" />
          </tokens>
        </chunking>
        <chunking id="4" string="come out of the case" type="VP">
          <tokens>
            <token id="16" string="come" />
            <token id="17" string="out" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="case" />
          </tokens>
        </chunking>
        <chunking id="5" string="the case" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="case" />
          </tokens>
        </chunking>
        <chunking id="6" string="the institute 's executive director" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="institute" />
            <token id="4" string="'s" />
            <token id="5" string="executive" />
            <token id="6" string="director" />
          </tokens>
        </chunking>
        <chunking id="7" string="said some good may come out of the case" type="VP">
          <tokens>
            <token id="12" string="said" />
            <token id="13" string="some" />
            <token id="14" string="good" />
            <token id="15" string="may" />
            <token id="16" string="come" />
            <token id="17" string="out" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="case" />
          </tokens>
        </chunking>
        <chunking id="8" string="Mary M. Emmons" type="NP">
          <tokens>
            <token id="8" string="Mary" />
            <token id="9" string="M." />
            <token id="10" string="Emmons" />
          </tokens>
        </chunking>
        <chunking id="9" string="the institute 's executive director , Mary M. Emmons ," type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="institute" />
            <token id="4" string="'s" />
            <token id="5" string="executive" />
            <token id="6" string="director" />
            <token id="7" string="," />
            <token id="8" string="Mary" />
            <token id="9" string="M." />
            <token id="10" string="Emmons" />
            <token id="11" string="," />
          </tokens>
        </chunking>
        <chunking id="10" string="some good" type="NP">
          <tokens>
            <token id="13" string="some" />
            <token id="14" string="good" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="12">said</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">institute</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">director</governor>
          <dependent id="3">institute</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">institute</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">director</governor>
          <dependent id="5">executive</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">said</governor>
          <dependent id="6">director</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Emmons</governor>
          <dependent id="8">Mary</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Emmons</governor>
          <dependent id="9">M.</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="6">director</governor>
          <dependent id="10">Emmons</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">good</governor>
          <dependent id="13">some</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">come</governor>
          <dependent id="14">good</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">come</governor>
          <dependent id="15">may</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">said</governor>
          <dependent id="16">come</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="16">come</governor>
          <dependent id="17">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">case</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">case</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">come</governor>
          <dependent id="20">case</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mary M. Emmons" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Mary" />
            <token id="9" string="M." />
            <token id="10" string="Emmons" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>``It has greatly increased the awareness about the issue of child sexual abuse and about the problems of prosecuting these cases,&amp;apost;&amp;apost; she said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="greatly" lemma="greatly" stem="greatli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="increased" lemma="increase" stem="increas" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="awareness" lemma="awareness" stem="awar" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="issue" lemma="issue" stem="issu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="child" lemma="child" stem="child" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="sexual" lemma="sexual" stem="sexual" pos="JJ" type="Word" isStopWord="false" ner="CRIMINAL_CHARGE" is_referenced="false" is_refers="false" />
        <token id="14" string="abuse" lemma="abuse" stem="abus" pos="NN" type="Word" isStopWord="false" ner="CRIMINAL_CHARGE" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="problems" lemma="problem" stem="problem" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="prosecuting" lemma="prosecute" stem="prosecut" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="these" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="cases" lemma="case" stem="case" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP It)) (VP (VBZ has) (ADVP (RB greatly)) (VP (VBN increased) (NP (DT the) (NN awareness)) (PP (PP (IN about) (NP (NP (DT the) (NN issue)) (PP (IN of) (NP (NN child) (JJ sexual) (NN abuse))))) (CC and) (PP (IN about) (NP (NP (DT the) (NNS problems)) (PP (IN of) (S (VP (VBG prosecuting) (NP (DT these) (NNS cases))))))))))) (, ,) ('' '') (NP (PRP she)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the issue of child sexual abuse" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="issue" />
            <token id="11" string="of" />
            <token id="12" string="child" />
            <token id="13" string="sexual" />
            <token id="14" string="abuse" />
          </tokens>
        </chunking>
        <chunking id="2" string="child sexual abuse" type="NP">
          <tokens>
            <token id="12" string="child" />
            <token id="13" string="sexual" />
            <token id="14" string="abuse" />
          </tokens>
        </chunking>
        <chunking id="3" string="the issue" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="issue" />
          </tokens>
        </chunking>
        <chunking id="4" string="the problems of prosecuting these cases" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="problems" />
            <token id="19" string="of" />
            <token id="20" string="prosecuting" />
            <token id="21" string="these" />
            <token id="22" string="cases" />
          </tokens>
        </chunking>
        <chunking id="5" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="6" string="these cases" type="NP">
          <tokens>
            <token id="21" string="these" />
            <token id="22" string="cases" />
          </tokens>
        </chunking>
        <chunking id="7" string="prosecuting these cases" type="VP">
          <tokens>
            <token id="20" string="prosecuting" />
            <token id="21" string="these" />
            <token id="22" string="cases" />
          </tokens>
        </chunking>
        <chunking id="8" string="she" type="NP">
          <tokens>
            <token id="25" string="she" />
          </tokens>
        </chunking>
        <chunking id="9" string="has greatly increased the awareness about the issue of child sexual abuse and about the problems of prosecuting these cases" type="VP">
          <tokens>
            <token id="3" string="has" />
            <token id="4" string="greatly" />
            <token id="5" string="increased" />
            <token id="6" string="the" />
            <token id="7" string="awareness" />
            <token id="8" string="about" />
            <token id="9" string="the" />
            <token id="10" string="issue" />
            <token id="11" string="of" />
            <token id="12" string="child" />
            <token id="13" string="sexual" />
            <token id="14" string="abuse" />
            <token id="15" string="and" />
            <token id="16" string="about" />
            <token id="17" string="the" />
            <token id="18" string="problems" />
            <token id="19" string="of" />
            <token id="20" string="prosecuting" />
            <token id="21" string="these" />
            <token id="22" string="cases" />
          </tokens>
        </chunking>
        <chunking id="10" string="the awareness" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="awareness" />
          </tokens>
        </chunking>
        <chunking id="11" string="the problems" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="problems" />
          </tokens>
        </chunking>
        <chunking id="12" string="increased the awareness about the issue of child sexual abuse and about the problems of prosecuting these cases" type="VP">
          <tokens>
            <token id="5" string="increased" />
            <token id="6" string="the" />
            <token id="7" string="awareness" />
            <token id="8" string="about" />
            <token id="9" string="the" />
            <token id="10" string="issue" />
            <token id="11" string="of" />
            <token id="12" string="child" />
            <token id="13" string="sexual" />
            <token id="14" string="abuse" />
            <token id="15" string="and" />
            <token id="16" string="about" />
            <token id="17" string="the" />
            <token id="18" string="problems" />
            <token id="19" string="of" />
            <token id="20" string="prosecuting" />
            <token id="21" string="these" />
            <token id="22" string="cases" />
          </tokens>
        </chunking>
        <chunking id="13" string="said" type="VP">
          <tokens>
            <token id="26" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">increased</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">increased</governor>
          <dependent id="3">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">increased</governor>
          <dependent id="4">greatly</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">increased</governor>
          <dependent id="5">increased</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="26">said</governor>
          <dependent id="5">increased</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">awareness</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">increased</governor>
          <dependent id="7">awareness</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">issue</governor>
          <dependent id="8">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">issue</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">increased</governor>
          <dependent id="10">issue</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">abuse</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">abuse</governor>
          <dependent id="12">child</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">abuse</governor>
          <dependent id="13">sexual</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">issue</governor>
          <dependent id="14">abuse</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">increased</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">problems</governor>
          <dependent id="16">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">problems</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">increased</governor>
          <dependent id="18">problems</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">prosecuting</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="18">problems</governor>
          <dependent id="20">prosecuting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">cases</governor>
          <dependent id="21">these</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">prosecuting</governor>
          <dependent id="22">cases</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">said</governor>
          <dependent id="25">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="26">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="sexual abuse" type="CRIMINAL_CHARGE" score="0.0">
          <tokens>
            <token id="13" string="sexual" />
            <token id="14" string="abuse" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="1" string="Therapist" id_sentence="3" />
      <mentions>
        <mention ids_tokens="1-2" string="A therapist" id_sentence="1" />
        <mention ids_tokens="4" string="her" id_sentence="1" />
        <mention ids_tokens="21" string="she" id_sentence="4" />
      </mentions>
    </coreference>
    <coreference id="2" type="NOMINAL">
      <referenced ids_tokens="22-23-24" string="the alleged victims" id_sentence="5" />
      <mentions>
        <mention ids_tokens="7-14" string="alleged victims in the McMartin Pre-School molestation trial" id_sentence="1" />
      </mentions>
    </coreference>
    <coreference id="3" type="NOMINAL">
      <referenced ids_tokens="26-27-28-29" string="the prosecution 's case" id_sentence="1" />
      <mentions>
        <mention ids_tokens="6-7" string="the case" id_sentence="18" />
        <mention ids_tokens="19-20" string="the case" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="2-3" string="The children" id_sentence="11" />
      <mentions>
        <mention ids_tokens="8" string="children" id_sentence="4" />
        <mention ids_tokens="14" string="children" id_sentence="9" />
        <mention ids_tokens="17" string="them" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="11-12" string="the evidence" id_sentence="9" />
      <mentions>
        <mention ids_tokens="1-17" string="Evidence introduced by prosecutors in what became the longest and most expensive criminal trial in U.S. history" id_sentence="5" />
      </mentions>
    </coreference>
    <coreference id="8" type="NOMINAL">
      <referenced ids_tokens="19-20-21-22-23-24" string="videotaped interviews of the alleged victims" id_sentence="5" />
      <mentions>
        <mention ids_tokens="3-4" string="the interviews" id_sentence="6" />
      </mentions>
    </coreference>
    <coreference id="9" type="PROPER">
      <referenced ids_tokens="17" string="MacFarlane" id_sentence="6" />
      <mentions>
        <mention ids_tokens="13" string="I" id_sentence="13" />
        <mention ids_tokens="19" string="I" id_sentence="13" />
        <mention ids_tokens="2" string="I" id_sentence="15" />
        <mention ids_tokens="2" string="I" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4" string="Many of the interviews" id_sentence="6" />
      <mentions>
        <mention ids_tokens="4" string="she" id_sentence="7" />
        <mention ids_tokens="24" string="she" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="12" type="LIST">
      <referenced ids_tokens="17-18-19-20-21-22-23-24-25-26-27-28-29" string="MacFarlane , a social worker and director of the Child Sexual Abuse Center" id_sentence="6" />
      <mentions>
        <mention ids_tokens="13" string="we" id_sentence="8" />
        <mention ids_tokens="16" string="we" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="13" type="NOMINAL">
      <referenced ids_tokens="20-21" string="these children" id_sentence="8" />
      <mentions>
        <mention ids_tokens="7-10" string="children from the school" id_sentence="7" />
        <mention ids_tokens="16" string="they" id_sentence="7" />
        <mention ids_tokens="20" string="their" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="14" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9" string="At least seven jurors who attended a news conference" id_sentence="9" />
      <mentions>
        <mention ids_tokens="2-3" string="the jurors" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="15" type="NOMINAL">
      <referenced ids_tokens="13-14" string="the institute" id_sentence="10" />
      <mentions>
        <mention ids_tokens="2-4" string="the institute's" id_sentence="19" />
        <mention ids_tokens="2" string="It" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="16" type="NOMINAL">
      <referenced ids_tokens="10-11-12-13-14-15-16" string="their own words what happened to them" id_sentence="11" />
      <mentions>
        <mention ids_tokens="6" string="words" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="17" type="PROPER">
      <referenced ids_tokens="30-31-32" string="juror Brenda Williams" id_sentence="13" />
      <mentions>
        <mention ids_tokens="12" string="she" id_sentence="15" />
        <mention ids_tokens="1" string="She" id_sentence="18" />
        <mention ids_tokens="25" string="she" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="18" type="NOMINAL">
      <referenced ids_tokens="13-14" string="small children" id_sentence="14" />
      <mentions>
        <mention ids_tokens="8" string="their" id_sentence="15" />
        <mention ids_tokens="6" string="them" id_sentence="16" />
        <mention ids_tokens="10" string="their" id_sentence="16" />
      </mentions>
    </coreference>
  </coreferences>
</document>
