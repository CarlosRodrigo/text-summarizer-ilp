<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP880521-0088">
  <sentences>
    <sentence id="1" has_coreference="false">
      <content>Greek divers have plunged 162 feet beneath the Aegean Sea and back into history, finding a treasure-laden Turkish warship sunk by Greek revolutionaries in 1822.</content>
      <tokens>
        <token id="1" string="Greek" lemma="greek" stem="greek" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="2" string="divers" lemma="diver" stem="diver" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="plunged" lemma="plunge" stem="plung" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="162" lemma="162" stem="162" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="6" string="feet" lemma="foot" stem="feet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="beneath" lemma="beneath" stem="beneath" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Aegean" lemma="Aegean" stem="aegean" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="10" string="Sea" lemma="Sea" stem="sea" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="history" lemma="history" stem="histori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="finding" lemma="find" stem="find" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="treasure-laden" lemma="treasure-laden" stem="treasure-laden" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="Turkish" lemma="turkish" stem="turkish" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="20" string="warship" lemma="warship" stem="warship" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="sunk" lemma="sink" stem="sunk" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Greek" lemma="greek" stem="greek" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="24" string="revolutionaries" lemma="revolutionary" stem="revolutionari" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="1822" lemma="1822" stem="1822" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (JJ Greek) (NNS divers)) (VP (VBP have) (VP (VBN plunged) (PP (PP (NP (CD 162) (NNS feet)) (IN beneath) (NP (DT the) (NNP Aegean) (NNP Sea))) (CC and) (PP (ADVP (RB back)) (IN into) (NP (NN history)))) (, ,) (S (VP (VBG finding) (NP (NP (DT a) (JJ treasure-laden) (JJ Turkish) (NN warship)) (VP (VBN sunk) (PP (IN by) (NP (NP (JJ Greek) (NNS revolutionaries)) (PP (IN in) (NP (CD 1822))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="plunged 162 feet beneath the Aegean Sea and back into history , finding a treasure-laden Turkish warship sunk by Greek revolutionaries in 1822" type="VP">
          <tokens>
            <token id="4" string="plunged" />
            <token id="5" string="162" />
            <token id="6" string="feet" />
            <token id="7" string="beneath" />
            <token id="8" string="the" />
            <token id="9" string="Aegean" />
            <token id="10" string="Sea" />
            <token id="11" string="and" />
            <token id="12" string="back" />
            <token id="13" string="into" />
            <token id="14" string="history" />
            <token id="15" string="," />
            <token id="16" string="finding" />
            <token id="17" string="a" />
            <token id="18" string="treasure-laden" />
            <token id="19" string="Turkish" />
            <token id="20" string="warship" />
            <token id="21" string="sunk" />
            <token id="22" string="by" />
            <token id="23" string="Greek" />
            <token id="24" string="revolutionaries" />
            <token id="25" string="in" />
            <token id="26" string="1822" />
          </tokens>
        </chunking>
        <chunking id="2" string="finding a treasure-laden Turkish warship sunk by Greek revolutionaries in 1822" type="VP">
          <tokens>
            <token id="16" string="finding" />
            <token id="17" string="a" />
            <token id="18" string="treasure-laden" />
            <token id="19" string="Turkish" />
            <token id="20" string="warship" />
            <token id="21" string="sunk" />
            <token id="22" string="by" />
            <token id="23" string="Greek" />
            <token id="24" string="revolutionaries" />
            <token id="25" string="in" />
            <token id="26" string="1822" />
          </tokens>
        </chunking>
        <chunking id="3" string="a treasure-laden Turkish warship" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="treasure-laden" />
            <token id="19" string="Turkish" />
            <token id="20" string="warship" />
          </tokens>
        </chunking>
        <chunking id="4" string="sunk by Greek revolutionaries in 1822" type="VP">
          <tokens>
            <token id="21" string="sunk" />
            <token id="22" string="by" />
            <token id="23" string="Greek" />
            <token id="24" string="revolutionaries" />
            <token id="25" string="in" />
            <token id="26" string="1822" />
          </tokens>
        </chunking>
        <chunking id="5" string="Greek divers" type="NP">
          <tokens>
            <token id="1" string="Greek" />
            <token id="2" string="divers" />
          </tokens>
        </chunking>
        <chunking id="6" string="a treasure-laden Turkish warship sunk by Greek revolutionaries in 1822" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="treasure-laden" />
            <token id="19" string="Turkish" />
            <token id="20" string="warship" />
            <token id="21" string="sunk" />
            <token id="22" string="by" />
            <token id="23" string="Greek" />
            <token id="24" string="revolutionaries" />
            <token id="25" string="in" />
            <token id="26" string="1822" />
          </tokens>
        </chunking>
        <chunking id="7" string="history" type="NP">
          <tokens>
            <token id="14" string="history" />
          </tokens>
        </chunking>
        <chunking id="8" string="162 feet" type="NP">
          <tokens>
            <token id="5" string="162" />
            <token id="6" string="feet" />
          </tokens>
        </chunking>
        <chunking id="9" string="Greek revolutionaries in 1822" type="NP">
          <tokens>
            <token id="23" string="Greek" />
            <token id="24" string="revolutionaries" />
            <token id="25" string="in" />
            <token id="26" string="1822" />
          </tokens>
        </chunking>
        <chunking id="10" string="1822" type="NP">
          <tokens>
            <token id="26" string="1822" />
          </tokens>
        </chunking>
        <chunking id="11" string="the Aegean Sea" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="Aegean" />
            <token id="10" string="Sea" />
          </tokens>
        </chunking>
        <chunking id="12" string="have plunged 162 feet beneath the Aegean Sea and back into history , finding a treasure-laden Turkish warship sunk by Greek revolutionaries in 1822" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="plunged" />
            <token id="5" string="162" />
            <token id="6" string="feet" />
            <token id="7" string="beneath" />
            <token id="8" string="the" />
            <token id="9" string="Aegean" />
            <token id="10" string="Sea" />
            <token id="11" string="and" />
            <token id="12" string="back" />
            <token id="13" string="into" />
            <token id="14" string="history" />
            <token id="15" string="," />
            <token id="16" string="finding" />
            <token id="17" string="a" />
            <token id="18" string="treasure-laden" />
            <token id="19" string="Turkish" />
            <token id="20" string="warship" />
            <token id="21" string="sunk" />
            <token id="22" string="by" />
            <token id="23" string="Greek" />
            <token id="24" string="revolutionaries" />
            <token id="25" string="in" />
            <token id="26" string="1822" />
          </tokens>
        </chunking>
        <chunking id="13" string="Greek revolutionaries" type="NP">
          <tokens>
            <token id="23" string="Greek" />
            <token id="24" string="revolutionaries" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">divers</governor>
          <dependent id="1">Greek</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">plunged</governor>
          <dependent id="2">divers</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">plunged</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">plunged</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">plunged</governor>
          <dependent id="4">plunged</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">feet</governor>
          <dependent id="5">162</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">plunged</governor>
          <dependent id="6">feet</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">feet</governor>
          <dependent id="7">beneath</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">Sea</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Sea</governor>
          <dependent id="9">Aegean</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">feet</governor>
          <dependent id="10">Sea</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">plunged</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">history</governor>
          <dependent id="12">back</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">history</governor>
          <dependent id="13">into</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">plunged</governor>
          <dependent id="14">history</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">plunged</governor>
          <dependent id="16">finding</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">warship</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">warship</governor>
          <dependent id="18">treasure-laden</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">warship</governor>
          <dependent id="19">Turkish</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">finding</governor>
          <dependent id="20">warship</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="20">warship</governor>
          <dependent id="21">sunk</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">revolutionaries</governor>
          <dependent id="22">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">revolutionaries</governor>
          <dependent id="23">Greek</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">sunk</governor>
          <dependent id="24">revolutionaries</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">1822</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">revolutionaries</governor>
          <dependent id="26">1822</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1822" type="DATE" score="0.0">
          <tokens>
            <token id="26" string="1822" />
          </tokens>
        </entity>
        <entity id="2" string="Greek" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="1" string="Greek" />
          </tokens>
        </entity>
        <entity id="3" string="Turkish" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="19" string="Turkish" />
          </tokens>
        </entity>
        <entity id="4" string="Aegean Sea" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Aegean" />
            <token id="10" string="Sea" />
          </tokens>
        </entity>
        <entity id="5" string="162" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="162" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>The remains of the wooden sailing ship were found near the island of Chios in the eastern Aegean at a point where historical accounts place the sinking of the Ottoman ship, according to Peter Nicolaides, a diver and salvage expert.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="remains" lemma="remains" stem="remain" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="wooden" lemma="wooden" stem="wooden" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="sailing" lemma="sailing" stem="sail" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="ship" lemma="ship" stem="ship" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="found" lemma="find" stem="found" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="near" lemma="near" stem="near" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="island" lemma="island" stem="island" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Chios" lemma="Chios" stem="chio" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="eastern" lemma="eastern" stem="eastern" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="Aegean" lemma="aegean" stem="aegean" pos="NN" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="19" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="point" lemma="point" stem="point" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="historical" lemma="historical" stem="histor" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="accounts" lemma="account" stem="account" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="place" lemma="place" stem="place" pos="VBP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="sinking" lemma="sinking" stem="sink" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="Ottoman" lemma="Ottoman" stem="ottoman" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="31" string="ship" lemma="ship" stem="ship" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="according" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="35" string="Peter" lemma="Peter" stem="peter" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="36" string="Nicolaides" lemma="Nicolaides" stem="nicolaid" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="37" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="38" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="39" string="diver" lemma="diver" stem="diver" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="40" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="41" string="salvage" lemma="salvage" stem="salvag" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="42" string="expert" lemma="expert" stem="expert" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="43" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NNS remains)) (PP (IN of) (NP (DT the) (JJ wooden) (NN sailing) (NN ship)))) (VP (VBD were) (VP (VBN found) (PP (IN near) (NP (NP (DT the) (NN island)) (PP (IN of) (NP (NNP Chios))))) (PP (IN in) (NP (NP (DT the) (JJ eastern) (NN Aegean)) (PP (IN at) (NP (NP (DT a) (NN point)) (SBAR (WHADVP (WRB where)) (S (NP (JJ historical) (NNS accounts)) (VP (VBP place) (NP (NP (DT the) (NN sinking)) (PP (IN of) (NP (DT the) (NNP Ottoman) (NN ship)))) (, ,) (PP (VBG according) (PP (TO to) (NP (NP (NNP Peter) (NNP Nicolaides)) (, ,) (NP (DT a) (NN diver)) (CC and) (NP (NN salvage) (NN expert)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="historical accounts" type="NP">
          <tokens>
            <token id="23" string="historical" />
            <token id="24" string="accounts" />
          </tokens>
        </chunking>
        <chunking id="2" string="the sinking of the Ottoman ship" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="sinking" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="Ottoman" />
            <token id="31" string="ship" />
          </tokens>
        </chunking>
        <chunking id="3" string="The remains" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="remains" />
          </tokens>
        </chunking>
        <chunking id="4" string="salvage expert" type="NP">
          <tokens>
            <token id="41" string="salvage" />
            <token id="42" string="expert" />
          </tokens>
        </chunking>
        <chunking id="5" string="the island" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="island" />
          </tokens>
        </chunking>
        <chunking id="6" string="a point" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="point" />
          </tokens>
        </chunking>
        <chunking id="7" string="Chios" type="NP">
          <tokens>
            <token id="14" string="Chios" />
          </tokens>
        </chunking>
        <chunking id="8" string="the wooden sailing ship" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="wooden" />
            <token id="6" string="sailing" />
            <token id="7" string="ship" />
          </tokens>
        </chunking>
        <chunking id="9" string="the eastern Aegean" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="eastern" />
            <token id="18" string="Aegean" />
          </tokens>
        </chunking>
        <chunking id="10" string="the sinking" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="sinking" />
          </tokens>
        </chunking>
        <chunking id="11" string="Peter Nicolaides , a diver and salvage expert" type="NP">
          <tokens>
            <token id="35" string="Peter" />
            <token id="36" string="Nicolaides" />
            <token id="37" string="," />
            <token id="38" string="a" />
            <token id="39" string="diver" />
            <token id="40" string="and" />
            <token id="41" string="salvage" />
            <token id="42" string="expert" />
          </tokens>
        </chunking>
        <chunking id="12" string="where historical accounts place the sinking of the Ottoman ship , according to Peter Nicolaides , a diver and salvage expert" type="SBAR">
          <tokens>
            <token id="22" string="where" />
            <token id="23" string="historical" />
            <token id="24" string="accounts" />
            <token id="25" string="place" />
            <token id="26" string="the" />
            <token id="27" string="sinking" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="Ottoman" />
            <token id="31" string="ship" />
            <token id="32" string="," />
            <token id="33" string="according" />
            <token id="34" string="to" />
            <token id="35" string="Peter" />
            <token id="36" string="Nicolaides" />
            <token id="37" string="," />
            <token id="38" string="a" />
            <token id="39" string="diver" />
            <token id="40" string="and" />
            <token id="41" string="salvage" />
            <token id="42" string="expert" />
          </tokens>
        </chunking>
        <chunking id="13" string="Peter Nicolaides" type="NP">
          <tokens>
            <token id="35" string="Peter" />
            <token id="36" string="Nicolaides" />
          </tokens>
        </chunking>
        <chunking id="14" string="a diver" type="NP">
          <tokens>
            <token id="38" string="a" />
            <token id="39" string="diver" />
          </tokens>
        </chunking>
        <chunking id="15" string="the eastern Aegean at a point where historical accounts place the sinking of the Ottoman ship , according to Peter Nicolaides , a diver and salvage expert" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="eastern" />
            <token id="18" string="Aegean" />
            <token id="19" string="at" />
            <token id="20" string="a" />
            <token id="21" string="point" />
            <token id="22" string="where" />
            <token id="23" string="historical" />
            <token id="24" string="accounts" />
            <token id="25" string="place" />
            <token id="26" string="the" />
            <token id="27" string="sinking" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="Ottoman" />
            <token id="31" string="ship" />
            <token id="32" string="," />
            <token id="33" string="according" />
            <token id="34" string="to" />
            <token id="35" string="Peter" />
            <token id="36" string="Nicolaides" />
            <token id="37" string="," />
            <token id="38" string="a" />
            <token id="39" string="diver" />
            <token id="40" string="and" />
            <token id="41" string="salvage" />
            <token id="42" string="expert" />
          </tokens>
        </chunking>
        <chunking id="16" string="the island of Chios" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="island" />
            <token id="13" string="of" />
            <token id="14" string="Chios" />
          </tokens>
        </chunking>
        <chunking id="17" string="place the sinking of the Ottoman ship , according to Peter Nicolaides , a diver and salvage expert" type="VP">
          <tokens>
            <token id="25" string="place" />
            <token id="26" string="the" />
            <token id="27" string="sinking" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="Ottoman" />
            <token id="31" string="ship" />
            <token id="32" string="," />
            <token id="33" string="according" />
            <token id="34" string="to" />
            <token id="35" string="Peter" />
            <token id="36" string="Nicolaides" />
            <token id="37" string="," />
            <token id="38" string="a" />
            <token id="39" string="diver" />
            <token id="40" string="and" />
            <token id="41" string="salvage" />
            <token id="42" string="expert" />
          </tokens>
        </chunking>
        <chunking id="18" string="The remains of the wooden sailing ship" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="remains" />
            <token id="3" string="of" />
            <token id="4" string="the" />
            <token id="5" string="wooden" />
            <token id="6" string="sailing" />
            <token id="7" string="ship" />
          </tokens>
        </chunking>
        <chunking id="19" string="found near the island of Chios in the eastern Aegean at a point where historical accounts place the sinking of the Ottoman ship , according to Peter Nicolaides , a diver and salvage expert" type="VP">
          <tokens>
            <token id="9" string="found" />
            <token id="10" string="near" />
            <token id="11" string="the" />
            <token id="12" string="island" />
            <token id="13" string="of" />
            <token id="14" string="Chios" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="eastern" />
            <token id="18" string="Aegean" />
            <token id="19" string="at" />
            <token id="20" string="a" />
            <token id="21" string="point" />
            <token id="22" string="where" />
            <token id="23" string="historical" />
            <token id="24" string="accounts" />
            <token id="25" string="place" />
            <token id="26" string="the" />
            <token id="27" string="sinking" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="Ottoman" />
            <token id="31" string="ship" />
            <token id="32" string="," />
            <token id="33" string="according" />
            <token id="34" string="to" />
            <token id="35" string="Peter" />
            <token id="36" string="Nicolaides" />
            <token id="37" string="," />
            <token id="38" string="a" />
            <token id="39" string="diver" />
            <token id="40" string="and" />
            <token id="41" string="salvage" />
            <token id="42" string="expert" />
          </tokens>
        </chunking>
        <chunking id="20" string="where" type="WHADVP">
          <tokens>
            <token id="22" string="where" />
          </tokens>
        </chunking>
        <chunking id="21" string="were found near the island of Chios in the eastern Aegean at a point where historical accounts place the sinking of the Ottoman ship , according to Peter Nicolaides , a diver and salvage expert" type="VP">
          <tokens>
            <token id="8" string="were" />
            <token id="9" string="found" />
            <token id="10" string="near" />
            <token id="11" string="the" />
            <token id="12" string="island" />
            <token id="13" string="of" />
            <token id="14" string="Chios" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="eastern" />
            <token id="18" string="Aegean" />
            <token id="19" string="at" />
            <token id="20" string="a" />
            <token id="21" string="point" />
            <token id="22" string="where" />
            <token id="23" string="historical" />
            <token id="24" string="accounts" />
            <token id="25" string="place" />
            <token id="26" string="the" />
            <token id="27" string="sinking" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="Ottoman" />
            <token id="31" string="ship" />
            <token id="32" string="," />
            <token id="33" string="according" />
            <token id="34" string="to" />
            <token id="35" string="Peter" />
            <token id="36" string="Nicolaides" />
            <token id="37" string="," />
            <token id="38" string="a" />
            <token id="39" string="diver" />
            <token id="40" string="and" />
            <token id="41" string="salvage" />
            <token id="42" string="expert" />
          </tokens>
        </chunking>
        <chunking id="22" string="the Ottoman ship" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="Ottoman" />
            <token id="31" string="ship" />
          </tokens>
        </chunking>
        <chunking id="23" string="a point where historical accounts place the sinking of the Ottoman ship , according to Peter Nicolaides , a diver and salvage expert" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="point" />
            <token id="22" string="where" />
            <token id="23" string="historical" />
            <token id="24" string="accounts" />
            <token id="25" string="place" />
            <token id="26" string="the" />
            <token id="27" string="sinking" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="Ottoman" />
            <token id="31" string="ship" />
            <token id="32" string="," />
            <token id="33" string="according" />
            <token id="34" string="to" />
            <token id="35" string="Peter" />
            <token id="36" string="Nicolaides" />
            <token id="37" string="," />
            <token id="38" string="a" />
            <token id="39" string="diver" />
            <token id="40" string="and" />
            <token id="41" string="salvage" />
            <token id="42" string="expert" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">remains</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">found</governor>
          <dependent id="2">remains</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">ship</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">ship</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">ship</governor>
          <dependent id="5">wooden</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">ship</governor>
          <dependent id="6">sailing</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">remains</governor>
          <dependent id="7">ship</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">found</governor>
          <dependent id="8">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">found</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">island</governor>
          <dependent id="10">near</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">island</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">found</governor>
          <dependent id="12">island</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Chios</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">island</governor>
          <dependent id="14">Chios</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Aegean</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">Aegean</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">Aegean</governor>
          <dependent id="17">eastern</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">found</governor>
          <dependent id="18">Aegean</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">point</governor>
          <dependent id="19">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">point</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">Aegean</governor>
          <dependent id="21">point</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">place</governor>
          <dependent id="22">where</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">accounts</governor>
          <dependent id="23">historical</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">place</governor>
          <dependent id="24">accounts</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="21">point</governor>
          <dependent id="25">place</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">sinking</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">place</governor>
          <dependent id="27">sinking</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">ship</governor>
          <dependent id="28">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">ship</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">ship</governor>
          <dependent id="30">Ottoman</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">sinking</governor>
          <dependent id="31">ship</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">Nicolaides</governor>
          <dependent id="33">according</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="33">according</governor>
          <dependent id="34">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">Nicolaides</governor>
          <dependent id="35">Peter</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">place</governor>
          <dependent id="36">Nicolaides</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">diver</governor>
          <dependent id="38">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="36">Nicolaides</governor>
          <dependent id="39">diver</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="36">Nicolaides</governor>
          <dependent id="40">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="42">expert</governor>
          <dependent id="41">salvage</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="36">Nicolaides</governor>
          <dependent id="42">expert</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Aegean" type="LOCATION" score="0.0">
          <tokens>
            <token id="18" string="Aegean" />
          </tokens>
        </entity>
        <entity id="2" string="Chios" type="MISC" score="0.0">
          <tokens>
            <token id="14" string="Chios" />
          </tokens>
        </entity>
        <entity id="3" string="Ottoman" type="MISC" score="0.0">
          <tokens>
            <token id="30" string="Ottoman" />
          </tokens>
        </entity>
        <entity id="4" string="Peter Nicolaides" type="PERSON" score="0.0">
          <tokens>
            <token id="35" string="Peter" />
            <token id="36" string="Nicolaides" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>The Bourloti Seimaz _ or ``Explosives Invincible&amp;apost;&amp;apost; _ was set afire and sunk by Greek Admiral Constantine Kanaris in revenge for Turkish killing and looting on Chios.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="Bourloti" lemma="Bourloti" stem="bourloti" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="Seimaz" lemma="Seimaz" stem="seimaz" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="_" lemma="_" stem="_" pos="CD" type="Symbol" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="5" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Explosives" lemma="Explosives" stem="explosiv" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Invincible" lemma="Invincible" stem="invincibl" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="set" lemma="set" stem="set" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="afire" lemma="afire" stem="afir" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="sunk" lemma="sink" stem="sunk" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Greek" lemma="greek" stem="greek" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="18" string="Admiral" lemma="admiral" stem="admiral" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="Constantine" lemma="Constantine" stem="constantin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="20" string="Kanaris" lemma="Kanaris" stem="kanari" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="revenge" lemma="revenge" stem="reveng" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Turkish" lemma="turkish" stem="turkish" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="25" string="killing" lemma="killing" stem="kill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="looting" lemma="looting" stem="loot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="Chios" lemma="Chios" stem="chio" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NNP Bourloti) (NNP Seimaz) (CD _)) (CC or) (NP (NP (`` ``) (NNP Explosives) (NNP Invincible) ('' '')) (NP (NN _)))) (VP (VBD was) (VP (VP (VBN set) (ADVP (RB afire))) (CC and) (VP (VBN sunk) (PP (IN by) (NP (JJ Greek) (NN Admiral) (NNP Constantine) (NNP Kanaris))) (PP (IN in) (NP (NP (NN revenge)) (PP (IN for) (NP (JJ Turkish) (NN killing) (CC and) (NN looting))))) (PP (IN on) (NP (NNP Chios)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="set afire and sunk by Greek Admiral Constantine Kanaris in revenge for Turkish killing and looting on Chios" type="VP">
          <tokens>
            <token id="12" string="set" />
            <token id="13" string="afire" />
            <token id="14" string="and" />
            <token id="15" string="sunk" />
            <token id="16" string="by" />
            <token id="17" string="Greek" />
            <token id="18" string="Admiral" />
            <token id="19" string="Constantine" />
            <token id="20" string="Kanaris" />
            <token id="21" string="in" />
            <token id="22" string="revenge" />
            <token id="23" string="for" />
            <token id="24" string="Turkish" />
            <token id="25" string="killing" />
            <token id="26" string="and" />
            <token id="27" string="looting" />
            <token id="28" string="on" />
            <token id="29" string="Chios" />
          </tokens>
        </chunking>
        <chunking id="2" string="Chios" type="NP">
          <tokens>
            <token id="29" string="Chios" />
          </tokens>
        </chunking>
        <chunking id="3" string="revenge" type="NP">
          <tokens>
            <token id="22" string="revenge" />
          </tokens>
        </chunking>
        <chunking id="4" string="was set afire and sunk by Greek Admiral Constantine Kanaris in revenge for Turkish killing and looting on Chios" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="set" />
            <token id="13" string="afire" />
            <token id="14" string="and" />
            <token id="15" string="sunk" />
            <token id="16" string="by" />
            <token id="17" string="Greek" />
            <token id="18" string="Admiral" />
            <token id="19" string="Constantine" />
            <token id="20" string="Kanaris" />
            <token id="21" string="in" />
            <token id="22" string="revenge" />
            <token id="23" string="for" />
            <token id="24" string="Turkish" />
            <token id="25" string="killing" />
            <token id="26" string="and" />
            <token id="27" string="looting" />
            <token id="28" string="on" />
            <token id="29" string="Chios" />
          </tokens>
        </chunking>
        <chunking id="5" string="`` Explosives Invincible '' _" type="NP">
          <tokens>
            <token id="6" string="``" />
            <token id="7" string="Explosives" />
            <token id="8" string="Invincible" />
            <token id="9" string="''" />
            <token id="10" string="_" />
          </tokens>
        </chunking>
        <chunking id="6" string="sunk by Greek Admiral Constantine Kanaris in revenge for Turkish killing and looting on Chios" type="VP">
          <tokens>
            <token id="15" string="sunk" />
            <token id="16" string="by" />
            <token id="17" string="Greek" />
            <token id="18" string="Admiral" />
            <token id="19" string="Constantine" />
            <token id="20" string="Kanaris" />
            <token id="21" string="in" />
            <token id="22" string="revenge" />
            <token id="23" string="for" />
            <token id="24" string="Turkish" />
            <token id="25" string="killing" />
            <token id="26" string="and" />
            <token id="27" string="looting" />
            <token id="28" string="on" />
            <token id="29" string="Chios" />
          </tokens>
        </chunking>
        <chunking id="7" string="set afire" type="VP">
          <tokens>
            <token id="12" string="set" />
            <token id="13" string="afire" />
          </tokens>
        </chunking>
        <chunking id="8" string="Turkish killing and looting" type="NP">
          <tokens>
            <token id="24" string="Turkish" />
            <token id="25" string="killing" />
            <token id="26" string="and" />
            <token id="27" string="looting" />
          </tokens>
        </chunking>
        <chunking id="9" string="revenge for Turkish killing and looting" type="NP">
          <tokens>
            <token id="22" string="revenge" />
            <token id="23" string="for" />
            <token id="24" string="Turkish" />
            <token id="25" string="killing" />
            <token id="26" string="and" />
            <token id="27" string="looting" />
          </tokens>
        </chunking>
        <chunking id="10" string="Greek Admiral Constantine Kanaris" type="NP">
          <tokens>
            <token id="17" string="Greek" />
            <token id="18" string="Admiral" />
            <token id="19" string="Constantine" />
            <token id="20" string="Kanaris" />
          </tokens>
        </chunking>
        <chunking id="11" string="The Bourloti Seimaz _" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Bourloti" />
            <token id="3" string="Seimaz" />
            <token id="4" string="_" />
          </tokens>
        </chunking>
        <chunking id="12" string="`` Explosives Invincible ''" type="NP">
          <tokens>
            <token id="6" string="``" />
            <token id="7" string="Explosives" />
            <token id="8" string="Invincible" />
            <token id="9" string="''" />
          </tokens>
        </chunking>
        <chunking id="13" string="_" type="NP">
          <tokens>
            <token id="10" string="_" />
          </tokens>
        </chunking>
        <chunking id="14" string="The Bourloti Seimaz _ or `` Explosives Invincible '' _" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Bourloti" />
            <token id="3" string="Seimaz" />
            <token id="4" string="_" />
            <token id="5" string="or" />
            <token id="6" string="``" />
            <token id="7" string="Explosives" />
            <token id="8" string="Invincible" />
            <token id="9" string="''" />
            <token id="10" string="_" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">Seimaz</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Seimaz</governor>
          <dependent id="2">Bourloti</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">set</governor>
          <dependent id="3">Seimaz</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="3">Seimaz</governor>
          <dependent id="4">_</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">Seimaz</governor>
          <dependent id="5">or</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Invincible</governor>
          <dependent id="7">Explosives</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">Seimaz</governor>
          <dependent id="8">Invincible</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">Invincible</governor>
          <dependent id="10">_</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">set</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">set</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">set</governor>
          <dependent id="13">afire</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">set</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">set</governor>
          <dependent id="15">sunk</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Kanaris</governor>
          <dependent id="16">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">Kanaris</governor>
          <dependent id="17">Greek</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Kanaris</governor>
          <dependent id="18">Admiral</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Kanaris</governor>
          <dependent id="19">Constantine</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">sunk</governor>
          <dependent id="20">Kanaris</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">revenge</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">sunk</governor>
          <dependent id="22">revenge</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">killing</governor>
          <dependent id="23">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">killing</governor>
          <dependent id="24">Turkish</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">revenge</governor>
          <dependent id="25">killing</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="25">killing</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="25">killing</governor>
          <dependent id="27">looting</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">Chios</governor>
          <dependent id="28">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">sunk</governor>
          <dependent id="29">Chios</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Greek" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="17" string="Greek" />
          </tokens>
        </entity>
        <entity id="2" string="Chios" type="MISC" score="0.0">
          <tokens>
            <token id="29" string="Chios" />
          </tokens>
        </entity>
        <entity id="3" string="Turkish" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="24" string="Turkish" />
          </tokens>
        </entity>
        <entity id="4" string="Constantine Kanaris" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Constantine" />
            <token id="20" string="Kanaris" />
          </tokens>
        </entity>
        <entity id="5" string="_" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="_" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>Thousands of islanders died in the Turkish raids, which shocked other nations and swung Western European countries behind the Greek struggle for independence from the Ottoman Empire.</content>
      <tokens>
        <token id="1" string="Thousands" lemma="thousand" stem="thousand" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="islanders" lemma="islander" stem="island" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="died" lemma="die" stem="di" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="Turkish" lemma="turkish" stem="turkish" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="8" string="raids" lemma="raid" stem="raid" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="shocked" lemma="shock" stem="shock" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="nations" lemma="nation" stem="nation" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="swung" lemma="swing" stem="swung" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="Western" lemma="western" stem="western" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="17" string="European" lemma="european" stem="european" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="18" string="countries" lemma="country" stem="countri" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="behind" lemma="behind" stem="behind" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Greek" lemma="greek" stem="greek" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="22" string="struggle" lemma="struggle" stem="struggl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="independence" lemma="independence" stem="independ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="Ottoman" lemma="Ottoman" stem="ottoman" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="Empire" lemma="Empire" stem="empire" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNS Thousands)) (PP (IN of) (NP (NNS islanders)))) (VP (VBD died) (PP (IN in) (NP (NP (DT the) (JJ Turkish) (NNS raids)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VP (VBD shocked) (NP (JJ other) (NNS nations))) (CC and) (VP (VBD swung) (NP (JJ Western) (JJ European) (NNS countries)) (PP (IN behind) (NP (NP (DT the) (JJ Greek) (NN struggle)) (PP (IN for) (NP (NN independence))))) (PP (IN from) (NP (DT the) (NNP Ottoman) (NNP Empire)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="which shocked other nations and swung Western European countries behind the Greek struggle for independence from the Ottoman Empire" type="SBAR">
          <tokens>
            <token id="10" string="which" />
            <token id="11" string="shocked" />
            <token id="12" string="other" />
            <token id="13" string="nations" />
            <token id="14" string="and" />
            <token id="15" string="swung" />
            <token id="16" string="Western" />
            <token id="17" string="European" />
            <token id="18" string="countries" />
            <token id="19" string="behind" />
            <token id="20" string="the" />
            <token id="21" string="Greek" />
            <token id="22" string="struggle" />
            <token id="23" string="for" />
            <token id="24" string="independence" />
            <token id="25" string="from" />
            <token id="26" string="the" />
            <token id="27" string="Ottoman" />
            <token id="28" string="Empire" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Greek struggle for independence" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="Greek" />
            <token id="22" string="struggle" />
            <token id="23" string="for" />
            <token id="24" string="independence" />
          </tokens>
        </chunking>
        <chunking id="3" string="Western European countries" type="NP">
          <tokens>
            <token id="16" string="Western" />
            <token id="17" string="European" />
            <token id="18" string="countries" />
          </tokens>
        </chunking>
        <chunking id="4" string="shocked other nations and swung Western European countries behind the Greek struggle for independence from the Ottoman Empire" type="VP">
          <tokens>
            <token id="11" string="shocked" />
            <token id="12" string="other" />
            <token id="13" string="nations" />
            <token id="14" string="and" />
            <token id="15" string="swung" />
            <token id="16" string="Western" />
            <token id="17" string="European" />
            <token id="18" string="countries" />
            <token id="19" string="behind" />
            <token id="20" string="the" />
            <token id="21" string="Greek" />
            <token id="22" string="struggle" />
            <token id="23" string="for" />
            <token id="24" string="independence" />
            <token id="25" string="from" />
            <token id="26" string="the" />
            <token id="27" string="Ottoman" />
            <token id="28" string="Empire" />
          </tokens>
        </chunking>
        <chunking id="5" string="died in the Turkish raids , which shocked other nations and swung Western European countries behind the Greek struggle for independence from the Ottoman Empire" type="VP">
          <tokens>
            <token id="4" string="died" />
            <token id="5" string="in" />
            <token id="6" string="the" />
            <token id="7" string="Turkish" />
            <token id="8" string="raids" />
            <token id="9" string="," />
            <token id="10" string="which" />
            <token id="11" string="shocked" />
            <token id="12" string="other" />
            <token id="13" string="nations" />
            <token id="14" string="and" />
            <token id="15" string="swung" />
            <token id="16" string="Western" />
            <token id="17" string="European" />
            <token id="18" string="countries" />
            <token id="19" string="behind" />
            <token id="20" string="the" />
            <token id="21" string="Greek" />
            <token id="22" string="struggle" />
            <token id="23" string="for" />
            <token id="24" string="independence" />
            <token id="25" string="from" />
            <token id="26" string="the" />
            <token id="27" string="Ottoman" />
            <token id="28" string="Empire" />
          </tokens>
        </chunking>
        <chunking id="6" string="independence" type="NP">
          <tokens>
            <token id="24" string="independence" />
          </tokens>
        </chunking>
        <chunking id="7" string="islanders" type="NP">
          <tokens>
            <token id="3" string="islanders" />
          </tokens>
        </chunking>
        <chunking id="8" string="other nations" type="NP">
          <tokens>
            <token id="12" string="other" />
            <token id="13" string="nations" />
          </tokens>
        </chunking>
        <chunking id="9" string="the Greek struggle" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="Greek" />
            <token id="22" string="struggle" />
          </tokens>
        </chunking>
        <chunking id="10" string="shocked other nations" type="VP">
          <tokens>
            <token id="11" string="shocked" />
            <token id="12" string="other" />
            <token id="13" string="nations" />
          </tokens>
        </chunking>
        <chunking id="11" string="the Turkish raids" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="Turkish" />
            <token id="8" string="raids" />
          </tokens>
        </chunking>
        <chunking id="12" string="the Ottoman Empire" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="Ottoman" />
            <token id="28" string="Empire" />
          </tokens>
        </chunking>
        <chunking id="13" string="the Turkish raids , which shocked other nations and swung Western European countries behind the Greek struggle for independence from the Ottoman Empire" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="Turkish" />
            <token id="8" string="raids" />
            <token id="9" string="," />
            <token id="10" string="which" />
            <token id="11" string="shocked" />
            <token id="12" string="other" />
            <token id="13" string="nations" />
            <token id="14" string="and" />
            <token id="15" string="swung" />
            <token id="16" string="Western" />
            <token id="17" string="European" />
            <token id="18" string="countries" />
            <token id="19" string="behind" />
            <token id="20" string="the" />
            <token id="21" string="Greek" />
            <token id="22" string="struggle" />
            <token id="23" string="for" />
            <token id="24" string="independence" />
            <token id="25" string="from" />
            <token id="26" string="the" />
            <token id="27" string="Ottoman" />
            <token id="28" string="Empire" />
          </tokens>
        </chunking>
        <chunking id="14" string="Thousands of islanders" type="NP">
          <tokens>
            <token id="1" string="Thousands" />
            <token id="2" string="of" />
            <token id="3" string="islanders" />
          </tokens>
        </chunking>
        <chunking id="15" string="Thousands" type="NP">
          <tokens>
            <token id="1" string="Thousands" />
          </tokens>
        </chunking>
        <chunking id="16" string="swung Western European countries behind the Greek struggle for independence from the Ottoman Empire" type="VP">
          <tokens>
            <token id="15" string="swung" />
            <token id="16" string="Western" />
            <token id="17" string="European" />
            <token id="18" string="countries" />
            <token id="19" string="behind" />
            <token id="20" string="the" />
            <token id="21" string="Greek" />
            <token id="22" string="struggle" />
            <token id="23" string="for" />
            <token id="24" string="independence" />
            <token id="25" string="from" />
            <token id="26" string="the" />
            <token id="27" string="Ottoman" />
            <token id="28" string="Empire" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">died</governor>
          <dependent id="1">Thousands</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">islanders</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Thousands</governor>
          <dependent id="3">islanders</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">died</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">raids</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">raids</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">raids</governor>
          <dependent id="7">Turkish</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">died</governor>
          <dependent id="8">raids</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">shocked</governor>
          <dependent id="10">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">raids</governor>
          <dependent id="11">shocked</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">nations</governor>
          <dependent id="12">other</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">shocked</governor>
          <dependent id="13">nations</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">shocked</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">shocked</governor>
          <dependent id="15">swung</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">countries</governor>
          <dependent id="16">Western</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">countries</governor>
          <dependent id="17">European</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">swung</governor>
          <dependent id="18">countries</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">struggle</governor>
          <dependent id="19">behind</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">struggle</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">struggle</governor>
          <dependent id="21">Greek</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">swung</governor>
          <dependent id="22">struggle</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">independence</governor>
          <dependent id="23">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">struggle</governor>
          <dependent id="24">independence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">Empire</governor>
          <dependent id="25">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">Empire</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">Empire</governor>
          <dependent id="27">Ottoman</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">swung</governor>
          <dependent id="28">Empire</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Greek" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="21" string="Greek" />
          </tokens>
        </entity>
        <entity id="2" string="Turkish" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="7" string="Turkish" />
          </tokens>
        </entity>
        <entity id="3" string="Western European" type="MISC" score="0.0">
          <tokens>
            <token id="16" string="Western" />
            <token id="17" string="European" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="false">
      <content>Greece won independence in 1830.</content>
      <tokens>
        <token id="1" string="Greece" lemma="Greece" stem="greec" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="2" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="independence" lemma="independence" stem="independ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="1830" lemma="1830" stem="1830" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Greece)) (VP (VBD won) (NP (NN independence)) (PP (IN in) (NP (CD 1830)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Greece" type="NP">
          <tokens>
            <token id="1" string="Greece" />
          </tokens>
        </chunking>
        <chunking id="2" string="1830" type="NP">
          <tokens>
            <token id="5" string="1830" />
          </tokens>
        </chunking>
        <chunking id="3" string="independence" type="NP">
          <tokens>
            <token id="3" string="independence" />
          </tokens>
        </chunking>
        <chunking id="4" string="won independence in 1830" type="VP">
          <tokens>
            <token id="2" string="won" />
            <token id="3" string="independence" />
            <token id="4" string="in" />
            <token id="5" string="1830" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">won</governor>
          <dependent id="1">Greece</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">won</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">won</governor>
          <dependent id="3">independence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">1830</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">won</governor>
          <dependent id="5">1830</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Greece" type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="Greece" />
          </tokens>
        </entity>
        <entity id="2" string="1830" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="1830" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>The French painter Eugene Delacroix produced a famous picture, ``The Massacre of Chios,&amp;apost;&amp;apost; based on the raids.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="French" lemma="french" stem="french" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="3" string="painter" lemma="painter" stem="painter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Eugene" lemma="Eugene" stem="eugen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="5" string="Delacroix" lemma="Delacroix" stem="delacroix" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="6" string="produced" lemma="produce" stem="produc" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="famous" lemma="famous" stem="famou" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="picture" lemma="picture" stem="pictur" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Massacre" lemma="massacre" stem="massacr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Chios" lemma="Chios" stem="chio" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="based" lemma="base" stem="base" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="raids" lemma="raid" stem="raid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (JJ French) (NN painter) (NNP Eugene) (NNP Delacroix)) (VP (VBD produced) (NP (NP (DT a) (JJ famous) (NN picture)) (, ,) (NP (`` ``) (NP (NP (DT The) (NN Massacre)) (PP (IN of) (NP (NNP Chios)))) (, ,) ('' '') (VP (VBN based) (PP (IN on) (NP (DT the) (NNS raids))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a famous picture" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="famous" />
            <token id="9" string="picture" />
          </tokens>
        </chunking>
        <chunking id="2" string="The Massacre of Chios" type="NP">
          <tokens>
            <token id="12" string="The" />
            <token id="13" string="Massacre" />
            <token id="14" string="of" />
            <token id="15" string="Chios" />
          </tokens>
        </chunking>
        <chunking id="3" string="produced a famous picture , `` The Massacre of Chios , '' based on the raids" type="VP">
          <tokens>
            <token id="6" string="produced" />
            <token id="7" string="a" />
            <token id="8" string="famous" />
            <token id="9" string="picture" />
            <token id="10" string="," />
            <token id="11" string="``" />
            <token id="12" string="The" />
            <token id="13" string="Massacre" />
            <token id="14" string="of" />
            <token id="15" string="Chios" />
            <token id="16" string="," />
            <token id="17" string="''" />
            <token id="18" string="based" />
            <token id="19" string="on" />
            <token id="20" string="the" />
            <token id="21" string="raids" />
          </tokens>
        </chunking>
        <chunking id="4" string="`` The Massacre of Chios , '' based on the raids" type="NP">
          <tokens>
            <token id="11" string="``" />
            <token id="12" string="The" />
            <token id="13" string="Massacre" />
            <token id="14" string="of" />
            <token id="15" string="Chios" />
            <token id="16" string="," />
            <token id="17" string="''" />
            <token id="18" string="based" />
            <token id="19" string="on" />
            <token id="20" string="the" />
            <token id="21" string="raids" />
          </tokens>
        </chunking>
        <chunking id="5" string="Chios" type="NP">
          <tokens>
            <token id="15" string="Chios" />
          </tokens>
        </chunking>
        <chunking id="6" string="The French painter Eugene Delacroix" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="French" />
            <token id="3" string="painter" />
            <token id="4" string="Eugene" />
            <token id="5" string="Delacroix" />
          </tokens>
        </chunking>
        <chunking id="7" string="The Massacre" type="NP">
          <tokens>
            <token id="12" string="The" />
            <token id="13" string="Massacre" />
          </tokens>
        </chunking>
        <chunking id="8" string="the raids" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="raids" />
          </tokens>
        </chunking>
        <chunking id="9" string="based on the raids" type="VP">
          <tokens>
            <token id="18" string="based" />
            <token id="19" string="on" />
            <token id="20" string="the" />
            <token id="21" string="raids" />
          </tokens>
        </chunking>
        <chunking id="10" string="a famous picture , `` The Massacre of Chios , '' based on the raids" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="famous" />
            <token id="9" string="picture" />
            <token id="10" string="," />
            <token id="11" string="``" />
            <token id="12" string="The" />
            <token id="13" string="Massacre" />
            <token id="14" string="of" />
            <token id="15" string="Chios" />
            <token id="16" string="," />
            <token id="17" string="''" />
            <token id="18" string="based" />
            <token id="19" string="on" />
            <token id="20" string="the" />
            <token id="21" string="raids" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="5">Delacroix</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">Delacroix</governor>
          <dependent id="2">French</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Delacroix</governor>
          <dependent id="3">painter</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Delacroix</governor>
          <dependent id="4">Eugene</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">produced</governor>
          <dependent id="5">Delacroix</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">produced</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">picture</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">picture</governor>
          <dependent id="8">famous</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">produced</governor>
          <dependent id="9">picture</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">Massacre</governor>
          <dependent id="12">The</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="9">picture</governor>
          <dependent id="13">Massacre</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Chios</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">Massacre</governor>
          <dependent id="15">Chios</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="13">Massacre</governor>
          <dependent id="18">based</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">raids</governor>
          <dependent id="19">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">raids</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">based</governor>
          <dependent id="21">raids</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="French" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="2" string="French" />
          </tokens>
        </entity>
        <entity id="2" string="Eugene Delacroix" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Eugene" />
            <token id="5" string="Delacroix" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>``It&amp;apost;s an incredible discovery, straight out of the history book we used to read in school about the War of Independence,&amp;apost;&amp;apost; Nicolaides said in an interview Friday with The Associated Press.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="incredible" lemma="incredible" stem="incred" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="discovery" lemma="discovery" stem="discoveri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="straight" lemma="straight" stem="straight" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="history" lemma="history" stem="histori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="used" lemma="use" stem="us" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="read" lemma="read" stem="read" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="War" lemma="war" stem="war" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="24" string="Independence" lemma="independence" stem="independ" pos="NN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="Nicolaides" lemma="Nicolaides" stem="nicolaid" pos="NNPS" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="28" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="interview" lemma="interview" stem="interview" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="Friday" lemma="Friday" stem="fridai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="33" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="Associated" lemma="Associated" stem="associat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="36" string="Press" lemma="Press" stem="press" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP It)) (VP (VBZ 's) (NP (DT an) (JJ incredible) (NN discovery)) (, ,) (PP (RB straight) (IN out) (IN of) (NP (NP (DT the) (NN history) (NN book)) (SBAR (S (NP (PRP we)) (VP (VBD used) (S (VP (TO to) (VP (VB read) (PP (IN in) (NP (NN school))) (PP (IN about) (NP (NP (DT the) (NN War)) (PP (IN of) (NP (NN Independence))))))))))))))) (, ,) ('' '') (NP (NNPS Nicolaides)) (VP (VBD said) (PP (IN in) (NP (DT an) (NN interview))) (NP-TMP (NNP Friday)) (PP (IN with) (NP (DT The) (NNP Associated) (NNP Press)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Independence" type="NP">
          <tokens>
            <token id="24" string="Independence" />
          </tokens>
        </chunking>
        <chunking id="2" string="'s an incredible discovery , straight out of the history book we used to read in school about the War of Independence" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="an" />
            <token id="5" string="incredible" />
            <token id="6" string="discovery" />
            <token id="7" string="," />
            <token id="8" string="straight" />
            <token id="9" string="out" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="history" />
            <token id="13" string="book" />
            <token id="14" string="we" />
            <token id="15" string="used" />
            <token id="16" string="to" />
            <token id="17" string="read" />
            <token id="18" string="in" />
            <token id="19" string="school" />
            <token id="20" string="about" />
            <token id="21" string="the" />
            <token id="22" string="War" />
            <token id="23" string="of" />
            <token id="24" string="Independence" />
          </tokens>
        </chunking>
        <chunking id="3" string="said in an interview Friday with The Associated Press" type="VP">
          <tokens>
            <token id="28" string="said" />
            <token id="29" string="in" />
            <token id="30" string="an" />
            <token id="31" string="interview" />
            <token id="32" string="Friday" />
            <token id="33" string="with" />
            <token id="34" string="The" />
            <token id="35" string="Associated" />
            <token id="36" string="Press" />
          </tokens>
        </chunking>
        <chunking id="4" string="the history book" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="history" />
            <token id="13" string="book" />
          </tokens>
        </chunking>
        <chunking id="5" string="Nicolaides" type="NP">
          <tokens>
            <token id="27" string="Nicolaides" />
          </tokens>
        </chunking>
        <chunking id="6" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="7" string="read in school about the War of Independence" type="VP">
          <tokens>
            <token id="17" string="read" />
            <token id="18" string="in" />
            <token id="19" string="school" />
            <token id="20" string="about" />
            <token id="21" string="the" />
            <token id="22" string="War" />
            <token id="23" string="of" />
            <token id="24" string="Independence" />
          </tokens>
        </chunking>
        <chunking id="8" string="we used to read in school about the War of Independence" type="SBAR">
          <tokens>
            <token id="14" string="we" />
            <token id="15" string="used" />
            <token id="16" string="to" />
            <token id="17" string="read" />
            <token id="18" string="in" />
            <token id="19" string="school" />
            <token id="20" string="about" />
            <token id="21" string="the" />
            <token id="22" string="War" />
            <token id="23" string="of" />
            <token id="24" string="Independence" />
          </tokens>
        </chunking>
        <chunking id="9" string="The Associated Press" type="NP">
          <tokens>
            <token id="34" string="The" />
            <token id="35" string="Associated" />
            <token id="36" string="Press" />
          </tokens>
        </chunking>
        <chunking id="10" string="we" type="NP">
          <tokens>
            <token id="14" string="we" />
          </tokens>
        </chunking>
        <chunking id="11" string="an incredible discovery" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="incredible" />
            <token id="6" string="discovery" />
          </tokens>
        </chunking>
        <chunking id="12" string="the War of Independence" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="War" />
            <token id="23" string="of" />
            <token id="24" string="Independence" />
          </tokens>
        </chunking>
        <chunking id="13" string="the War" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="War" />
          </tokens>
        </chunking>
        <chunking id="14" string="school" type="NP">
          <tokens>
            <token id="19" string="school" />
          </tokens>
        </chunking>
        <chunking id="15" string="an interview" type="NP">
          <tokens>
            <token id="30" string="an" />
            <token id="31" string="interview" />
          </tokens>
        </chunking>
        <chunking id="16" string="to read in school about the War of Independence" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="read" />
            <token id="18" string="in" />
            <token id="19" string="school" />
            <token id="20" string="about" />
            <token id="21" string="the" />
            <token id="22" string="War" />
            <token id="23" string="of" />
            <token id="24" string="Independence" />
          </tokens>
        </chunking>
        <chunking id="17" string="used to read in school about the War of Independence" type="VP">
          <tokens>
            <token id="15" string="used" />
            <token id="16" string="to" />
            <token id="17" string="read" />
            <token id="18" string="in" />
            <token id="19" string="school" />
            <token id="20" string="about" />
            <token id="21" string="the" />
            <token id="22" string="War" />
            <token id="23" string="of" />
            <token id="24" string="Independence" />
          </tokens>
        </chunking>
        <chunking id="18" string="the history book we used to read in school about the War of Independence" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="history" />
            <token id="13" string="book" />
            <token id="14" string="we" />
            <token id="15" string="used" />
            <token id="16" string="to" />
            <token id="17" string="read" />
            <token id="18" string="in" />
            <token id="19" string="school" />
            <token id="20" string="about" />
            <token id="21" string="the" />
            <token id="22" string="War" />
            <token id="23" string="of" />
            <token id="24" string="Independence" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">discovery</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">discovery</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">discovery</governor>
          <dependent id="4">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">discovery</governor>
          <dependent id="5">incredible</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="28">said</governor>
          <dependent id="6">discovery</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">book</governor>
          <dependent id="8">straight</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">book</governor>
          <dependent id="9">out</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="9">out</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">book</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">book</governor>
          <dependent id="12">history</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">discovery</governor>
          <dependent id="13">book</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">used</governor>
          <dependent id="14">we</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">book</governor>
          <dependent id="15">used</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">read</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">used</governor>
          <dependent id="17">read</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">school</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">read</governor>
          <dependent id="19">school</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">War</governor>
          <dependent id="20">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">War</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">read</governor>
          <dependent id="22">War</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">Independence</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">War</governor>
          <dependent id="24">Independence</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">said</governor>
          <dependent id="27">Nicolaides</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="28">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">interview</governor>
          <dependent id="29">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">interview</governor>
          <dependent id="30">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">said</governor>
          <dependent id="31">interview</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="28">said</governor>
          <dependent id="32">Friday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">Press</governor>
          <dependent id="33">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">Press</governor>
          <dependent id="34">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">Press</governor>
          <dependent id="35">Associated</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">said</governor>
          <dependent id="36">Press</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Independence" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="24" string="Independence" />
          </tokens>
        </entity>
        <entity id="2" string="Friday" type="DATE" score="0.0">
          <tokens>
            <token id="32" string="Friday" />
          </tokens>
        </entity>
        <entity id="3" string="Associated Press" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="35" string="Associated" />
            <token id="36" string="Press" />
          </tokens>
        </entity>
        <entity id="4" string="Nicolaides" type="PERSON" score="0.0">
          <tokens>
            <token id="27" string="Nicolaides" />
          </tokens>
        </entity>
        <entity id="5" string="War of" type="MISC" score="0.0">
          <tokens>
            <token id="22" string="War" />
            <token id="23" string="of" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>Nicolaides, who heard about the wreck while teaching an underwater archaeology course to local divers last winter, started querying fishermen about where their nets snagged on seabed obstacles.</content>
      <tokens>
        <token id="1" string="Nicolaides" lemma="nicolaide" stem="nicolaid" pos="NNS" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="heard" lemma="hear" stem="heard" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="7" string="wreck" lemma="wreck" stem="wreck" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="8" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="teaching" lemma="teach" stem="teach" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="underwater" lemma="underwater" stem="underwat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="archaeology" lemma="archaeology" stem="archaeologi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="course" lemma="course" stem="cours" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="local" lemma="local" stem="local" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="16" string="divers" lemma="diver" stem="diver" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="17" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="18" string="winter" lemma="winter" stem="winter" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="started" lemma="start" stem="start" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="querying" lemma="query" stem="queri" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="fishermen" lemma="fisherman" stem="fishermen" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="nets" lemma="net" stem="net" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="snagged" lemma="snag" stem="snag" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="seabed" lemma="seab" stem="seab" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="obstacles" lemma="obstacle" stem="obstacl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNS Nicolaides)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD heard) (PP (IN about) (NP (DT the) (NN wreck))) (SBAR (IN while) (S (VP (VBG teaching) (NP (DT an) (JJ underwater) (NN archaeology) (NN course)) (PP (TO to) (NP (JJ local) (NNS divers))) (NP-TMP (JJ last) (NN winter)))))))) (, ,)) (VP (VBD started) (NP (NP (VBG querying) (NNS fishermen)) (PP (IN about) (SBAR (WHADVP (WRB where)) (S (NP (PRP$ their) (NNS nets)) (VP (VBD snagged) (PP (IN on) (S (VP (VBN seabed) (NP (NNS obstacles))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="obstacles" type="NP">
          <tokens>
            <token id="30" string="obstacles" />
          </tokens>
        </chunking>
        <chunking id="2" string="querying fishermen" type="NP">
          <tokens>
            <token id="21" string="querying" />
            <token id="22" string="fishermen" />
          </tokens>
        </chunking>
        <chunking id="3" string="started querying fishermen about where their nets snagged on seabed obstacles" type="VP">
          <tokens>
            <token id="20" string="started" />
            <token id="21" string="querying" />
            <token id="22" string="fishermen" />
            <token id="23" string="about" />
            <token id="24" string="where" />
            <token id="25" string="their" />
            <token id="26" string="nets" />
            <token id="27" string="snagged" />
            <token id="28" string="on" />
            <token id="29" string="seabed" />
            <token id="30" string="obstacles" />
          </tokens>
        </chunking>
        <chunking id="4" string="their nets" type="NP">
          <tokens>
            <token id="25" string="their" />
            <token id="26" string="nets" />
          </tokens>
        </chunking>
        <chunking id="5" string="teaching an underwater archaeology course to local divers last winter" type="VP">
          <tokens>
            <token id="9" string="teaching" />
            <token id="10" string="an" />
            <token id="11" string="underwater" />
            <token id="12" string="archaeology" />
            <token id="13" string="course" />
            <token id="14" string="to" />
            <token id="15" string="local" />
            <token id="16" string="divers" />
            <token id="17" string="last" />
            <token id="18" string="winter" />
          </tokens>
        </chunking>
        <chunking id="6" string="snagged on seabed obstacles" type="VP">
          <tokens>
            <token id="27" string="snagged" />
            <token id="28" string="on" />
            <token id="29" string="seabed" />
            <token id="30" string="obstacles" />
          </tokens>
        </chunking>
        <chunking id="7" string="Nicolaides" type="NP">
          <tokens>
            <token id="1" string="Nicolaides" />
          </tokens>
        </chunking>
        <chunking id="8" string="the wreck" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="wreck" />
          </tokens>
        </chunking>
        <chunking id="9" string="heard about the wreck while teaching an underwater archaeology course to local divers last winter" type="VP">
          <tokens>
            <token id="4" string="heard" />
            <token id="5" string="about" />
            <token id="6" string="the" />
            <token id="7" string="wreck" />
            <token id="8" string="while" />
            <token id="9" string="teaching" />
            <token id="10" string="an" />
            <token id="11" string="underwater" />
            <token id="12" string="archaeology" />
            <token id="13" string="course" />
            <token id="14" string="to" />
            <token id="15" string="local" />
            <token id="16" string="divers" />
            <token id="17" string="last" />
            <token id="18" string="winter" />
          </tokens>
        </chunking>
        <chunking id="10" string="Nicolaides , who heard about the wreck while teaching an underwater archaeology course to local divers last winter ," type="NP">
          <tokens>
            <token id="1" string="Nicolaides" />
            <token id="2" string="," />
            <token id="3" string="who" />
            <token id="4" string="heard" />
            <token id="5" string="about" />
            <token id="6" string="the" />
            <token id="7" string="wreck" />
            <token id="8" string="while" />
            <token id="9" string="teaching" />
            <token id="10" string="an" />
            <token id="11" string="underwater" />
            <token id="12" string="archaeology" />
            <token id="13" string="course" />
            <token id="14" string="to" />
            <token id="15" string="local" />
            <token id="16" string="divers" />
            <token id="17" string="last" />
            <token id="18" string="winter" />
            <token id="19" string="," />
          </tokens>
        </chunking>
        <chunking id="11" string="local divers" type="NP">
          <tokens>
            <token id="15" string="local" />
            <token id="16" string="divers" />
          </tokens>
        </chunking>
        <chunking id="12" string="seabed obstacles" type="VP">
          <tokens>
            <token id="29" string="seabed" />
            <token id="30" string="obstacles" />
          </tokens>
        </chunking>
        <chunking id="13" string="querying fishermen about where their nets snagged on seabed obstacles" type="NP">
          <tokens>
            <token id="21" string="querying" />
            <token id="22" string="fishermen" />
            <token id="23" string="about" />
            <token id="24" string="where" />
            <token id="25" string="their" />
            <token id="26" string="nets" />
            <token id="27" string="snagged" />
            <token id="28" string="on" />
            <token id="29" string="seabed" />
            <token id="30" string="obstacles" />
          </tokens>
        </chunking>
        <chunking id="14" string="while teaching an underwater archaeology course to local divers last winter" type="SBAR">
          <tokens>
            <token id="8" string="while" />
            <token id="9" string="teaching" />
            <token id="10" string="an" />
            <token id="11" string="underwater" />
            <token id="12" string="archaeology" />
            <token id="13" string="course" />
            <token id="14" string="to" />
            <token id="15" string="local" />
            <token id="16" string="divers" />
            <token id="17" string="last" />
            <token id="18" string="winter" />
          </tokens>
        </chunking>
        <chunking id="15" string="an underwater archaeology course" type="NP">
          <tokens>
            <token id="10" string="an" />
            <token id="11" string="underwater" />
            <token id="12" string="archaeology" />
            <token id="13" string="course" />
          </tokens>
        </chunking>
        <chunking id="16" string="who heard about the wreck while teaching an underwater archaeology course to local divers last winter" type="SBAR">
          <tokens>
            <token id="3" string="who" />
            <token id="4" string="heard" />
            <token id="5" string="about" />
            <token id="6" string="the" />
            <token id="7" string="wreck" />
            <token id="8" string="while" />
            <token id="9" string="teaching" />
            <token id="10" string="an" />
            <token id="11" string="underwater" />
            <token id="12" string="archaeology" />
            <token id="13" string="course" />
            <token id="14" string="to" />
            <token id="15" string="local" />
            <token id="16" string="divers" />
            <token id="17" string="last" />
            <token id="18" string="winter" />
          </tokens>
        </chunking>
        <chunking id="17" string="where" type="WHADVP">
          <tokens>
            <token id="24" string="where" />
          </tokens>
        </chunking>
        <chunking id="18" string="where their nets snagged on seabed obstacles" type="SBAR">
          <tokens>
            <token id="24" string="where" />
            <token id="25" string="their" />
            <token id="26" string="nets" />
            <token id="27" string="snagged" />
            <token id="28" string="on" />
            <token id="29" string="seabed" />
            <token id="30" string="obstacles" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="20">started</governor>
          <dependent id="1">Nicolaides</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">heard</governor>
          <dependent id="3">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="1">Nicolaides</governor>
          <dependent id="4">heard</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">wreck</governor>
          <dependent id="5">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">wreck</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">heard</governor>
          <dependent id="7">wreck</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">teaching</governor>
          <dependent id="8">while</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">heard</governor>
          <dependent id="9">teaching</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">course</governor>
          <dependent id="10">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">course</governor>
          <dependent id="11">underwater</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">course</governor>
          <dependent id="12">archaeology</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">teaching</governor>
          <dependent id="13">course</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">divers</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">divers</governor>
          <dependent id="15">local</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">teaching</governor>
          <dependent id="16">divers</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">winter</governor>
          <dependent id="17">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="9">teaching</governor>
          <dependent id="18">winter</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">started</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">fishermen</governor>
          <dependent id="21">querying</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">started</governor>
          <dependent id="22">fishermen</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">snagged</governor>
          <dependent id="23">about</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="27">snagged</governor>
          <dependent id="24">where</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="26">nets</governor>
          <dependent id="25">their</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">snagged</governor>
          <dependent id="26">nets</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="22">fishermen</governor>
          <dependent id="27">snagged</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">seabed</governor>
          <dependent id="28">on</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="27">snagged</governor>
          <dependent id="29">seabed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">seabed</governor>
          <dependent id="30">obstacles</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="last winter" type="DATE" score="0.0">
          <tokens>
            <token id="17" string="last" />
            <token id="18" string="winter" />
          </tokens>
        </entity>
        <entity id="2" string="Nicolaides" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Nicolaides" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>He pinpointed the wreck on May 3, he said.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="pinpointed" lemma="pinpoint" stem="pinpoint" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="wreck" lemma="wreck" stem="wreck" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="May" lemma="May" stem="mai" pos="NNP" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="3" lemma="3" stem="3" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP He)) (VP (VBD pinpointed) (NP (DT the) (NN wreck)) (PP (IN on) (NP (NNP May) (CD 3))))) (, ,) (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="pinpointed the wreck on May 3" type="VP">
          <tokens>
            <token id="2" string="pinpointed" />
            <token id="3" string="the" />
            <token id="4" string="wreck" />
            <token id="5" string="on" />
            <token id="6" string="May" />
            <token id="7" string="3" />
          </tokens>
        </chunking>
        <chunking id="2" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="3" string="he" type="NP">
          <tokens>
            <token id="9" string="he" />
          </tokens>
        </chunking>
        <chunking id="4" string="the wreck" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="wreck" />
          </tokens>
        </chunking>
        <chunking id="5" string="May 3" type="NP">
          <tokens>
            <token id="6" string="May" />
            <token id="7" string="3" />
          </tokens>
        </chunking>
        <chunking id="6" string="said" type="VP">
          <tokens>
            <token id="10" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">pinpointed</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">said</governor>
          <dependent id="2">pinpointed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">wreck</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">pinpointed</governor>
          <dependent id="4">wreck</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">May</governor>
          <dependent id="5">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">pinpointed</governor>
          <dependent id="6">May</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">May</governor>
          <dependent id="7">3</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">said</governor>
          <dependent id="9">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="May 3" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="May" />
            <token id="7" string="3" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>``When I dived, I found ships&amp;apost; timbers sticking out of the muddy seabed and dozens of objects _ Islamic cooking pots, cannon balls, a candlestick, even a chalice from a Greek Orthodox church,&amp;apost;&amp;apost; he said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="dived" lemma="dive" stem="dive" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="found" lemma="find" stem="found" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="ships" lemma="ship" stem="ship" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="timbers" lemma="timber" stem="timber" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="sticking" lemma="stick" stem="stick" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="muddy" lemma="muddy" stem="muddi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="seabed" lemma="seabed" stem="seab" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="dozens" lemma="dozen" stem="dozen" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="objects" lemma="object" stem="object" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="_" lemma="_" stem="_" pos="VBP" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Islamic" lemma="islamic" stem="islamic" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="23" string="cooking" lemma="cooking" stem="cook" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="pots" lemma="pot" stem="pot" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="cannon" lemma="cannon" stem="cannon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="balls" lemma="ball" stem="ball" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="candlestick" lemma="candlestick" stem="candlestick" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="chalice" lemma="chalice" stem="chalic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="Greek" lemma="greek" stem="greek" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="38" string="Orthodox" lemma="Orthodox" stem="orthodox" pos="NNP" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="39" string="church" lemma="church" stem="church" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="43" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (SBAR (WHADVP (WRB When)) (S (NP (PRP I)) (VP (VBD dived)))) (, ,) (NP (PRP I)) (VP (VBD found) (NP (NP (NNS ships) (POS ')) (NNS timbers)) (S (VP (VBG sticking) (PRT (IN out)) (PP (IN of) (NP (DT the) (JJ muddy) (NN seabed))))))) (CC and) (S (NP (NP (NNS dozens)) (PP (IN of) (NP (NNS objects)))) (VP (VBP _) (NP (NP (JJ Islamic) (NN cooking) (NNS pots)) (, ,) (NP (NN cannon) (NNS balls)) (, ,) (NP (DT a) (NN candlestick)) (, ,) (NP (NP (RB even) (DT a) (NN chalice)) (PP (IN from) (NP (DT a) (JJ Greek) (NNP Orthodox) (NN church)))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="objects" type="NP">
          <tokens>
            <token id="20" string="objects" />
          </tokens>
        </chunking>
        <chunking id="2" string="even a chalice from a Greek Orthodox church" type="NP">
          <tokens>
            <token id="32" string="even" />
            <token id="33" string="a" />
            <token id="34" string="chalice" />
            <token id="35" string="from" />
            <token id="36" string="a" />
            <token id="37" string="Greek" />
            <token id="38" string="Orthodox" />
            <token id="39" string="church" />
          </tokens>
        </chunking>
        <chunking id="3" string="_ Islamic cooking pots , cannon balls , a candlestick , even a chalice from a Greek Orthodox church" type="VP">
          <tokens>
            <token id="21" string="_" />
            <token id="22" string="Islamic" />
            <token id="23" string="cooking" />
            <token id="24" string="pots" />
            <token id="25" string="," />
            <token id="26" string="cannon" />
            <token id="27" string="balls" />
            <token id="28" string="," />
            <token id="29" string="a" />
            <token id="30" string="candlestick" />
            <token id="31" string="," />
            <token id="32" string="even" />
            <token id="33" string="a" />
            <token id="34" string="chalice" />
            <token id="35" string="from" />
            <token id="36" string="a" />
            <token id="37" string="Greek" />
            <token id="38" string="Orthodox" />
            <token id="39" string="church" />
          </tokens>
        </chunking>
        <chunking id="4" string="a candlestick" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="candlestick" />
          </tokens>
        </chunking>
        <chunking id="5" string="dozens" type="NP">
          <tokens>
            <token id="18" string="dozens" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="3" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="found ships ' timbers sticking out of the muddy seabed" type="VP">
          <tokens>
            <token id="7" string="found" />
            <token id="8" string="ships" />
            <token id="9" string="'" />
            <token id="10" string="timbers" />
            <token id="11" string="sticking" />
            <token id="12" string="out" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="muddy" />
            <token id="16" string="seabed" />
          </tokens>
        </chunking>
        <chunking id="8" string="the muddy seabed" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="muddy" />
            <token id="16" string="seabed" />
          </tokens>
        </chunking>
        <chunking id="9" string="Islamic cooking pots , cannon balls , a candlestick , even a chalice from a Greek Orthodox church" type="NP">
          <tokens>
            <token id="22" string="Islamic" />
            <token id="23" string="cooking" />
            <token id="24" string="pots" />
            <token id="25" string="," />
            <token id="26" string="cannon" />
            <token id="27" string="balls" />
            <token id="28" string="," />
            <token id="29" string="a" />
            <token id="30" string="candlestick" />
            <token id="31" string="," />
            <token id="32" string="even" />
            <token id="33" string="a" />
            <token id="34" string="chalice" />
            <token id="35" string="from" />
            <token id="36" string="a" />
            <token id="37" string="Greek" />
            <token id="38" string="Orthodox" />
            <token id="39" string="church" />
          </tokens>
        </chunking>
        <chunking id="10" string="When" type="WHADVP">
          <tokens>
            <token id="2" string="When" />
          </tokens>
        </chunking>
        <chunking id="11" string="When I dived" type="SBAR">
          <tokens>
            <token id="2" string="When" />
            <token id="3" string="I" />
            <token id="4" string="dived" />
          </tokens>
        </chunking>
        <chunking id="12" string="Islamic cooking pots" type="NP">
          <tokens>
            <token id="22" string="Islamic" />
            <token id="23" string="cooking" />
            <token id="24" string="pots" />
          </tokens>
        </chunking>
        <chunking id="13" string="ships ' timbers" type="NP">
          <tokens>
            <token id="8" string="ships" />
            <token id="9" string="'" />
            <token id="10" string="timbers" />
          </tokens>
        </chunking>
        <chunking id="14" string="a Greek Orthodox church" type="NP">
          <tokens>
            <token id="36" string="a" />
            <token id="37" string="Greek" />
            <token id="38" string="Orthodox" />
            <token id="39" string="church" />
          </tokens>
        </chunking>
        <chunking id="15" string="even a chalice" type="NP">
          <tokens>
            <token id="32" string="even" />
            <token id="33" string="a" />
            <token id="34" string="chalice" />
          </tokens>
        </chunking>
        <chunking id="16" string="he" type="NP">
          <tokens>
            <token id="42" string="he" />
          </tokens>
        </chunking>
        <chunking id="17" string="dived" type="VP">
          <tokens>
            <token id="4" string="dived" />
          </tokens>
        </chunking>
        <chunking id="18" string="ships '" type="NP">
          <tokens>
            <token id="8" string="ships" />
            <token id="9" string="'" />
          </tokens>
        </chunking>
        <chunking id="19" string="said" type="VP">
          <tokens>
            <token id="43" string="said" />
          </tokens>
        </chunking>
        <chunking id="20" string="dozens of objects" type="NP">
          <tokens>
            <token id="18" string="dozens" />
            <token id="19" string="of" />
            <token id="20" string="objects" />
          </tokens>
        </chunking>
        <chunking id="21" string="cannon balls" type="NP">
          <tokens>
            <token id="26" string="cannon" />
            <token id="27" string="balls" />
          </tokens>
        </chunking>
        <chunking id="22" string="sticking out of the muddy seabed" type="VP">
          <tokens>
            <token id="11" string="sticking" />
            <token id="12" string="out" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="muddy" />
            <token id="16" string="seabed" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">dived</governor>
          <dependent id="2">When</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">dived</governor>
          <dependent id="3">I</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">found</governor>
          <dependent id="4">dived</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">found</governor>
          <dependent id="6">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="43">said</governor>
          <dependent id="7">found</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">timbers</governor>
          <dependent id="8">ships</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">ships</governor>
          <dependent id="9">'</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">found</governor>
          <dependent id="10">timbers</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">found</governor>
          <dependent id="11">sticking</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="11">sticking</governor>
          <dependent id="12">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">seabed</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">seabed</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">seabed</governor>
          <dependent id="15">muddy</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">sticking</governor>
          <dependent id="16">seabed</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">found</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">_</governor>
          <dependent id="18">dozens</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">objects</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">dozens</governor>
          <dependent id="20">objects</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">found</governor>
          <dependent id="21">_</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">pots</governor>
          <dependent id="22">Islamic</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">pots</governor>
          <dependent id="23">cooking</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">_</governor>
          <dependent id="24">pots</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">balls</governor>
          <dependent id="26">cannon</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="24">pots</governor>
          <dependent id="27">balls</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">candlestick</governor>
          <dependent id="29">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="24">pots</governor>
          <dependent id="30">candlestick</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="34">chalice</governor>
          <dependent id="32">even</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">chalice</governor>
          <dependent id="33">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="24">pots</governor>
          <dependent id="34">chalice</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">church</governor>
          <dependent id="35">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">church</governor>
          <dependent id="36">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="39">church</governor>
          <dependent id="37">Greek</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="39">church</governor>
          <dependent id="38">Orthodox</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">chalice</governor>
          <dependent id="39">church</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="43">said</governor>
          <dependent id="42">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="43">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Islamic" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="22" string="Islamic" />
          </tokens>
        </entity>
        <entity id="2" string="Greek Orthodox" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="37" string="Greek" />
            <token id="38" string="Orthodox" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>``The ship was obviously crammed with loot from Chios.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="ship" lemma="ship" stem="ship" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="obviously" lemma="obviously" stem="obvious" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="crammed" lemma="cram" stem="cram" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="loot" lemma="loot" stem="loot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Chios" lemma="Chios" stem="chio" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (DT The) (NN ship)) (VP (VBD was) (ADVP (RB obviously)) (VP (VBN crammed) (PP (IN with) (NP (NN loot))) (PP (IN from) (NP (NNP Chios))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="loot" type="NP">
          <tokens>
            <token id="8" string="loot" />
          </tokens>
        </chunking>
        <chunking id="2" string="Chios" type="NP">
          <tokens>
            <token id="10" string="Chios" />
          </tokens>
        </chunking>
        <chunking id="3" string="The ship" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="ship" />
          </tokens>
        </chunking>
        <chunking id="4" string="crammed with loot from Chios" type="VP">
          <tokens>
            <token id="6" string="crammed" />
            <token id="7" string="with" />
            <token id="8" string="loot" />
            <token id="9" string="from" />
            <token id="10" string="Chios" />
          </tokens>
        </chunking>
        <chunking id="5" string="was obviously crammed with loot from Chios" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="obviously" />
            <token id="6" string="crammed" />
            <token id="7" string="with" />
            <token id="8" string="loot" />
            <token id="9" string="from" />
            <token id="10" string="Chios" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">ship</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">crammed</governor>
          <dependent id="3">ship</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">crammed</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">crammed</governor>
          <dependent id="5">obviously</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">crammed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">loot</governor>
          <dependent id="7">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">crammed</governor>
          <dependent id="8">loot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Chios</governor>
          <dependent id="9">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">crammed</governor>
          <dependent id="10">Chios</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Chios" type="MISC" score="0.0">
          <tokens>
            <token id="10" string="Chios" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="false">
      <content>I think there may be gold and silver items as well,&amp;apost;&amp;apost; he said.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="gold" lemma="gold" stem="gold" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="silver" lemma="silver" stem="silver" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="items" lemma="item" stem="item" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP I)) (VP (VBP think) (SBAR (S (NP (EX there)) (VP (MD may) (VP (VB be) (NP (JJ gold) (CC and) (JJ silver) (NNS items)) (ADVP (RB as) (RB well)))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="there" type="NP">
          <tokens>
            <token id="3" string="there" />
          </tokens>
        </chunking>
        <chunking id="2" string="gold and silver items" type="NP">
          <tokens>
            <token id="6" string="gold" />
            <token id="7" string="and" />
            <token id="8" string="silver" />
            <token id="9" string="items" />
          </tokens>
        </chunking>
        <chunking id="3" string="think there may be gold and silver items as well" type="VP">
          <tokens>
            <token id="2" string="think" />
            <token id="3" string="there" />
            <token id="4" string="may" />
            <token id="5" string="be" />
            <token id="6" string="gold" />
            <token id="7" string="and" />
            <token id="8" string="silver" />
            <token id="9" string="items" />
            <token id="10" string="as" />
            <token id="11" string="well" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="be gold and silver items as well" type="VP">
          <tokens>
            <token id="5" string="be" />
            <token id="6" string="gold" />
            <token id="7" string="and" />
            <token id="8" string="silver" />
            <token id="9" string="items" />
            <token id="10" string="as" />
            <token id="11" string="well" />
          </tokens>
        </chunking>
        <chunking id="6" string="there may be gold and silver items as well" type="SBAR">
          <tokens>
            <token id="3" string="there" />
            <token id="4" string="may" />
            <token id="5" string="be" />
            <token id="6" string="gold" />
            <token id="7" string="and" />
            <token id="8" string="silver" />
            <token id="9" string="items" />
            <token id="10" string="as" />
            <token id="11" string="well" />
          </tokens>
        </chunking>
        <chunking id="7" string="he" type="NP">
          <tokens>
            <token id="14" string="he" />
          </tokens>
        </chunking>
        <chunking id="8" string="may be gold and silver items as well" type="VP">
          <tokens>
            <token id="4" string="may" />
            <token id="5" string="be" />
            <token id="6" string="gold" />
            <token id="7" string="and" />
            <token id="8" string="silver" />
            <token id="9" string="items" />
            <token id="10" string="as" />
            <token id="11" string="well" />
          </tokens>
        </chunking>
        <chunking id="9" string="said" type="VP">
          <tokens>
            <token id="15" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">think</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">said</governor>
          <dependent id="2">think</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="9">items</governor>
          <dependent id="3">there</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">items</governor>
          <dependent id="4">may</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">items</governor>
          <dependent id="5">be</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">items</governor>
          <dependent id="6">gold</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">gold</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">gold</governor>
          <dependent id="8">silver</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">think</governor>
          <dependent id="9">items</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">items</governor>
          <dependent id="10">as</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="10">as</governor>
          <dependent id="11">well</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">said</governor>
          <dependent id="14">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>``I also saw what I recognized as human bones,&amp;apost;&amp;apost; he added.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="saw" lemma="see" stem="saw" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="recognized" lemma="recognize" stem="recogn" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="human" lemma="human" stem="human" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="bones" lemma="bone" stem="bone" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="added" lemma="add" stem="ad" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (ADVP (RB also)) (VP (VBD saw) (SBAR (WHNP (WP what)) (S (NP (PRP I)) (VP (VBD recognized) (PP (IN as) (NP (JJ human) (NNS bones)))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD added)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="what I recognized as human bones" type="SBAR">
          <tokens>
            <token id="5" string="what" />
            <token id="6" string="I" />
            <token id="7" string="recognized" />
            <token id="8" string="as" />
            <token id="9" string="human" />
            <token id="10" string="bones" />
          </tokens>
        </chunking>
        <chunking id="2" string="saw what I recognized as human bones" type="VP">
          <tokens>
            <token id="4" string="saw" />
            <token id="5" string="what" />
            <token id="6" string="I" />
            <token id="7" string="recognized" />
            <token id="8" string="as" />
            <token id="9" string="human" />
            <token id="10" string="bones" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="recognized as human bones" type="VP">
          <tokens>
            <token id="7" string="recognized" />
            <token id="8" string="as" />
            <token id="9" string="human" />
            <token id="10" string="bones" />
          </tokens>
        </chunking>
        <chunking id="5" string="added" type="VP">
          <tokens>
            <token id="14" string="added" />
          </tokens>
        </chunking>
        <chunking id="6" string="human bones" type="NP">
          <tokens>
            <token id="9" string="human" />
            <token id="10" string="bones" />
          </tokens>
        </chunking>
        <chunking id="7" string="he" type="NP">
          <tokens>
            <token id="13" string="he" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">saw</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">saw</governor>
          <dependent id="3">also</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">added</governor>
          <dependent id="4">saw</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">recognized</governor>
          <dependent id="5">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">recognized</governor>
          <dependent id="6">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">saw</governor>
          <dependent id="7">recognized</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">bones</governor>
          <dependent id="8">as</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">bones</governor>
          <dependent id="9">human</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">recognized</governor>
          <dependent id="10">bones</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">added</governor>
          <dependent id="13">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">added</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>He said the wreckage indicated the vessel was at least 100 feet in length.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="wreckage" lemma="wreckage" stem="wreckag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="indicated" lemma="indicate" stem="indic" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="vessel" lemma="vessel" stem="vessel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="least" lemma="least" stem="least" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="100" lemma="100" stem="100" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="12" string="feet" lemma="foot" stem="feet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="length" lemma="length" stem="length" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD said) (SBAR (S (NP (DT the) (NN wreckage)) (VP (VBD indicated) (SBAR (S (NP (DT the) (NN vessel)) (VP (VBD was) (NP (NP (QP (IN at) (JJS least) (CD 100)) (NNS feet)) (PP (IN in) (NP (NN length))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was at least 100 feet in length" type="VP">
          <tokens>
            <token id="8" string="was" />
            <token id="9" string="at" />
            <token id="10" string="least" />
            <token id="11" string="100" />
            <token id="12" string="feet" />
            <token id="13" string="in" />
            <token id="14" string="length" />
          </tokens>
        </chunking>
        <chunking id="2" string="at least 100 feet in length" type="NP">
          <tokens>
            <token id="9" string="at" />
            <token id="10" string="least" />
            <token id="11" string="100" />
            <token id="12" string="feet" />
            <token id="13" string="in" />
            <token id="14" string="length" />
          </tokens>
        </chunking>
        <chunking id="3" string="the wreckage" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="wreckage" />
          </tokens>
        </chunking>
        <chunking id="4" string="indicated the vessel was at least 100 feet in length" type="VP">
          <tokens>
            <token id="5" string="indicated" />
            <token id="6" string="the" />
            <token id="7" string="vessel" />
            <token id="8" string="was" />
            <token id="9" string="at" />
            <token id="10" string="least" />
            <token id="11" string="100" />
            <token id="12" string="feet" />
            <token id="13" string="in" />
            <token id="14" string="length" />
          </tokens>
        </chunking>
        <chunking id="5" string="at least 100 feet" type="NP">
          <tokens>
            <token id="9" string="at" />
            <token id="10" string="least" />
            <token id="11" string="100" />
            <token id="12" string="feet" />
          </tokens>
        </chunking>
        <chunking id="6" string="the vessel was at least 100 feet in length" type="SBAR">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="vessel" />
            <token id="8" string="was" />
            <token id="9" string="at" />
            <token id="10" string="least" />
            <token id="11" string="100" />
            <token id="12" string="feet" />
            <token id="13" string="in" />
            <token id="14" string="length" />
          </tokens>
        </chunking>
        <chunking id="7" string="the vessel" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="vessel" />
          </tokens>
        </chunking>
        <chunking id="8" string="said the wreckage indicated the vessel was at least 100 feet in length" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="the" />
            <token id="4" string="wreckage" />
            <token id="5" string="indicated" />
            <token id="6" string="the" />
            <token id="7" string="vessel" />
            <token id="8" string="was" />
            <token id="9" string="at" />
            <token id="10" string="least" />
            <token id="11" string="100" />
            <token id="12" string="feet" />
            <token id="13" string="in" />
            <token id="14" string="length" />
          </tokens>
        </chunking>
        <chunking id="9" string="the wreckage indicated the vessel was at least 100 feet in length" type="SBAR">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="wreckage" />
            <token id="5" string="indicated" />
            <token id="6" string="the" />
            <token id="7" string="vessel" />
            <token id="8" string="was" />
            <token id="9" string="at" />
            <token id="10" string="least" />
            <token id="11" string="100" />
            <token id="12" string="feet" />
            <token id="13" string="in" />
            <token id="14" string="length" />
          </tokens>
        </chunking>
        <chunking id="10" string="length" type="NP">
          <tokens>
            <token id="14" string="length" />
          </tokens>
        </chunking>
        <chunking id="11" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">wreckage</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">indicated</governor>
          <dependent id="4">wreckage</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="5">indicated</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">vessel</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">feet</governor>
          <dependent id="7">vessel</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">feet</governor>
          <dependent id="8">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">least</governor>
          <dependent id="9">at</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="11">100</governor>
          <dependent id="10">least</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">feet</governor>
          <dependent id="11">100</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">indicated</governor>
          <dependent id="12">feet</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">length</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">feet</governor>
          <dependent id="14">length</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="100" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="100" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>According to historians, more than 1,000 people _ including 400 Greek captives _ were aboard the ship when Kanaris staged his attack in the early hours of June 7, 1822.</content>
      <tokens>
        <token id="1" string="According" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="historians" lemma="historian" stem="historian" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="1,000" lemma="1,000" stem="1,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="8" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="_" lemma="_" stem="_" pos="VBP" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="400" lemma="400" stem="400" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="12" string="Greek" lemma="greek" stem="greek" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="13" string="captives" lemma="captive" stem="captiv" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="_" lemma="_" stem="_" pos="VBP" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="aboard" lemma="aboard" stem="aboard" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="ship" lemma="ship" stem="ship" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Kanaris" lemma="Kanaris" stem="kanari" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="21" string="staged" lemma="stage" stem="stage" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="attack" lemma="attack" stem="attack" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="24" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="26" string="early" lemma="early" stem="earli" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="27" string="hours" lemma="hour" stem="hour" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="28" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="29" string="June" lemma="June" stem="june" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="30" string="7" lemma="7" stem="7" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="31" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="32" string="1822" lemma="1822" stem="1822" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (VBG According) (PP (TO to) (NP (NNS historians)))) (, ,) (NP (QP (JJR more) (IN than) (CD 1,000)) (NNS people)) (VP (VBP _) (PP (VBG including) (NP (NP (CD 400) (JJ Greek) (NNS captives)) (SBAR (S (VP (VBP _) (SBAR (S (VP (VBD were) (PP (IN aboard) (NP (DT the) (NN ship))) (SBAR (WHADVP (WRB when)) (S (NP (NNP Kanaris)) (VP (VBD staged) (NP (PRP$ his) (NN attack)) (PP (IN in) (NP (NP (DT the) (JJ early) (NNS hours)) (PP (IN of) (NP (NNP June) (CD 7) (, ,) (CD 1822))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="were aboard the ship when Kanaris staged his attack in the early hours of June 7 , 1822" type="SBAR">
          <tokens>
            <token id="15" string="were" />
            <token id="16" string="aboard" />
            <token id="17" string="the" />
            <token id="18" string="ship" />
            <token id="19" string="when" />
            <token id="20" string="Kanaris" />
            <token id="21" string="staged" />
            <token id="22" string="his" />
            <token id="23" string="attack" />
            <token id="24" string="in" />
            <token id="25" string="the" />
            <token id="26" string="early" />
            <token id="27" string="hours" />
            <token id="28" string="of" />
            <token id="29" string="June" />
            <token id="30" string="7" />
            <token id="31" string="," />
            <token id="32" string="1822" />
          </tokens>
        </chunking>
        <chunking id="2" string="his attack" type="NP">
          <tokens>
            <token id="22" string="his" />
            <token id="23" string="attack" />
          </tokens>
        </chunking>
        <chunking id="3" string="historians" type="NP">
          <tokens>
            <token id="3" string="historians" />
          </tokens>
        </chunking>
        <chunking id="4" string="400 Greek captives _ were aboard the ship when Kanaris staged his attack in the early hours of June 7 , 1822" type="NP">
          <tokens>
            <token id="11" string="400" />
            <token id="12" string="Greek" />
            <token id="13" string="captives" />
            <token id="14" string="_" />
            <token id="15" string="were" />
            <token id="16" string="aboard" />
            <token id="17" string="the" />
            <token id="18" string="ship" />
            <token id="19" string="when" />
            <token id="20" string="Kanaris" />
            <token id="21" string="staged" />
            <token id="22" string="his" />
            <token id="23" string="attack" />
            <token id="24" string="in" />
            <token id="25" string="the" />
            <token id="26" string="early" />
            <token id="27" string="hours" />
            <token id="28" string="of" />
            <token id="29" string="June" />
            <token id="30" string="7" />
            <token id="31" string="," />
            <token id="32" string="1822" />
          </tokens>
        </chunking>
        <chunking id="5" string="Kanaris" type="NP">
          <tokens>
            <token id="20" string="Kanaris" />
          </tokens>
        </chunking>
        <chunking id="6" string="the ship" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="ship" />
          </tokens>
        </chunking>
        <chunking id="7" string="more than 1,000 people" type="NP">
          <tokens>
            <token id="5" string="more" />
            <token id="6" string="than" />
            <token id="7" string="1,000" />
            <token id="8" string="people" />
          </tokens>
        </chunking>
        <chunking id="8" string="_ were aboard the ship when Kanaris staged his attack in the early hours of June 7 , 1822" type="SBAR">
          <tokens>
            <token id="14" string="_" />
            <token id="15" string="were" />
            <token id="16" string="aboard" />
            <token id="17" string="the" />
            <token id="18" string="ship" />
            <token id="19" string="when" />
            <token id="20" string="Kanaris" />
            <token id="21" string="staged" />
            <token id="22" string="his" />
            <token id="23" string="attack" />
            <token id="24" string="in" />
            <token id="25" string="the" />
            <token id="26" string="early" />
            <token id="27" string="hours" />
            <token id="28" string="of" />
            <token id="29" string="June" />
            <token id="30" string="7" />
            <token id="31" string="," />
            <token id="32" string="1822" />
          </tokens>
        </chunking>
        <chunking id="9" string="when" type="WHADVP">
          <tokens>
            <token id="19" string="when" />
          </tokens>
        </chunking>
        <chunking id="10" string="the early hours" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="early" />
            <token id="27" string="hours" />
          </tokens>
        </chunking>
        <chunking id="11" string="_ including 400 Greek captives _ were aboard the ship when Kanaris staged his attack in the early hours of June 7 , 1822" type="VP">
          <tokens>
            <token id="9" string="_" />
            <token id="10" string="including" />
            <token id="11" string="400" />
            <token id="12" string="Greek" />
            <token id="13" string="captives" />
            <token id="14" string="_" />
            <token id="15" string="were" />
            <token id="16" string="aboard" />
            <token id="17" string="the" />
            <token id="18" string="ship" />
            <token id="19" string="when" />
            <token id="20" string="Kanaris" />
            <token id="21" string="staged" />
            <token id="22" string="his" />
            <token id="23" string="attack" />
            <token id="24" string="in" />
            <token id="25" string="the" />
            <token id="26" string="early" />
            <token id="27" string="hours" />
            <token id="28" string="of" />
            <token id="29" string="June" />
            <token id="30" string="7" />
            <token id="31" string="," />
            <token id="32" string="1822" />
          </tokens>
        </chunking>
        <chunking id="12" string="when Kanaris staged his attack in the early hours of June 7 , 1822" type="SBAR">
          <tokens>
            <token id="19" string="when" />
            <token id="20" string="Kanaris" />
            <token id="21" string="staged" />
            <token id="22" string="his" />
            <token id="23" string="attack" />
            <token id="24" string="in" />
            <token id="25" string="the" />
            <token id="26" string="early" />
            <token id="27" string="hours" />
            <token id="28" string="of" />
            <token id="29" string="June" />
            <token id="30" string="7" />
            <token id="31" string="," />
            <token id="32" string="1822" />
          </tokens>
        </chunking>
        <chunking id="13" string="June 7 , 1822" type="NP">
          <tokens>
            <token id="29" string="June" />
            <token id="30" string="7" />
            <token id="31" string="," />
            <token id="32" string="1822" />
          </tokens>
        </chunking>
        <chunking id="14" string="400 Greek captives" type="NP">
          <tokens>
            <token id="11" string="400" />
            <token id="12" string="Greek" />
            <token id="13" string="captives" />
          </tokens>
        </chunking>
        <chunking id="15" string="staged his attack in the early hours of June 7 , 1822" type="VP">
          <tokens>
            <token id="21" string="staged" />
            <token id="22" string="his" />
            <token id="23" string="attack" />
            <token id="24" string="in" />
            <token id="25" string="the" />
            <token id="26" string="early" />
            <token id="27" string="hours" />
            <token id="28" string="of" />
            <token id="29" string="June" />
            <token id="30" string="7" />
            <token id="31" string="," />
            <token id="32" string="1822" />
          </tokens>
        </chunking>
        <chunking id="16" string="the early hours of June 7 , 1822" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="early" />
            <token id="27" string="hours" />
            <token id="28" string="of" />
            <token id="29" string="June" />
            <token id="30" string="7" />
            <token id="31" string="," />
            <token id="32" string="1822" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">historians</governor>
          <dependent id="1">According</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">According</governor>
          <dependent id="2">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">_</governor>
          <dependent id="3">historians</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">1,000</governor>
          <dependent id="5">more</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="5">more</governor>
          <dependent id="6">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">people</governor>
          <dependent id="7">1,000</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">_</governor>
          <dependent id="8">people</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">_</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">captives</governor>
          <dependent id="10">including</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">captives</governor>
          <dependent id="11">400</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">captives</governor>
          <dependent id="12">Greek</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">_</governor>
          <dependent id="13">captives</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">captives</governor>
          <dependent id="14">_</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="18">ship</governor>
          <dependent id="15">were</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">ship</governor>
          <dependent id="16">aboard</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">ship</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">_</governor>
          <dependent id="18">ship</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">staged</governor>
          <dependent id="19">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">staged</governor>
          <dependent id="20">Kanaris</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="18">ship</governor>
          <dependent id="21">staged</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">attack</governor>
          <dependent id="22">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">staged</governor>
          <dependent id="23">attack</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">hours</governor>
          <dependent id="24">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">hours</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">hours</governor>
          <dependent id="26">early</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">staged</governor>
          <dependent id="27">hours</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">June</governor>
          <dependent id="28">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">hours</governor>
          <dependent id="29">June</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="29">June</governor>
          <dependent id="30">7</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="29">June</governor>
          <dependent id="32">1822</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Greek" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="12" string="Greek" />
          </tokens>
        </entity>
        <entity id="2" string="1,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="1,000" />
          </tokens>
        </entity>
        <entity id="3" string="400" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="400" />
          </tokens>
        </entity>
        <entity id="4" string="Kanaris" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Kanaris" />
          </tokens>
        </entity>
        <entity id="5" string="attack" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="23" string="attack" />
          </tokens>
        </entity>
        <entity id="6" string="the early hours of June 7 , 1822" type="DATE" score="0.0">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="early" />
            <token id="27" string="hours" />
            <token id="28" string="of" />
            <token id="29" string="June" />
            <token id="30" string="7" />
            <token id="31" string="," />
            <token id="32" string="1822" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>The Greek admiral sailed from the nearby island of Psara, towing a boat stuffed with explosives.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Greek" lemma="greek" stem="greek" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="3" string="admiral" lemma="admiral" stem="admir" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="sailed" lemma="sail" stem="sail" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="nearby" lemma="nearby" stem="nearbi" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="island" lemma="island" stem="island" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="Psara" lemma="psara" stem="psara" pos="NN" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="towing" lemma="tow" stem="tow" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="boat" lemma="boat" stem="boat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="stuffed" lemma="stuff" stem="stuf" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="explosives" lemma="explosive" stem="explos" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (JJ Greek) (JJ admiral)) (VP (VBN sailed) (PP (IN from) (NP (NP (DT the) (JJ nearby) (NN island)) (PP (IN of) (NP (NN Psara))))) (, ,) (S (VP (VBG towing) (NP (DT a) (NN boat)))))) (VP (VBN stuffed) (PP (IN with) (NP (NNS explosives)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Psara" type="NP">
          <tokens>
            <token id="10" string="Psara" />
          </tokens>
        </chunking>
        <chunking id="2" string="the nearby island of Psara" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="nearby" />
            <token id="8" string="island" />
            <token id="9" string="of" />
            <token id="10" string="Psara" />
          </tokens>
        </chunking>
        <chunking id="3" string="the nearby island" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="nearby" />
            <token id="8" string="island" />
          </tokens>
        </chunking>
        <chunking id="4" string="a boat" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="boat" />
          </tokens>
        </chunking>
        <chunking id="5" string="The Greek admiral sailed from the nearby island of Psara , towing a boat" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Greek" />
            <token id="3" string="admiral" />
            <token id="4" string="sailed" />
            <token id="5" string="from" />
            <token id="6" string="the" />
            <token id="7" string="nearby" />
            <token id="8" string="island" />
            <token id="9" string="of" />
            <token id="10" string="Psara" />
            <token id="11" string="," />
            <token id="12" string="towing" />
            <token id="13" string="a" />
            <token id="14" string="boat" />
          </tokens>
        </chunking>
        <chunking id="6" string="towing a boat" type="VP">
          <tokens>
            <token id="12" string="towing" />
            <token id="13" string="a" />
            <token id="14" string="boat" />
          </tokens>
        </chunking>
        <chunking id="7" string="The Greek admiral" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Greek" />
            <token id="3" string="admiral" />
          </tokens>
        </chunking>
        <chunking id="8" string="sailed from the nearby island of Psara , towing a boat" type="VP">
          <tokens>
            <token id="4" string="sailed" />
            <token id="5" string="from" />
            <token id="6" string="the" />
            <token id="7" string="nearby" />
            <token id="8" string="island" />
            <token id="9" string="of" />
            <token id="10" string="Psara" />
            <token id="11" string="," />
            <token id="12" string="towing" />
            <token id="13" string="a" />
            <token id="14" string="boat" />
          </tokens>
        </chunking>
        <chunking id="9" string="stuffed with explosives" type="VP">
          <tokens>
            <token id="15" string="stuffed" />
            <token id="16" string="with" />
            <token id="17" string="explosives" />
          </tokens>
        </chunking>
        <chunking id="10" string="explosives" type="NP">
          <tokens>
            <token id="17" string="explosives" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">admiral</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">admiral</governor>
          <dependent id="2">Greek</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">stuffed</governor>
          <dependent id="3">admiral</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="3">admiral</governor>
          <dependent id="4">sailed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">island</governor>
          <dependent id="5">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">island</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">island</governor>
          <dependent id="7">nearby</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">sailed</governor>
          <dependent id="8">island</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Psara</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">island</governor>
          <dependent id="10">Psara</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">sailed</governor>
          <dependent id="12">towing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">boat</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">towing</governor>
          <dependent id="14">boat</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">stuffed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">explosives</governor>
          <dependent id="16">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">stuffed</governor>
          <dependent id="17">explosives</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Psara" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="Psara" />
          </tokens>
        </entity>
        <entity id="2" string="Greek" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="2" string="Greek" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>Its pointed bow was rammed into the mouth of a cannon on the Bourloti Seimaz and a fuse lit.</content>
      <tokens>
        <token id="1" string="Its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="pointed" lemma="pointed" stem="point" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="bow" lemma="bow" stem="bow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="rammed" lemma="ram" stem="ram" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="mouth" lemma="mouth" stem="mouth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="cannon" lemma="cannon" stem="cannon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="Bourloti" lemma="Bourloti" stem="bourloti" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="Seimaz" lemma="Seimaz" stem="seimaz" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="fuse" lemma="fuse" stem="fuse" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="lit" lemma="light" stem="lit" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP$ Its) (JJ pointed) (NN bow)) (VP (VBD was) (VP (VBN rammed) (PP (IN into) (NP (NP (DT the) (NN mouth)) (PP (IN of) (NP (NP (DT a) (NN cannon)) (PP (IN on) (NP (DT the) (NNP Bourloti) (NNP Seimaz)))))))))) (CC and) (S (NP (DT a) (NN fuse)) (VP (VBD lit))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Bourloti Seimaz" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="Bourloti" />
            <token id="15" string="Seimaz" />
          </tokens>
        </chunking>
        <chunking id="2" string="the mouth" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="mouth" />
          </tokens>
        </chunking>
        <chunking id="3" string="a cannon on the Bourloti Seimaz" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="cannon" />
            <token id="12" string="on" />
            <token id="13" string="the" />
            <token id="14" string="Bourloti" />
            <token id="15" string="Seimaz" />
          </tokens>
        </chunking>
        <chunking id="4" string="a fuse" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="fuse" />
          </tokens>
        </chunking>
        <chunking id="5" string="Its pointed bow" type="NP">
          <tokens>
            <token id="1" string="Its" />
            <token id="2" string="pointed" />
            <token id="3" string="bow" />
          </tokens>
        </chunking>
        <chunking id="6" string="lit" type="VP">
          <tokens>
            <token id="19" string="lit" />
          </tokens>
        </chunking>
        <chunking id="7" string="was rammed into the mouth of a cannon on the Bourloti Seimaz" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="rammed" />
            <token id="6" string="into" />
            <token id="7" string="the" />
            <token id="8" string="mouth" />
            <token id="9" string="of" />
            <token id="10" string="a" />
            <token id="11" string="cannon" />
            <token id="12" string="on" />
            <token id="13" string="the" />
            <token id="14" string="Bourloti" />
            <token id="15" string="Seimaz" />
          </tokens>
        </chunking>
        <chunking id="8" string="a cannon" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="cannon" />
          </tokens>
        </chunking>
        <chunking id="9" string="rammed into the mouth of a cannon on the Bourloti Seimaz" type="VP">
          <tokens>
            <token id="5" string="rammed" />
            <token id="6" string="into" />
            <token id="7" string="the" />
            <token id="8" string="mouth" />
            <token id="9" string="of" />
            <token id="10" string="a" />
            <token id="11" string="cannon" />
            <token id="12" string="on" />
            <token id="13" string="the" />
            <token id="14" string="Bourloti" />
            <token id="15" string="Seimaz" />
          </tokens>
        </chunking>
        <chunking id="10" string="the mouth of a cannon on the Bourloti Seimaz" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="mouth" />
            <token id="9" string="of" />
            <token id="10" string="a" />
            <token id="11" string="cannon" />
            <token id="12" string="on" />
            <token id="13" string="the" />
            <token id="14" string="Bourloti" />
            <token id="15" string="Seimaz" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">bow</governor>
          <dependent id="1">Its</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">bow</governor>
          <dependent id="2">pointed</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">rammed</governor>
          <dependent id="3">bow</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">rammed</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">rammed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">mouth</governor>
          <dependent id="6">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">mouth</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">rammed</governor>
          <dependent id="8">mouth</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">cannon</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">cannon</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">mouth</governor>
          <dependent id="11">cannon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Seimaz</governor>
          <dependent id="12">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">Seimaz</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Seimaz</governor>
          <dependent id="14">Bourloti</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">cannon</governor>
          <dependent id="15">Seimaz</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">rammed</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">fuse</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">lit</governor>
          <dependent id="18">fuse</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">rammed</governor>
          <dependent id="19">lit</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>The Ottoman commander, Admiral Kara Ali, was killed in the blast that split the ship.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Ottoman" lemma="Ottoman" stem="ottoman" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="3" string="commander" lemma="commander" stem="command" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Admiral" lemma="admiral" stem="admiral" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Kara" lemma="Kara" stem="kara" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="Ali" lemma="Ali" stem="ali" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="killed" lemma="kill" stem="kill" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="blast" lemma="blast" stem="blast" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="split" lemma="split" stem="split" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="ship" lemma="ship" stem="ship" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NNP Ottoman) (NN commander)) (, ,) (NP (NN Admiral) (NNP Kara) (NNP Ali)) (, ,)) (VP (VBD was) (VP (VBN killed) (PP (IN in) (NP (NP (DT the) (NN blast)) (SBAR (WHNP (WDT that)) (S (VP (VBD split) (NP (DT the) (NN ship))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The Ottoman commander" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Ottoman" />
            <token id="3" string="commander" />
          </tokens>
        </chunking>
        <chunking id="2" string="the ship" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="ship" />
          </tokens>
        </chunking>
        <chunking id="3" string="was killed in the blast that split the ship" type="VP">
          <tokens>
            <token id="9" string="was" />
            <token id="10" string="killed" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="blast" />
            <token id="14" string="that" />
            <token id="15" string="split" />
            <token id="16" string="the" />
            <token id="17" string="ship" />
          </tokens>
        </chunking>
        <chunking id="4" string="the blast that split the ship" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="blast" />
            <token id="14" string="that" />
            <token id="15" string="split" />
            <token id="16" string="the" />
            <token id="17" string="ship" />
          </tokens>
        </chunking>
        <chunking id="5" string="split the ship" type="VP">
          <tokens>
            <token id="15" string="split" />
            <token id="16" string="the" />
            <token id="17" string="ship" />
          </tokens>
        </chunking>
        <chunking id="6" string="the blast" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="blast" />
          </tokens>
        </chunking>
        <chunking id="7" string="The Ottoman commander , Admiral Kara Ali ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Ottoman" />
            <token id="3" string="commander" />
            <token id="4" string="," />
            <token id="5" string="Admiral" />
            <token id="6" string="Kara" />
            <token id="7" string="Ali" />
            <token id="8" string="," />
          </tokens>
        </chunking>
        <chunking id="8" string="killed in the blast that split the ship" type="VP">
          <tokens>
            <token id="10" string="killed" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="blast" />
            <token id="14" string="that" />
            <token id="15" string="split" />
            <token id="16" string="the" />
            <token id="17" string="ship" />
          </tokens>
        </chunking>
        <chunking id="9" string="Admiral Kara Ali" type="NP">
          <tokens>
            <token id="5" string="Admiral" />
            <token id="6" string="Kara" />
            <token id="7" string="Ali" />
          </tokens>
        </chunking>
        <chunking id="10" string="that split the ship" type="SBAR">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="split" />
            <token id="16" string="the" />
            <token id="17" string="ship" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">commander</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">commander</governor>
          <dependent id="2">Ottoman</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="10">killed</governor>
          <dependent id="3">commander</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Ali</governor>
          <dependent id="5">Admiral</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Ali</governor>
          <dependent id="6">Kara</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">commander</governor>
          <dependent id="7">Ali</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">killed</governor>
          <dependent id="9">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">killed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">blast</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">blast</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">killed</governor>
          <dependent id="13">blast</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">split</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">blast</governor>
          <dependent id="15">split</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">ship</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">split</governor>
          <dependent id="17">ship</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Kara Ali" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Kara" />
            <token id="7" string="Ali" />
          </tokens>
        </entity>
        <entity id="2" string="Ottoman" type="MISC" score="0.0">
          <tokens>
            <token id="2" string="Ottoman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>Kanaris and his crew of Greeks escaped.</content>
      <tokens>
        <token id="1" string="Kanaris" lemma="Kanaris" stem="kanari" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="crew" lemma="crew" stem="crew" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Greeks" lemma="Greeks" stem="greek" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="7" string="escaped" lemma="escape" stem="escap" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Kanaris)) (CC and) (NP (NP (PRP$ his) (NN crew)) (PP (IN of) (NP (NNPS Greeks))))) (VP (VBD escaped)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="escaped" type="VP">
          <tokens>
            <token id="7" string="escaped" />
          </tokens>
        </chunking>
        <chunking id="2" string="his crew of Greeks" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="crew" />
            <token id="5" string="of" />
            <token id="6" string="Greeks" />
          </tokens>
        </chunking>
        <chunking id="3" string="Kanaris" type="NP">
          <tokens>
            <token id="1" string="Kanaris" />
          </tokens>
        </chunking>
        <chunking id="4" string="Kanaris and his crew of Greeks" type="NP">
          <tokens>
            <token id="1" string="Kanaris" />
            <token id="2" string="and" />
            <token id="3" string="his" />
            <token id="4" string="crew" />
            <token id="5" string="of" />
            <token id="6" string="Greeks" />
          </tokens>
        </chunking>
        <chunking id="5" string="his crew" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="crew" />
          </tokens>
        </chunking>
        <chunking id="6" string="Greeks" type="NP">
          <tokens>
            <token id="6" string="Greeks" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">escaped</governor>
          <dependent id="1">Kanaris</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Kanaris</governor>
          <dependent id="2">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">crew</governor>
          <dependent id="3">his</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Kanaris</governor>
          <dependent id="4">crew</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Greeks</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">crew</governor>
          <dependent id="6">Greeks</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">escaped</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Kanaris" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Kanaris" />
          </tokens>
        </entity>
        <entity id="2" string="Greeks" type="MISC" score="0.0">
          <tokens>
            <token id="6" string="Greeks" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>``This is a very significant, very emotive find, coming from this particular period of history,&amp;apost;&amp;apost; said George Papathanassopoulos, the Culture Ministry&amp;apost;s adviser on marine archaeology.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="significant" lemma="significant" stem="signific" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="emotive" lemma="emotive" stem="emot" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="find" lemma="find" stem="find" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="coming" lemma="come" stem="come" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="particular" lemma="particular" stem="particular" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="period" lemma="period" stem="period" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="history" lemma="history" stem="histori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="George" lemma="George" stem="georg" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="23" string="Papathanassopoulos" lemma="Papathanassopoulos" stem="papathanassopoulo" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Culture" lemma="Culture" stem="cultur" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="Ministry" lemma="Ministry" stem="ministri" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="adviser" lemma="adviser" stem="advis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="marine" lemma="marine" stem="marin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="archaeology" lemma="archaeology" stem="archaeologi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (DT This)) (VP (VBZ is) (ADJP (DT a) (ADJP (RB very) (JJ significant)) (, ,) (ADJP (RB very) (JJ emotive))) (S (VP (VB find))) (, ,) (S (VP (VBG coming) (PP (IN from) (NP (NP (DT this) (JJ particular) (NN period)) (PP (IN of) (NP (NN history))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP George) (NNP Papathanassopoulos)) (, ,) (NP (NP (NP (DT the) (NNP Culture) (NNP Ministry) (POS 's)) (NN adviser)) (PP (IN on) (NP (JJ marine) (NN archaeology))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Culture Ministry 's adviser" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="Culture" />
            <token id="27" string="Ministry" />
            <token id="28" string="'s" />
            <token id="29" string="adviser" />
          </tokens>
        </chunking>
        <chunking id="2" string="very significant" type="ADJP">
          <tokens>
            <token id="5" string="very" />
            <token id="6" string="significant" />
          </tokens>
        </chunking>
        <chunking id="3" string="coming from this particular period of history" type="VP">
          <tokens>
            <token id="12" string="coming" />
            <token id="13" string="from" />
            <token id="14" string="this" />
            <token id="15" string="particular" />
            <token id="16" string="period" />
            <token id="17" string="of" />
            <token id="18" string="history" />
          </tokens>
        </chunking>
        <chunking id="4" string="a very significant , very emotive" type="ADJP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="very" />
            <token id="6" string="significant" />
            <token id="7" string="," />
            <token id="8" string="very" />
            <token id="9" string="emotive" />
          </tokens>
        </chunking>
        <chunking id="5" string="George Papathanassopoulos , the Culture Ministry 's adviser on marine archaeology" type="NP">
          <tokens>
            <token id="22" string="George" />
            <token id="23" string="Papathanassopoulos" />
            <token id="24" string="," />
            <token id="25" string="the" />
            <token id="26" string="Culture" />
            <token id="27" string="Ministry" />
            <token id="28" string="'s" />
            <token id="29" string="adviser" />
            <token id="30" string="on" />
            <token id="31" string="marine" />
            <token id="32" string="archaeology" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Culture Ministry 's" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="Culture" />
            <token id="27" string="Ministry" />
            <token id="28" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="history" type="NP">
          <tokens>
            <token id="18" string="history" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Culture Ministry 's adviser on marine archaeology" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="Culture" />
            <token id="27" string="Ministry" />
            <token id="28" string="'s" />
            <token id="29" string="adviser" />
            <token id="30" string="on" />
            <token id="31" string="marine" />
            <token id="32" string="archaeology" />
          </tokens>
        </chunking>
        <chunking id="9" string="is a very significant , very emotive find , coming from this particular period of history" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="a" />
            <token id="5" string="very" />
            <token id="6" string="significant" />
            <token id="7" string="," />
            <token id="8" string="very" />
            <token id="9" string="emotive" />
            <token id="10" string="find" />
            <token id="11" string="," />
            <token id="12" string="coming" />
            <token id="13" string="from" />
            <token id="14" string="this" />
            <token id="15" string="particular" />
            <token id="16" string="period" />
            <token id="17" string="of" />
            <token id="18" string="history" />
          </tokens>
        </chunking>
        <chunking id="10" string="this particular period of history" type="NP">
          <tokens>
            <token id="14" string="this" />
            <token id="15" string="particular" />
            <token id="16" string="period" />
            <token id="17" string="of" />
            <token id="18" string="history" />
          </tokens>
        </chunking>
        <chunking id="11" string="this particular period" type="NP">
          <tokens>
            <token id="14" string="this" />
            <token id="15" string="particular" />
            <token id="16" string="period" />
          </tokens>
        </chunking>
        <chunking id="12" string="very emotive" type="ADJP">
          <tokens>
            <token id="8" string="very" />
            <token id="9" string="emotive" />
          </tokens>
        </chunking>
        <chunking id="13" string="find" type="VP">
          <tokens>
            <token id="10" string="find" />
          </tokens>
        </chunking>
        <chunking id="14" string="marine archaeology" type="NP">
          <tokens>
            <token id="31" string="marine" />
            <token id="32" string="archaeology" />
          </tokens>
        </chunking>
        <chunking id="15" string="This" type="NP">
          <tokens>
            <token id="2" string="This" />
          </tokens>
        </chunking>
        <chunking id="16" string="said" type="VP">
          <tokens>
            <token id="21" string="said" />
          </tokens>
        </chunking>
        <chunking id="17" string="George Papathanassopoulos" type="NP">
          <tokens>
            <token id="22" string="George" />
            <token id="23" string="Papathanassopoulos" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">significant</governor>
          <dependent id="2">This</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">significant</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">significant</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">significant</governor>
          <dependent id="5">very</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">said</governor>
          <dependent id="6">significant</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">emotive</governor>
          <dependent id="8">very</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">significant</governor>
          <dependent id="9">emotive</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">significant</governor>
          <dependent id="10">find</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">significant</governor>
          <dependent id="12">coming</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">period</governor>
          <dependent id="13">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">period</governor>
          <dependent id="14">this</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">period</governor>
          <dependent id="15">particular</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">coming</governor>
          <dependent id="16">period</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">history</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">period</governor>
          <dependent id="18">history</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Papathanassopoulos</governor>
          <dependent id="22">George</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">said</governor>
          <dependent id="23">Papathanassopoulos</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">Ministry</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Ministry</governor>
          <dependent id="26">Culture</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="29">adviser</governor>
          <dependent id="27">Ministry</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">Ministry</governor>
          <dependent id="28">'s</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="23">Papathanassopoulos</governor>
          <dependent id="29">adviser</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">archaeology</governor>
          <dependent id="30">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">archaeology</governor>
          <dependent id="31">marine</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">adviser</governor>
          <dependent id="32">archaeology</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="George Papathanassopoulos" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="George" />
            <token id="23" string="Papathanassopoulos" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>Papathanassopoulos said the 162-foot water depth at the site will make investigation difficult since underwater archaeology rarely is attempted at depths over 113 feet, but he said, ``This is a ship that must be explored.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="Papathanassopoulos" lemma="Papathanassopoulos" stem="papathanassopoulo" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="162-foot" lemma="162-foot" stem="162-foot" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="water" lemma="water" stem="water" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="depth" lemma="depth" stem="depth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="site" lemma="site" stem="site" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="investigation" lemma="investigation" stem="investig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="difficult" lemma="difficult" stem="difficult" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="underwater" lemma="underwater" stem="underwat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="archaeology" lemma="archaeology" stem="archaeologi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="rarely" lemma="rarely" stem="rare" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="attempted" lemma="attempt" stem="attempt" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="depths" lemma="depths" stem="depth" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="113" lemma="113" stem="113" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="24" string="feet" lemma="foot" stem="feet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="34" string="ship" lemma="ship" stem="ship" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="36" string="must" lemma="must" stem="must" pos="MD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="37" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="38" string="explored" lemma="explore" stem="explor" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Papathanassopoulos)) (VP (VBD said) (SBAR (S (NP (NP (DT the) (JJ 162-foot) (NN water) (NN depth)) (PP (IN at) (NP (DT the) (NN site)))) (VP (MD will) (VP (VB make) (S (NP (NN investigation)) (ADJP (JJ difficult)) (SBAR (IN since) (S (NP (JJ underwater) (NN archaeology)) (ADVP (RB rarely)) (VP (VBZ is) (VP (VBN attempted) (PP (IN at) (NP (NP (NNS depths)) (PP (IN over) (NP (CD 113) (NNS feet)))))))))))))))) (, ,) (CC but) (S (NP (PRP he)) (VP (VBD said) (, ,) (`` ``) (S (NP (DT This)) (VP (VBZ is) (NP (NP (DT a) (NN ship)) (SBAR (WHNP (WDT that)) (S (VP (MD must) (VP (VB be) (VP (VBN explored))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="is attempted at depths over 113 feet" type="VP">
          <tokens>
            <token id="18" string="is" />
            <token id="19" string="attempted" />
            <token id="20" string="at" />
            <token id="21" string="depths" />
            <token id="22" string="over" />
            <token id="23" string="113" />
            <token id="24" string="feet" />
          </tokens>
        </chunking>
        <chunking id="2" string="a ship that must be explored" type="NP">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="ship" />
            <token id="35" string="that" />
            <token id="36" string="must" />
            <token id="37" string="be" />
            <token id="38" string="explored" />
          </tokens>
        </chunking>
        <chunking id="3" string="a ship" type="NP">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="ship" />
          </tokens>
        </chunking>
        <chunking id="4" string="must be explored" type="VP">
          <tokens>
            <token id="36" string="must" />
            <token id="37" string="be" />
            <token id="38" string="explored" />
          </tokens>
        </chunking>
        <chunking id="5" string="depths" type="NP">
          <tokens>
            <token id="21" string="depths" />
          </tokens>
        </chunking>
        <chunking id="6" string="difficult" type="ADJP">
          <tokens>
            <token id="13" string="difficult" />
          </tokens>
        </chunking>
        <chunking id="7" string="underwater archaeology" type="NP">
          <tokens>
            <token id="15" string="underwater" />
            <token id="16" string="archaeology" />
          </tokens>
        </chunking>
        <chunking id="8" string="is a ship that must be explored" type="VP">
          <tokens>
            <token id="32" string="is" />
            <token id="33" string="a" />
            <token id="34" string="ship" />
            <token id="35" string="that" />
            <token id="36" string="must" />
            <token id="37" string="be" />
            <token id="38" string="explored" />
          </tokens>
        </chunking>
        <chunking id="9" string="will make investigation difficult since underwater archaeology rarely is attempted at depths over 113 feet" type="VP">
          <tokens>
            <token id="10" string="will" />
            <token id="11" string="make" />
            <token id="12" string="investigation" />
            <token id="13" string="difficult" />
            <token id="14" string="since" />
            <token id="15" string="underwater" />
            <token id="16" string="archaeology" />
            <token id="17" string="rarely" />
            <token id="18" string="is" />
            <token id="19" string="attempted" />
            <token id="20" string="at" />
            <token id="21" string="depths" />
            <token id="22" string="over" />
            <token id="23" string="113" />
            <token id="24" string="feet" />
          </tokens>
        </chunking>
        <chunking id="10" string="make investigation difficult since underwater archaeology rarely is attempted at depths over 113 feet" type="VP">
          <tokens>
            <token id="11" string="make" />
            <token id="12" string="investigation" />
            <token id="13" string="difficult" />
            <token id="14" string="since" />
            <token id="15" string="underwater" />
            <token id="16" string="archaeology" />
            <token id="17" string="rarely" />
            <token id="18" string="is" />
            <token id="19" string="attempted" />
            <token id="20" string="at" />
            <token id="21" string="depths" />
            <token id="22" string="over" />
            <token id="23" string="113" />
            <token id="24" string="feet" />
          </tokens>
        </chunking>
        <chunking id="11" string="be explored" type="VP">
          <tokens>
            <token id="37" string="be" />
            <token id="38" string="explored" />
          </tokens>
        </chunking>
        <chunking id="12" string="the site" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="site" />
          </tokens>
        </chunking>
        <chunking id="13" string="explored" type="VP">
          <tokens>
            <token id="38" string="explored" />
          </tokens>
        </chunking>
        <chunking id="14" string="the 162-foot water depth" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="162-foot" />
            <token id="5" string="water" />
            <token id="6" string="depth" />
          </tokens>
        </chunking>
        <chunking id="15" string="investigation" type="NP">
          <tokens>
            <token id="12" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="16" string="attempted at depths over 113 feet" type="VP">
          <tokens>
            <token id="19" string="attempted" />
            <token id="20" string="at" />
            <token id="21" string="depths" />
            <token id="22" string="over" />
            <token id="23" string="113" />
            <token id="24" string="feet" />
          </tokens>
        </chunking>
        <chunking id="17" string="he" type="NP">
          <tokens>
            <token id="27" string="he" />
          </tokens>
        </chunking>
        <chunking id="18" string="113 feet" type="NP">
          <tokens>
            <token id="23" string="113" />
            <token id="24" string="feet" />
          </tokens>
        </chunking>
        <chunking id="19" string="said the 162-foot water depth at the site will make investigation difficult since underwater archaeology rarely is attempted at depths over 113 feet" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="the" />
            <token id="4" string="162-foot" />
            <token id="5" string="water" />
            <token id="6" string="depth" />
            <token id="7" string="at" />
            <token id="8" string="the" />
            <token id="9" string="site" />
            <token id="10" string="will" />
            <token id="11" string="make" />
            <token id="12" string="investigation" />
            <token id="13" string="difficult" />
            <token id="14" string="since" />
            <token id="15" string="underwater" />
            <token id="16" string="archaeology" />
            <token id="17" string="rarely" />
            <token id="18" string="is" />
            <token id="19" string="attempted" />
            <token id="20" string="at" />
            <token id="21" string="depths" />
            <token id="22" string="over" />
            <token id="23" string="113" />
            <token id="24" string="feet" />
          </tokens>
        </chunking>
        <chunking id="20" string="the 162-foot water depth at the site will make investigation difficult since underwater archaeology rarely is attempted at depths over 113 feet" type="SBAR">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="162-foot" />
            <token id="5" string="water" />
            <token id="6" string="depth" />
            <token id="7" string="at" />
            <token id="8" string="the" />
            <token id="9" string="site" />
            <token id="10" string="will" />
            <token id="11" string="make" />
            <token id="12" string="investigation" />
            <token id="13" string="difficult" />
            <token id="14" string="since" />
            <token id="15" string="underwater" />
            <token id="16" string="archaeology" />
            <token id="17" string="rarely" />
            <token id="18" string="is" />
            <token id="19" string="attempted" />
            <token id="20" string="at" />
            <token id="21" string="depths" />
            <token id="22" string="over" />
            <token id="23" string="113" />
            <token id="24" string="feet" />
          </tokens>
        </chunking>
        <chunking id="21" string="the 162-foot water depth at the site" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="162-foot" />
            <token id="5" string="water" />
            <token id="6" string="depth" />
            <token id="7" string="at" />
            <token id="8" string="the" />
            <token id="9" string="site" />
          </tokens>
        </chunking>
        <chunking id="22" string="that must be explored" type="SBAR">
          <tokens>
            <token id="35" string="that" />
            <token id="36" string="must" />
            <token id="37" string="be" />
            <token id="38" string="explored" />
          </tokens>
        </chunking>
        <chunking id="23" string="said , `` This is a ship that must be explored" type="VP">
          <tokens>
            <token id="28" string="said" />
            <token id="29" string="," />
            <token id="30" string="``" />
            <token id="31" string="This" />
            <token id="32" string="is" />
            <token id="33" string="a" />
            <token id="34" string="ship" />
            <token id="35" string="that" />
            <token id="36" string="must" />
            <token id="37" string="be" />
            <token id="38" string="explored" />
          </tokens>
        </chunking>
        <chunking id="24" string="depths over 113 feet" type="NP">
          <tokens>
            <token id="21" string="depths" />
            <token id="22" string="over" />
            <token id="23" string="113" />
            <token id="24" string="feet" />
          </tokens>
        </chunking>
        <chunking id="25" string="This" type="NP">
          <tokens>
            <token id="31" string="This" />
          </tokens>
        </chunking>
        <chunking id="26" string="since underwater archaeology rarely is attempted at depths over 113 feet" type="SBAR">
          <tokens>
            <token id="14" string="since" />
            <token id="15" string="underwater" />
            <token id="16" string="archaeology" />
            <token id="17" string="rarely" />
            <token id="18" string="is" />
            <token id="19" string="attempted" />
            <token id="20" string="at" />
            <token id="21" string="depths" />
            <token id="22" string="over" />
            <token id="23" string="113" />
            <token id="24" string="feet" />
          </tokens>
        </chunking>
        <chunking id="27" string="Papathanassopoulos" type="NP">
          <tokens>
            <token id="1" string="Papathanassopoulos" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Papathanassopoulos</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">depth</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">depth</governor>
          <dependent id="4">162-foot</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">depth</governor>
          <dependent id="5">water</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">make</governor>
          <dependent id="6">depth</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">site</governor>
          <dependent id="7">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">site</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">depth</governor>
          <dependent id="9">site</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">make</governor>
          <dependent id="10">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="11">make</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="19">attempted</governor>
          <dependent id="12">investigation</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="19">attempted</governor>
          <dependent id="13">difficult</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">attempted</governor>
          <dependent id="14">since</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">archaeology</governor>
          <dependent id="15">underwater</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="19">attempted</governor>
          <dependent id="16">archaeology</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">attempted</governor>
          <dependent id="17">rarely</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="19">attempted</governor>
          <dependent id="18">is</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">make</governor>
          <dependent id="19">attempted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">depths</governor>
          <dependent id="20">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">attempted</governor>
          <dependent id="21">depths</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">feet</governor>
          <dependent id="22">over</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="24">feet</governor>
          <dependent id="23">113</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">depths</governor>
          <dependent id="24">feet</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">said</governor>
          <dependent id="26">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">said</governor>
          <dependent id="27">he</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">said</governor>
          <dependent id="28">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">ship</governor>
          <dependent id="31">This</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="34">ship</governor>
          <dependent id="32">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">ship</governor>
          <dependent id="33">a</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="28">said</governor>
          <dependent id="34">ship</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="38">explored</governor>
          <dependent id="35">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="38">explored</governor>
          <dependent id="36">must</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="38">explored</governor>
          <dependent id="37">be</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="34">ship</governor>
          <dependent id="38">explored</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="113" type="NUMBER" score="0.0">
          <tokens>
            <token id="23" string="113" />
          </tokens>
        </entity>
        <entity id="2" string="Papathanassopoulos" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Papathanassopoulos" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>Nicolaides said he hoped it would be possible to tap American and Turkish expertise to excavate the wreck as an international project.</content>
      <tokens>
        <token id="1" string="Nicolaides" lemma="Nicolaides" stem="nicolaid" pos="NNPS" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="hoped" lemma="hope" stem="hope" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="possible" lemma="possible" stem="possibl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="tap" lemma="tap" stem="tap" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="American" lemma="american" stem="american" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Turkish" lemma="turkish" stem="turkish" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="14" string="expertise" lemma="expertise" stem="expertis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="excavate" lemma="excavate" stem="excav" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="wreck" lemma="wreck" stem="wreck" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="international" lemma="international" stem="intern" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="project" lemma="project" stem="project" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNPS Nicolaides)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBD hoped) (SBAR (S (NP (PRP it)) (VP (MD would) (VP (VB be) (ADJP (JJ possible) (S (VP (TO to) (VP (VB tap) (NP (JJ American) (CC and) (JJ Turkish) (NN expertise)) (S (VP (TO to) (VP (VB excavate) (NP (DT the) (NN wreck)) (PP (IN as) (NP (DT an) (JJ international) (NN project)))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="possible to tap American and Turkish expertise to excavate the wreck as an international project" type="ADJP">
          <tokens>
            <token id="8" string="possible" />
            <token id="9" string="to" />
            <token id="10" string="tap" />
            <token id="11" string="American" />
            <token id="12" string="and" />
            <token id="13" string="Turkish" />
            <token id="14" string="expertise" />
            <token id="15" string="to" />
            <token id="16" string="excavate" />
            <token id="17" string="the" />
            <token id="18" string="wreck" />
            <token id="19" string="as" />
            <token id="20" string="an" />
            <token id="21" string="international" />
            <token id="22" string="project" />
          </tokens>
        </chunking>
        <chunking id="2" string="hoped it would be possible to tap American and Turkish expertise to excavate the wreck as an international project" type="VP">
          <tokens>
            <token id="4" string="hoped" />
            <token id="5" string="it" />
            <token id="6" string="would" />
            <token id="7" string="be" />
            <token id="8" string="possible" />
            <token id="9" string="to" />
            <token id="10" string="tap" />
            <token id="11" string="American" />
            <token id="12" string="and" />
            <token id="13" string="Turkish" />
            <token id="14" string="expertise" />
            <token id="15" string="to" />
            <token id="16" string="excavate" />
            <token id="17" string="the" />
            <token id="18" string="wreck" />
            <token id="19" string="as" />
            <token id="20" string="an" />
            <token id="21" string="international" />
            <token id="22" string="project" />
          </tokens>
        </chunking>
        <chunking id="3" string="would be possible to tap American and Turkish expertise to excavate the wreck as an international project" type="VP">
          <tokens>
            <token id="6" string="would" />
            <token id="7" string="be" />
            <token id="8" string="possible" />
            <token id="9" string="to" />
            <token id="10" string="tap" />
            <token id="11" string="American" />
            <token id="12" string="and" />
            <token id="13" string="Turkish" />
            <token id="14" string="expertise" />
            <token id="15" string="to" />
            <token id="16" string="excavate" />
            <token id="17" string="the" />
            <token id="18" string="wreck" />
            <token id="19" string="as" />
            <token id="20" string="an" />
            <token id="21" string="international" />
            <token id="22" string="project" />
          </tokens>
        </chunking>
        <chunking id="4" string="Nicolaides" type="NP">
          <tokens>
            <token id="1" string="Nicolaides" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="5" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="the wreck" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="wreck" />
          </tokens>
        </chunking>
        <chunking id="7" string="he hoped it would be possible to tap American and Turkish expertise to excavate the wreck as an international project" type="SBAR">
          <tokens>
            <token id="3" string="he" />
            <token id="4" string="hoped" />
            <token id="5" string="it" />
            <token id="6" string="would" />
            <token id="7" string="be" />
            <token id="8" string="possible" />
            <token id="9" string="to" />
            <token id="10" string="tap" />
            <token id="11" string="American" />
            <token id="12" string="and" />
            <token id="13" string="Turkish" />
            <token id="14" string="expertise" />
            <token id="15" string="to" />
            <token id="16" string="excavate" />
            <token id="17" string="the" />
            <token id="18" string="wreck" />
            <token id="19" string="as" />
            <token id="20" string="an" />
            <token id="21" string="international" />
            <token id="22" string="project" />
          </tokens>
        </chunking>
        <chunking id="8" string="tap American and Turkish expertise to excavate the wreck as an international project" type="VP">
          <tokens>
            <token id="10" string="tap" />
            <token id="11" string="American" />
            <token id="12" string="and" />
            <token id="13" string="Turkish" />
            <token id="14" string="expertise" />
            <token id="15" string="to" />
            <token id="16" string="excavate" />
            <token id="17" string="the" />
            <token id="18" string="wreck" />
            <token id="19" string="as" />
            <token id="20" string="an" />
            <token id="21" string="international" />
            <token id="22" string="project" />
          </tokens>
        </chunking>
        <chunking id="9" string="said he hoped it would be possible to tap American and Turkish expertise to excavate the wreck as an international project" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="he" />
            <token id="4" string="hoped" />
            <token id="5" string="it" />
            <token id="6" string="would" />
            <token id="7" string="be" />
            <token id="8" string="possible" />
            <token id="9" string="to" />
            <token id="10" string="tap" />
            <token id="11" string="American" />
            <token id="12" string="and" />
            <token id="13" string="Turkish" />
            <token id="14" string="expertise" />
            <token id="15" string="to" />
            <token id="16" string="excavate" />
            <token id="17" string="the" />
            <token id="18" string="wreck" />
            <token id="19" string="as" />
            <token id="20" string="an" />
            <token id="21" string="international" />
            <token id="22" string="project" />
          </tokens>
        </chunking>
        <chunking id="10" string="to excavate the wreck as an international project" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="excavate" />
            <token id="17" string="the" />
            <token id="18" string="wreck" />
            <token id="19" string="as" />
            <token id="20" string="an" />
            <token id="21" string="international" />
            <token id="22" string="project" />
          </tokens>
        </chunking>
        <chunking id="11" string="it would be possible to tap American and Turkish expertise to excavate the wreck as an international project" type="SBAR">
          <tokens>
            <token id="5" string="it" />
            <token id="6" string="would" />
            <token id="7" string="be" />
            <token id="8" string="possible" />
            <token id="9" string="to" />
            <token id="10" string="tap" />
            <token id="11" string="American" />
            <token id="12" string="and" />
            <token id="13" string="Turkish" />
            <token id="14" string="expertise" />
            <token id="15" string="to" />
            <token id="16" string="excavate" />
            <token id="17" string="the" />
            <token id="18" string="wreck" />
            <token id="19" string="as" />
            <token id="20" string="an" />
            <token id="21" string="international" />
            <token id="22" string="project" />
          </tokens>
        </chunking>
        <chunking id="12" string="excavate the wreck as an international project" type="VP">
          <tokens>
            <token id="16" string="excavate" />
            <token id="17" string="the" />
            <token id="18" string="wreck" />
            <token id="19" string="as" />
            <token id="20" string="an" />
            <token id="21" string="international" />
            <token id="22" string="project" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
        <chunking id="14" string="an international project" type="NP">
          <tokens>
            <token id="20" string="an" />
            <token id="21" string="international" />
            <token id="22" string="project" />
          </tokens>
        </chunking>
        <chunking id="15" string="be possible to tap American and Turkish expertise to excavate the wreck as an international project" type="VP">
          <tokens>
            <token id="7" string="be" />
            <token id="8" string="possible" />
            <token id="9" string="to" />
            <token id="10" string="tap" />
            <token id="11" string="American" />
            <token id="12" string="and" />
            <token id="13" string="Turkish" />
            <token id="14" string="expertise" />
            <token id="15" string="to" />
            <token id="16" string="excavate" />
            <token id="17" string="the" />
            <token id="18" string="wreck" />
            <token id="19" string="as" />
            <token id="20" string="an" />
            <token id="21" string="international" />
            <token id="22" string="project" />
          </tokens>
        </chunking>
        <chunking id="16" string="to tap American and Turkish expertise to excavate the wreck as an international project" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="tap" />
            <token id="11" string="American" />
            <token id="12" string="and" />
            <token id="13" string="Turkish" />
            <token id="14" string="expertise" />
            <token id="15" string="to" />
            <token id="16" string="excavate" />
            <token id="17" string="the" />
            <token id="18" string="wreck" />
            <token id="19" string="as" />
            <token id="20" string="an" />
            <token id="21" string="international" />
            <token id="22" string="project" />
          </tokens>
        </chunking>
        <chunking id="17" string="American and Turkish expertise" type="NP">
          <tokens>
            <token id="11" string="American" />
            <token id="12" string="and" />
            <token id="13" string="Turkish" />
            <token id="14" string="expertise" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Nicolaides</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">hoped</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="4">hoped</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">possible</governor>
          <dependent id="5">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">possible</governor>
          <dependent id="6">would</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">possible</governor>
          <dependent id="7">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">hoped</governor>
          <dependent id="8">possible</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">tap</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">possible</governor>
          <dependent id="10">tap</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">expertise</governor>
          <dependent id="11">American</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">American</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">American</governor>
          <dependent id="13">Turkish</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">tap</governor>
          <dependent id="14">expertise</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">excavate</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">tap</governor>
          <dependent id="16">excavate</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">wreck</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">excavate</governor>
          <dependent id="18">wreck</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">project</governor>
          <dependent id="19">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">project</governor>
          <dependent id="20">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">project</governor>
          <dependent id="21">international</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">excavate</governor>
          <dependent id="22">project</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Turkish" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="13" string="Turkish" />
          </tokens>
        </entity>
        <entity id="2" string="Nicolaides" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Nicolaides" />
          </tokens>
        </entity>
        <entity id="3" string="American" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="11" string="American" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>American experts from the Institute of Nautical Archaeology at Texas A &amp;amp;amp; M University, working in cooperation with Turkish divers, have pioneered underwater excavation off the Turkish Aegean coast.</content>
      <tokens>
        <token id="1" string="American" lemma="american" stem="american" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="2" string="experts" lemma="expert" stem="expert" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Institute" lemma="Institute" stem="institut" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="7" string="Nautical" lemma="Nautical" stem="nautic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="8" string="Archaeology" lemma="Archaeology" stem="archaeologi" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="9" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="10" string="Texas" lemma="Texas" stem="texa" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="11" string="A" lemma="A" stem="a" pos="NNP" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="12" string="&amp;amp;" lemma="&amp;" stem="&amp;amp;" pos="CC" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="13" string="M" lemma="M" stem="m" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="14" string="University" lemma="University" stem="univers" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="working" lemma="work" stem="work" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="cooperation" lemma="cooperation" stem="cooper" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Turkish" lemma="turkish" stem="turkish" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="21" string="divers" lemma="diver" stem="diver" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="pioneered" lemma="pioneer" stem="pioneer" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="underwater" lemma="underwater" stem="underwat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="excavation" lemma="excavation" stem="excav" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="off" lemma="off" stem="off" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="Turkish" lemma="turkish" stem="turkish" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="30" string="Aegean" lemma="aegean" stem="aegean" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="31" string="coast" lemma="coast" stem="coast" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (JJ American) (NNS experts)) (PP (IN from) (NP (NP (DT the) (NNP Institute)) (PP (IN of) (NP (NP (NNP Nautical) (NNP Archaeology)) (PP (IN at) (NP (NNP Texas) (NNP A) (CC &amp;) (NNP M) (NNP University)))))))) (, ,) (S (VP (VBG working) (PP (IN in) (NP (NN cooperation))) (PP (IN with) (NP (JJ Turkish) (NNS divers))))) (, ,) (VP (VBP have) (VP (VBN pioneered) (NP (JJ underwater) (NN excavation)) (PP (IN off) (NP (DT the) (JJ Turkish) (JJ Aegean) (NN coast))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="working in cooperation with Turkish divers" type="VP">
          <tokens>
            <token id="16" string="working" />
            <token id="17" string="in" />
            <token id="18" string="cooperation" />
            <token id="19" string="with" />
            <token id="20" string="Turkish" />
            <token id="21" string="divers" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Institute of Nautical Archaeology at Texas A &amp; M University" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Institute" />
            <token id="6" string="of" />
            <token id="7" string="Nautical" />
            <token id="8" string="Archaeology" />
            <token id="9" string="at" />
            <token id="10" string="Texas" />
            <token id="11" string="A" />
            <token id="12" string="&amp;amp;" />
            <token id="13" string="M" />
            <token id="14" string="University" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Turkish Aegean coast" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="Turkish" />
            <token id="30" string="Aegean" />
            <token id="31" string="coast" />
          </tokens>
        </chunking>
        <chunking id="4" string="American experts from the Institute of Nautical Archaeology at Texas A &amp; M University" type="NP">
          <tokens>
            <token id="1" string="American" />
            <token id="2" string="experts" />
            <token id="3" string="from" />
            <token id="4" string="the" />
            <token id="5" string="Institute" />
            <token id="6" string="of" />
            <token id="7" string="Nautical" />
            <token id="8" string="Archaeology" />
            <token id="9" string="at" />
            <token id="10" string="Texas" />
            <token id="11" string="A" />
            <token id="12" string="&amp;amp;" />
            <token id="13" string="M" />
            <token id="14" string="University" />
          </tokens>
        </chunking>
        <chunking id="5" string="have pioneered underwater excavation off the Turkish Aegean coast" type="VP">
          <tokens>
            <token id="23" string="have" />
            <token id="24" string="pioneered" />
            <token id="25" string="underwater" />
            <token id="26" string="excavation" />
            <token id="27" string="off" />
            <token id="28" string="the" />
            <token id="29" string="Turkish" />
            <token id="30" string="Aegean" />
            <token id="31" string="coast" />
          </tokens>
        </chunking>
        <chunking id="6" string="pioneered underwater excavation off the Turkish Aegean coast" type="VP">
          <tokens>
            <token id="24" string="pioneered" />
            <token id="25" string="underwater" />
            <token id="26" string="excavation" />
            <token id="27" string="off" />
            <token id="28" string="the" />
            <token id="29" string="Turkish" />
            <token id="30" string="Aegean" />
            <token id="31" string="coast" />
          </tokens>
        </chunking>
        <chunking id="7" string="Turkish divers" type="NP">
          <tokens>
            <token id="20" string="Turkish" />
            <token id="21" string="divers" />
          </tokens>
        </chunking>
        <chunking id="8" string="Texas A &amp; M University" type="NP">
          <tokens>
            <token id="10" string="Texas" />
            <token id="11" string="A" />
            <token id="12" string="&amp;amp;" />
            <token id="13" string="M" />
            <token id="14" string="University" />
          </tokens>
        </chunking>
        <chunking id="9" string="the Institute" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Institute" />
          </tokens>
        </chunking>
        <chunking id="10" string="Nautical Archaeology" type="NP">
          <tokens>
            <token id="7" string="Nautical" />
            <token id="8" string="Archaeology" />
          </tokens>
        </chunking>
        <chunking id="11" string="Nautical Archaeology at Texas A &amp; M University" type="NP">
          <tokens>
            <token id="7" string="Nautical" />
            <token id="8" string="Archaeology" />
            <token id="9" string="at" />
            <token id="10" string="Texas" />
            <token id="11" string="A" />
            <token id="12" string="&amp;amp;" />
            <token id="13" string="M" />
            <token id="14" string="University" />
          </tokens>
        </chunking>
        <chunking id="12" string="American experts" type="NP">
          <tokens>
            <token id="1" string="American" />
            <token id="2" string="experts" />
          </tokens>
        </chunking>
        <chunking id="13" string="cooperation" type="NP">
          <tokens>
            <token id="18" string="cooperation" />
          </tokens>
        </chunking>
        <chunking id="14" string="underwater excavation" type="NP">
          <tokens>
            <token id="25" string="underwater" />
            <token id="26" string="excavation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">experts</governor>
          <dependent id="1">American</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">pioneered</governor>
          <dependent id="2">experts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Institute</governor>
          <dependent id="3">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">Institute</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">experts</governor>
          <dependent id="5">Institute</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Archaeology</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Archaeology</governor>
          <dependent id="7">Nautical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">Institute</governor>
          <dependent id="8">Archaeology</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">A</governor>
          <dependent id="9">at</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">A</governor>
          <dependent id="10">Texas</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">Archaeology</governor>
          <dependent id="11">A</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">A</governor>
          <dependent id="12">&amp;</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">University</governor>
          <dependent id="13">M</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">A</governor>
          <dependent id="14">University</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="24">pioneered</governor>
          <dependent id="16">working</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">cooperation</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">working</governor>
          <dependent id="18">cooperation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">divers</governor>
          <dependent id="19">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">divers</governor>
          <dependent id="20">Turkish</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">working</governor>
          <dependent id="21">divers</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">pioneered</governor>
          <dependent id="23">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="24">pioneered</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">excavation</governor>
          <dependent id="25">underwater</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">pioneered</governor>
          <dependent id="26">excavation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">coast</governor>
          <dependent id="27">off</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">coast</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">coast</governor>
          <dependent id="29">Turkish</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">coast</governor>
          <dependent id="30">Aegean</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">pioneered</governor>
          <dependent id="31">coast</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Aegean" type="MISC" score="0.0">
          <tokens>
            <token id="30" string="Aegean" />
          </tokens>
        </entity>
        <entity id="2" string="Institute of Nautical Archaeology at Texas A &amp;amp; M University" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="5" string="Institute" />
            <token id="6" string="of" />
            <token id="7" string="Nautical" />
            <token id="8" string="Archaeology" />
            <token id="9" string="at" />
            <token id="10" string="Texas" />
            <token id="11" string="A" />
            <token id="12" string="&amp;amp;" />
            <token id="13" string="M" />
            <token id="14" string="University" />
          </tokens>
        </entity>
        <entity id="3" string="Turkish" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="20" string="Turkish" />
          </tokens>
        </entity>
        <entity id="4" string="American" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="1" string="American" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>Greek marine archaeologists focus on locating and surveying historic wrecks scattered around the Aegean and rarely carry out excavations.</content>
      <tokens>
        <token id="1" string="Greek" lemma="greek" stem="greek" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="2" string="marine" lemma="marine" stem="marin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="archaeologists" lemma="archaeologist" stem="archaeologist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="focus" lemma="focus" stem="focu" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="locating" lemma="locate" stem="locat" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="surveying" lemma="survey" stem="survei" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="historic" lemma="historic" stem="histor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="wrecks" lemma="wreck" stem="wreck" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="scattered" lemma="scatter" stem="scatter" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="around" lemma="around" stem="around" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="Aegean" lemma="Aegean" stem="aegean" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="rarely" lemma="rarely" stem="rare" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="carry" lemma="carry" stem="carri" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="excavations" lemma="excavation" stem="excav" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (JJ Greek) (JJ marine) (NNS archaeologists)) (VP (VP (VBP focus) (PP (IN on) (S (VP (VBG locating) (CC and) (VBG surveying) (NP (NP (JJ historic) (NNS wrecks)) (VP (VBN scattered) (PP (IN around) (NP (DT the) (NNP Aegean))))))))) (CC and) (ADVP (RB rarely)) (VP (VBP carry) (PRT (RP out)) (NP (NNS excavations)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Aegean" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="Aegean" />
          </tokens>
        </chunking>
        <chunking id="2" string="focus on locating and surveying historic wrecks scattered around the Aegean" type="VP">
          <tokens>
            <token id="4" string="focus" />
            <token id="5" string="on" />
            <token id="6" string="locating" />
            <token id="7" string="and" />
            <token id="8" string="surveying" />
            <token id="9" string="historic" />
            <token id="10" string="wrecks" />
            <token id="11" string="scattered" />
            <token id="12" string="around" />
            <token id="13" string="the" />
            <token id="14" string="Aegean" />
          </tokens>
        </chunking>
        <chunking id="3" string="historic wrecks" type="NP">
          <tokens>
            <token id="9" string="historic" />
            <token id="10" string="wrecks" />
          </tokens>
        </chunking>
        <chunking id="4" string="scattered around the Aegean" type="VP">
          <tokens>
            <token id="11" string="scattered" />
            <token id="12" string="around" />
            <token id="13" string="the" />
            <token id="14" string="Aegean" />
          </tokens>
        </chunking>
        <chunking id="5" string="focus on locating and surveying historic wrecks scattered around the Aegean and rarely carry out excavations" type="VP">
          <tokens>
            <token id="4" string="focus" />
            <token id="5" string="on" />
            <token id="6" string="locating" />
            <token id="7" string="and" />
            <token id="8" string="surveying" />
            <token id="9" string="historic" />
            <token id="10" string="wrecks" />
            <token id="11" string="scattered" />
            <token id="12" string="around" />
            <token id="13" string="the" />
            <token id="14" string="Aegean" />
            <token id="15" string="and" />
            <token id="16" string="rarely" />
            <token id="17" string="carry" />
            <token id="18" string="out" />
            <token id="19" string="excavations" />
          </tokens>
        </chunking>
        <chunking id="6" string="locating and surveying historic wrecks scattered around the Aegean" type="VP">
          <tokens>
            <token id="6" string="locating" />
            <token id="7" string="and" />
            <token id="8" string="surveying" />
            <token id="9" string="historic" />
            <token id="10" string="wrecks" />
            <token id="11" string="scattered" />
            <token id="12" string="around" />
            <token id="13" string="the" />
            <token id="14" string="Aegean" />
          </tokens>
        </chunking>
        <chunking id="7" string="carry out excavations" type="VP">
          <tokens>
            <token id="17" string="carry" />
            <token id="18" string="out" />
            <token id="19" string="excavations" />
          </tokens>
        </chunking>
        <chunking id="8" string="excavations" type="NP">
          <tokens>
            <token id="19" string="excavations" />
          </tokens>
        </chunking>
        <chunking id="9" string="historic wrecks scattered around the Aegean" type="NP">
          <tokens>
            <token id="9" string="historic" />
            <token id="10" string="wrecks" />
            <token id="11" string="scattered" />
            <token id="12" string="around" />
            <token id="13" string="the" />
            <token id="14" string="Aegean" />
          </tokens>
        </chunking>
        <chunking id="10" string="Greek marine archaeologists" type="NP">
          <tokens>
            <token id="1" string="Greek" />
            <token id="2" string="marine" />
            <token id="3" string="archaeologists" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="3">archaeologists</governor>
          <dependent id="1">Greek</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">archaeologists</governor>
          <dependent id="2">marine</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">focus</governor>
          <dependent id="3">archaeologists</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">focus</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">locating</governor>
          <dependent id="5">on</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">focus</governor>
          <dependent id="6">locating</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">locating</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">locating</governor>
          <dependent id="8">surveying</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">wrecks</governor>
          <dependent id="9">historic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">locating</governor>
          <dependent id="10">wrecks</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="10">wrecks</governor>
          <dependent id="11">scattered</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Aegean</governor>
          <dependent id="12">around</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">Aegean</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">scattered</governor>
          <dependent id="14">Aegean</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">focus</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">carry</governor>
          <dependent id="16">rarely</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">focus</governor>
          <dependent id="17">carry</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="17">carry</governor>
          <dependent id="18">out</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">carry</governor>
          <dependent id="19">excavations</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Greek" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="1" string="Greek" />
          </tokens>
        </entity>
        <entity id="2" string="Aegean" type="LOCATION" score="0.0">
          <tokens>
            <token id="14" string="Aegean" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="35-36" string="Peter Nicolaides" id_sentence="2" />
      <mentions>
        <mention ids_tokens="27" string="Nicolaides" id_sentence="7" />
        <mention ids_tokens="1-18" string="Nicolaides , who heard about the wreck while teaching an underwater archaeology course to local divers last winter" id_sentence="8" />
        <mention ids_tokens="1" string="Nicolaides" id_sentence="8" />
        <mention ids_tokens="1" string="He" id_sentence="9" />
        <mention ids_tokens="9" string="he" id_sentence="9" />
        <mention ids_tokens="3" string="I" id_sentence="10" />
        <mention ids_tokens="6" string="I" id_sentence="10" />
        <mention ids_tokens="42" string="he" id_sentence="10" />
        <mention ids_tokens="1" string="Nicolaides" id_sentence="22" />
        <mention ids_tokens="3" string="he" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="4-5-6-7" string="the wooden sailing ship" id_sentence="2" />
      <mentions>
        <mention ids_tokens="2-3" string="The ship" id_sentence="11" />
        <mention ids_tokens="17-18" string="the ship" id_sentence="15" />
        <mention ids_tokens="16-17" string="the ship" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="16-17-18-19-20-21-22-23-24-25-26-27-28-29-30-31-32-33-34-35-36-37-38-39-40-41-42" string="the eastern Aegean at a point where historical accounts place the sinking of the Ottoman ship , according to Peter Nicolaides , a diver and salvage expert" id_sentence="2" />
      <mentions>
        <mention ids_tokens="30" string="Aegean" id_sentence="23" />
        <mention ids_tokens="13-14" string="the Aegean" id_sentence="24" />
        <mention ids_tokens="14" string="Aegean" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="6" type="PROPER">
      <referenced ids_tokens="1-2-3-4" string="The Bourloti Seimaz _" id_sentence="3" />
      <mentions>
        <mention ids_tokens="13-15" string="the Bourloti Seimaz" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="7" type="PROPER">
      <referenced ids_tokens="17-18-19-20" string="Greek Admiral Constantine Kanaris" id_sentence="3" />
      <mentions>
        <mention ids_tokens="20" string="Kanaris" id_sentence="15" />
        <mention ids_tokens="22" string="his" id_sentence="15" />
        <mention ids_tokens="1" string="Kanaris" id_sentence="19" />
        <mention ids_tokens="3" string="his" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="8" type="NOMINAL">
      <referenced ids_tokens="1-2-3" string="Thousands of islanders" id_sentence="4" />
      <mentions>
        <mention ids_tokens="14" string="we" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="6-7-8" string="the Turkish raids" id_sentence="4" />
      <mentions>
        <mention ids_tokens="20-21" string="the raids" id_sentence="6" />
      </mentions>
    </coreference>
    <coreference id="10" type="NOMINAL">
      <referenced ids_tokens="7-8-9" string="a famous picture" id_sentence="6" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="7" />
        <mention ids_tokens="4-6" string="an incredible discovery" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="14" type="NOMINAL">
      <referenced ids_tokens="9-10" string="human bones" id_sentence="13" />
      <mentions>
        <mention ids_tokens="1" string="He" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="15" type="NOMINAL">
      <referenced ids_tokens="6-7-8-9-10" string="the nearby island of Psara" id_sentence="16" />
      <mentions>
        <mention ids_tokens="1" string="Its" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="16" type="PROPER">
      <referenced ids_tokens="22-23" string="George Papathanassopoulos" id_sentence="20" />
      <mentions>
        <mention ids_tokens="1" string="Papathanassopoulos" id_sentence="21" />
        <mention ids_tokens="27" string="he" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="17" type="NOMINAL">
      <referenced ids_tokens="33-34-35-36-37-38" string="a ship that must be explored" id_sentence="21" />
      <mentions>
        <mention ids_tokens="2" string="This" id_sentence="20" />
      </mentions>
    </coreference>
  </coreferences>
</document>
