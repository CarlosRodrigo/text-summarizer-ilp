<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="SJMN91-06256124">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Supreme Court nominee Clarence Thomas told the Senate Judiciary Committee today it is &amp;quot;irrelevant&amp;quot; whether he holds any personal opinion on abortion, spurring new frustration among the committee&amp;apost;s Democrats But as the hearings&amp;apost; third day got under way, no groundswell of opposition to his confirmation seemed to be emerging.</content>
      <tokens>
        <token id="1" string="Supreme" lemma="Supreme" stem="suprem" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="2" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="3" string="nominee" lemma="nominee" stem="nomine" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="9" string="Judiciary" lemma="Judiciary" stem="judiciari" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="10" string="Committee" lemma="Committee" stem="committe" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="11" string="today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="irrelevant" lemma="irrelevant" stem="irrelev" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="holds" lemma="hold" stem="hold" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="personal" lemma="personal" stem="person" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="opinion" lemma="opinion" stem="opinion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="abortion" lemma="abortion" stem="abort" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="spurring" lemma="spur" stem="spur" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="frustration" lemma="frustration" stem="frustrat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="committee" lemma="committee" stem="committe" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="Democrats" lemma="Democrats" stem="democrat" pos="NNPS" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="true" />
        <token id="34" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="35" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="hearings" lemma="hearing" stem="hear" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="third" lemma="third" stem="third" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="40" string="day" lemma="day" stem="dai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="41" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="under" lemma="under" stem="under" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="groundswell" lemma="groundswell" stem="groundswel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="opposition" lemma="opposition" stem="opposit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="51" string="confirmation" lemma="confirmation" stem="confirm" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="52" string="seemed" lemma="seem" stem="seem" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="53" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="54" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="55" string="emerging" lemma="emerge" stem="emerg" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="56" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Supreme) (NNP Court) (NN nominee) (NNP Clarence) (NNP Thomas)) (VP (VBD told) (NP (DT the) (NNP Senate) (NNP Judiciary) (NNP Committee)) (NP-TMP (NN today)) (SBAR (S (NP (PRP it)) (VP (VBZ is) (`` ``) (ADJP (JJ irrelevant)) ('' '') (SBAR (IN whether) (S (NP (PRP he)) (VP (VBZ holds) (NP (NP (DT any) (JJ personal) (NN opinion)) (PP (IN on) (NP (NN abortion)))) (, ,) (S (VP (VBG spurring) (NP (JJ new) (NN frustration)) (PP (IN among) (NP (NP (DT the) (NN committee) (POS 's)) (NNPS Democrats))))))))))))) (CC But) (S (SBAR (IN as) (S (NP (NP (DT the) (NNS hearings) (POS ')) (JJ third) (NN day)) (VP (VBD got) (PP (IN under) (NP (NN way)))))) (, ,) (NP (NP (DT no) (NN groundswell)) (PP (IN of) (NP (NP (NN opposition)) (PP (TO to) (NP (PRP$ his) (NN confirmation)))))) (VP (VBD seemed) (S (VP (TO to) (VP (VB be) (VP (VBG emerging))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his confirmation" type="NP">
          <tokens>
            <token id="50" string="his" />
            <token id="51" string="confirmation" />
          </tokens>
        </chunking>
        <chunking id="2" string="got under way" type="VP">
          <tokens>
            <token id="41" string="got" />
            <token id="42" string="under" />
            <token id="43" string="way" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Senate Judiciary Committee" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Senate" />
            <token id="9" string="Judiciary" />
            <token id="10" string="Committee" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="12" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="holds any personal opinion on abortion , spurring new frustration among the committee 's Democrats" type="VP">
          <tokens>
            <token id="19" string="holds" />
            <token id="20" string="any" />
            <token id="21" string="personal" />
            <token id="22" string="opinion" />
            <token id="23" string="on" />
            <token id="24" string="abortion" />
            <token id="25" string="," />
            <token id="26" string="spurring" />
            <token id="27" string="new" />
            <token id="28" string="frustration" />
            <token id="29" string="among" />
            <token id="30" string="the" />
            <token id="31" string="committee" />
            <token id="32" string="'s" />
            <token id="33" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="6" string="be emerging" type="VP">
          <tokens>
            <token id="54" string="be" />
            <token id="55" string="emerging" />
          </tokens>
        </chunking>
        <chunking id="7" string="way" type="NP">
          <tokens>
            <token id="43" string="way" />
          </tokens>
        </chunking>
        <chunking id="8" string="Supreme Court nominee Clarence Thomas" type="NP">
          <tokens>
            <token id="1" string="Supreme" />
            <token id="2" string="Court" />
            <token id="3" string="nominee" />
            <token id="4" string="Clarence" />
            <token id="5" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="9" string="seemed to be emerging" type="VP">
          <tokens>
            <token id="52" string="seemed" />
            <token id="53" string="to" />
            <token id="54" string="be" />
            <token id="55" string="emerging" />
          </tokens>
        </chunking>
        <chunking id="10" string="told the Senate Judiciary Committee today it is `` irrelevant '' whether he holds any personal opinion on abortion , spurring new frustration among the committee 's Democrats" type="VP">
          <tokens>
            <token id="6" string="told" />
            <token id="7" string="the" />
            <token id="8" string="Senate" />
            <token id="9" string="Judiciary" />
            <token id="10" string="Committee" />
            <token id="11" string="today" />
            <token id="12" string="it" />
            <token id="13" string="is" />
            <token id="14" string="&quot;" />
            <token id="15" string="irrelevant" />
            <token id="16" string="&quot;" />
            <token id="17" string="whether" />
            <token id="18" string="he" />
            <token id="19" string="holds" />
            <token id="20" string="any" />
            <token id="21" string="personal" />
            <token id="22" string="opinion" />
            <token id="23" string="on" />
            <token id="24" string="abortion" />
            <token id="25" string="," />
            <token id="26" string="spurring" />
            <token id="27" string="new" />
            <token id="28" string="frustration" />
            <token id="29" string="among" />
            <token id="30" string="the" />
            <token id="31" string="committee" />
            <token id="32" string="'s" />
            <token id="33" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="11" string="he" type="NP">
          <tokens>
            <token id="18" string="he" />
          </tokens>
        </chunking>
        <chunking id="12" string="any personal opinion on abortion" type="NP">
          <tokens>
            <token id="20" string="any" />
            <token id="21" string="personal" />
            <token id="22" string="opinion" />
            <token id="23" string="on" />
            <token id="24" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="13" string="the committee 's" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="committee" />
            <token id="32" string="'s" />
          </tokens>
        </chunking>
        <chunking id="14" string="irrelevant" type="ADJP">
          <tokens>
            <token id="15" string="irrelevant" />
          </tokens>
        </chunking>
        <chunking id="15" string="to be emerging" type="VP">
          <tokens>
            <token id="53" string="to" />
            <token id="54" string="be" />
            <token id="55" string="emerging" />
          </tokens>
        </chunking>
        <chunking id="16" string="emerging" type="VP">
          <tokens>
            <token id="55" string="emerging" />
          </tokens>
        </chunking>
        <chunking id="17" string="new frustration" type="NP">
          <tokens>
            <token id="27" string="new" />
            <token id="28" string="frustration" />
          </tokens>
        </chunking>
        <chunking id="18" string="whether he holds any personal opinion on abortion , spurring new frustration among the committee 's Democrats" type="SBAR">
          <tokens>
            <token id="17" string="whether" />
            <token id="18" string="he" />
            <token id="19" string="holds" />
            <token id="20" string="any" />
            <token id="21" string="personal" />
            <token id="22" string="opinion" />
            <token id="23" string="on" />
            <token id="24" string="abortion" />
            <token id="25" string="," />
            <token id="26" string="spurring" />
            <token id="27" string="new" />
            <token id="28" string="frustration" />
            <token id="29" string="among" />
            <token id="30" string="the" />
            <token id="31" string="committee" />
            <token id="32" string="'s" />
            <token id="33" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="19" string="the hearings ' third day" type="NP">
          <tokens>
            <token id="36" string="the" />
            <token id="37" string="hearings" />
            <token id="38" string="'" />
            <token id="39" string="third" />
            <token id="40" string="day" />
          </tokens>
        </chunking>
        <chunking id="20" string="no groundswell" type="NP">
          <tokens>
            <token id="45" string="no" />
            <token id="46" string="groundswell" />
          </tokens>
        </chunking>
        <chunking id="21" string="no groundswell of opposition to his confirmation" type="NP">
          <tokens>
            <token id="45" string="no" />
            <token id="46" string="groundswell" />
            <token id="47" string="of" />
            <token id="48" string="opposition" />
            <token id="49" string="to" />
            <token id="50" string="his" />
            <token id="51" string="confirmation" />
          </tokens>
        </chunking>
        <chunking id="22" string="it is `` irrelevant '' whether he holds any personal opinion on abortion , spurring new frustration among the committee 's Democrats" type="SBAR">
          <tokens>
            <token id="12" string="it" />
            <token id="13" string="is" />
            <token id="14" string="&quot;" />
            <token id="15" string="irrelevant" />
            <token id="16" string="&quot;" />
            <token id="17" string="whether" />
            <token id="18" string="he" />
            <token id="19" string="holds" />
            <token id="20" string="any" />
            <token id="21" string="personal" />
            <token id="22" string="opinion" />
            <token id="23" string="on" />
            <token id="24" string="abortion" />
            <token id="25" string="," />
            <token id="26" string="spurring" />
            <token id="27" string="new" />
            <token id="28" string="frustration" />
            <token id="29" string="among" />
            <token id="30" string="the" />
            <token id="31" string="committee" />
            <token id="32" string="'s" />
            <token id="33" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="23" string="abortion" type="NP">
          <tokens>
            <token id="24" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="24" string="is `` irrelevant '' whether he holds any personal opinion on abortion , spurring new frustration among the committee 's Democrats" type="VP">
          <tokens>
            <token id="13" string="is" />
            <token id="14" string="&quot;" />
            <token id="15" string="irrelevant" />
            <token id="16" string="&quot;" />
            <token id="17" string="whether" />
            <token id="18" string="he" />
            <token id="19" string="holds" />
            <token id="20" string="any" />
            <token id="21" string="personal" />
            <token id="22" string="opinion" />
            <token id="23" string="on" />
            <token id="24" string="abortion" />
            <token id="25" string="," />
            <token id="26" string="spurring" />
            <token id="27" string="new" />
            <token id="28" string="frustration" />
            <token id="29" string="among" />
            <token id="30" string="the" />
            <token id="31" string="committee" />
            <token id="32" string="'s" />
            <token id="33" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="25" string="as the hearings ' third day got under way" type="SBAR">
          <tokens>
            <token id="35" string="as" />
            <token id="36" string="the" />
            <token id="37" string="hearings" />
            <token id="38" string="'" />
            <token id="39" string="third" />
            <token id="40" string="day" />
            <token id="41" string="got" />
            <token id="42" string="under" />
            <token id="43" string="way" />
          </tokens>
        </chunking>
        <chunking id="26" string="opposition" type="NP">
          <tokens>
            <token id="48" string="opposition" />
          </tokens>
        </chunking>
        <chunking id="27" string="the committee 's Democrats" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="committee" />
            <token id="32" string="'s" />
            <token id="33" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="28" string="the hearings '" type="NP">
          <tokens>
            <token id="36" string="the" />
            <token id="37" string="hearings" />
            <token id="38" string="'" />
          </tokens>
        </chunking>
        <chunking id="29" string="opposition to his confirmation" type="NP">
          <tokens>
            <token id="48" string="opposition" />
            <token id="49" string="to" />
            <token id="50" string="his" />
            <token id="51" string="confirmation" />
          </tokens>
        </chunking>
        <chunking id="30" string="any personal opinion" type="NP">
          <tokens>
            <token id="20" string="any" />
            <token id="21" string="personal" />
            <token id="22" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="31" string="spurring new frustration among the committee 's Democrats" type="VP">
          <tokens>
            <token id="26" string="spurring" />
            <token id="27" string="new" />
            <token id="28" string="frustration" />
            <token id="29" string="among" />
            <token id="30" string="the" />
            <token id="31" string="committee" />
            <token id="32" string="'s" />
            <token id="33" string="Democrats" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="5">Thomas</governor>
          <dependent id="1">Supreme</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Thomas</governor>
          <dependent id="2">Court</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Thomas</governor>
          <dependent id="3">nominee</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Thomas</governor>
          <dependent id="4">Clarence</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">told</governor>
          <dependent id="5">Thomas</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">told</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">Committee</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Committee</governor>
          <dependent id="8">Senate</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Committee</governor>
          <dependent id="9">Judiciary</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">told</governor>
          <dependent id="10">Committee</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="6">told</governor>
          <dependent id="11">today</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">irrelevant</governor>
          <dependent id="12">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">irrelevant</governor>
          <dependent id="13">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">told</governor>
          <dependent id="15">irrelevant</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">holds</governor>
          <dependent id="17">whether</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">holds</governor>
          <dependent id="18">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">irrelevant</governor>
          <dependent id="19">holds</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">opinion</governor>
          <dependent id="20">any</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">opinion</governor>
          <dependent id="21">personal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">holds</governor>
          <dependent id="22">opinion</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">abortion</governor>
          <dependent id="23">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">opinion</governor>
          <dependent id="24">abortion</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">holds</governor>
          <dependent id="26">spurring</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">frustration</governor>
          <dependent id="27">new</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">spurring</governor>
          <dependent id="28">frustration</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">Democrats</governor>
          <dependent id="29">among</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">committee</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="33">Democrats</governor>
          <dependent id="31">committee</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">committee</governor>
          <dependent id="32">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">spurring</governor>
          <dependent id="33">Democrats</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">told</governor>
          <dependent id="34">But</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="41">got</governor>
          <dependent id="35">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">hearings</governor>
          <dependent id="36">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="40">day</governor>
          <dependent id="37">hearings</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">hearings</governor>
          <dependent id="38">'</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="40">day</governor>
          <dependent id="39">third</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="41">got</governor>
          <dependent id="40">day</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="52">seemed</governor>
          <dependent id="41">got</dependent>
        </dependency>
        <dependency type="case">
          <governor id="43">way</governor>
          <dependent id="42">under</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="41">got</governor>
          <dependent id="43">way</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="46">groundswell</governor>
          <dependent id="45">no</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="52">seemed</governor>
          <dependent id="46">groundswell</dependent>
        </dependency>
        <dependency type="case">
          <governor id="48">opposition</governor>
          <dependent id="47">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="46">groundswell</governor>
          <dependent id="48">opposition</dependent>
        </dependency>
        <dependency type="case">
          <governor id="51">confirmation</governor>
          <dependent id="49">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="51">confirmation</governor>
          <dependent id="50">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="48">opposition</governor>
          <dependent id="51">confirmation</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">told</governor>
          <dependent id="52">seemed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="55">emerging</governor>
          <dependent id="53">to</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="55">emerging</governor>
          <dependent id="54">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="52">seemed</governor>
          <dependent id="55">emerging</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Supreme Court" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="1" string="Supreme" />
            <token id="2" string="Court" />
          </tokens>
        </entity>
        <entity id="2" string="Democrats" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="33" string="Democrats" />
          </tokens>
        </entity>
        <entity id="3" string="But" type="MISC" score="0.0">
          <tokens>
            <token id="34" string="But" />
          </tokens>
        </entity>
        <entity id="4" string="today" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="today" />
          </tokens>
        </entity>
        <entity id="5" string="third day" type="DATE" score="0.0">
          <tokens>
            <token id="39" string="third" />
            <token id="40" string="day" />
          </tokens>
        </entity>
        <entity id="6" string="Senate Judiciary Committee" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="Senate" />
            <token id="9" string="Judiciary" />
            <token id="10" string="Committee" />
          </tokens>
        </entity>
        <entity id="7" string="Clarence Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Clarence" />
            <token id="5" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>Asked several times by Sen. Herb Kohl, D-Wis., about women&amp;apost;s right to end their pregnancies, Thomas said, &amp;quot;Whether or not I have a view is irrelevant.&amp;quot;</content>
      <tokens>
        <token id="1" string="Asked" lemma="ask" stem="asked" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="several" lemma="several" stem="sever" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="times" lemma="time" stem="time" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Sen." lemma="Sen." stem="sen." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Herb" lemma="Herb" stem="herb" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="Kohl" lemma="Kohl" stem="kohl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="D-Wis." lemma="D-Wis." stem="d-wis." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="women" lemma="woman" stem="women" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="right" lemma="right" stem="right" pos="NN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="end" lemma="end" stem="end" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="pregnancies" lemma="pregnancy" stem="pregnanc" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="21" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Whether" lemma="Whether" stem="whether" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="view" lemma="view" stem="view" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="32" string="irrelevant" lemma="irrelevant" stem="irrelev" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (S (VP (VBN Asked) (NP (QP (JJ several) (NNS times))) (PP (IN by) (NP (NP (NNP Sen.) (NNP Herb) (NNP Kohl)) (, ,) (NP (NNP D-Wis.)))) (, ,) (PP (IN about) (NP (NP (NNS women) (POS 's)) (NN right) (S (VP (TO to) (VP (VB end) (NP (PRP$ their) (NNS pregnancies))))))))) (, ,) (NP (NNP Thomas)) (VP (VBD said) (, ,) (S (`` ``) (NP (NNP Whether))))) (CC or) (RB not) (S (NP (PRP I)) (VP (VBP have) (NP (NP (DT a) (NN view)) (SBAR (S (VP (VBZ is) (ADJP (JJ irrelevant)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="irrelevant" type="ADJP">
          <tokens>
            <token id="32" string="irrelevant" />
          </tokens>
        </chunking>
        <chunking id="2" string="a view" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="view" />
          </tokens>
        </chunking>
        <chunking id="3" string="women 's right to end their pregnancies" type="NP">
          <tokens>
            <token id="12" string="women" />
            <token id="13" string="'s" />
            <token id="14" string="right" />
            <token id="15" string="to" />
            <token id="16" string="end" />
            <token id="17" string="their" />
            <token id="18" string="pregnancies" />
          </tokens>
        </chunking>
        <chunking id="4" string="Thomas" type="NP">
          <tokens>
            <token id="20" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="27" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="Asked several times by Sen. Herb Kohl , D-Wis. , about women 's right to end their pregnancies" type="VP">
          <tokens>
            <token id="1" string="Asked" />
            <token id="2" string="several" />
            <token id="3" string="times" />
            <token id="4" string="by" />
            <token id="5" string="Sen." />
            <token id="6" string="Herb" />
            <token id="7" string="Kohl" />
            <token id="8" string="," />
            <token id="9" string="D-Wis." />
            <token id="10" string="," />
            <token id="11" string="about" />
            <token id="12" string="women" />
            <token id="13" string="'s" />
            <token id="14" string="right" />
            <token id="15" string="to" />
            <token id="16" string="end" />
            <token id="17" string="their" />
            <token id="18" string="pregnancies" />
          </tokens>
        </chunking>
        <chunking id="7" string="a view is irrelevant" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="view" />
            <token id="31" string="is" />
            <token id="32" string="irrelevant" />
          </tokens>
        </chunking>
        <chunking id="8" string="women 's" type="NP">
          <tokens>
            <token id="12" string="women" />
            <token id="13" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="to end their pregnancies" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="end" />
            <token id="17" string="their" />
            <token id="18" string="pregnancies" />
          </tokens>
        </chunking>
        <chunking id="10" string="Whether" type="NP">
          <tokens>
            <token id="24" string="Whether" />
          </tokens>
        </chunking>
        <chunking id="11" string="several times" type="NP">
          <tokens>
            <token id="2" string="several" />
            <token id="3" string="times" />
          </tokens>
        </chunking>
        <chunking id="12" string="Sen. Herb Kohl , D-Wis." type="NP">
          <tokens>
            <token id="5" string="Sen." />
            <token id="6" string="Herb" />
            <token id="7" string="Kohl" />
            <token id="8" string="," />
            <token id="9" string="D-Wis." />
          </tokens>
        </chunking>
        <chunking id="13" string="said , `` Whether" type="VP">
          <tokens>
            <token id="21" string="said" />
            <token id="22" string="," />
            <token id="23" string="&quot;" />
            <token id="24" string="Whether" />
          </tokens>
        </chunking>
        <chunking id="14" string="end their pregnancies" type="VP">
          <tokens>
            <token id="16" string="end" />
            <token id="17" string="their" />
            <token id="18" string="pregnancies" />
          </tokens>
        </chunking>
        <chunking id="15" string="their pregnancies" type="NP">
          <tokens>
            <token id="17" string="their" />
            <token id="18" string="pregnancies" />
          </tokens>
        </chunking>
        <chunking id="16" string="D-Wis." type="NP">
          <tokens>
            <token id="9" string="D-Wis." />
          </tokens>
        </chunking>
        <chunking id="17" string="is irrelevant" type="SBAR">
          <tokens>
            <token id="31" string="is" />
            <token id="32" string="irrelevant" />
          </tokens>
        </chunking>
        <chunking id="18" string="Sen. Herb Kohl" type="NP">
          <tokens>
            <token id="5" string="Sen." />
            <token id="6" string="Herb" />
            <token id="7" string="Kohl" />
          </tokens>
        </chunking>
        <chunking id="19" string="have a view is irrelevant" type="VP">
          <tokens>
            <token id="28" string="have" />
            <token id="29" string="a" />
            <token id="30" string="view" />
            <token id="31" string="is" />
            <token id="32" string="irrelevant" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="21">said</governor>
          <dependent id="1">Asked</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">times</governor>
          <dependent id="2">several</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Asked</governor>
          <dependent id="3">times</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Kohl</governor>
          <dependent id="4">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Kohl</governor>
          <dependent id="5">Sen.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Kohl</governor>
          <dependent id="6">Herb</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Asked</governor>
          <dependent id="7">Kohl</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="7">Kohl</governor>
          <dependent id="9">D-Wis.</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">right</governor>
          <dependent id="11">about</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">right</governor>
          <dependent id="12">women</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">women</governor>
          <dependent id="13">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Asked</governor>
          <dependent id="14">right</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">end</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">right</governor>
          <dependent id="16">end</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">pregnancies</governor>
          <dependent id="17">their</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">end</governor>
          <dependent id="18">pregnancies</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">said</governor>
          <dependent id="20">Thomas</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">said</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="21">said</governor>
          <dependent id="24">Whether</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">said</governor>
          <dependent id="25">or</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="28">have</governor>
          <dependent id="26">not</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">have</governor>
          <dependent id="27">I</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">said</governor>
          <dependent id="28">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">view</governor>
          <dependent id="29">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">have</governor>
          <dependent id="30">view</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="32">irrelevant</governor>
          <dependent id="31">is</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="30">view</governor>
          <dependent id="32">irrelevant</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Herb Kohl" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Herb" />
            <token id="7" string="Kohl" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Thomas" />
          </tokens>
        </entity>
        <entity id="3" string="D-Wis." type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="D-Wis." />
          </tokens>
        </entity>
        <entity id="4" string="right" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="14" string="right" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>; President Bush, asked at a news conference whether Thomas&amp;apost; claim not to have an opinion on abortion is credible, answered, &amp;quot;That&amp;apost;s a question for the Senate to decide.&amp;quot;</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="President" lemma="President" stem="presid" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="3" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="asked" lemma="ask" stem="ask" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="news" lemma="news" stem="new" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="conference" lemma="conference" stem="confer" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="claim" lemma="claim" stem="claim" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="opinion" lemma="opinion" stem="opinion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="abortion" lemma="abortion" stem="abort" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="credible" lemma="credible" stem="credibl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="answered" lemma="answer" stem="answer" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="question" lemma="question" stem="question" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="34" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="decide" lemma="decide" stem="decid" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (NP (NP (NNP President)) (NP (NNP Bush))) (, ,) (S (VP (VBD asked) (PP (IN at) (NP (DT a) (NN news) (NN conference))) (SBAR (IN whether) (S (NP (NP (NNP Thomas) (POS ')) (NN claim) (S (VP (RB not) (TO to) (VP (VB have) (NP (NP (DT an) (NN opinion)) (PP (IN on) (NP (NN abortion)))))))) (VP (VBZ is) (ADJP (JJ credible))))))) (, ,) (PRN (S (VP (VBN answered)))) (, ,) (`` ``) (NP (DT That)) (VP (VBZ 's) (NP (NP (DT a) (NN question)) (PP (IN for) (NP (DT the) (NNP Senate))) (S (VP (TO to) (VP (VB decide)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="an opinion" type="NP">
          <tokens>
            <token id="17" string="an" />
            <token id="18" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="2" string="That" type="NP">
          <tokens>
            <token id="27" string="That" />
          </tokens>
        </chunking>
        <chunking id="3" string="a news conference" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="news" />
            <token id="9" string="conference" />
          </tokens>
        </chunking>
        <chunking id="4" string="to decide" type="VP">
          <tokens>
            <token id="34" string="to" />
            <token id="35" string="decide" />
          </tokens>
        </chunking>
        <chunking id="5" string="answered" type="VP">
          <tokens>
            <token id="24" string="answered" />
          </tokens>
        </chunking>
        <chunking id="6" string="decide" type="VP">
          <tokens>
            <token id="35" string="decide" />
          </tokens>
        </chunking>
        <chunking id="7" string="a question" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="question" />
          </tokens>
        </chunking>
        <chunking id="8" string="asked at a news conference whether Thomas ' claim not to have an opinion on abortion is credible" type="VP">
          <tokens>
            <token id="5" string="asked" />
            <token id="6" string="at" />
            <token id="7" string="a" />
            <token id="8" string="news" />
            <token id="9" string="conference" />
            <token id="10" string="whether" />
            <token id="11" string="Thomas" />
            <token id="12" string="'" />
            <token id="13" string="claim" />
            <token id="14" string="not" />
            <token id="15" string="to" />
            <token id="16" string="have" />
            <token id="17" string="an" />
            <token id="18" string="opinion" />
            <token id="19" string="on" />
            <token id="20" string="abortion" />
            <token id="21" string="is" />
            <token id="22" string="credible" />
          </tokens>
        </chunking>
        <chunking id="9" string="Thomas '" type="NP">
          <tokens>
            <token id="11" string="Thomas" />
            <token id="12" string="'" />
          </tokens>
        </chunking>
        <chunking id="10" string="President Bush" type="NP">
          <tokens>
            <token id="2" string="President" />
            <token id="3" string="Bush" />
          </tokens>
        </chunking>
        <chunking id="11" string="is credible" type="VP">
          <tokens>
            <token id="21" string="is" />
            <token id="22" string="credible" />
          </tokens>
        </chunking>
        <chunking id="12" string="have an opinion on abortion" type="VP">
          <tokens>
            <token id="16" string="have" />
            <token id="17" string="an" />
            <token id="18" string="opinion" />
            <token id="19" string="on" />
            <token id="20" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="13" string="abortion" type="NP">
          <tokens>
            <token id="20" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="14" string="President" type="NP">
          <tokens>
            <token id="2" string="President" />
          </tokens>
        </chunking>
        <chunking id="15" string="Thomas ' claim not to have an opinion on abortion" type="NP">
          <tokens>
            <token id="11" string="Thomas" />
            <token id="12" string="'" />
            <token id="13" string="claim" />
            <token id="14" string="not" />
            <token id="15" string="to" />
            <token id="16" string="have" />
            <token id="17" string="an" />
            <token id="18" string="opinion" />
            <token id="19" string="on" />
            <token id="20" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="16" string="a question for the Senate to decide" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="question" />
            <token id="31" string="for" />
            <token id="32" string="the" />
            <token id="33" string="Senate" />
            <token id="34" string="to" />
            <token id="35" string="decide" />
          </tokens>
        </chunking>
        <chunking id="17" string="the Senate" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="Senate" />
          </tokens>
        </chunking>
        <chunking id="18" string="whether Thomas ' claim not to have an opinion on abortion is credible" type="SBAR">
          <tokens>
            <token id="10" string="whether" />
            <token id="11" string="Thomas" />
            <token id="12" string="'" />
            <token id="13" string="claim" />
            <token id="14" string="not" />
            <token id="15" string="to" />
            <token id="16" string="have" />
            <token id="17" string="an" />
            <token id="18" string="opinion" />
            <token id="19" string="on" />
            <token id="20" string="abortion" />
            <token id="21" string="is" />
            <token id="22" string="credible" />
          </tokens>
        </chunking>
        <chunking id="19" string="Bush" type="NP">
          <tokens>
            <token id="3" string="Bush" />
          </tokens>
        </chunking>
        <chunking id="20" string="credible" type="ADJP">
          <tokens>
            <token id="22" string="credible" />
          </tokens>
        </chunking>
        <chunking id="21" string="not to have an opinion on abortion" type="VP">
          <tokens>
            <token id="14" string="not" />
            <token id="15" string="to" />
            <token id="16" string="have" />
            <token id="17" string="an" />
            <token id="18" string="opinion" />
            <token id="19" string="on" />
            <token id="20" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="22" string="'s a question for the Senate to decide" type="VP">
          <tokens>
            <token id="28" string="'s" />
            <token id="29" string="a" />
            <token id="30" string="question" />
            <token id="31" string="for" />
            <token id="32" string="the" />
            <token id="33" string="Senate" />
            <token id="34" string="to" />
            <token id="35" string="decide" />
          </tokens>
        </chunking>
        <chunking id="23" string="an opinion on abortion" type="NP">
          <tokens>
            <token id="17" string="an" />
            <token id="18" string="opinion" />
            <token id="19" string="on" />
            <token id="20" string="abortion" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="30">question</governor>
          <dependent id="2">President</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">President</governor>
          <dependent id="3">Bush</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="30">question</governor>
          <dependent id="5">asked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">conference</governor>
          <dependent id="6">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">conference</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">conference</governor>
          <dependent id="8">news</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">asked</governor>
          <dependent id="9">conference</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">credible</governor>
          <dependent id="10">whether</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">claim</governor>
          <dependent id="11">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Thomas</governor>
          <dependent id="12">'</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">credible</governor>
          <dependent id="13">claim</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="16">have</governor>
          <dependent id="14">not</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">have</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="13">claim</governor>
          <dependent id="16">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">opinion</governor>
          <dependent id="17">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">have</governor>
          <dependent id="18">opinion</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">abortion</governor>
          <dependent id="19">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">opinion</governor>
          <dependent id="20">abortion</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="22">credible</governor>
          <dependent id="21">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">asked</governor>
          <dependent id="22">credible</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="30">question</governor>
          <dependent id="24">answered</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">question</governor>
          <dependent id="27">That</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="30">question</governor>
          <dependent id="28">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">question</governor>
          <dependent id="29">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="30">question</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">Senate</governor>
          <dependent id="31">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">Senate</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">question</governor>
          <dependent id="33">Senate</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="35">decide</governor>
          <dependent id="34">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="30">question</governor>
          <dependent id="35">decide</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="33" string="Senate" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Thomas" />
          </tokens>
        </entity>
        <entity id="3" string="Bush" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Bush" />
          </tokens>
        </entity>
        <entity id="4" string="President" type="TITLE" score="0.0">
          <tokens>
            <token id="2" string="President" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>; &amp;quot;He&amp;apost;s handling himself very well,&amp;quot; the president said.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="handling" lemma="handle" stem="handl" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="himself" lemma="himself" stem="himself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="president" lemma="president" stem="presid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (`` ``) (S (NP (PRP He)) (VP (VBZ 's) (VP (VBG handling) (NP (PRP himself)) (ADVP (RB very) (RB well))))) (, ,) ('' '') (NP (DT the) (NN president)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the president" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="president" />
          </tokens>
        </chunking>
        <chunking id="2" string="'s handling himself very well" type="VP">
          <tokens>
            <token id="4" string="'s" />
            <token id="5" string="handling" />
            <token id="6" string="himself" />
            <token id="7" string="very" />
            <token id="8" string="well" />
          </tokens>
        </chunking>
        <chunking id="3" string="handling himself very well" type="VP">
          <tokens>
            <token id="5" string="handling" />
            <token id="6" string="himself" />
            <token id="7" string="very" />
            <token id="8" string="well" />
          </tokens>
        </chunking>
        <chunking id="4" string="He" type="NP">
          <tokens>
            <token id="3" string="He" />
          </tokens>
        </chunking>
        <chunking id="5" string="himself" type="NP">
          <tokens>
            <token id="6" string="himself" />
          </tokens>
        </chunking>
        <chunking id="6" string="said" type="VP">
          <tokens>
            <token id="13" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">handling</governor>
          <dependent id="3">He</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">handling</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">said</governor>
          <dependent id="5">handling</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">handling</governor>
          <dependent id="6">himself</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">well</governor>
          <dependent id="7">very</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">handling</governor>
          <dependent id="8">well</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">president</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">said</governor>
          <dependent id="12">president</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>&amp;quot;I think he&amp;apost;s doing a beautiful job up there.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="doing" lemma="do" stem="do" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="beautiful" lemma="beautiful" stem="beauti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="job" lemma="job" stem="job" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="up" lemma="up" stem="up" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="there" lemma="there" stem="there" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBP think) (SBAR (S (NP (PRP he)) (VP (VBZ 's) (VP (VBG doing) (NP (DT a) (JJ beautiful) (NN job)) (ADVP (IN up) (RB there))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="he 's doing a beautiful job up there" type="SBAR">
          <tokens>
            <token id="4" string="he" />
            <token id="5" string="'s" />
            <token id="6" string="doing" />
            <token id="7" string="a" />
            <token id="8" string="beautiful" />
            <token id="9" string="job" />
            <token id="10" string="up" />
            <token id="11" string="there" />
          </tokens>
        </chunking>
        <chunking id="2" string="'s doing a beautiful job up there" type="VP">
          <tokens>
            <token id="5" string="'s" />
            <token id="6" string="doing" />
            <token id="7" string="a" />
            <token id="8" string="beautiful" />
            <token id="9" string="job" />
            <token id="10" string="up" />
            <token id="11" string="there" />
          </tokens>
        </chunking>
        <chunking id="3" string="doing a beautiful job up there" type="VP">
          <tokens>
            <token id="6" string="doing" />
            <token id="7" string="a" />
            <token id="8" string="beautiful" />
            <token id="9" string="job" />
            <token id="10" string="up" />
            <token id="11" string="there" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="a beautiful job" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="beautiful" />
            <token id="9" string="job" />
          </tokens>
        </chunking>
        <chunking id="6" string="think he 's doing a beautiful job up there" type="VP">
          <tokens>
            <token id="3" string="think" />
            <token id="4" string="he" />
            <token id="5" string="'s" />
            <token id="6" string="doing" />
            <token id="7" string="a" />
            <token id="8" string="beautiful" />
            <token id="9" string="job" />
            <token id="10" string="up" />
            <token id="11" string="there" />
          </tokens>
        </chunking>
        <chunking id="7" string="he" type="NP">
          <tokens>
            <token id="4" string="he" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">think</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">think</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">doing</governor>
          <dependent id="4">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">doing</governor>
          <dependent id="5">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">think</governor>
          <dependent id="6">doing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">job</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">job</governor>
          <dependent id="8">beautiful</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">doing</governor>
          <dependent id="9">job</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">there</governor>
          <dependent id="10">up</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">doing</governor>
          <dependent id="11">there</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>I feel more confident than ever that he will be confirmed.&amp;quot;</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="feel" lemma="feel" stem="feel" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="confident" lemma="confident" stem="confid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="ever" lemma="ever" stem="ever" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="confirmed" lemma="confirm" stem="confirm" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP feel) (ADJP (ADJP (RBR more) (JJ confident) (PP (IN than) (ADVP (RB ever)))) (SBAR (IN that) (S (NP (PRP he)) (VP (MD will) (VP (VB be) (VP (VBN confirmed)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="feel more confident than ever that he will be confirmed" type="VP">
          <tokens>
            <token id="2" string="feel" />
            <token id="3" string="more" />
            <token id="4" string="confident" />
            <token id="5" string="than" />
            <token id="6" string="ever" />
            <token id="7" string="that" />
            <token id="8" string="he" />
            <token id="9" string="will" />
            <token id="10" string="be" />
            <token id="11" string="confirmed" />
          </tokens>
        </chunking>
        <chunking id="2" string="that he will be confirmed" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="he" />
            <token id="9" string="will" />
            <token id="10" string="be" />
            <token id="11" string="confirmed" />
          </tokens>
        </chunking>
        <chunking id="3" string="will be confirmed" type="VP">
          <tokens>
            <token id="9" string="will" />
            <token id="10" string="be" />
            <token id="11" string="confirmed" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="more confident than ever" type="ADJP">
          <tokens>
            <token id="3" string="more" />
            <token id="4" string="confident" />
            <token id="5" string="than" />
            <token id="6" string="ever" />
          </tokens>
        </chunking>
        <chunking id="6" string="he" type="NP">
          <tokens>
            <token id="8" string="he" />
          </tokens>
        </chunking>
        <chunking id="7" string="confirmed" type="VP">
          <tokens>
            <token id="11" string="confirmed" />
          </tokens>
        </chunking>
        <chunking id="8" string="be confirmed" type="VP">
          <tokens>
            <token id="10" string="be" />
            <token id="11" string="confirmed" />
          </tokens>
        </chunking>
        <chunking id="9" string="more confident than ever that he will be confirmed" type="ADJP">
          <tokens>
            <token id="3" string="more" />
            <token id="4" string="confident" />
            <token id="5" string="than" />
            <token id="6" string="ever" />
            <token id="7" string="that" />
            <token id="8" string="he" />
            <token id="9" string="will" />
            <token id="10" string="be" />
            <token id="11" string="confirmed" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">feel</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">feel</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">confident</governor>
          <dependent id="3">more</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">feel</governor>
          <dependent id="4">confident</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">ever</governor>
          <dependent id="5">than</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">confident</governor>
          <dependent id="6">ever</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">confirmed</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="11">confirmed</governor>
          <dependent id="8">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">confirmed</governor>
          <dependent id="9">will</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="11">confirmed</governor>
          <dependent id="10">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">confident</governor>
          <dependent id="11">confirmed</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>; Thomas&amp;apost; answers have frustrated the committee&amp;apost;s Democrats, who say he is an evasive witness.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="3" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="answers" lemma="answer" stem="answer" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="frustrated" lemma="frustrate" stem="frustrat" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="committee" lemma="committee" stem="committe" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="Democrats" lemma="Democrats" stem="democrat" pos="NNPS" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="evasive" lemma="evasive" stem="evas" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="witness" lemma="witness" stem="wit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (S (NP (NP (NNP Thomas) (POS ')) (NNS answers)) (VP (VBP have) (VP (VBN frustrated) (NP (NP (NP (DT the) (NN committee) (POS 's)) (NNPS Democrats)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBP say) (SBAR (S (NP (PRP he)) (VP (VBZ is) (NP (DT an) (JJ evasive) (NN witness)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is an evasive witness" type="VP">
          <tokens>
            <token id="15" string="is" />
            <token id="16" string="an" />
            <token id="17" string="evasive" />
            <token id="18" string="witness" />
          </tokens>
        </chunking>
        <chunking id="2" string="Thomas ' answers" type="NP">
          <tokens>
            <token id="2" string="Thomas" />
            <token id="3" string="'" />
            <token id="4" string="answers" />
          </tokens>
        </chunking>
        <chunking id="3" string="Thomas '" type="NP">
          <tokens>
            <token id="2" string="Thomas" />
            <token id="3" string="'" />
          </tokens>
        </chunking>
        <chunking id="4" string="an evasive witness" type="NP">
          <tokens>
            <token id="16" string="an" />
            <token id="17" string="evasive" />
            <token id="18" string="witness" />
          </tokens>
        </chunking>
        <chunking id="5" string="frustrated the committee 's Democrats , who say he is an evasive witness" type="VP">
          <tokens>
            <token id="6" string="frustrated" />
            <token id="7" string="the" />
            <token id="8" string="committee" />
            <token id="9" string="'s" />
            <token id="10" string="Democrats" />
            <token id="11" string="," />
            <token id="12" string="who" />
            <token id="13" string="say" />
            <token id="14" string="he" />
            <token id="15" string="is" />
            <token id="16" string="an" />
            <token id="17" string="evasive" />
            <token id="18" string="witness" />
          </tokens>
        </chunking>
        <chunking id="6" string="who say he is an evasive witness" type="SBAR">
          <tokens>
            <token id="12" string="who" />
            <token id="13" string="say" />
            <token id="14" string="he" />
            <token id="15" string="is" />
            <token id="16" string="an" />
            <token id="17" string="evasive" />
            <token id="18" string="witness" />
          </tokens>
        </chunking>
        <chunking id="7" string="have frustrated the committee 's Democrats , who say he is an evasive witness" type="VP">
          <tokens>
            <token id="5" string="have" />
            <token id="6" string="frustrated" />
            <token id="7" string="the" />
            <token id="8" string="committee" />
            <token id="9" string="'s" />
            <token id="10" string="Democrats" />
            <token id="11" string="," />
            <token id="12" string="who" />
            <token id="13" string="say" />
            <token id="14" string="he" />
            <token id="15" string="is" />
            <token id="16" string="an" />
            <token id="17" string="evasive" />
            <token id="18" string="witness" />
          </tokens>
        </chunking>
        <chunking id="8" string="the committee 's Democrats" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="committee" />
            <token id="9" string="'s" />
            <token id="10" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="9" string="the committee 's Democrats , who say he is an evasive witness" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="committee" />
            <token id="9" string="'s" />
            <token id="10" string="Democrats" />
            <token id="11" string="," />
            <token id="12" string="who" />
            <token id="13" string="say" />
            <token id="14" string="he" />
            <token id="15" string="is" />
            <token id="16" string="an" />
            <token id="17" string="evasive" />
            <token id="18" string="witness" />
          </tokens>
        </chunking>
        <chunking id="10" string="he is an evasive witness" type="SBAR">
          <tokens>
            <token id="14" string="he" />
            <token id="15" string="is" />
            <token id="16" string="an" />
            <token id="17" string="evasive" />
            <token id="18" string="witness" />
          </tokens>
        </chunking>
        <chunking id="11" string="say he is an evasive witness" type="VP">
          <tokens>
            <token id="13" string="say" />
            <token id="14" string="he" />
            <token id="15" string="is" />
            <token id="16" string="an" />
            <token id="17" string="evasive" />
            <token id="18" string="witness" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="14" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="the committee 's" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="committee" />
            <token id="9" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="4">answers</governor>
          <dependent id="2">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Thomas</governor>
          <dependent id="3">'</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">frustrated</governor>
          <dependent id="4">answers</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">frustrated</governor>
          <dependent id="5">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">frustrated</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">committee</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">Democrats</governor>
          <dependent id="8">committee</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">committee</governor>
          <dependent id="9">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">frustrated</governor>
          <dependent id="10">Democrats</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">say</governor>
          <dependent id="12">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">Democrats</governor>
          <dependent id="13">say</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">witness</governor>
          <dependent id="14">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="18">witness</governor>
          <dependent id="15">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">witness</governor>
          <dependent id="16">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">witness</governor>
          <dependent id="17">evasive</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">say</governor>
          <dependent id="18">witness</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Democrats" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="10" string="Democrats" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>They also have voiced skepticism about his backing away from stands he took in past writings and speeches Committee Chairman Joseph Biden, D-Del., began to show signs of exasperation today during spirited questioning about the nominee&amp;apost;s views on &amp;quot;natural law,&amp;quot; a theory that certain rights exist independent of written law At one point, Biden accused Thomas of using &amp;quot;tortuous logic.&amp;quot;</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="voiced" lemma="voice" stem="voic" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="skepticism" lemma="skepticism" stem="skeptic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="backing" lemma="back" stem="back" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="away" lemma="away" stem="awai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="stands" lemma="stand" stem="stand" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="past" lemma="past" stem="past" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="writings" lemma="writings" stem="write" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="speeches" lemma="speech" stem="speech" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="Committee" lemma="Committee" stem="committe" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="20" string="Chairman" lemma="Chairman" stem="chairman" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="Joseph" lemma="Joseph" stem="joseph" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="22" string="Biden" lemma="Biden" stem="biden" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="D-Del." lemma="D-Del." stem="d-del." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="show" lemma="show" stem="show" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="signs" lemma="sign" stem="sign" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="exasperation" lemma="exasperation" stem="exasper" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="33" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="spirited" lemma="spirited" stem="spirit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="questioning" lemma="question" stem="question" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="38" string="nominee" lemma="nominee" stem="nomine" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="39" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="40" string="views" lemma="view" stem="view" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="natural" lemma="natural" stem="natur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="theory" lemma="theory" stem="theori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="certain" lemma="certain" stem="certain" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="51" string="rights" lemma="rights" stem="right" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="52" string="exist" lemma="exist" stem="exist" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="53" string="independent" lemma="independent" stem="independ" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="54" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="55" string="written" lemma="written" stem="written" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="56" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="57" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="58" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="59" string="point" lemma="point" stem="point" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="60" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="61" string="Biden" lemma="Biden" stem="biden" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="62" string="accused" lemma="accuse" stem="accus" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="63" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="64" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="65" string="using" lemma="use" stem="us" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="66" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="67" string="tortuous" lemma="tortuous" stem="tortuou" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="68" string="logic" lemma="logic" stem="logic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="69" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="70" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP They)) (ADVP (RB also)) (VP (VBP have) (VP (VBN voiced) (NP (NN skepticism)) (PP (IN about) (S (NP (PRP$ his)) (VP (VBG backing) (ADVP (RB away)) (PP (IN from) (NP (NP (NNS stands)) (SBAR (S (NP (PRP he)) (VP (VBD took) (PRT (RP in)) (NP (NP (JJ past) (NNS writings) (CC and) (NNS speeches)) (SBAR (S (NP (NP (NNP Committee) (NNP Chairman) (NNP Joseph) (NNP Biden)) (, ,) (NP (NNP D-Del.)) (, ,)) (VP (VBD began) (S (VP (TO to) (VP (VB show) (NP (NP (NNS signs)) (PP (IN of) (NP (NN exasperation))))))) (NP-TMP (NN today)) (PP (IN during) (NP (NP (JJ spirited) (VBG questioning)) (PP (IN about) (NP (NP (DT the) (NN nominee) (POS 's)) (NNS views))))))))) (PP (IN on) (NP (`` ``) (NP (JJ natural) (NN law)) (, ,) ('' '') (NP (NP (DT a) (NN theory)) (SBAR (WHNP (WDT that)) (S (NP (JJ certain) (NNS rights)) (VP (VBP exist) (S (ADJP (JJ independent) (PP (IN of) (NP (JJ written) (NN law)))) (PP (IN At) (NP (CD one) (NN point))))))))))))))))))))) (, ,) (NP (NNP Biden)) (VP (VBD accused) (NP (NP (NNP Thomas)) (PP (IN of) (S (VP (VBG using) (`` ``) (NP (JJ tortuous) (NN logic))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="stands he took in past writings and speeches Committee Chairman Joseph Biden , D-Del. , began to show signs of exasperation today during spirited questioning about the nominee 's views on `` natural law , '' a theory that certain rights exist independent of written law At one point" type="NP">
          <tokens>
            <token id="11" string="stands" />
            <token id="12" string="he" />
            <token id="13" string="took" />
            <token id="14" string="in" />
            <token id="15" string="past" />
            <token id="16" string="writings" />
            <token id="17" string="and" />
            <token id="18" string="speeches" />
            <token id="19" string="Committee" />
            <token id="20" string="Chairman" />
            <token id="21" string="Joseph" />
            <token id="22" string="Biden" />
            <token id="23" string="," />
            <token id="24" string="D-Del." />
            <token id="25" string="," />
            <token id="26" string="began" />
            <token id="27" string="to" />
            <token id="28" string="show" />
            <token id="29" string="signs" />
            <token id="30" string="of" />
            <token id="31" string="exasperation" />
            <token id="32" string="today" />
            <token id="33" string="during" />
            <token id="34" string="spirited" />
            <token id="35" string="questioning" />
            <token id="36" string="about" />
            <token id="37" string="the" />
            <token id="38" string="nominee" />
            <token id="39" string="'s" />
            <token id="40" string="views" />
            <token id="41" string="on" />
            <token id="42" string="&quot;" />
            <token id="43" string="natural" />
            <token id="44" string="law" />
            <token id="45" string="," />
            <token id="46" string="&quot;" />
            <token id="47" string="a" />
            <token id="48" string="theory" />
            <token id="49" string="that" />
            <token id="50" string="certain" />
            <token id="51" string="rights" />
            <token id="52" string="exist" />
            <token id="53" string="independent" />
            <token id="54" string="of" />
            <token id="55" string="written" />
            <token id="56" string="law" />
            <token id="57" string="At" />
            <token id="58" string="one" />
            <token id="59" string="point" />
          </tokens>
        </chunking>
        <chunking id="3" string="have voiced skepticism about his backing away from stands he took in past writings and speeches Committee Chairman Joseph Biden , D-Del. , began to show signs of exasperation today during spirited questioning about the nominee 's views on `` natural law , '' a theory that certain rights exist independent of written law At one point" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="voiced" />
            <token id="5" string="skepticism" />
            <token id="6" string="about" />
            <token id="7" string="his" />
            <token id="8" string="backing" />
            <token id="9" string="away" />
            <token id="10" string="from" />
            <token id="11" string="stands" />
            <token id="12" string="he" />
            <token id="13" string="took" />
            <token id="14" string="in" />
            <token id="15" string="past" />
            <token id="16" string="writings" />
            <token id="17" string="and" />
            <token id="18" string="speeches" />
            <token id="19" string="Committee" />
            <token id="20" string="Chairman" />
            <token id="21" string="Joseph" />
            <token id="22" string="Biden" />
            <token id="23" string="," />
            <token id="24" string="D-Del." />
            <token id="25" string="," />
            <token id="26" string="began" />
            <token id="27" string="to" />
            <token id="28" string="show" />
            <token id="29" string="signs" />
            <token id="30" string="of" />
            <token id="31" string="exasperation" />
            <token id="32" string="today" />
            <token id="33" string="during" />
            <token id="34" string="spirited" />
            <token id="35" string="questioning" />
            <token id="36" string="about" />
            <token id="37" string="the" />
            <token id="38" string="nominee" />
            <token id="39" string="'s" />
            <token id="40" string="views" />
            <token id="41" string="on" />
            <token id="42" string="&quot;" />
            <token id="43" string="natural" />
            <token id="44" string="law" />
            <token id="45" string="," />
            <token id="46" string="&quot;" />
            <token id="47" string="a" />
            <token id="48" string="theory" />
            <token id="49" string="that" />
            <token id="50" string="certain" />
            <token id="51" string="rights" />
            <token id="52" string="exist" />
            <token id="53" string="independent" />
            <token id="54" string="of" />
            <token id="55" string="written" />
            <token id="56" string="law" />
            <token id="57" string="At" />
            <token id="58" string="one" />
            <token id="59" string="point" />
          </tokens>
        </chunking>
        <chunking id="4" string="show signs of exasperation" type="VP">
          <tokens>
            <token id="28" string="show" />
            <token id="29" string="signs" />
            <token id="30" string="of" />
            <token id="31" string="exasperation" />
          </tokens>
        </chunking>
        <chunking id="5" string="independent of written law" type="ADJP">
          <tokens>
            <token id="53" string="independent" />
            <token id="54" string="of" />
            <token id="55" string="written" />
            <token id="56" string="law" />
          </tokens>
        </chunking>
        <chunking id="6" string="skepticism" type="NP">
          <tokens>
            <token id="5" string="skepticism" />
          </tokens>
        </chunking>
        <chunking id="7" string="Thomas" type="NP">
          <tokens>
            <token id="63" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="8" string="he took in past writings and speeches Committee Chairman Joseph Biden , D-Del. , began to show signs of exasperation today during spirited questioning about the nominee 's views on `` natural law , '' a theory that certain rights exist independent of written law At one point" type="SBAR">
          <tokens>
            <token id="12" string="he" />
            <token id="13" string="took" />
            <token id="14" string="in" />
            <token id="15" string="past" />
            <token id="16" string="writings" />
            <token id="17" string="and" />
            <token id="18" string="speeches" />
            <token id="19" string="Committee" />
            <token id="20" string="Chairman" />
            <token id="21" string="Joseph" />
            <token id="22" string="Biden" />
            <token id="23" string="," />
            <token id="24" string="D-Del." />
            <token id="25" string="," />
            <token id="26" string="began" />
            <token id="27" string="to" />
            <token id="28" string="show" />
            <token id="29" string="signs" />
            <token id="30" string="of" />
            <token id="31" string="exasperation" />
            <token id="32" string="today" />
            <token id="33" string="during" />
            <token id="34" string="spirited" />
            <token id="35" string="questioning" />
            <token id="36" string="about" />
            <token id="37" string="the" />
            <token id="38" string="nominee" />
            <token id="39" string="'s" />
            <token id="40" string="views" />
            <token id="41" string="on" />
            <token id="42" string="&quot;" />
            <token id="43" string="natural" />
            <token id="44" string="law" />
            <token id="45" string="," />
            <token id="46" string="&quot;" />
            <token id="47" string="a" />
            <token id="48" string="theory" />
            <token id="49" string="that" />
            <token id="50" string="certain" />
            <token id="51" string="rights" />
            <token id="52" string="exist" />
            <token id="53" string="independent" />
            <token id="54" string="of" />
            <token id="55" string="written" />
            <token id="56" string="law" />
            <token id="57" string="At" />
            <token id="58" string="one" />
            <token id="59" string="point" />
          </tokens>
        </chunking>
        <chunking id="9" string="to show signs of exasperation" type="VP">
          <tokens>
            <token id="27" string="to" />
            <token id="28" string="show" />
            <token id="29" string="signs" />
            <token id="30" string="of" />
            <token id="31" string="exasperation" />
          </tokens>
        </chunking>
        <chunking id="10" string="one point" type="NP">
          <tokens>
            <token id="58" string="one" />
            <token id="59" string="point" />
          </tokens>
        </chunking>
        <chunking id="11" string="began to show signs of exasperation today during spirited questioning about the nominee 's views" type="VP">
          <tokens>
            <token id="26" string="began" />
            <token id="27" string="to" />
            <token id="28" string="show" />
            <token id="29" string="signs" />
            <token id="30" string="of" />
            <token id="31" string="exasperation" />
            <token id="32" string="today" />
            <token id="33" string="during" />
            <token id="34" string="spirited" />
            <token id="35" string="questioning" />
            <token id="36" string="about" />
            <token id="37" string="the" />
            <token id="38" string="nominee" />
            <token id="39" string="'s" />
            <token id="40" string="views" />
          </tokens>
        </chunking>
        <chunking id="12" string="tortuous logic" type="NP">
          <tokens>
            <token id="67" string="tortuous" />
            <token id="68" string="logic" />
          </tokens>
        </chunking>
        <chunking id="13" string="D-Del." type="NP">
          <tokens>
            <token id="24" string="D-Del." />
          </tokens>
        </chunking>
        <chunking id="14" string="Committee Chairman Joseph Biden , D-Del. ," type="NP">
          <tokens>
            <token id="19" string="Committee" />
            <token id="20" string="Chairman" />
            <token id="21" string="Joseph" />
            <token id="22" string="Biden" />
            <token id="23" string="," />
            <token id="24" string="D-Del." />
            <token id="25" string="," />
          </tokens>
        </chunking>
        <chunking id="15" string="signs of exasperation" type="NP">
          <tokens>
            <token id="29" string="signs" />
            <token id="30" string="of" />
            <token id="31" string="exasperation" />
          </tokens>
        </chunking>
        <chunking id="16" string="certain rights" type="NP">
          <tokens>
            <token id="50" string="certain" />
            <token id="51" string="rights" />
          </tokens>
        </chunking>
        <chunking id="17" string="Committee Chairman Joseph Biden" type="NP">
          <tokens>
            <token id="19" string="Committee" />
            <token id="20" string="Chairman" />
            <token id="21" string="Joseph" />
            <token id="22" string="Biden" />
          </tokens>
        </chunking>
        <chunking id="18" string="accused Thomas of using `` tortuous logic" type="VP">
          <tokens>
            <token id="62" string="accused" />
            <token id="63" string="Thomas" />
            <token id="64" string="of" />
            <token id="65" string="using" />
            <token id="66" string="&quot;" />
            <token id="67" string="tortuous" />
            <token id="68" string="logic" />
          </tokens>
        </chunking>
        <chunking id="19" string="a theory" type="NP">
          <tokens>
            <token id="47" string="a" />
            <token id="48" string="theory" />
          </tokens>
        </chunking>
        <chunking id="20" string="using `` tortuous logic" type="VP">
          <tokens>
            <token id="65" string="using" />
            <token id="66" string="&quot;" />
            <token id="67" string="tortuous" />
            <token id="68" string="logic" />
          </tokens>
        </chunking>
        <chunking id="21" string="natural law" type="NP">
          <tokens>
            <token id="43" string="natural" />
            <token id="44" string="law" />
          </tokens>
        </chunking>
        <chunking id="22" string="Thomas of using `` tortuous logic" type="NP">
          <tokens>
            <token id="63" string="Thomas" />
            <token id="64" string="of" />
            <token id="65" string="using" />
            <token id="66" string="&quot;" />
            <token id="67" string="tortuous" />
            <token id="68" string="logic" />
          </tokens>
        </chunking>
        <chunking id="23" string="he" type="NP">
          <tokens>
            <token id="12" string="he" />
          </tokens>
        </chunking>
        <chunking id="24" string="spirited questioning" type="NP">
          <tokens>
            <token id="34" string="spirited" />
            <token id="35" string="questioning" />
          </tokens>
        </chunking>
        <chunking id="25" string="written law" type="NP">
          <tokens>
            <token id="55" string="written" />
            <token id="56" string="law" />
          </tokens>
        </chunking>
        <chunking id="26" string="past writings and speeches Committee Chairman Joseph Biden , D-Del. , began to show signs of exasperation today during spirited questioning about the nominee 's views" type="NP">
          <tokens>
            <token id="15" string="past" />
            <token id="16" string="writings" />
            <token id="17" string="and" />
            <token id="18" string="speeches" />
            <token id="19" string="Committee" />
            <token id="20" string="Chairman" />
            <token id="21" string="Joseph" />
            <token id="22" string="Biden" />
            <token id="23" string="," />
            <token id="24" string="D-Del." />
            <token id="25" string="," />
            <token id="26" string="began" />
            <token id="27" string="to" />
            <token id="28" string="show" />
            <token id="29" string="signs" />
            <token id="30" string="of" />
            <token id="31" string="exasperation" />
            <token id="32" string="today" />
            <token id="33" string="during" />
            <token id="34" string="spirited" />
            <token id="35" string="questioning" />
            <token id="36" string="about" />
            <token id="37" string="the" />
            <token id="38" string="nominee" />
            <token id="39" string="'s" />
            <token id="40" string="views" />
          </tokens>
        </chunking>
        <chunking id="27" string="a theory that certain rights exist independent of written law At one point" type="NP">
          <tokens>
            <token id="47" string="a" />
            <token id="48" string="theory" />
            <token id="49" string="that" />
            <token id="50" string="certain" />
            <token id="51" string="rights" />
            <token id="52" string="exist" />
            <token id="53" string="independent" />
            <token id="54" string="of" />
            <token id="55" string="written" />
            <token id="56" string="law" />
            <token id="57" string="At" />
            <token id="58" string="one" />
            <token id="59" string="point" />
          </tokens>
        </chunking>
        <chunking id="28" string="exist independent of written law At one point" type="VP">
          <tokens>
            <token id="52" string="exist" />
            <token id="53" string="independent" />
            <token id="54" string="of" />
            <token id="55" string="written" />
            <token id="56" string="law" />
            <token id="57" string="At" />
            <token id="58" string="one" />
            <token id="59" string="point" />
          </tokens>
        </chunking>
        <chunking id="29" string="spirited questioning about the nominee 's views" type="NP">
          <tokens>
            <token id="34" string="spirited" />
            <token id="35" string="questioning" />
            <token id="36" string="about" />
            <token id="37" string="the" />
            <token id="38" string="nominee" />
            <token id="39" string="'s" />
            <token id="40" string="views" />
          </tokens>
        </chunking>
        <chunking id="30" string="that certain rights exist independent of written law At one point" type="SBAR">
          <tokens>
            <token id="49" string="that" />
            <token id="50" string="certain" />
            <token id="51" string="rights" />
            <token id="52" string="exist" />
            <token id="53" string="independent" />
            <token id="54" string="of" />
            <token id="55" string="written" />
            <token id="56" string="law" />
            <token id="57" string="At" />
            <token id="58" string="one" />
            <token id="59" string="point" />
          </tokens>
        </chunking>
        <chunking id="31" string="voiced skepticism about his backing away from stands he took in past writings and speeches Committee Chairman Joseph Biden , D-Del. , began to show signs of exasperation today during spirited questioning about the nominee 's views on `` natural law , '' a theory that certain rights exist independent of written law At one point" type="VP">
          <tokens>
            <token id="4" string="voiced" />
            <token id="5" string="skepticism" />
            <token id="6" string="about" />
            <token id="7" string="his" />
            <token id="8" string="backing" />
            <token id="9" string="away" />
            <token id="10" string="from" />
            <token id="11" string="stands" />
            <token id="12" string="he" />
            <token id="13" string="took" />
            <token id="14" string="in" />
            <token id="15" string="past" />
            <token id="16" string="writings" />
            <token id="17" string="and" />
            <token id="18" string="speeches" />
            <token id="19" string="Committee" />
            <token id="20" string="Chairman" />
            <token id="21" string="Joseph" />
            <token id="22" string="Biden" />
            <token id="23" string="," />
            <token id="24" string="D-Del." />
            <token id="25" string="," />
            <token id="26" string="began" />
            <token id="27" string="to" />
            <token id="28" string="show" />
            <token id="29" string="signs" />
            <token id="30" string="of" />
            <token id="31" string="exasperation" />
            <token id="32" string="today" />
            <token id="33" string="during" />
            <token id="34" string="spirited" />
            <token id="35" string="questioning" />
            <token id="36" string="about" />
            <token id="37" string="the" />
            <token id="38" string="nominee" />
            <token id="39" string="'s" />
            <token id="40" string="views" />
            <token id="41" string="on" />
            <token id="42" string="&quot;" />
            <token id="43" string="natural" />
            <token id="44" string="law" />
            <token id="45" string="," />
            <token id="46" string="&quot;" />
            <token id="47" string="a" />
            <token id="48" string="theory" />
            <token id="49" string="that" />
            <token id="50" string="certain" />
            <token id="51" string="rights" />
            <token id="52" string="exist" />
            <token id="53" string="independent" />
            <token id="54" string="of" />
            <token id="55" string="written" />
            <token id="56" string="law" />
            <token id="57" string="At" />
            <token id="58" string="one" />
            <token id="59" string="point" />
          </tokens>
        </chunking>
        <chunking id="32" string="the nominee 's views" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="nominee" />
            <token id="39" string="'s" />
            <token id="40" string="views" />
          </tokens>
        </chunking>
        <chunking id="33" string="took in past writings and speeches Committee Chairman Joseph Biden , D-Del. , began to show signs of exasperation today during spirited questioning about the nominee 's views on `` natural law , '' a theory that certain rights exist independent of written law At one point" type="VP">
          <tokens>
            <token id="13" string="took" />
            <token id="14" string="in" />
            <token id="15" string="past" />
            <token id="16" string="writings" />
            <token id="17" string="and" />
            <token id="18" string="speeches" />
            <token id="19" string="Committee" />
            <token id="20" string="Chairman" />
            <token id="21" string="Joseph" />
            <token id="22" string="Biden" />
            <token id="23" string="," />
            <token id="24" string="D-Del." />
            <token id="25" string="," />
            <token id="26" string="began" />
            <token id="27" string="to" />
            <token id="28" string="show" />
            <token id="29" string="signs" />
            <token id="30" string="of" />
            <token id="31" string="exasperation" />
            <token id="32" string="today" />
            <token id="33" string="during" />
            <token id="34" string="spirited" />
            <token id="35" string="questioning" />
            <token id="36" string="about" />
            <token id="37" string="the" />
            <token id="38" string="nominee" />
            <token id="39" string="'s" />
            <token id="40" string="views" />
            <token id="41" string="on" />
            <token id="42" string="&quot;" />
            <token id="43" string="natural" />
            <token id="44" string="law" />
            <token id="45" string="," />
            <token id="46" string="&quot;" />
            <token id="47" string="a" />
            <token id="48" string="theory" />
            <token id="49" string="that" />
            <token id="50" string="certain" />
            <token id="51" string="rights" />
            <token id="52" string="exist" />
            <token id="53" string="independent" />
            <token id="54" string="of" />
            <token id="55" string="written" />
            <token id="56" string="law" />
            <token id="57" string="At" />
            <token id="58" string="one" />
            <token id="59" string="point" />
          </tokens>
        </chunking>
        <chunking id="34" string="the nominee 's" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="nominee" />
            <token id="39" string="'s" />
          </tokens>
        </chunking>
        <chunking id="35" string="backing away from stands he took in past writings and speeches Committee Chairman Joseph Biden , D-Del. , began to show signs of exasperation today during spirited questioning about the nominee 's views on `` natural law , '' a theory that certain rights exist independent of written law At one point" type="VP">
          <tokens>
            <token id="8" string="backing" />
            <token id="9" string="away" />
            <token id="10" string="from" />
            <token id="11" string="stands" />
            <token id="12" string="he" />
            <token id="13" string="took" />
            <token id="14" string="in" />
            <token id="15" string="past" />
            <token id="16" string="writings" />
            <token id="17" string="and" />
            <token id="18" string="speeches" />
            <token id="19" string="Committee" />
            <token id="20" string="Chairman" />
            <token id="21" string="Joseph" />
            <token id="22" string="Biden" />
            <token id="23" string="," />
            <token id="24" string="D-Del." />
            <token id="25" string="," />
            <token id="26" string="began" />
            <token id="27" string="to" />
            <token id="28" string="show" />
            <token id="29" string="signs" />
            <token id="30" string="of" />
            <token id="31" string="exasperation" />
            <token id="32" string="today" />
            <token id="33" string="during" />
            <token id="34" string="spirited" />
            <token id="35" string="questioning" />
            <token id="36" string="about" />
            <token id="37" string="the" />
            <token id="38" string="nominee" />
            <token id="39" string="'s" />
            <token id="40" string="views" />
            <token id="41" string="on" />
            <token id="42" string="&quot;" />
            <token id="43" string="natural" />
            <token id="44" string="law" />
            <token id="45" string="," />
            <token id="46" string="&quot;" />
            <token id="47" string="a" />
            <token id="48" string="theory" />
            <token id="49" string="that" />
            <token id="50" string="certain" />
            <token id="51" string="rights" />
            <token id="52" string="exist" />
            <token id="53" string="independent" />
            <token id="54" string="of" />
            <token id="55" string="written" />
            <token id="56" string="law" />
            <token id="57" string="At" />
            <token id="58" string="one" />
            <token id="59" string="point" />
          </tokens>
        </chunking>
        <chunking id="36" string="Committee Chairman Joseph Biden , D-Del. , began to show signs of exasperation today during spirited questioning about the nominee 's views" type="SBAR">
          <tokens>
            <token id="19" string="Committee" />
            <token id="20" string="Chairman" />
            <token id="21" string="Joseph" />
            <token id="22" string="Biden" />
            <token id="23" string="," />
            <token id="24" string="D-Del." />
            <token id="25" string="," />
            <token id="26" string="began" />
            <token id="27" string="to" />
            <token id="28" string="show" />
            <token id="29" string="signs" />
            <token id="30" string="of" />
            <token id="31" string="exasperation" />
            <token id="32" string="today" />
            <token id="33" string="during" />
            <token id="34" string="spirited" />
            <token id="35" string="questioning" />
            <token id="36" string="about" />
            <token id="37" string="the" />
            <token id="38" string="nominee" />
            <token id="39" string="'s" />
            <token id="40" string="views" />
          </tokens>
        </chunking>
        <chunking id="37" string="past writings and speeches" type="NP">
          <tokens>
            <token id="15" string="past" />
            <token id="16" string="writings" />
            <token id="17" string="and" />
            <token id="18" string="speeches" />
          </tokens>
        </chunking>
        <chunking id="38" string="`` natural law , '' a theory that certain rights exist independent of written law At one point" type="NP">
          <tokens>
            <token id="42" string="&quot;" />
            <token id="43" string="natural" />
            <token id="44" string="law" />
            <token id="45" string="," />
            <token id="46" string="&quot;" />
            <token id="47" string="a" />
            <token id="48" string="theory" />
            <token id="49" string="that" />
            <token id="50" string="certain" />
            <token id="51" string="rights" />
            <token id="52" string="exist" />
            <token id="53" string="independent" />
            <token id="54" string="of" />
            <token id="55" string="written" />
            <token id="56" string="law" />
            <token id="57" string="At" />
            <token id="58" string="one" />
            <token id="59" string="point" />
          </tokens>
        </chunking>
        <chunking id="39" string="his" type="NP">
          <tokens>
            <token id="7" string="his" />
          </tokens>
        </chunking>
        <chunking id="40" string="signs" type="NP">
          <tokens>
            <token id="29" string="signs" />
          </tokens>
        </chunking>
        <chunking id="41" string="stands" type="NP">
          <tokens>
            <token id="11" string="stands" />
          </tokens>
        </chunking>
        <chunking id="42" string="exasperation" type="NP">
          <tokens>
            <token id="31" string="exasperation" />
          </tokens>
        </chunking>
        <chunking id="43" string="Biden" type="NP">
          <tokens>
            <token id="61" string="Biden" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">voiced</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">voiced</governor>
          <dependent id="2">also</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">voiced</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="62">accused</governor>
          <dependent id="4">voiced</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">voiced</governor>
          <dependent id="5">skepticism</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">backing</governor>
          <dependent id="6">about</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">backing</governor>
          <dependent id="7">his</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">voiced</governor>
          <dependent id="8">backing</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">backing</governor>
          <dependent id="9">away</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">stands</governor>
          <dependent id="10">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">backing</governor>
          <dependent id="11">stands</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">took</governor>
          <dependent id="12">he</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">stands</governor>
          <dependent id="13">took</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="13">took</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">writings</governor>
          <dependent id="15">past</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">took</governor>
          <dependent id="16">writings</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">writings</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">writings</governor>
          <dependent id="18">speeches</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Biden</governor>
          <dependent id="19">Committee</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Biden</governor>
          <dependent id="20">Chairman</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Biden</governor>
          <dependent id="21">Joseph</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">began</governor>
          <dependent id="22">Biden</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="22">Biden</governor>
          <dependent id="24">D-Del.</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="16">writings</governor>
          <dependent id="26">began</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">show</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="26">began</governor>
          <dependent id="28">show</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">show</governor>
          <dependent id="29">signs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">exasperation</governor>
          <dependent id="30">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">signs</governor>
          <dependent id="31">exasperation</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="26">began</governor>
          <dependent id="32">today</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">spirited</governor>
          <dependent id="33">during</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">began</governor>
          <dependent id="34">spirited</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">spirited</governor>
          <dependent id="35">questioning</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">views</governor>
          <dependent id="36">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">nominee</governor>
          <dependent id="37">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="40">views</governor>
          <dependent id="38">nominee</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">nominee</governor>
          <dependent id="39">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">spirited</governor>
          <dependent id="40">views</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">law</governor>
          <dependent id="41">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="44">law</governor>
          <dependent id="43">natural</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">took</governor>
          <dependent id="44">law</dependent>
        </dependency>
        <dependency type="det">
          <governor id="48">theory</governor>
          <dependent id="47">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="44">law</governor>
          <dependent id="48">theory</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="53">independent</governor>
          <dependent id="49">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="51">rights</governor>
          <dependent id="50">certain</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="52">exist</governor>
          <dependent id="51">rights</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="48">theory</governor>
          <dependent id="52">exist</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="52">exist</governor>
          <dependent id="53">independent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="56">law</governor>
          <dependent id="54">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="56">law</governor>
          <dependent id="55">written</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="53">independent</governor>
          <dependent id="56">law</dependent>
        </dependency>
        <dependency type="case">
          <governor id="59">point</governor>
          <dependent id="57">At</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="59">point</governor>
          <dependent id="58">one</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="53">independent</governor>
          <dependent id="59">point</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="62">accused</governor>
          <dependent id="61">Biden</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="62">accused</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="62">accused</governor>
          <dependent id="63">Thomas</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="65">using</governor>
          <dependent id="64">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="63">Thomas</governor>
          <dependent id="65">using</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="68">logic</governor>
          <dependent id="67">tortuous</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="65">using</governor>
          <dependent id="68">logic</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="58" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="past" type="DATE" score="0.0">
          <tokens>
            <token id="15" string="past" />
          </tokens>
        </entity>
        <entity id="3" string="today" type="DATE" score="0.0">
          <tokens>
            <token id="32" string="today" />
          </tokens>
        </entity>
        <entity id="4" string="Biden" type="PERSON" score="0.0">
          <tokens>
            <token id="61" string="Biden" />
          </tokens>
        </entity>
        <entity id="5" string="independent" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="53" string="independent" />
          </tokens>
        </entity>
        <entity id="6" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="63" string="Thomas" />
          </tokens>
        </entity>
        <entity id="7" string="Committee" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="19" string="Committee" />
          </tokens>
        </entity>
        <entity id="8" string="Joseph Biden" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Joseph" />
            <token id="22" string="Biden" />
          </tokens>
        </entity>
        <entity id="9" string="D-Del." type="LOCATION" score="0.0">
          <tokens>
            <token id="24" string="D-Del." />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>Later, he referred to one of Thomas&amp;apost; replies as &amp;quot;the most unartful dodge I&amp;apost;ve heard.&amp;quot;</content>
      <tokens>
        <token id="1" string="Later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="referred" lemma="refer" stem="refer" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="9" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="replies" lemma="reply" stem="repli" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="unartful" lemma="unartful" stem="unart" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="dodge" lemma="dodge" stem="dodg" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="'ve" lemma="have" stem="'ve" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="heard" lemma="hear" stem="heard" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Later)) (, ,) (NP (PRP he)) (VP (VBD referred) (PP (TO to) (NP (NP (CD one)) (PP (IN of) (NP (NP (NNP Thomas) (POS ')) (NNS replies))))) (SBAR (IN as) (`` ``) (S (NP (DT the) (RBS most) (JJ unartful)) (VP (VBP dodge) (SBAR (S (NP (PRP I)) (VP (VBP 've) (VP (VBN heard))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the most unartful" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="most" />
            <token id="15" string="unartful" />
          </tokens>
        </chunking>
        <chunking id="2" string="as `` the most unartful dodge I 've heard" type="SBAR">
          <tokens>
            <token id="11" string="as" />
            <token id="12" string="&quot;" />
            <token id="13" string="the" />
            <token id="14" string="most" />
            <token id="15" string="unartful" />
            <token id="16" string="dodge" />
            <token id="17" string="I" />
            <token id="18" string="'ve" />
            <token id="19" string="heard" />
          </tokens>
        </chunking>
        <chunking id="3" string="I 've heard" type="SBAR">
          <tokens>
            <token id="17" string="I" />
            <token id="18" string="'ve" />
            <token id="19" string="heard" />
          </tokens>
        </chunking>
        <chunking id="4" string="one of Thomas ' replies" type="NP">
          <tokens>
            <token id="6" string="one" />
            <token id="7" string="of" />
            <token id="8" string="Thomas" />
            <token id="9" string="'" />
            <token id="10" string="replies" />
          </tokens>
        </chunking>
        <chunking id="5" string="one" type="NP">
          <tokens>
            <token id="6" string="one" />
          </tokens>
        </chunking>
        <chunking id="6" string="Thomas '" type="NP">
          <tokens>
            <token id="8" string="Thomas" />
            <token id="9" string="'" />
          </tokens>
        </chunking>
        <chunking id="7" string="I" type="NP">
          <tokens>
            <token id="17" string="I" />
          </tokens>
        </chunking>
        <chunking id="8" string="dodge I 've heard" type="VP">
          <tokens>
            <token id="16" string="dodge" />
            <token id="17" string="I" />
            <token id="18" string="'ve" />
            <token id="19" string="heard" />
          </tokens>
        </chunking>
        <chunking id="9" string="Thomas ' replies" type="NP">
          <tokens>
            <token id="8" string="Thomas" />
            <token id="9" string="'" />
            <token id="10" string="replies" />
          </tokens>
        </chunking>
        <chunking id="10" string="referred to one of Thomas ' replies as `` the most unartful dodge I 've heard" type="VP">
          <tokens>
            <token id="4" string="referred" />
            <token id="5" string="to" />
            <token id="6" string="one" />
            <token id="7" string="of" />
            <token id="8" string="Thomas" />
            <token id="9" string="'" />
            <token id="10" string="replies" />
            <token id="11" string="as" />
            <token id="12" string="&quot;" />
            <token id="13" string="the" />
            <token id="14" string="most" />
            <token id="15" string="unartful" />
            <token id="16" string="dodge" />
            <token id="17" string="I" />
            <token id="18" string="'ve" />
            <token id="19" string="heard" />
          </tokens>
        </chunking>
        <chunking id="11" string="'ve heard" type="VP">
          <tokens>
            <token id="18" string="'ve" />
            <token id="19" string="heard" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="heard" type="VP">
          <tokens>
            <token id="19" string="heard" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">referred</governor>
          <dependent id="1">Later</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">referred</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">referred</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">one</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">referred</governor>
          <dependent id="6">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">replies</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">replies</governor>
          <dependent id="8">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Thomas</governor>
          <dependent id="9">'</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">one</governor>
          <dependent id="10">replies</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">dodge</governor>
          <dependent id="11">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">unartful</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">unartful</governor>
          <dependent id="14">most</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">dodge</governor>
          <dependent id="15">unartful</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">referred</governor>
          <dependent id="16">dodge</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">heard</governor>
          <dependent id="17">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">heard</governor>
          <dependent id="18">'ve</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">dodge</governor>
          <dependent id="19">heard</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>After still another Thomas answer, Biden said, &amp;quot;That&amp;apost;s not the question I asked you, judge.&amp;quot;</content>
      <tokens>
        <token id="1" string="After" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="5" string="answer" lemma="answer" stem="answer" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Biden" lemma="Biden" stem="biden" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="question" lemma="question" stem="question" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="asked" lemma="ask" stem="ask" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="judge" lemma="judge" stem="judg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN After) (NP (RB still) (DT another) (NNP Thomas) (NN answer))) (PRN (, ,) (NP (NNP Biden)) (VP (VBD said)) (, ,)) (`` ``) (NP (DT That)) (VP (VBZ 's) (RB not) (NP (NP (DT the) (NN question)) (SBAR (S (NP (PRP I)) (VP (VBD asked) (NP (NP (PRP you)) (, ,) (NP (NN judge)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="That" type="NP">
          <tokens>
            <token id="11" string="That" />
          </tokens>
        </chunking>
        <chunking id="2" string="the question" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="question" />
          </tokens>
        </chunking>
        <chunking id="3" string="I asked you , judge" type="SBAR">
          <tokens>
            <token id="16" string="I" />
            <token id="17" string="asked" />
            <token id="18" string="you" />
            <token id="19" string="," />
            <token id="20" string="judge" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="16" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="asked you , judge" type="VP">
          <tokens>
            <token id="17" string="asked" />
            <token id="18" string="you" />
            <token id="19" string="," />
            <token id="20" string="judge" />
          </tokens>
        </chunking>
        <chunking id="6" string="still another Thomas answer" type="NP">
          <tokens>
            <token id="2" string="still" />
            <token id="3" string="another" />
            <token id="4" string="Thomas" />
            <token id="5" string="answer" />
          </tokens>
        </chunking>
        <chunking id="7" string="'s not the question I asked you , judge" type="VP">
          <tokens>
            <token id="12" string="'s" />
            <token id="13" string="not" />
            <token id="14" string="the" />
            <token id="15" string="question" />
            <token id="16" string="I" />
            <token id="17" string="asked" />
            <token id="18" string="you" />
            <token id="19" string="," />
            <token id="20" string="judge" />
          </tokens>
        </chunking>
        <chunking id="8" string="Biden" type="NP">
          <tokens>
            <token id="7" string="Biden" />
          </tokens>
        </chunking>
        <chunking id="9" string="you , judge" type="NP">
          <tokens>
            <token id="18" string="you" />
            <token id="19" string="," />
            <token id="20" string="judge" />
          </tokens>
        </chunking>
        <chunking id="10" string="the question I asked you , judge" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="question" />
            <token id="16" string="I" />
            <token id="17" string="asked" />
            <token id="18" string="you" />
            <token id="19" string="," />
            <token id="20" string="judge" />
          </tokens>
        </chunking>
        <chunking id="11" string="judge" type="NP">
          <tokens>
            <token id="20" string="judge" />
          </tokens>
        </chunking>
        <chunking id="12" string="said" type="VP">
          <tokens>
            <token id="8" string="said" />
          </tokens>
        </chunking>
        <chunking id="13" string="you" type="NP">
          <tokens>
            <token id="18" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">answer</governor>
          <dependent id="1">After</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">answer</governor>
          <dependent id="2">still</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">answer</governor>
          <dependent id="3">another</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">answer</governor>
          <dependent id="4">Thomas</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">question</governor>
          <dependent id="5">answer</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">said</governor>
          <dependent id="7">Biden</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="15">question</governor>
          <dependent id="8">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">question</governor>
          <dependent id="11">That</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">question</governor>
          <dependent id="12">'s</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="15">question</governor>
          <dependent id="13">not</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">question</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">question</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">asked</governor>
          <dependent id="16">I</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">question</governor>
          <dependent id="17">asked</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">asked</governor>
          <dependent id="18">you</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="18">you</governor>
          <dependent id="20">judge</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Biden" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Biden" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>; Republicans tried to deflect criticism over Thomas&amp;apost; refusal to answer questions from the Democrats &amp;quot;It is, in my view, inappropriate to keep this up,&amp;quot; said Sen. Orrin Hatch, R-Utah.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Republicans" lemma="Republicans" stem="republican" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="3" string="tried" lemma="try" stem="tri" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="deflect" lemma="deflect" stem="deflect" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="criticism" lemma="criticism" stem="critic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="refusal" lemma="refusal" stem="refus" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="answer" lemma="answer" stem="answer" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="questions" lemma="question" stem="question" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="Democrats" lemma="Democrats" stem="democrat" pos="NNPS" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="17" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="view" lemma="view" stem="view" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="inappropriate" lemma="inappropriate" stem="inappropri" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="keep" lemma="keep" stem="keep" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="Sen." lemma="Sen." stem="sen." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="Orrin" lemma="Orrin" stem="orrin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="35" string="Hatch" lemma="Hatch" stem="hatch" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="36" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="37" string="R-Utah" lemma="R-Utah" stem="r-utah" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (NP (NNPS Republicans)) (VP (VBD tried) (S (VP (TO to) (VP (VB deflect) (NP (NN criticism)) (PP (IN over) (NP (NP (NNP Thomas) (POS ')) (NN refusal) (S (VP (TO to) (VP (VB answer) (NP (NNS questions)) (PP (IN from) (NP (DT the) (NNPS Democrats))) (SBAR (SINV (`` ``) (S (NP (PRP It)) (VP (VBZ is) (, ,) (PP (IN in) (NP (PRP$ my) (NN view))) (, ,) (ADJP (JJ inappropriate) (S (VP (TO to) (VP (VB keep) (NP (DT this)) (PRT (RP up)))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Sen.) (NNP Orrin) (NNP Hatch)) (, ,) (NP (NNP R-Utah)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is , in my view , inappropriate to keep this up" type="VP">
          <tokens>
            <token id="19" string="is" />
            <token id="20" string="," />
            <token id="21" string="in" />
            <token id="22" string="my" />
            <token id="23" string="view" />
            <token id="24" string="," />
            <token id="25" string="inappropriate" />
            <token id="26" string="to" />
            <token id="27" string="keep" />
            <token id="28" string="this" />
            <token id="29" string="up" />
          </tokens>
        </chunking>
        <chunking id="2" string="Sen. Orrin Hatch , R-Utah" type="NP">
          <tokens>
            <token id="33" string="Sen." />
            <token id="34" string="Orrin" />
            <token id="35" string="Hatch" />
            <token id="36" string="," />
            <token id="37" string="R-Utah" />
          </tokens>
        </chunking>
        <chunking id="3" string="my view" type="NP">
          <tokens>
            <token id="22" string="my" />
            <token id="23" string="view" />
          </tokens>
        </chunking>
        <chunking id="4" string="inappropriate to keep this up" type="ADJP">
          <tokens>
            <token id="25" string="inappropriate" />
            <token id="26" string="to" />
            <token id="27" string="keep" />
            <token id="28" string="this" />
            <token id="29" string="up" />
          </tokens>
        </chunking>
        <chunking id="5" string="Thomas '" type="NP">
          <tokens>
            <token id="8" string="Thomas" />
            <token id="9" string="'" />
          </tokens>
        </chunking>
        <chunking id="6" string="to answer questions from the Democrats `` It is , in my view , inappropriate to keep this up , '' said Sen. Orrin Hatch , R-Utah" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="answer" />
            <token id="13" string="questions" />
            <token id="14" string="from" />
            <token id="15" string="the" />
            <token id="16" string="Democrats" />
            <token id="17" string="&quot;" />
            <token id="18" string="It" />
            <token id="19" string="is" />
            <token id="20" string="," />
            <token id="21" string="in" />
            <token id="22" string="my" />
            <token id="23" string="view" />
            <token id="24" string="," />
            <token id="25" string="inappropriate" />
            <token id="26" string="to" />
            <token id="27" string="keep" />
            <token id="28" string="this" />
            <token id="29" string="up" />
            <token id="30" string="," />
            <token id="31" string="&quot;" />
            <token id="32" string="said" />
            <token id="33" string="Sen." />
            <token id="34" string="Orrin" />
            <token id="35" string="Hatch" />
            <token id="36" string="," />
            <token id="37" string="R-Utah" />
          </tokens>
        </chunking>
        <chunking id="7" string="questions" type="NP">
          <tokens>
            <token id="13" string="questions" />
          </tokens>
        </chunking>
        <chunking id="8" string="to deflect criticism over Thomas ' refusal to answer questions from the Democrats `` It is , in my view , inappropriate to keep this up , '' said Sen. Orrin Hatch , R-Utah" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="deflect" />
            <token id="6" string="criticism" />
            <token id="7" string="over" />
            <token id="8" string="Thomas" />
            <token id="9" string="'" />
            <token id="10" string="refusal" />
            <token id="11" string="to" />
            <token id="12" string="answer" />
            <token id="13" string="questions" />
            <token id="14" string="from" />
            <token id="15" string="the" />
            <token id="16" string="Democrats" />
            <token id="17" string="&quot;" />
            <token id="18" string="It" />
            <token id="19" string="is" />
            <token id="20" string="," />
            <token id="21" string="in" />
            <token id="22" string="my" />
            <token id="23" string="view" />
            <token id="24" string="," />
            <token id="25" string="inappropriate" />
            <token id="26" string="to" />
            <token id="27" string="keep" />
            <token id="28" string="this" />
            <token id="29" string="up" />
            <token id="30" string="," />
            <token id="31" string="&quot;" />
            <token id="32" string="said" />
            <token id="33" string="Sen." />
            <token id="34" string="Orrin" />
            <token id="35" string="Hatch" />
            <token id="36" string="," />
            <token id="37" string="R-Utah" />
          </tokens>
        </chunking>
        <chunking id="9" string="It" type="NP">
          <tokens>
            <token id="18" string="It" />
          </tokens>
        </chunking>
        <chunking id="10" string="this" type="NP">
          <tokens>
            <token id="28" string="this" />
          </tokens>
        </chunking>
        <chunking id="11" string="answer questions from the Democrats `` It is , in my view , inappropriate to keep this up , '' said Sen. Orrin Hatch , R-Utah" type="VP">
          <tokens>
            <token id="12" string="answer" />
            <token id="13" string="questions" />
            <token id="14" string="from" />
            <token id="15" string="the" />
            <token id="16" string="Democrats" />
            <token id="17" string="&quot;" />
            <token id="18" string="It" />
            <token id="19" string="is" />
            <token id="20" string="," />
            <token id="21" string="in" />
            <token id="22" string="my" />
            <token id="23" string="view" />
            <token id="24" string="," />
            <token id="25" string="inappropriate" />
            <token id="26" string="to" />
            <token id="27" string="keep" />
            <token id="28" string="this" />
            <token id="29" string="up" />
            <token id="30" string="," />
            <token id="31" string="&quot;" />
            <token id="32" string="said" />
            <token id="33" string="Sen." />
            <token id="34" string="Orrin" />
            <token id="35" string="Hatch" />
            <token id="36" string="," />
            <token id="37" string="R-Utah" />
          </tokens>
        </chunking>
        <chunking id="12" string="the Democrats" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="13" string="to keep this up" type="VP">
          <tokens>
            <token id="26" string="to" />
            <token id="27" string="keep" />
            <token id="28" string="this" />
            <token id="29" string="up" />
          </tokens>
        </chunking>
        <chunking id="14" string="R-Utah" type="NP">
          <tokens>
            <token id="37" string="R-Utah" />
          </tokens>
        </chunking>
        <chunking id="15" string="Republicans" type="NP">
          <tokens>
            <token id="2" string="Republicans" />
          </tokens>
        </chunking>
        <chunking id="16" string="`` It is , in my view , inappropriate to keep this up , '' said Sen. Orrin Hatch , R-Utah" type="SBAR">
          <tokens>
            <token id="17" string="&quot;" />
            <token id="18" string="It" />
            <token id="19" string="is" />
            <token id="20" string="," />
            <token id="21" string="in" />
            <token id="22" string="my" />
            <token id="23" string="view" />
            <token id="24" string="," />
            <token id="25" string="inappropriate" />
            <token id="26" string="to" />
            <token id="27" string="keep" />
            <token id="28" string="this" />
            <token id="29" string="up" />
            <token id="30" string="," />
            <token id="31" string="&quot;" />
            <token id="32" string="said" />
            <token id="33" string="Sen." />
            <token id="34" string="Orrin" />
            <token id="35" string="Hatch" />
            <token id="36" string="," />
            <token id="37" string="R-Utah" />
          </tokens>
        </chunking>
        <chunking id="17" string="keep this up" type="VP">
          <tokens>
            <token id="27" string="keep" />
            <token id="28" string="this" />
            <token id="29" string="up" />
          </tokens>
        </chunking>
        <chunking id="18" string="deflect criticism over Thomas ' refusal to answer questions from the Democrats `` It is , in my view , inappropriate to keep this up , '' said Sen. Orrin Hatch , R-Utah" type="VP">
          <tokens>
            <token id="5" string="deflect" />
            <token id="6" string="criticism" />
            <token id="7" string="over" />
            <token id="8" string="Thomas" />
            <token id="9" string="'" />
            <token id="10" string="refusal" />
            <token id="11" string="to" />
            <token id="12" string="answer" />
            <token id="13" string="questions" />
            <token id="14" string="from" />
            <token id="15" string="the" />
            <token id="16" string="Democrats" />
            <token id="17" string="&quot;" />
            <token id="18" string="It" />
            <token id="19" string="is" />
            <token id="20" string="," />
            <token id="21" string="in" />
            <token id="22" string="my" />
            <token id="23" string="view" />
            <token id="24" string="," />
            <token id="25" string="inappropriate" />
            <token id="26" string="to" />
            <token id="27" string="keep" />
            <token id="28" string="this" />
            <token id="29" string="up" />
            <token id="30" string="," />
            <token id="31" string="&quot;" />
            <token id="32" string="said" />
            <token id="33" string="Sen." />
            <token id="34" string="Orrin" />
            <token id="35" string="Hatch" />
            <token id="36" string="," />
            <token id="37" string="R-Utah" />
          </tokens>
        </chunking>
        <chunking id="19" string="Sen. Orrin Hatch" type="NP">
          <tokens>
            <token id="33" string="Sen." />
            <token id="34" string="Orrin" />
            <token id="35" string="Hatch" />
          </tokens>
        </chunking>
        <chunking id="20" string="tried to deflect criticism over Thomas ' refusal to answer questions from the Democrats `` It is , in my view , inappropriate to keep this up , '' said Sen. Orrin Hatch , R-Utah" type="VP">
          <tokens>
            <token id="3" string="tried" />
            <token id="4" string="to" />
            <token id="5" string="deflect" />
            <token id="6" string="criticism" />
            <token id="7" string="over" />
            <token id="8" string="Thomas" />
            <token id="9" string="'" />
            <token id="10" string="refusal" />
            <token id="11" string="to" />
            <token id="12" string="answer" />
            <token id="13" string="questions" />
            <token id="14" string="from" />
            <token id="15" string="the" />
            <token id="16" string="Democrats" />
            <token id="17" string="&quot;" />
            <token id="18" string="It" />
            <token id="19" string="is" />
            <token id="20" string="," />
            <token id="21" string="in" />
            <token id="22" string="my" />
            <token id="23" string="view" />
            <token id="24" string="," />
            <token id="25" string="inappropriate" />
            <token id="26" string="to" />
            <token id="27" string="keep" />
            <token id="28" string="this" />
            <token id="29" string="up" />
            <token id="30" string="," />
            <token id="31" string="&quot;" />
            <token id="32" string="said" />
            <token id="33" string="Sen." />
            <token id="34" string="Orrin" />
            <token id="35" string="Hatch" />
            <token id="36" string="," />
            <token id="37" string="R-Utah" />
          </tokens>
        </chunking>
        <chunking id="21" string="Thomas ' refusal to answer questions from the Democrats `` It is , in my view , inappropriate to keep this up , '' said Sen. Orrin Hatch , R-Utah" type="NP">
          <tokens>
            <token id="8" string="Thomas" />
            <token id="9" string="'" />
            <token id="10" string="refusal" />
            <token id="11" string="to" />
            <token id="12" string="answer" />
            <token id="13" string="questions" />
            <token id="14" string="from" />
            <token id="15" string="the" />
            <token id="16" string="Democrats" />
            <token id="17" string="&quot;" />
            <token id="18" string="It" />
            <token id="19" string="is" />
            <token id="20" string="," />
            <token id="21" string="in" />
            <token id="22" string="my" />
            <token id="23" string="view" />
            <token id="24" string="," />
            <token id="25" string="inappropriate" />
            <token id="26" string="to" />
            <token id="27" string="keep" />
            <token id="28" string="this" />
            <token id="29" string="up" />
            <token id="30" string="," />
            <token id="31" string="&quot;" />
            <token id="32" string="said" />
            <token id="33" string="Sen." />
            <token id="34" string="Orrin" />
            <token id="35" string="Hatch" />
            <token id="36" string="," />
            <token id="37" string="R-Utah" />
          </tokens>
        </chunking>
        <chunking id="22" string="criticism" type="NP">
          <tokens>
            <token id="6" string="criticism" />
          </tokens>
        </chunking>
        <chunking id="23" string="said" type="VP">
          <tokens>
            <token id="32" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">tried</governor>
          <dependent id="2">Republicans</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">tried</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">deflect</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">tried</governor>
          <dependent id="5">deflect</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">deflect</governor>
          <dependent id="6">criticism</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">refusal</governor>
          <dependent id="7">over</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">refusal</governor>
          <dependent id="8">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Thomas</governor>
          <dependent id="9">'</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">deflect</governor>
          <dependent id="10">refusal</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">answer</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="10">refusal</governor>
          <dependent id="12">answer</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">answer</governor>
          <dependent id="13">questions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Democrats</governor>
          <dependent id="14">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">Democrats</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">answer</governor>
          <dependent id="16">Democrats</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">inappropriate</governor>
          <dependent id="18">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="25">inappropriate</governor>
          <dependent id="19">is</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">view</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">view</governor>
          <dependent id="22">my</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">inappropriate</governor>
          <dependent id="23">view</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="32">said</governor>
          <dependent id="25">inappropriate</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">keep</governor>
          <dependent id="26">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="25">inappropriate</governor>
          <dependent id="27">keep</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">keep</governor>
          <dependent id="28">this</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="27">keep</governor>
          <dependent id="29">up</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">answer</governor>
          <dependent id="32">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Hatch</governor>
          <dependent id="33">Sen.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Hatch</governor>
          <dependent id="34">Orrin</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">said</governor>
          <dependent id="35">Hatch</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="35">Hatch</governor>
          <dependent id="37">R-Utah</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Republicans" type="MISC" score="0.0">
          <tokens>
            <token id="2" string="Republicans" />
          </tokens>
        </entity>
        <entity id="2" string="Democrats" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="16" string="Democrats" />
          </tokens>
        </entity>
        <entity id="3" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Thomas" />
          </tokens>
        </entity>
        <entity id="4" string="Orrin Hatch" type="PERSON" score="0.0">
          <tokens>
            <token id="34" string="Orrin" />
            <token id="35" string="Hatch" />
          </tokens>
        </entity>
        <entity id="5" string="R-Utah" type="LOCATION" score="0.0">
          <tokens>
            <token id="37" string="R-Utah" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>He said Thomas had been asked more than 70 questions about his abortion views even though Justice David H. Souter was asked only 36 such questions during his confirmation hearings last year &amp;quot;What are we going to have?</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="asked" lemma="ask" stem="ask" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="70" lemma="70" stem="70" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="10" string="questions" lemma="question" stem="question" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="abortion" lemma="abortion" stem="abort" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="views" lemma="view" stem="view" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="though" lemma="though" stem="though" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="Justice" lemma="Justice" stem="justic" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="David" lemma="David" stem="david" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="19" string="H." lemma="H." stem="h." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="20" string="Souter" lemma="Souter" stem="souter" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="21" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="asked" lemma="ask" stem="ask" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="36" lemma="36" stem="36" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="25" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="questions" lemma="question" stem="question" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="confirmation" lemma="confirmation" stem="confirm" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="hearings" lemma="hearing" stem="hear" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="32" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="33" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="What" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="37" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD said) (SBAR (S (NP (NNP Thomas)) (VP (VBD had) (VP (VBN been) (VP (VBN asked) (NP (NP (QP (RBR more) (IN than) (CD 70)) (NNS questions)) (PP (IN about) (NP (PRP$ his) (NN abortion) (NNS views)))) (SBAR (RB even) (IN though) (S (NP (NNP Justice) (NNP David) (NNP H.) (NNP Souter)) (VP (VBD was) (S (S (VP (VBN asked) (NP (QP (RB only) (CD 36)) (JJ such) (NNS questions)) (PP (IN during) (NP (PRP$ his) (NN confirmation) (NNS hearings))) (NP-TMP (JJ last) (NN year)))) (SBARQ (`` ``) (WHNP (WP What)) (SQ (VBP are) (NP (PRP we)) (VP (VBG going) (S (VP (TO to) (VP (VB have)))))) (. ?))))))))))))))</syntactictree>
      <chunkings>
        <chunking id="1" string="only 36 such questions" type="NP">
          <tokens>
            <token id="23" string="only" />
            <token id="24" string="36" />
            <token id="25" string="such" />
            <token id="26" string="questions" />
          </tokens>
        </chunking>
        <chunking id="2" string="asked more than 70 questions about his abortion views even though Justice David H. Souter was asked only 36 such questions during his confirmation hearings last year `` What are we going to have ?" type="VP">
          <tokens>
            <token id="6" string="asked" />
            <token id="7" string="more" />
            <token id="8" string="than" />
            <token id="9" string="70" />
            <token id="10" string="questions" />
            <token id="11" string="about" />
            <token id="12" string="his" />
            <token id="13" string="abortion" />
            <token id="14" string="views" />
            <token id="15" string="even" />
            <token id="16" string="though" />
            <token id="17" string="Justice" />
            <token id="18" string="David" />
            <token id="19" string="H." />
            <token id="20" string="Souter" />
            <token id="21" string="was" />
            <token id="22" string="asked" />
            <token id="23" string="only" />
            <token id="24" string="36" />
            <token id="25" string="such" />
            <token id="26" string="questions" />
            <token id="27" string="during" />
            <token id="28" string="his" />
            <token id="29" string="confirmation" />
            <token id="30" string="hearings" />
            <token id="31" string="last" />
            <token id="32" string="year" />
            <token id="33" string="&quot;" />
            <token id="34" string="What" />
            <token id="35" string="are" />
            <token id="36" string="we" />
            <token id="37" string="going" />
            <token id="38" string="to" />
            <token id="39" string="have" />
            <token id="40" string="?" />
          </tokens>
        </chunking>
        <chunking id="3" string="Justice David H. Souter" type="NP">
          <tokens>
            <token id="17" string="Justice" />
            <token id="18" string="David" />
            <token id="19" string="H." />
            <token id="20" string="Souter" />
          </tokens>
        </chunking>
        <chunking id="4" string="Thomas had been asked more than 70 questions about his abortion views even though Justice David H. Souter was asked only 36 such questions during his confirmation hearings last year `` What are we going to have ?" type="SBAR">
          <tokens>
            <token id="3" string="Thomas" />
            <token id="4" string="had" />
            <token id="5" string="been" />
            <token id="6" string="asked" />
            <token id="7" string="more" />
            <token id="8" string="than" />
            <token id="9" string="70" />
            <token id="10" string="questions" />
            <token id="11" string="about" />
            <token id="12" string="his" />
            <token id="13" string="abortion" />
            <token id="14" string="views" />
            <token id="15" string="even" />
            <token id="16" string="though" />
            <token id="17" string="Justice" />
            <token id="18" string="David" />
            <token id="19" string="H." />
            <token id="20" string="Souter" />
            <token id="21" string="was" />
            <token id="22" string="asked" />
            <token id="23" string="only" />
            <token id="24" string="36" />
            <token id="25" string="such" />
            <token id="26" string="questions" />
            <token id="27" string="during" />
            <token id="28" string="his" />
            <token id="29" string="confirmation" />
            <token id="30" string="hearings" />
            <token id="31" string="last" />
            <token id="32" string="year" />
            <token id="33" string="&quot;" />
            <token id="34" string="What" />
            <token id="35" string="are" />
            <token id="36" string="we" />
            <token id="37" string="going" />
            <token id="38" string="to" />
            <token id="39" string="have" />
            <token id="40" string="?" />
          </tokens>
        </chunking>
        <chunking id="5" string="Thomas" type="NP">
          <tokens>
            <token id="3" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="6" string="said Thomas had been asked more than 70 questions about his abortion views even though Justice David H. Souter was asked only 36 such questions during his confirmation hearings last year `` What are we going to have ?" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="Thomas" />
            <token id="4" string="had" />
            <token id="5" string="been" />
            <token id="6" string="asked" />
            <token id="7" string="more" />
            <token id="8" string="than" />
            <token id="9" string="70" />
            <token id="10" string="questions" />
            <token id="11" string="about" />
            <token id="12" string="his" />
            <token id="13" string="abortion" />
            <token id="14" string="views" />
            <token id="15" string="even" />
            <token id="16" string="though" />
            <token id="17" string="Justice" />
            <token id="18" string="David" />
            <token id="19" string="H." />
            <token id="20" string="Souter" />
            <token id="21" string="was" />
            <token id="22" string="asked" />
            <token id="23" string="only" />
            <token id="24" string="36" />
            <token id="25" string="such" />
            <token id="26" string="questions" />
            <token id="27" string="during" />
            <token id="28" string="his" />
            <token id="29" string="confirmation" />
            <token id="30" string="hearings" />
            <token id="31" string="last" />
            <token id="32" string="year" />
            <token id="33" string="&quot;" />
            <token id="34" string="What" />
            <token id="35" string="are" />
            <token id="36" string="we" />
            <token id="37" string="going" />
            <token id="38" string="to" />
            <token id="39" string="have" />
            <token id="40" string="?" />
          </tokens>
        </chunking>
        <chunking id="7" string="more than 70 questions about his abortion views" type="NP">
          <tokens>
            <token id="7" string="more" />
            <token id="8" string="than" />
            <token id="9" string="70" />
            <token id="10" string="questions" />
            <token id="11" string="about" />
            <token id="12" string="his" />
            <token id="13" string="abortion" />
            <token id="14" string="views" />
          </tokens>
        </chunking>
        <chunking id="8" string="asked only 36 such questions during his confirmation hearings last year" type="VP">
          <tokens>
            <token id="22" string="asked" />
            <token id="23" string="only" />
            <token id="24" string="36" />
            <token id="25" string="such" />
            <token id="26" string="questions" />
            <token id="27" string="during" />
            <token id="28" string="his" />
            <token id="29" string="confirmation" />
            <token id="30" string="hearings" />
            <token id="31" string="last" />
            <token id="32" string="year" />
          </tokens>
        </chunking>
        <chunking id="9" string="his confirmation hearings" type="NP">
          <tokens>
            <token id="28" string="his" />
            <token id="29" string="confirmation" />
            <token id="30" string="hearings" />
          </tokens>
        </chunking>
        <chunking id="10" string="was asked only 36 such questions during his confirmation hearings last year `` What are we going to have ?" type="VP">
          <tokens>
            <token id="21" string="was" />
            <token id="22" string="asked" />
            <token id="23" string="only" />
            <token id="24" string="36" />
            <token id="25" string="such" />
            <token id="26" string="questions" />
            <token id="27" string="during" />
            <token id="28" string="his" />
            <token id="29" string="confirmation" />
            <token id="30" string="hearings" />
            <token id="31" string="last" />
            <token id="32" string="year" />
            <token id="33" string="&quot;" />
            <token id="34" string="What" />
            <token id="35" string="are" />
            <token id="36" string="we" />
            <token id="37" string="going" />
            <token id="38" string="to" />
            <token id="39" string="have" />
            <token id="40" string="?" />
          </tokens>
        </chunking>
        <chunking id="11" string="more than 70 questions" type="NP">
          <tokens>
            <token id="7" string="more" />
            <token id="8" string="than" />
            <token id="9" string="70" />
            <token id="10" string="questions" />
          </tokens>
        </chunking>
        <chunking id="12" string="we" type="NP">
          <tokens>
            <token id="36" string="we" />
          </tokens>
        </chunking>
        <chunking id="13" string="even though Justice David H. Souter was asked only 36 such questions during his confirmation hearings last year `` What are we going to have ?" type="SBAR">
          <tokens>
            <token id="15" string="even" />
            <token id="16" string="though" />
            <token id="17" string="Justice" />
            <token id="18" string="David" />
            <token id="19" string="H." />
            <token id="20" string="Souter" />
            <token id="21" string="was" />
            <token id="22" string="asked" />
            <token id="23" string="only" />
            <token id="24" string="36" />
            <token id="25" string="such" />
            <token id="26" string="questions" />
            <token id="27" string="during" />
            <token id="28" string="his" />
            <token id="29" string="confirmation" />
            <token id="30" string="hearings" />
            <token id="31" string="last" />
            <token id="32" string="year" />
            <token id="33" string="&quot;" />
            <token id="34" string="What" />
            <token id="35" string="are" />
            <token id="36" string="we" />
            <token id="37" string="going" />
            <token id="38" string="to" />
            <token id="39" string="have" />
            <token id="40" string="?" />
          </tokens>
        </chunking>
        <chunking id="14" string="his abortion views" type="NP">
          <tokens>
            <token id="12" string="his" />
            <token id="13" string="abortion" />
            <token id="14" string="views" />
          </tokens>
        </chunking>
        <chunking id="15" string="have" type="VP">
          <tokens>
            <token id="39" string="have" />
          </tokens>
        </chunking>
        <chunking id="16" string="had been asked more than 70 questions about his abortion views even though Justice David H. Souter was asked only 36 such questions during his confirmation hearings last year `` What are we going to have ?" type="VP">
          <tokens>
            <token id="4" string="had" />
            <token id="5" string="been" />
            <token id="6" string="asked" />
            <token id="7" string="more" />
            <token id="8" string="than" />
            <token id="9" string="70" />
            <token id="10" string="questions" />
            <token id="11" string="about" />
            <token id="12" string="his" />
            <token id="13" string="abortion" />
            <token id="14" string="views" />
            <token id="15" string="even" />
            <token id="16" string="though" />
            <token id="17" string="Justice" />
            <token id="18" string="David" />
            <token id="19" string="H." />
            <token id="20" string="Souter" />
            <token id="21" string="was" />
            <token id="22" string="asked" />
            <token id="23" string="only" />
            <token id="24" string="36" />
            <token id="25" string="such" />
            <token id="26" string="questions" />
            <token id="27" string="during" />
            <token id="28" string="his" />
            <token id="29" string="confirmation" />
            <token id="30" string="hearings" />
            <token id="31" string="last" />
            <token id="32" string="year" />
            <token id="33" string="&quot;" />
            <token id="34" string="What" />
            <token id="35" string="are" />
            <token id="36" string="we" />
            <token id="37" string="going" />
            <token id="38" string="to" />
            <token id="39" string="have" />
            <token id="40" string="?" />
          </tokens>
        </chunking>
        <chunking id="17" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="18" string="been asked more than 70 questions about his abortion views even though Justice David H. Souter was asked only 36 such questions during his confirmation hearings last year `` What are we going to have ?" type="VP">
          <tokens>
            <token id="5" string="been" />
            <token id="6" string="asked" />
            <token id="7" string="more" />
            <token id="8" string="than" />
            <token id="9" string="70" />
            <token id="10" string="questions" />
            <token id="11" string="about" />
            <token id="12" string="his" />
            <token id="13" string="abortion" />
            <token id="14" string="views" />
            <token id="15" string="even" />
            <token id="16" string="though" />
            <token id="17" string="Justice" />
            <token id="18" string="David" />
            <token id="19" string="H." />
            <token id="20" string="Souter" />
            <token id="21" string="was" />
            <token id="22" string="asked" />
            <token id="23" string="only" />
            <token id="24" string="36" />
            <token id="25" string="such" />
            <token id="26" string="questions" />
            <token id="27" string="during" />
            <token id="28" string="his" />
            <token id="29" string="confirmation" />
            <token id="30" string="hearings" />
            <token id="31" string="last" />
            <token id="32" string="year" />
            <token id="33" string="&quot;" />
            <token id="34" string="What" />
            <token id="35" string="are" />
            <token id="36" string="we" />
            <token id="37" string="going" />
            <token id="38" string="to" />
            <token id="39" string="have" />
            <token id="40" string="?" />
          </tokens>
        </chunking>
        <chunking id="19" string="to have" type="VP">
          <tokens>
            <token id="38" string="to" />
            <token id="39" string="have" />
          </tokens>
        </chunking>
        <chunking id="20" string="going to have" type="VP">
          <tokens>
            <token id="37" string="going" />
            <token id="38" string="to" />
            <token id="39" string="have" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">asked</governor>
          <dependent id="3">Thomas</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">asked</governor>
          <dependent id="4">had</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">asked</governor>
          <dependent id="5">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="6">asked</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">70</governor>
          <dependent id="7">more</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="7">more</governor>
          <dependent id="8">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">questions</governor>
          <dependent id="9">70</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">asked</governor>
          <dependent id="10">questions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">views</governor>
          <dependent id="11">about</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">views</governor>
          <dependent id="12">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">views</governor>
          <dependent id="13">abortion</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">questions</governor>
          <dependent id="14">views</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">was</governor>
          <dependent id="15">even</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">was</governor>
          <dependent id="16">though</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Souter</governor>
          <dependent id="17">Justice</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Souter</governor>
          <dependent id="18">David</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Souter</governor>
          <dependent id="19">H.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">was</governor>
          <dependent id="20">Souter</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">asked</governor>
          <dependent id="21">was</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="21">was</governor>
          <dependent id="22">asked</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">36</governor>
          <dependent id="23">only</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="26">questions</governor>
          <dependent id="24">36</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">questions</governor>
          <dependent id="25">such</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">asked</governor>
          <dependent id="26">questions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">hearings</governor>
          <dependent id="27">during</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="30">hearings</governor>
          <dependent id="28">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">hearings</governor>
          <dependent id="29">confirmation</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">asked</governor>
          <dependent id="30">hearings</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">year</governor>
          <dependent id="31">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="22">asked</governor>
          <dependent id="32">year</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="37">going</governor>
          <dependent id="34">What</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="37">going</governor>
          <dependent id="35">are</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="37">going</governor>
          <dependent id="36">we</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="22">asked</governor>
          <dependent id="37">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="39">have</governor>
          <dependent id="38">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="37">going</governor>
          <dependent id="39">have</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="36" type="NUMBER" score="0.0">
          <tokens>
            <token id="24" string="36" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Thomas" />
          </tokens>
        </entity>
        <entity id="3" string="70" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="70" />
          </tokens>
        </entity>
        <entity id="4" string="David H. Souter" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="David" />
            <token id="19" string="H." />
            <token id="20" string="Souter" />
          </tokens>
        </entity>
        <entity id="5" string="last year" type="DATE" score="0.0">
          <tokens>
            <token id="31" string="last" />
            <token id="32" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>Sixty-four-thousand questions on abortion before we&amp;apost;re done with this approach?&amp;quot;</content>
      <tokens>
        <token id="1" string="Sixty-four-thousand" lemma="sixty-four-thousand" stem="sixty-four-thousand" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="questions" lemma="question" stem="question" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="abortion" lemma="abortion" stem="abort" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="done" lemma="do" stem="done" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="approach" lemma="approach" stem="approach" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (NP (NP (JJ Sixty-four-thousand) (NNS questions)) (PP (IN on) (NP (NN abortion))) (SBAR (IN before) (S (NP (PRP we)) (VP (VBP 're) (VP (VBN done) (PP (IN with) (NP (DT this) (NN approach)))))))) (. ?) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Sixty-four-thousand questions" type="NP">
          <tokens>
            <token id="1" string="Sixty-four-thousand" />
            <token id="2" string="questions" />
          </tokens>
        </chunking>
        <chunking id="2" string="this approach" type="NP">
          <tokens>
            <token id="10" string="this" />
            <token id="11" string="approach" />
          </tokens>
        </chunking>
        <chunking id="3" string="'re done with this approach" type="VP">
          <tokens>
            <token id="7" string="'re" />
            <token id="8" string="done" />
            <token id="9" string="with" />
            <token id="10" string="this" />
            <token id="11" string="approach" />
          </tokens>
        </chunking>
        <chunking id="4" string="before we 're done with this approach" type="SBAR">
          <tokens>
            <token id="5" string="before" />
            <token id="6" string="we" />
            <token id="7" string="'re" />
            <token id="8" string="done" />
            <token id="9" string="with" />
            <token id="10" string="this" />
            <token id="11" string="approach" />
          </tokens>
        </chunking>
        <chunking id="5" string="Sixty-four-thousand questions on abortion before we 're done with this approach" type="NP">
          <tokens>
            <token id="1" string="Sixty-four-thousand" />
            <token id="2" string="questions" />
            <token id="3" string="on" />
            <token id="4" string="abortion" />
            <token id="5" string="before" />
            <token id="6" string="we" />
            <token id="7" string="'re" />
            <token id="8" string="done" />
            <token id="9" string="with" />
            <token id="10" string="this" />
            <token id="11" string="approach" />
          </tokens>
        </chunking>
        <chunking id="6" string="done with this approach" type="VP">
          <tokens>
            <token id="8" string="done" />
            <token id="9" string="with" />
            <token id="10" string="this" />
            <token id="11" string="approach" />
          </tokens>
        </chunking>
        <chunking id="7" string="abortion" type="NP">
          <tokens>
            <token id="4" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="8" string="we" type="NP">
          <tokens>
            <token id="6" string="we" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">questions</governor>
          <dependent id="1">Sixty-four-thousand</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">questions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">abortion</governor>
          <dependent id="3">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">questions</governor>
          <dependent id="4">abortion</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">done</governor>
          <dependent id="5">before</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">done</governor>
          <dependent id="6">we</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">done</governor>
          <dependent id="7">'re</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="2">questions</governor>
          <dependent id="8">done</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">approach</governor>
          <dependent id="9">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">approach</governor>
          <dependent id="10">this</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">done</governor>
          <dependent id="11">approach</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>Hatch asked.</content>
      <tokens>
        <token id="1" string="Hatch" lemma="Hatch" stem="hatch" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="asked" lemma="ask" stem="ask" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Hatch)) (VP (VBD asked)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Hatch" type="NP">
          <tokens>
            <token id="1" string="Hatch" />
          </tokens>
        </chunking>
        <chunking id="2" string="asked" type="VP">
          <tokens>
            <token id="2" string="asked" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">asked</governor>
          <dependent id="1">Hatch</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">asked</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hatch" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Hatch" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="false">
      <content>&amp;quot;Enough is enough.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Enough" lemma="Enough" stem="enough" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="enough" lemma="enough" stem="enough" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NNP Enough)) (VP (VBZ is) (ADJP (RB enough))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="enough" type="ADJP">
          <tokens>
            <token id="4" string="enough" />
          </tokens>
        </chunking>
        <chunking id="2" string="is enough" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="enough" />
          </tokens>
        </chunking>
        <chunking id="3" string="Enough" type="NP">
          <tokens>
            <token id="2" string="Enough" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">enough</governor>
          <dependent id="2">Enough</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">enough</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">enough</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>; Thomas said Senate confirmation of his nomination would give him &amp;quot;an opportunity to serve and give back&amp;quot; and to &amp;quot;bring something different to the court.&amp;quot;</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="5" string="confirmation" lemma="confirmation" stem="confirm" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="nomination" lemma="nomination" stem="nomin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="give" lemma="give" stem="give" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="opportunity" lemma="opportunity" stem="opportun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="serve" lemma="serve" stem="serv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="give" lemma="give" stem="give" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="back" lemma="back" stem="back" pos="RP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="bring" lemma="bring" stem="bring" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="something" lemma="something" stem="someth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="different" lemma="different" stem="differ" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="court" lemma="court" stem="court" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (PRN (: ;) (S (NP (NNP Thomas)) (VP (VBD said) (SBAR (S (NP (NP (NNP Senate) (NN confirmation)) (PP (IN of) (NP (PRP$ his) (NN nomination)))) (VP (MD would) (VP (VP (VB give) (NP (PRP him)) (`` ``) (NP (NP (DT an) (NN opportunity)) (SBAR (S (VP (TO to) (VP (VP (VB serve)) (CC and) (VP (VB give) (PRT (RP back))))) ('' ''))))) (CC and) (VP (TO to) (`` ``) (VP (VB bring) (NP (NN something)) (FRAG (ADJP (JJ different) (PP (TO to) (NP (DT the) (NN court)))) (. .))) ('' ''))))))))))</syntactictree>
      <chunkings>
        <chunking id="1" string="Senate confirmation of his nomination" type="NP">
          <tokens>
            <token id="4" string="Senate" />
            <token id="5" string="confirmation" />
            <token id="6" string="of" />
            <token id="7" string="his" />
            <token id="8" string="nomination" />
          </tokens>
        </chunking>
        <chunking id="2" string="give him `` an opportunity to serve and give back '' and to `` bring something different to the court . ''" type="VP">
          <tokens>
            <token id="10" string="give" />
            <token id="11" string="him" />
            <token id="12" string="&quot;" />
            <token id="13" string="an" />
            <token id="14" string="opportunity" />
            <token id="15" string="to" />
            <token id="16" string="serve" />
            <token id="17" string="and" />
            <token id="18" string="give" />
            <token id="19" string="back" />
            <token id="20" string="&quot;" />
            <token id="21" string="and" />
            <token id="22" string="to" />
            <token id="23" string="&quot;" />
            <token id="24" string="bring" />
            <token id="25" string="something" />
            <token id="26" string="different" />
            <token id="27" string="to" />
            <token id="28" string="the" />
            <token id="29" string="court" />
            <token id="30" string="." />
            <token id="31" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="3" string="to serve and give back" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="serve" />
            <token id="17" string="and" />
            <token id="18" string="give" />
            <token id="19" string="back" />
          </tokens>
        </chunking>
        <chunking id="4" string="Senate confirmation of his nomination would give him `` an opportunity to serve and give back '' and to `` bring something different to the court . ''" type="SBAR">
          <tokens>
            <token id="4" string="Senate" />
            <token id="5" string="confirmation" />
            <token id="6" string="of" />
            <token id="7" string="his" />
            <token id="8" string="nomination" />
            <token id="9" string="would" />
            <token id="10" string="give" />
            <token id="11" string="him" />
            <token id="12" string="&quot;" />
            <token id="13" string="an" />
            <token id="14" string="opportunity" />
            <token id="15" string="to" />
            <token id="16" string="serve" />
            <token id="17" string="and" />
            <token id="18" string="give" />
            <token id="19" string="back" />
            <token id="20" string="&quot;" />
            <token id="21" string="and" />
            <token id="22" string="to" />
            <token id="23" string="&quot;" />
            <token id="24" string="bring" />
            <token id="25" string="something" />
            <token id="26" string="different" />
            <token id="27" string="to" />
            <token id="28" string="the" />
            <token id="29" string="court" />
            <token id="30" string="." />
            <token id="31" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="5" string="Senate confirmation" type="NP">
          <tokens>
            <token id="4" string="Senate" />
            <token id="5" string="confirmation" />
          </tokens>
        </chunking>
        <chunking id="6" string="give him `` an opportunity to serve and give back ''" type="VP">
          <tokens>
            <token id="10" string="give" />
            <token id="11" string="him" />
            <token id="12" string="&quot;" />
            <token id="13" string="an" />
            <token id="14" string="opportunity" />
            <token id="15" string="to" />
            <token id="16" string="serve" />
            <token id="17" string="and" />
            <token id="18" string="give" />
            <token id="19" string="back" />
            <token id="20" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="7" string="Thomas" type="NP">
          <tokens>
            <token id="2" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="8" string="an opportunity to serve and give back ''" type="NP">
          <tokens>
            <token id="13" string="an" />
            <token id="14" string="opportunity" />
            <token id="15" string="to" />
            <token id="16" string="serve" />
            <token id="17" string="and" />
            <token id="18" string="give" />
            <token id="19" string="back" />
            <token id="20" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="9" string="to `` bring something different to the court . ''" type="VP">
          <tokens>
            <token id="22" string="to" />
            <token id="23" string="&quot;" />
            <token id="24" string="bring" />
            <token id="25" string="something" />
            <token id="26" string="different" />
            <token id="27" string="to" />
            <token id="28" string="the" />
            <token id="29" string="court" />
            <token id="30" string="." />
            <token id="31" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="10" string="him" type="NP">
          <tokens>
            <token id="11" string="him" />
          </tokens>
        </chunking>
        <chunking id="11" string="serve" type="VP">
          <tokens>
            <token id="16" string="serve" />
          </tokens>
        </chunking>
        <chunking id="12" string="something" type="NP">
          <tokens>
            <token id="25" string="something" />
          </tokens>
        </chunking>
        <chunking id="13" string="the court" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="court" />
          </tokens>
        </chunking>
        <chunking id="14" string="would give him `` an opportunity to serve and give back '' and to `` bring something different to the court . ''" type="VP">
          <tokens>
            <token id="9" string="would" />
            <token id="10" string="give" />
            <token id="11" string="him" />
            <token id="12" string="&quot;" />
            <token id="13" string="an" />
            <token id="14" string="opportunity" />
            <token id="15" string="to" />
            <token id="16" string="serve" />
            <token id="17" string="and" />
            <token id="18" string="give" />
            <token id="19" string="back" />
            <token id="20" string="&quot;" />
            <token id="21" string="and" />
            <token id="22" string="to" />
            <token id="23" string="&quot;" />
            <token id="24" string="bring" />
            <token id="25" string="something" />
            <token id="26" string="different" />
            <token id="27" string="to" />
            <token id="28" string="the" />
            <token id="29" string="court" />
            <token id="30" string="." />
            <token id="31" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="15" string="bring something different to the court ." type="VP">
          <tokens>
            <token id="24" string="bring" />
            <token id="25" string="something" />
            <token id="26" string="different" />
            <token id="27" string="to" />
            <token id="28" string="the" />
            <token id="29" string="court" />
            <token id="30" string="." />
          </tokens>
        </chunking>
        <chunking id="16" string="serve and give back" type="VP">
          <tokens>
            <token id="16" string="serve" />
            <token id="17" string="and" />
            <token id="18" string="give" />
            <token id="19" string="back" />
          </tokens>
        </chunking>
        <chunking id="17" string="said Senate confirmation of his nomination would give him `` an opportunity to serve and give back '' and to `` bring something different to the court . ''" type="VP">
          <tokens>
            <token id="3" string="said" />
            <token id="4" string="Senate" />
            <token id="5" string="confirmation" />
            <token id="6" string="of" />
            <token id="7" string="his" />
            <token id="8" string="nomination" />
            <token id="9" string="would" />
            <token id="10" string="give" />
            <token id="11" string="him" />
            <token id="12" string="&quot;" />
            <token id="13" string="an" />
            <token id="14" string="opportunity" />
            <token id="15" string="to" />
            <token id="16" string="serve" />
            <token id="17" string="and" />
            <token id="18" string="give" />
            <token id="19" string="back" />
            <token id="20" string="&quot;" />
            <token id="21" string="and" />
            <token id="22" string="to" />
            <token id="23" string="&quot;" />
            <token id="24" string="bring" />
            <token id="25" string="something" />
            <token id="26" string="different" />
            <token id="27" string="to" />
            <token id="28" string="the" />
            <token id="29" string="court" />
            <token id="30" string="." />
            <token id="31" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="18" string="his nomination" type="NP">
          <tokens>
            <token id="7" string="his" />
            <token id="8" string="nomination" />
          </tokens>
        </chunking>
        <chunking id="19" string="different to the court" type="ADJP">
          <tokens>
            <token id="26" string="different" />
            <token id="27" string="to" />
            <token id="28" string="the" />
            <token id="29" string="court" />
          </tokens>
        </chunking>
        <chunking id="20" string="give back" type="VP">
          <tokens>
            <token id="18" string="give" />
            <token id="19" string="back" />
          </tokens>
        </chunking>
        <chunking id="21" string="an opportunity" type="NP">
          <tokens>
            <token id="13" string="an" />
            <token id="14" string="opportunity" />
          </tokens>
        </chunking>
        <chunking id="22" string="to serve and give back ''" type="SBAR">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="serve" />
            <token id="17" string="and" />
            <token id="18" string="give" />
            <token id="19" string="back" />
            <token id="20" string="&quot;" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">said</governor>
          <dependent id="2">Thomas</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">confirmation</governor>
          <dependent id="4">Senate</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">give</governor>
          <dependent id="5">confirmation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">nomination</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">nomination</governor>
          <dependent id="7">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">confirmation</governor>
          <dependent id="8">nomination</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">give</governor>
          <dependent id="9">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">said</governor>
          <dependent id="10">give</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">give</governor>
          <dependent id="11">him</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">opportunity</governor>
          <dependent id="13">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">give</governor>
          <dependent id="14">opportunity</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">serve</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">opportunity</governor>
          <dependent id="16">serve</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">serve</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">serve</governor>
          <dependent id="18">give</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="18">give</governor>
          <dependent id="19">back</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">give</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">bring</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">give</governor>
          <dependent id="24">bring</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">bring</governor>
          <dependent id="25">something</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="24">bring</governor>
          <dependent id="26">different</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">court</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">court</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">different</governor>
          <dependent id="29">court</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="4" string="Senate" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>; &amp;quot;I can walk in the shoes of the people who are affected by what the court does,&amp;quot; Thomas said Several senators were openly skeptical Wednesday over Thomas&amp;apost; insistence that he has no opinion on the 1973 Supreme Court decision legalizing abortion If that&amp;apost;s so, said Sen. Paul Simon, D-Ill., &amp;quot;he&amp;apost;s the only person gathered in the room who does not have an opinion.&amp;quot;</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="walk" lemma="walk" stem="walk" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="shoes" lemma="shoe" stem="shoe" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="affected" lemma="affect" stem="affect" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="18" string="court" lemma="court" stem="court" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="19" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="23" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="Several" lemma="several" stem="sever" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="senators" lemma="senator" stem="senat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="openly" lemma="openly" stem="openli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="skeptical" lemma="skeptical" stem="skeptic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="Wednesday" lemma="Wednesday" stem="wednesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="30" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="32" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="insistence" lemma="insistence" stem="insist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="opinion" lemma="opinion" stem="opinion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="41" string="1973" lemma="1973" stem="1973" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="42" string="Supreme" lemma="Supreme" stem="suprem" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="43" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="44" string="decision" lemma="decision" stem="decis" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="45" string="legalizing" lemma="legalize" stem="legal" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="46" string="abortion" lemma="abortion" stem="abort" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="47" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="49" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="51" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="52" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="53" string="Sen." lemma="Sen." stem="sen." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="54" string="Paul" lemma="Paul" stem="paul" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="55" string="Simon" lemma="Simon" stem="simon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="56" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="57" string="D-Ill." lemma="D-Ill." stem="d-ill." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="58" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="59" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="60" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="61" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="62" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="63" string="only" lemma="only" stem="onli" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="64" string="person" lemma="person" stem="person" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="65" string="gathered" lemma="gather" stem="gather" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="66" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="67" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="68" string="room" lemma="room" stem="room" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="69" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="70" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="71" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="72" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="73" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="74" string="opinion" lemma="opinion" stem="opinion" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="75" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="76" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (`` ``) (S (NP (PRP I)) (VP (MD can) (VP (VB walk) (PP (IN in) (NP (NP (DT the) (NNS shoes)) (PP (IN of) (NP (NP (DT the) (NNS people)) (SBAR (WHNP (WP who)) (S (VP (VBP are) (VP (VBN affected) (PP (IN by) (SBAR (WHNP (WP what)) (S (NP (DT the) (NN court)) (VP (VBZ does)))))))))))))))) (, ,) ('' '') (PRN (SINV (S (NP (NNP Thomas)) (VP (VBD said) (SBAR (S (NP (JJ Several) (NNS senators)) (VP (VBD were) (ADVP (RB openly)) (ADJP (JJ skeptical) (NP-TMP (NNP Wednesday)) (PP (IN over) (NP (NP (NNP Thomas) (POS ')) (NN insistence)))) (SBAR (IN that) (S (NP (PRP he)) (VP (VBZ has) (NP (NP (DT no) (NN opinion)) (PP (IN on) (NP (NP (DT the) (CD 1973) (NNP Supreme) (NNP Court) (NN decision)) (VP (VBG legalizing) (NP (NN abortion))))))))))))) (SBAR (IN If) (S (NP (DT that)) (VP (VBZ 's) (ADVP (RB so)))))) (, ,) (VP (VBD said)) (NP (NP (NNP Sen.) (NNP Paul) (NNP Simon)) (, ,) (NP (NNP D-Ill.))))) (, ,) (`` ``) (NP (PRP he)) (VP (VBZ 's) (NP (NP (DT the) (JJ only) (NN person)) (VP (VBN gathered) (PP (IN in) (NP (NP (DT the) (NN room)) (SBAR (WHNP (WP who)) (S (VP (VBZ does) (RB not) (VP (VB have) (NP (DT an) (NN opinion))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="'s the only person gathered in the room who does not have an opinion" type="VP">
          <tokens>
            <token id="61" string="'s" />
            <token id="62" string="the" />
            <token id="63" string="only" />
            <token id="64" string="person" />
            <token id="65" string="gathered" />
            <token id="66" string="in" />
            <token id="67" string="the" />
            <token id="68" string="room" />
            <token id="69" string="who" />
            <token id="70" string="does" />
            <token id="71" string="not" />
            <token id="72" string="have" />
            <token id="73" string="an" />
            <token id="74" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="2" string="the 1973 Supreme Court decision legalizing abortion" type="NP">
          <tokens>
            <token id="40" string="the" />
            <token id="41" string="1973" />
            <token id="42" string="Supreme" />
            <token id="43" string="Court" />
            <token id="44" string="decision" />
            <token id="45" string="legalizing" />
            <token id="46" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="3" string="legalizing abortion" type="VP">
          <tokens>
            <token id="45" string="legalizing" />
            <token id="46" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="4" string="affected by what the court does" type="VP">
          <tokens>
            <token id="14" string="affected" />
            <token id="15" string="by" />
            <token id="16" string="what" />
            <token id="17" string="the" />
            <token id="18" string="court" />
            <token id="19" string="does" />
          </tokens>
        </chunking>
        <chunking id="5" string="the room who does not have an opinion" type="NP">
          <tokens>
            <token id="67" string="the" />
            <token id="68" string="room" />
            <token id="69" string="who" />
            <token id="70" string="does" />
            <token id="71" string="not" />
            <token id="72" string="have" />
            <token id="73" string="an" />
            <token id="74" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="6" string="are affected by what the court does" type="VP">
          <tokens>
            <token id="13" string="are" />
            <token id="14" string="affected" />
            <token id="15" string="by" />
            <token id="16" string="what" />
            <token id="17" string="the" />
            <token id="18" string="court" />
            <token id="19" string="does" />
          </tokens>
        </chunking>
        <chunking id="7" string="Thomas" type="NP">
          <tokens>
            <token id="22" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="8" string="Thomas '" type="NP">
          <tokens>
            <token id="31" string="Thomas" />
            <token id="32" string="'" />
          </tokens>
        </chunking>
        <chunking id="9" string="skeptical Wednesday over Thomas ' insistence" type="ADJP">
          <tokens>
            <token id="28" string="skeptical" />
            <token id="29" string="Wednesday" />
            <token id="30" string="over" />
            <token id="31" string="Thomas" />
            <token id="32" string="'" />
            <token id="33" string="insistence" />
          </tokens>
        </chunking>
        <chunking id="10" string="the 1973 Supreme Court decision" type="NP">
          <tokens>
            <token id="40" string="the" />
            <token id="41" string="1973" />
            <token id="42" string="Supreme" />
            <token id="43" string="Court" />
            <token id="44" string="decision" />
          </tokens>
        </chunking>
        <chunking id="11" string="no opinion" type="NP">
          <tokens>
            <token id="37" string="no" />
            <token id="38" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="12" string="that he has no opinion on the 1973 Supreme Court decision legalizing abortion" type="SBAR">
          <tokens>
            <token id="34" string="that" />
            <token id="35" string="he" />
            <token id="36" string="has" />
            <token id="37" string="no" />
            <token id="38" string="opinion" />
            <token id="39" string="on" />
            <token id="40" string="the" />
            <token id="41" string="1973" />
            <token id="42" string="Supreme" />
            <token id="43" string="Court" />
            <token id="44" string="decision" />
            <token id="45" string="legalizing" />
            <token id="46" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="13" string="If that 's so" type="SBAR">
          <tokens>
            <token id="47" string="If" />
            <token id="48" string="that" />
            <token id="49" string="'s" />
            <token id="50" string="so" />
          </tokens>
        </chunking>
        <chunking id="14" string="were openly skeptical Wednesday over Thomas ' insistence that he has no opinion on the 1973 Supreme Court decision legalizing abortion" type="VP">
          <tokens>
            <token id="26" string="were" />
            <token id="27" string="openly" />
            <token id="28" string="skeptical" />
            <token id="29" string="Wednesday" />
            <token id="30" string="over" />
            <token id="31" string="Thomas" />
            <token id="32" string="'" />
            <token id="33" string="insistence" />
            <token id="34" string="that" />
            <token id="35" string="he" />
            <token id="36" string="has" />
            <token id="37" string="no" />
            <token id="38" string="opinion" />
            <token id="39" string="on" />
            <token id="40" string="the" />
            <token id="41" string="1973" />
            <token id="42" string="Supreme" />
            <token id="43" string="Court" />
            <token id="44" string="decision" />
            <token id="45" string="legalizing" />
            <token id="46" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="15" string="Sen. Paul Simon" type="NP">
          <tokens>
            <token id="53" string="Sen." />
            <token id="54" string="Paul" />
            <token id="55" string="Simon" />
          </tokens>
        </chunking>
        <chunking id="16" string="the people who are affected by what the court does" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="people" />
            <token id="12" string="who" />
            <token id="13" string="are" />
            <token id="14" string="affected" />
            <token id="15" string="by" />
            <token id="16" string="what" />
            <token id="17" string="the" />
            <token id="18" string="court" />
            <token id="19" string="does" />
          </tokens>
        </chunking>
        <chunking id="17" string="who are affected by what the court does" type="SBAR">
          <tokens>
            <token id="12" string="who" />
            <token id="13" string="are" />
            <token id="14" string="affected" />
            <token id="15" string="by" />
            <token id="16" string="what" />
            <token id="17" string="the" />
            <token id="18" string="court" />
            <token id="19" string="does" />
          </tokens>
        </chunking>
        <chunking id="18" string="said Several senators were openly skeptical Wednesday over Thomas ' insistence that he has no opinion on the 1973 Supreme Court decision legalizing abortion" type="VP">
          <tokens>
            <token id="23" string="said" />
            <token id="24" string="Several" />
            <token id="25" string="senators" />
            <token id="26" string="were" />
            <token id="27" string="openly" />
            <token id="28" string="skeptical" />
            <token id="29" string="Wednesday" />
            <token id="30" string="over" />
            <token id="31" string="Thomas" />
            <token id="32" string="'" />
            <token id="33" string="insistence" />
            <token id="34" string="that" />
            <token id="35" string="he" />
            <token id="36" string="has" />
            <token id="37" string="no" />
            <token id="38" string="opinion" />
            <token id="39" string="on" />
            <token id="40" string="the" />
            <token id="41" string="1973" />
            <token id="42" string="Supreme" />
            <token id="43" string="Court" />
            <token id="44" string="decision" />
            <token id="45" string="legalizing" />
            <token id="46" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="19" string="Sen. Paul Simon , D-Ill." type="NP">
          <tokens>
            <token id="53" string="Sen." />
            <token id="54" string="Paul" />
            <token id="55" string="Simon" />
            <token id="56" string="," />
            <token id="57" string="D-Ill." />
          </tokens>
        </chunking>
        <chunking id="20" string="he" type="NP">
          <tokens>
            <token id="35" string="he" />
          </tokens>
        </chunking>
        <chunking id="21" string="what the court does" type="SBAR">
          <tokens>
            <token id="16" string="what" />
            <token id="17" string="the" />
            <token id="18" string="court" />
            <token id="19" string="does" />
          </tokens>
        </chunking>
        <chunking id="22" string="an opinion" type="NP">
          <tokens>
            <token id="73" string="an" />
            <token id="74" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="23" string="Several senators were openly skeptical Wednesday over Thomas ' insistence that he has no opinion on the 1973 Supreme Court decision legalizing abortion" type="SBAR">
          <tokens>
            <token id="24" string="Several" />
            <token id="25" string="senators" />
            <token id="26" string="were" />
            <token id="27" string="openly" />
            <token id="28" string="skeptical" />
            <token id="29" string="Wednesday" />
            <token id="30" string="over" />
            <token id="31" string="Thomas" />
            <token id="32" string="'" />
            <token id="33" string="insistence" />
            <token id="34" string="that" />
            <token id="35" string="he" />
            <token id="36" string="has" />
            <token id="37" string="no" />
            <token id="38" string="opinion" />
            <token id="39" string="on" />
            <token id="40" string="the" />
            <token id="41" string="1973" />
            <token id="42" string="Supreme" />
            <token id="43" string="Court" />
            <token id="44" string="decision" />
            <token id="45" string="legalizing" />
            <token id="46" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="24" string="the only person" type="NP">
          <tokens>
            <token id="62" string="the" />
            <token id="63" string="only" />
            <token id="64" string="person" />
          </tokens>
        </chunking>
        <chunking id="25" string="gathered in the room who does not have an opinion" type="VP">
          <tokens>
            <token id="65" string="gathered" />
            <token id="66" string="in" />
            <token id="67" string="the" />
            <token id="68" string="room" />
            <token id="69" string="who" />
            <token id="70" string="does" />
            <token id="71" string="not" />
            <token id="72" string="have" />
            <token id="73" string="an" />
            <token id="74" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="26" string="the shoes of the people who are affected by what the court does" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="shoes" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="people" />
            <token id="12" string="who" />
            <token id="13" string="are" />
            <token id="14" string="affected" />
            <token id="15" string="by" />
            <token id="16" string="what" />
            <token id="17" string="the" />
            <token id="18" string="court" />
            <token id="19" string="does" />
          </tokens>
        </chunking>
        <chunking id="27" string="I" type="NP">
          <tokens>
            <token id="3" string="I" />
          </tokens>
        </chunking>
        <chunking id="28" string="can walk in the shoes of the people who are affected by what the court does" type="VP">
          <tokens>
            <token id="4" string="can" />
            <token id="5" string="walk" />
            <token id="6" string="in" />
            <token id="7" string="the" />
            <token id="8" string="shoes" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="people" />
            <token id="12" string="who" />
            <token id="13" string="are" />
            <token id="14" string="affected" />
            <token id="15" string="by" />
            <token id="16" string="what" />
            <token id="17" string="the" />
            <token id="18" string="court" />
            <token id="19" string="does" />
          </tokens>
        </chunking>
        <chunking id="29" string="the people" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="people" />
          </tokens>
        </chunking>
        <chunking id="30" string="the shoes" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="shoes" />
          </tokens>
        </chunking>
        <chunking id="31" string="no opinion on the 1973 Supreme Court decision legalizing abortion" type="NP">
          <tokens>
            <token id="37" string="no" />
            <token id="38" string="opinion" />
            <token id="39" string="on" />
            <token id="40" string="the" />
            <token id="41" string="1973" />
            <token id="42" string="Supreme" />
            <token id="43" string="Court" />
            <token id="44" string="decision" />
            <token id="45" string="legalizing" />
            <token id="46" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="32" string="D-Ill." type="NP">
          <tokens>
            <token id="57" string="D-Ill." />
          </tokens>
        </chunking>
        <chunking id="33" string="the room" type="NP">
          <tokens>
            <token id="67" string="the" />
            <token id="68" string="room" />
          </tokens>
        </chunking>
        <chunking id="34" string="have an opinion" type="VP">
          <tokens>
            <token id="72" string="have" />
            <token id="73" string="an" />
            <token id="74" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="35" string="abortion" type="NP">
          <tokens>
            <token id="46" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="36" string="the court" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="court" />
          </tokens>
        </chunking>
        <chunking id="37" string="has no opinion on the 1973 Supreme Court decision legalizing abortion" type="VP">
          <tokens>
            <token id="36" string="has" />
            <token id="37" string="no" />
            <token id="38" string="opinion" />
            <token id="39" string="on" />
            <token id="40" string="the" />
            <token id="41" string="1973" />
            <token id="42" string="Supreme" />
            <token id="43" string="Court" />
            <token id="44" string="decision" />
            <token id="45" string="legalizing" />
            <token id="46" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="38" string="Several senators" type="NP">
          <tokens>
            <token id="24" string="Several" />
            <token id="25" string="senators" />
          </tokens>
        </chunking>
        <chunking id="39" string="that" type="NP">
          <tokens>
            <token id="48" string="that" />
          </tokens>
        </chunking>
        <chunking id="40" string="the only person gathered in the room who does not have an opinion" type="NP">
          <tokens>
            <token id="62" string="the" />
            <token id="63" string="only" />
            <token id="64" string="person" />
            <token id="65" string="gathered" />
            <token id="66" string="in" />
            <token id="67" string="the" />
            <token id="68" string="room" />
            <token id="69" string="who" />
            <token id="70" string="does" />
            <token id="71" string="not" />
            <token id="72" string="have" />
            <token id="73" string="an" />
            <token id="74" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="41" string="who does not have an opinion" type="SBAR">
          <tokens>
            <token id="69" string="who" />
            <token id="70" string="does" />
            <token id="71" string="not" />
            <token id="72" string="have" />
            <token id="73" string="an" />
            <token id="74" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="42" string="'s so" type="VP">
          <tokens>
            <token id="49" string="'s" />
            <token id="50" string="so" />
          </tokens>
        </chunking>
        <chunking id="43" string="does" type="VP">
          <tokens>
            <token id="19" string="does" />
          </tokens>
        </chunking>
        <chunking id="44" string="does not have an opinion" type="VP">
          <tokens>
            <token id="70" string="does" />
            <token id="71" string="not" />
            <token id="72" string="have" />
            <token id="73" string="an" />
            <token id="74" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="45" string="walk in the shoes of the people who are affected by what the court does" type="VP">
          <tokens>
            <token id="5" string="walk" />
            <token id="6" string="in" />
            <token id="7" string="the" />
            <token id="8" string="shoes" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="people" />
            <token id="12" string="who" />
            <token id="13" string="are" />
            <token id="14" string="affected" />
            <token id="15" string="by" />
            <token id="16" string="what" />
            <token id="17" string="the" />
            <token id="18" string="court" />
            <token id="19" string="does" />
          </tokens>
        </chunking>
        <chunking id="46" string="Thomas ' insistence" type="NP">
          <tokens>
            <token id="31" string="Thomas" />
            <token id="32" string="'" />
            <token id="33" string="insistence" />
          </tokens>
        </chunking>
        <chunking id="47" string="said" type="VP">
          <tokens>
            <token id="52" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">walk</governor>
          <dependent id="3">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">walk</governor>
          <dependent id="4">can</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="64">person</governor>
          <dependent id="5">walk</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">shoes</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">shoes</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">walk</governor>
          <dependent id="8">shoes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">people</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">people</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">shoes</governor>
          <dependent id="11">people</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="14">affected</governor>
          <dependent id="12">who</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="14">affected</governor>
          <dependent id="13">are</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">people</governor>
          <dependent id="14">affected</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">does</governor>
          <dependent id="15">by</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">does</governor>
          <dependent id="16">what</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">court</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">does</governor>
          <dependent id="18">court</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">affected</governor>
          <dependent id="19">does</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">said</governor>
          <dependent id="22">Thomas</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="52">said</governor>
          <dependent id="23">said</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">senators</governor>
          <dependent id="24">Several</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">skeptical</governor>
          <dependent id="25">senators</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="28">skeptical</governor>
          <dependent id="26">were</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">skeptical</governor>
          <dependent id="27">openly</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="23">said</governor>
          <dependent id="28">skeptical</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="28">skeptical</governor>
          <dependent id="29">Wednesday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">insistence</governor>
          <dependent id="30">over</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="33">insistence</governor>
          <dependent id="31">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">Thomas</governor>
          <dependent id="32">'</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">skeptical</governor>
          <dependent id="33">insistence</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="36">has</governor>
          <dependent id="34">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">has</governor>
          <dependent id="35">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="28">skeptical</governor>
          <dependent id="36">has</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="38">opinion</governor>
          <dependent id="37">no</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="36">has</governor>
          <dependent id="38">opinion</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">decision</governor>
          <dependent id="39">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="44">decision</governor>
          <dependent id="40">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="44">decision</governor>
          <dependent id="41">1973</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="44">decision</governor>
          <dependent id="42">Supreme</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="44">decision</governor>
          <dependent id="43">Court</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">opinion</governor>
          <dependent id="44">decision</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="44">decision</governor>
          <dependent id="45">legalizing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="45">legalizing</governor>
          <dependent id="46">abortion</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="49">'s</governor>
          <dependent id="47">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="49">'s</governor>
          <dependent id="48">that</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="23">said</governor>
          <dependent id="49">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="49">'s</governor>
          <dependent id="50">so</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="64">person</governor>
          <dependent id="52">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="55">Simon</governor>
          <dependent id="53">Sen.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="55">Simon</governor>
          <dependent id="54">Paul</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="52">said</governor>
          <dependent id="55">Simon</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="55">Simon</governor>
          <dependent id="57">D-Ill.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="64">person</governor>
          <dependent id="60">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="64">person</governor>
          <dependent id="61">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="64">person</governor>
          <dependent id="62">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="64">person</governor>
          <dependent id="63">only</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="64">person</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="64">person</governor>
          <dependent id="65">gathered</dependent>
        </dependency>
        <dependency type="case">
          <governor id="68">room</governor>
          <dependent id="66">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="68">room</governor>
          <dependent id="67">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="65">gathered</governor>
          <dependent id="68">room</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="72">have</governor>
          <dependent id="69">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="72">have</governor>
          <dependent id="70">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="72">have</governor>
          <dependent id="71">not</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="68">room</governor>
          <dependent id="72">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="74">opinion</governor>
          <dependent id="73">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="72">have</governor>
          <dependent id="74">opinion</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Supreme Court" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="42" string="Supreme" />
            <token id="43" string="Court" />
          </tokens>
        </entity>
        <entity id="2" string="Wednesday" type="DATE" score="0.0">
          <tokens>
            <token id="29" string="Wednesday" />
          </tokens>
        </entity>
        <entity id="3" string="1973" type="DATE" score="0.0">
          <tokens>
            <token id="41" string="1973" />
          </tokens>
        </entity>
        <entity id="4" string="Paul Simon" type="PERSON" score="0.0">
          <tokens>
            <token id="54" string="Paul" />
            <token id="55" string="Simon" />
          </tokens>
        </entity>
        <entity id="5" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Thomas" />
          </tokens>
        </entity>
        <entity id="6" string="D-Ill." type="LOCATION" score="0.0">
          <tokens>
            <token id="57" string="D-Ill." />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>; Kohl added, &amp;quot;I&amp;apost;m concerned about his candor, his willingness to be forthcoming.&amp;quot;</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Kohl" lemma="Kohl" stem="kohl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="added" lemma="add" stem="ad" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="concerned" lemma="concerned" stem="concern" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="11" string="candor" lemma="candor" stem="candor" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="willingness" lemma="willingness" stem="willing" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="forthcoming" lemma="forthcoming" stem="forthcom" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (PRN (: ;) (S (NP (NNP Kohl)) (VP (VBD added) (, ,) (`` ``) (S (NP (PRP I)) (VP (VBP 'm) (ADJP (JJ concerned) (PP (IN about) (NP (NP (PRP$ his) (NN candor)) (, ,) (NP (PRP$ his) (NN willingness) (S (VP (TO to) (VP (VB be) (ADJP (JJ forthcoming)))))))))) (. .) ('' ''))))))</syntactictree>
      <chunkings>
        <chunking id="1" string="Kohl" type="NP">
          <tokens>
            <token id="2" string="Kohl" />
          </tokens>
        </chunking>
        <chunking id="2" string="his candor" type="NP">
          <tokens>
            <token id="10" string="his" />
            <token id="11" string="candor" />
          </tokens>
        </chunking>
        <chunking id="3" string="added , `` I 'm concerned about his candor , his willingness to be forthcoming . ''" type="VP">
          <tokens>
            <token id="3" string="added" />
            <token id="4" string="," />
            <token id="5" string="&quot;" />
            <token id="6" string="I" />
            <token id="7" string="'m" />
            <token id="8" string="concerned" />
            <token id="9" string="about" />
            <token id="10" string="his" />
            <token id="11" string="candor" />
            <token id="12" string="," />
            <token id="13" string="his" />
            <token id="14" string="willingness" />
            <token id="15" string="to" />
            <token id="16" string="be" />
            <token id="17" string="forthcoming" />
            <token id="18" string="." />
            <token id="19" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="4" string="'m concerned about his candor , his willingness to be forthcoming" type="VP">
          <tokens>
            <token id="7" string="'m" />
            <token id="8" string="concerned" />
            <token id="9" string="about" />
            <token id="10" string="his" />
            <token id="11" string="candor" />
            <token id="12" string="," />
            <token id="13" string="his" />
            <token id="14" string="willingness" />
            <token id="15" string="to" />
            <token id="16" string="be" />
            <token id="17" string="forthcoming" />
          </tokens>
        </chunking>
        <chunking id="5" string="to be forthcoming" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="be" />
            <token id="17" string="forthcoming" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="6" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="his candor , his willingness to be forthcoming" type="NP">
          <tokens>
            <token id="10" string="his" />
            <token id="11" string="candor" />
            <token id="12" string="," />
            <token id="13" string="his" />
            <token id="14" string="willingness" />
            <token id="15" string="to" />
            <token id="16" string="be" />
            <token id="17" string="forthcoming" />
          </tokens>
        </chunking>
        <chunking id="8" string="his willingness to be forthcoming" type="NP">
          <tokens>
            <token id="13" string="his" />
            <token id="14" string="willingness" />
            <token id="15" string="to" />
            <token id="16" string="be" />
            <token id="17" string="forthcoming" />
          </tokens>
        </chunking>
        <chunking id="9" string="concerned about his candor , his willingness to be forthcoming" type="ADJP">
          <tokens>
            <token id="8" string="concerned" />
            <token id="9" string="about" />
            <token id="10" string="his" />
            <token id="11" string="candor" />
            <token id="12" string="," />
            <token id="13" string="his" />
            <token id="14" string="willingness" />
            <token id="15" string="to" />
            <token id="16" string="be" />
            <token id="17" string="forthcoming" />
          </tokens>
        </chunking>
        <chunking id="10" string="be forthcoming" type="VP">
          <tokens>
            <token id="16" string="be" />
            <token id="17" string="forthcoming" />
          </tokens>
        </chunking>
        <chunking id="11" string="forthcoming" type="ADJP">
          <tokens>
            <token id="17" string="forthcoming" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">added</governor>
          <dependent id="2">Kohl</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">added</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">concerned</governor>
          <dependent id="6">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">concerned</governor>
          <dependent id="7">'m</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">added</governor>
          <dependent id="8">concerned</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">candor</governor>
          <dependent id="9">about</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">candor</governor>
          <dependent id="10">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">concerned</governor>
          <dependent id="11">candor</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">willingness</governor>
          <dependent id="13">his</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="11">candor</governor>
          <dependent id="14">willingness</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">forthcoming</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">forthcoming</governor>
          <dependent id="16">be</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">willingness</governor>
          <dependent id="17">forthcoming</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Kohl" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Kohl" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>; Today, Kohl asked the nominee, &amp;quot;Is it fair of you to say to us, for the most part, just view me on what I&amp;apost;m saying here this week?&amp;quot;</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Kohl" lemma="Kohl" stem="kohl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="asked" lemma="ask" stem="ask" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="nominee" lemma="nominee" stem="nomine" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="Is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="fair" lemma="fair" stem="fair" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="us" lemma="we" stem="u" pos="PRP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="most" lemma="most" stem="most" pos="JJS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="part" lemma="part" stem="part" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="view" lemma="view" stem="view" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="27" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="32" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="33" string="here" lemma="here" stem="here" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="true" />
        <token id="35" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="true" />
        <token id="36" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="37" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
      </tokens>
      <syntactictree>(ROOT (PRN (: ;) (S (NP (NN Today)) (, ,) (NP (NNP Kohl)) (VP (VBD asked) (NP (NP (DT the) (NN nominee)) (, ,) (`` ``) (SQ (VBZ Is) (NP (PRP it)) (ADJP (JJ fair) (PP (IN of) (S (NP (PRP you)) (VP (TO to) (VP (VP (VB say) (PP (TO to) (NP (PRP us))) (, ,) (PP (IN for) (NP (DT the) (JJS most) (NN part)))) (, ,) (ADVP (RB just)) (VP (VB view) (NP (PRP me)) (PP (IN on) (SBAR (WHNP (WP what)) (S (NP (PRP I)) (VP (VBP 'm) (VP (VBG saying) (ADVP (RB here)) (NP-TMP (DT this) (NN week)))))))))))))) (. ?) ('' ''))))))</syntactictree>
      <chunkings>
        <chunking id="1" string="view me on what I 'm saying here this week" type="VP">
          <tokens>
            <token id="26" string="view" />
            <token id="27" string="me" />
            <token id="28" string="on" />
            <token id="29" string="what" />
            <token id="30" string="I" />
            <token id="31" string="'m" />
            <token id="32" string="saying" />
            <token id="33" string="here" />
            <token id="34" string="this" />
            <token id="35" string="week" />
          </tokens>
        </chunking>
        <chunking id="2" string="Kohl" type="NP">
          <tokens>
            <token id="4" string="Kohl" />
          </tokens>
        </chunking>
        <chunking id="3" string="the nominee" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="nominee" />
          </tokens>
        </chunking>
        <chunking id="4" string="say to us , for the most part , just view me on what I 'm saying here this week" type="VP">
          <tokens>
            <token id="16" string="say" />
            <token id="17" string="to" />
            <token id="18" string="us" />
            <token id="19" string="," />
            <token id="20" string="for" />
            <token id="21" string="the" />
            <token id="22" string="most" />
            <token id="23" string="part" />
            <token id="24" string="," />
            <token id="25" string="just" />
            <token id="26" string="view" />
            <token id="27" string="me" />
            <token id="28" string="on" />
            <token id="29" string="what" />
            <token id="30" string="I" />
            <token id="31" string="'m" />
            <token id="32" string="saying" />
            <token id="33" string="here" />
            <token id="34" string="this" />
            <token id="35" string="week" />
          </tokens>
        </chunking>
        <chunking id="5" string="what I 'm saying here this week" type="SBAR">
          <tokens>
            <token id="29" string="what" />
            <token id="30" string="I" />
            <token id="31" string="'m" />
            <token id="32" string="saying" />
            <token id="33" string="here" />
            <token id="34" string="this" />
            <token id="35" string="week" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="30" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="11" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="to say to us , for the most part , just view me on what I 'm saying here this week" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="say" />
            <token id="17" string="to" />
            <token id="18" string="us" />
            <token id="19" string="," />
            <token id="20" string="for" />
            <token id="21" string="the" />
            <token id="22" string="most" />
            <token id="23" string="part" />
            <token id="24" string="," />
            <token id="25" string="just" />
            <token id="26" string="view" />
            <token id="27" string="me" />
            <token id="28" string="on" />
            <token id="29" string="what" />
            <token id="30" string="I" />
            <token id="31" string="'m" />
            <token id="32" string="saying" />
            <token id="33" string="here" />
            <token id="34" string="this" />
            <token id="35" string="week" />
          </tokens>
        </chunking>
        <chunking id="9" string="the nominee , `` Is it fair of you to say to us , for the most part , just view me on what I 'm saying here this week ? ''" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="nominee" />
            <token id="8" string="," />
            <token id="9" string="&quot;" />
            <token id="10" string="Is" />
            <token id="11" string="it" />
            <token id="12" string="fair" />
            <token id="13" string="of" />
            <token id="14" string="you" />
            <token id="15" string="to" />
            <token id="16" string="say" />
            <token id="17" string="to" />
            <token id="18" string="us" />
            <token id="19" string="," />
            <token id="20" string="for" />
            <token id="21" string="the" />
            <token id="22" string="most" />
            <token id="23" string="part" />
            <token id="24" string="," />
            <token id="25" string="just" />
            <token id="26" string="view" />
            <token id="27" string="me" />
            <token id="28" string="on" />
            <token id="29" string="what" />
            <token id="30" string="I" />
            <token id="31" string="'m" />
            <token id="32" string="saying" />
            <token id="33" string="here" />
            <token id="34" string="this" />
            <token id="35" string="week" />
            <token id="36" string="?" />
            <token id="37" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="10" string="the most part" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="most" />
            <token id="23" string="part" />
          </tokens>
        </chunking>
        <chunking id="11" string="'m saying here this week" type="VP">
          <tokens>
            <token id="31" string="'m" />
            <token id="32" string="saying" />
            <token id="33" string="here" />
            <token id="34" string="this" />
            <token id="35" string="week" />
          </tokens>
        </chunking>
        <chunking id="12" string="Today" type="NP">
          <tokens>
            <token id="2" string="Today" />
          </tokens>
        </chunking>
        <chunking id="13" string="say to us , for the most part" type="VP">
          <tokens>
            <token id="16" string="say" />
            <token id="17" string="to" />
            <token id="18" string="us" />
            <token id="19" string="," />
            <token id="20" string="for" />
            <token id="21" string="the" />
            <token id="22" string="most" />
            <token id="23" string="part" />
          </tokens>
        </chunking>
        <chunking id="14" string="me" type="NP">
          <tokens>
            <token id="27" string="me" />
          </tokens>
        </chunking>
        <chunking id="15" string="fair of you to say to us , for the most part , just view me on what I 'm saying here this week" type="ADJP">
          <tokens>
            <token id="12" string="fair" />
            <token id="13" string="of" />
            <token id="14" string="you" />
            <token id="15" string="to" />
            <token id="16" string="say" />
            <token id="17" string="to" />
            <token id="18" string="us" />
            <token id="19" string="," />
            <token id="20" string="for" />
            <token id="21" string="the" />
            <token id="22" string="most" />
            <token id="23" string="part" />
            <token id="24" string="," />
            <token id="25" string="just" />
            <token id="26" string="view" />
            <token id="27" string="me" />
            <token id="28" string="on" />
            <token id="29" string="what" />
            <token id="30" string="I" />
            <token id="31" string="'m" />
            <token id="32" string="saying" />
            <token id="33" string="here" />
            <token id="34" string="this" />
            <token id="35" string="week" />
          </tokens>
        </chunking>
        <chunking id="16" string="asked the nominee , `` Is it fair of you to say to us , for the most part , just view me on what I 'm saying here this week ? ''" type="VP">
          <tokens>
            <token id="5" string="asked" />
            <token id="6" string="the" />
            <token id="7" string="nominee" />
            <token id="8" string="," />
            <token id="9" string="&quot;" />
            <token id="10" string="Is" />
            <token id="11" string="it" />
            <token id="12" string="fair" />
            <token id="13" string="of" />
            <token id="14" string="you" />
            <token id="15" string="to" />
            <token id="16" string="say" />
            <token id="17" string="to" />
            <token id="18" string="us" />
            <token id="19" string="," />
            <token id="20" string="for" />
            <token id="21" string="the" />
            <token id="22" string="most" />
            <token id="23" string="part" />
            <token id="24" string="," />
            <token id="25" string="just" />
            <token id="26" string="view" />
            <token id="27" string="me" />
            <token id="28" string="on" />
            <token id="29" string="what" />
            <token id="30" string="I" />
            <token id="31" string="'m" />
            <token id="32" string="saying" />
            <token id="33" string="here" />
            <token id="34" string="this" />
            <token id="35" string="week" />
            <token id="36" string="?" />
            <token id="37" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="17" string="us" type="NP">
          <tokens>
            <token id="18" string="us" />
          </tokens>
        </chunking>
        <chunking id="18" string="saying here this week" type="VP">
          <tokens>
            <token id="32" string="saying" />
            <token id="33" string="here" />
            <token id="34" string="this" />
            <token id="35" string="week" />
          </tokens>
        </chunking>
        <chunking id="19" string="you" type="NP">
          <tokens>
            <token id="14" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:tmod">
          <governor id="5">asked</governor>
          <dependent id="2">Today</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">asked</governor>
          <dependent id="4">Kohl</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">asked</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">nominee</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">asked</governor>
          <dependent id="7">nominee</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">fair</governor>
          <dependent id="10">Is</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">fair</governor>
          <dependent id="11">it</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">nominee</governor>
          <dependent id="12">fair</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">say</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">say</governor>
          <dependent id="14">you</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">say</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">fair</governor>
          <dependent id="16">say</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">us</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">say</governor>
          <dependent id="18">us</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">part</governor>
          <dependent id="20">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">part</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">part</governor>
          <dependent id="22">most</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">say</governor>
          <dependent id="23">part</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">view</governor>
          <dependent id="25">just</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">say</governor>
          <dependent id="26">view</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">view</governor>
          <dependent id="27">me</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="32">saying</governor>
          <dependent id="28">on</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="32">saying</governor>
          <dependent id="29">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">saying</governor>
          <dependent id="30">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="32">saying</governor>
          <dependent id="31">'m</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="26">view</governor>
          <dependent id="32">saying</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="32">saying</governor>
          <dependent id="33">here</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">week</governor>
          <dependent id="34">this</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="32">saying</governor>
          <dependent id="35">week</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Today" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="Today" />
          </tokens>
        </entity>
        <entity id="2" string="Kohl" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Kohl" />
          </tokens>
        </entity>
        <entity id="3" string="this week" type="DATE" score="0.0">
          <tokens>
            <token id="34" string="this" />
            <token id="35" string="week" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>; Kohl asked the black federal judge whether he was offended by published comments calling his appointment by President Bush a &amp;quot;quota.&amp;quot;</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Kohl" lemma="Kohl" stem="kohl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="asked" lemma="ask" stem="ask" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="federal" lemma="federal" stem="feder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="judge" lemma="judge" stem="judg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="offended" lemma="offend" stem="offend" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="published" lemma="publish" stem="publish" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="comments" lemma="comment" stem="comment" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="calling" lemma="call" stem="call" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="17" string="appointment" lemma="appointment" stem="appoint" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="President" lemma="President" stem="presid" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="true" />
        <token id="20" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="quota" lemma="quota" stem="quota" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (PRN (: ;) (S (NP (NNP Kohl)) (VP (VBD asked) (NP (DT the) (JJ black) (JJ federal) (NN judge)) (SBAR (IN whether) (S (NP (PRP he)) (VP (VBD was) (VP (VBN offended) (PP (IN by) (NP (NP (VBN published) (NNS comments)) (VP (VBG calling) (NP (PRP$ his) (NN appointment)) (PP (IN by) (NP (NP (NNP President) (NNP Bush)) (NP (DT a) (`` ``) (NN quota))))))))) (. .) ('' '')))))))</syntactictree>
      <chunkings>
        <chunking id="1" string="Kohl" type="NP">
          <tokens>
            <token id="2" string="Kohl" />
          </tokens>
        </chunking>
        <chunking id="2" string="a `` quota" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="&quot;" />
            <token id="23" string="quota" />
          </tokens>
        </chunking>
        <chunking id="3" string="offended by published comments calling his appointment by President Bush a `` quota" type="VP">
          <tokens>
            <token id="11" string="offended" />
            <token id="12" string="by" />
            <token id="13" string="published" />
            <token id="14" string="comments" />
            <token id="15" string="calling" />
            <token id="16" string="his" />
            <token id="17" string="appointment" />
            <token id="18" string="by" />
            <token id="19" string="President" />
            <token id="20" string="Bush" />
            <token id="21" string="a" />
            <token id="22" string="&quot;" />
            <token id="23" string="quota" />
          </tokens>
        </chunking>
        <chunking id="4" string="published comments" type="NP">
          <tokens>
            <token id="13" string="published" />
            <token id="14" string="comments" />
          </tokens>
        </chunking>
        <chunking id="5" string="President Bush" type="NP">
          <tokens>
            <token id="19" string="President" />
            <token id="20" string="Bush" />
          </tokens>
        </chunking>
        <chunking id="6" string="the black federal judge" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="black" />
            <token id="6" string="federal" />
            <token id="7" string="judge" />
          </tokens>
        </chunking>
        <chunking id="7" string="was offended by published comments calling his appointment by President Bush a `` quota" type="VP">
          <tokens>
            <token id="10" string="was" />
            <token id="11" string="offended" />
            <token id="12" string="by" />
            <token id="13" string="published" />
            <token id="14" string="comments" />
            <token id="15" string="calling" />
            <token id="16" string="his" />
            <token id="17" string="appointment" />
            <token id="18" string="by" />
            <token id="19" string="President" />
            <token id="20" string="Bush" />
            <token id="21" string="a" />
            <token id="22" string="&quot;" />
            <token id="23" string="quota" />
          </tokens>
        </chunking>
        <chunking id="8" string="his appointment" type="NP">
          <tokens>
            <token id="16" string="his" />
            <token id="17" string="appointment" />
          </tokens>
        </chunking>
        <chunking id="9" string="whether he was offended by published comments calling his appointment by President Bush a `` quota . ''" type="SBAR">
          <tokens>
            <token id="8" string="whether" />
            <token id="9" string="he" />
            <token id="10" string="was" />
            <token id="11" string="offended" />
            <token id="12" string="by" />
            <token id="13" string="published" />
            <token id="14" string="comments" />
            <token id="15" string="calling" />
            <token id="16" string="his" />
            <token id="17" string="appointment" />
            <token id="18" string="by" />
            <token id="19" string="President" />
            <token id="20" string="Bush" />
            <token id="21" string="a" />
            <token id="22" string="&quot;" />
            <token id="23" string="quota" />
            <token id="24" string="." />
            <token id="25" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="10" string="President Bush a `` quota" type="NP">
          <tokens>
            <token id="19" string="President" />
            <token id="20" string="Bush" />
            <token id="21" string="a" />
            <token id="22" string="&quot;" />
            <token id="23" string="quota" />
          </tokens>
        </chunking>
        <chunking id="11" string="asked the black federal judge whether he was offended by published comments calling his appointment by President Bush a `` quota . ''" type="VP">
          <tokens>
            <token id="3" string="asked" />
            <token id="4" string="the" />
            <token id="5" string="black" />
            <token id="6" string="federal" />
            <token id="7" string="judge" />
            <token id="8" string="whether" />
            <token id="9" string="he" />
            <token id="10" string="was" />
            <token id="11" string="offended" />
            <token id="12" string="by" />
            <token id="13" string="published" />
            <token id="14" string="comments" />
            <token id="15" string="calling" />
            <token id="16" string="his" />
            <token id="17" string="appointment" />
            <token id="18" string="by" />
            <token id="19" string="President" />
            <token id="20" string="Bush" />
            <token id="21" string="a" />
            <token id="22" string="&quot;" />
            <token id="23" string="quota" />
            <token id="24" string="." />
            <token id="25" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="12" string="calling his appointment by President Bush a `` quota" type="VP">
          <tokens>
            <token id="15" string="calling" />
            <token id="16" string="his" />
            <token id="17" string="appointment" />
            <token id="18" string="by" />
            <token id="19" string="President" />
            <token id="20" string="Bush" />
            <token id="21" string="a" />
            <token id="22" string="&quot;" />
            <token id="23" string="quota" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="9" string="he" />
          </tokens>
        </chunking>
        <chunking id="14" string="published comments calling his appointment by President Bush a `` quota" type="NP">
          <tokens>
            <token id="13" string="published" />
            <token id="14" string="comments" />
            <token id="15" string="calling" />
            <token id="16" string="his" />
            <token id="17" string="appointment" />
            <token id="18" string="by" />
            <token id="19" string="President" />
            <token id="20" string="Bush" />
            <token id="21" string="a" />
            <token id="22" string="&quot;" />
            <token id="23" string="quota" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">asked</governor>
          <dependent id="2">Kohl</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">asked</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">judge</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">judge</governor>
          <dependent id="5">black</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">judge</governor>
          <dependent id="6">federal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">asked</governor>
          <dependent id="7">judge</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">offended</governor>
          <dependent id="8">whether</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="11">offended</governor>
          <dependent id="9">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="11">offended</governor>
          <dependent id="10">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">asked</governor>
          <dependent id="11">offended</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">comments</governor>
          <dependent id="12">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">comments</governor>
          <dependent id="13">published</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">offended</governor>
          <dependent id="14">comments</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">comments</governor>
          <dependent id="15">calling</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">appointment</governor>
          <dependent id="16">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">calling</governor>
          <dependent id="17">appointment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Bush</governor>
          <dependent id="18">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Bush</governor>
          <dependent id="19">President</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">calling</governor>
          <dependent id="20">Bush</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">quota</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="20">Bush</governor>
          <dependent id="23">quota</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Kohl" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Kohl" />
          </tokens>
        </entity>
        <entity id="2" string="Bush" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Bush" />
          </tokens>
        </entity>
        <entity id="3" string="President" type="TITLE" score="0.0">
          <tokens>
            <token id="19" string="President" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>; &amp;quot;That would trouble anyone,&amp;quot; Thomas said, adding, &amp;quot;I don&amp;apost;t think it&amp;apost;s accurate.&amp;quot;</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="trouble" lemma="trouble" stem="troubl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="anyone" lemma="anyone" stem="anyon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="adding" lemma="add" stem="ad" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="think" lemma="think" stem="think" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="accurate" lemma="accurate" stem="accur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (`` ``) (S (NP (DT That)) (VP (MD would) (VP (NP (NN trouble) (NN anyone))))) (, ,) ('' '') (PRN (S (NP (NNP Thomas)) (VP (VBD said) (, ,) (S (VP (VBG adding)))))) (, ,) (`` ``) (NP (PRP I)) (VP (VBP do) (RB n't) (VP (VB think) (SBAR (S (NP (PRP it)) (VP (VBZ 's) (ADJP (JJ accurate))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="That" type="NP">
          <tokens>
            <token id="3" string="That" />
          </tokens>
        </chunking>
        <chunking id="2" string="said , adding" type="VP">
          <tokens>
            <token id="10" string="said" />
            <token id="11" string="," />
            <token id="12" string="adding" />
          </tokens>
        </chunking>
        <chunking id="3" string="think it 's accurate" type="VP">
          <tokens>
            <token id="18" string="think" />
            <token id="19" string="it" />
            <token id="20" string="'s" />
            <token id="21" string="accurate" />
          </tokens>
        </chunking>
        <chunking id="4" string="accurate" type="ADJP">
          <tokens>
            <token id="21" string="accurate" />
          </tokens>
        </chunking>
        <chunking id="5" string="Thomas" type="NP">
          <tokens>
            <token id="9" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="15" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="would trouble anyone" type="VP">
          <tokens>
            <token id="4" string="would" />
            <token id="5" string="trouble" />
            <token id="6" string="anyone" />
          </tokens>
        </chunking>
        <chunking id="8" string="trouble anyone" type="VP">
          <tokens>
            <token id="5" string="trouble" />
            <token id="6" string="anyone" />
          </tokens>
        </chunking>
        <chunking id="9" string="it" type="NP">
          <tokens>
            <token id="19" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="it 's accurate" type="SBAR">
          <tokens>
            <token id="19" string="it" />
            <token id="20" string="'s" />
            <token id="21" string="accurate" />
          </tokens>
        </chunking>
        <chunking id="11" string="'s accurate" type="VP">
          <tokens>
            <token id="20" string="'s" />
            <token id="21" string="accurate" />
          </tokens>
        </chunking>
        <chunking id="12" string="adding" type="VP">
          <tokens>
            <token id="12" string="adding" />
          </tokens>
        </chunking>
        <chunking id="13" string="do n't think it 's accurate" type="VP">
          <tokens>
            <token id="16" string="do" />
            <token id="17" string="n't" />
            <token id="18" string="think" />
            <token id="19" string="it" />
            <token id="20" string="'s" />
            <token id="21" string="accurate" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">anyone</governor>
          <dependent id="3">That</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">anyone</governor>
          <dependent id="4">would</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">anyone</governor>
          <dependent id="5">trouble</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">think</governor>
          <dependent id="6">anyone</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">said</governor>
          <dependent id="9">Thomas</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="18">think</governor>
          <dependent id="10">said</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">said</governor>
          <dependent id="12">adding</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">think</governor>
          <dependent id="15">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">think</governor>
          <dependent id="16">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="18">think</governor>
          <dependent id="17">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">think</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">accurate</governor>
          <dependent id="19">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">accurate</governor>
          <dependent id="20">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">think</governor>
          <dependent id="21">accurate</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>He said Bush assured him he was picked because he was the best qualified of those potential nominees considered Thomas is expected to continue testifying through Friday.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="assured" lemma="assure" stem="assur" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="picked" lemma="pick" stem="pick" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="best" lemma="best" stem="best" pos="JJS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="qualified" lemma="qualify" stem="qualifi" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="potential" lemma="potential" stem="potenti" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="nominees" lemma="nominee" stem="nomine" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="considered" lemma="consider" stem="consid" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="21" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="expected" lemma="expect" stem="expect" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="continue" lemma="continue" stem="continu" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="testifying" lemma="testify" stem="testifi" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="Friday" lemma="Friday" stem="fridai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD said) (SBAR (S (NP (NNP Bush)) (VP (VBD assured) (NP (PRP him)) (SBAR (S (NP (PRP he)) (VP (VBD was) (VP (VBN picked) (SBAR (IN because) (S (NP (PRP he)) (VP (VBD was) (NP (NP (DT the) (ADJP (JJS best) (VBN qualified))) (PP (IN of) (NP (NP (DT those) (JJ potential) (NNS nominees)) (VP (VBN considered) (SBAR (S (NP (NNP Thomas)) (VP (VBZ is) (VP (VBN expected) (S (VP (TO to) (VP (VB continue) (S (VP (VBG testifying) (PP (IN through) (NP (NNP Friday))))))))))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="assured him he was picked because he was the best qualified of those potential nominees considered Thomas is expected to continue testifying through Friday" type="VP">
          <tokens>
            <token id="4" string="assured" />
            <token id="5" string="him" />
            <token id="6" string="he" />
            <token id="7" string="was" />
            <token id="8" string="picked" />
            <token id="9" string="because" />
            <token id="10" string="he" />
            <token id="11" string="was" />
            <token id="12" string="the" />
            <token id="13" string="best" />
            <token id="14" string="qualified" />
            <token id="15" string="of" />
            <token id="16" string="those" />
            <token id="17" string="potential" />
            <token id="18" string="nominees" />
            <token id="19" string="considered" />
            <token id="20" string="Thomas" />
            <token id="21" string="is" />
            <token id="22" string="expected" />
            <token id="23" string="to" />
            <token id="24" string="continue" />
            <token id="25" string="testifying" />
            <token id="26" string="through" />
            <token id="27" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="2" string="because he was the best qualified of those potential nominees considered Thomas is expected to continue testifying through Friday" type="SBAR">
          <tokens>
            <token id="9" string="because" />
            <token id="10" string="he" />
            <token id="11" string="was" />
            <token id="12" string="the" />
            <token id="13" string="best" />
            <token id="14" string="qualified" />
            <token id="15" string="of" />
            <token id="16" string="those" />
            <token id="17" string="potential" />
            <token id="18" string="nominees" />
            <token id="19" string="considered" />
            <token id="20" string="Thomas" />
            <token id="21" string="is" />
            <token id="22" string="expected" />
            <token id="23" string="to" />
            <token id="24" string="continue" />
            <token id="25" string="testifying" />
            <token id="26" string="through" />
            <token id="27" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="3" string="those potential nominees considered Thomas is expected to continue testifying through Friday" type="NP">
          <tokens>
            <token id="16" string="those" />
            <token id="17" string="potential" />
            <token id="18" string="nominees" />
            <token id="19" string="considered" />
            <token id="20" string="Thomas" />
            <token id="21" string="is" />
            <token id="22" string="expected" />
            <token id="23" string="to" />
            <token id="24" string="continue" />
            <token id="25" string="testifying" />
            <token id="26" string="through" />
            <token id="27" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="4" string="the best qualified of those potential nominees considered Thomas is expected to continue testifying through Friday" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="best" />
            <token id="14" string="qualified" />
            <token id="15" string="of" />
            <token id="16" string="those" />
            <token id="17" string="potential" />
            <token id="18" string="nominees" />
            <token id="19" string="considered" />
            <token id="20" string="Thomas" />
            <token id="21" string="is" />
            <token id="22" string="expected" />
            <token id="23" string="to" />
            <token id="24" string="continue" />
            <token id="25" string="testifying" />
            <token id="26" string="through" />
            <token id="27" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="5" string="Thomas" type="NP">
          <tokens>
            <token id="20" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="6" string="Bush assured him he was picked because he was the best qualified of those potential nominees considered Thomas is expected to continue testifying through Friday" type="SBAR">
          <tokens>
            <token id="3" string="Bush" />
            <token id="4" string="assured" />
            <token id="5" string="him" />
            <token id="6" string="he" />
            <token id="7" string="was" />
            <token id="8" string="picked" />
            <token id="9" string="because" />
            <token id="10" string="he" />
            <token id="11" string="was" />
            <token id="12" string="the" />
            <token id="13" string="best" />
            <token id="14" string="qualified" />
            <token id="15" string="of" />
            <token id="16" string="those" />
            <token id="17" string="potential" />
            <token id="18" string="nominees" />
            <token id="19" string="considered" />
            <token id="20" string="Thomas" />
            <token id="21" string="is" />
            <token id="22" string="expected" />
            <token id="23" string="to" />
            <token id="24" string="continue" />
            <token id="25" string="testifying" />
            <token id="26" string="through" />
            <token id="27" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="7" string="to continue testifying through Friday" type="VP">
          <tokens>
            <token id="23" string="to" />
            <token id="24" string="continue" />
            <token id="25" string="testifying" />
            <token id="26" string="through" />
            <token id="27" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="8" string="picked because he was the best qualified of those potential nominees considered Thomas is expected to continue testifying through Friday" type="VP">
          <tokens>
            <token id="8" string="picked" />
            <token id="9" string="because" />
            <token id="10" string="he" />
            <token id="11" string="was" />
            <token id="12" string="the" />
            <token id="13" string="best" />
            <token id="14" string="qualified" />
            <token id="15" string="of" />
            <token id="16" string="those" />
            <token id="17" string="potential" />
            <token id="18" string="nominees" />
            <token id="19" string="considered" />
            <token id="20" string="Thomas" />
            <token id="21" string="is" />
            <token id="22" string="expected" />
            <token id="23" string="to" />
            <token id="24" string="continue" />
            <token id="25" string="testifying" />
            <token id="26" string="through" />
            <token id="27" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="9" string="testifying through Friday" type="VP">
          <tokens>
            <token id="25" string="testifying" />
            <token id="26" string="through" />
            <token id="27" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="10" string="said Bush assured him he was picked because he was the best qualified of those potential nominees considered Thomas is expected to continue testifying through Friday" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="Bush" />
            <token id="4" string="assured" />
            <token id="5" string="him" />
            <token id="6" string="he" />
            <token id="7" string="was" />
            <token id="8" string="picked" />
            <token id="9" string="because" />
            <token id="10" string="he" />
            <token id="11" string="was" />
            <token id="12" string="the" />
            <token id="13" string="best" />
            <token id="14" string="qualified" />
            <token id="15" string="of" />
            <token id="16" string="those" />
            <token id="17" string="potential" />
            <token id="18" string="nominees" />
            <token id="19" string="considered" />
            <token id="20" string="Thomas" />
            <token id="21" string="is" />
            <token id="22" string="expected" />
            <token id="23" string="to" />
            <token id="24" string="continue" />
            <token id="25" string="testifying" />
            <token id="26" string="through" />
            <token id="27" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="11" string="considered Thomas is expected to continue testifying through Friday" type="VP">
          <tokens>
            <token id="19" string="considered" />
            <token id="20" string="Thomas" />
            <token id="21" string="is" />
            <token id="22" string="expected" />
            <token id="23" string="to" />
            <token id="24" string="continue" />
            <token id="25" string="testifying" />
            <token id="26" string="through" />
            <token id="27" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="6" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="Thomas is expected to continue testifying through Friday" type="SBAR">
          <tokens>
            <token id="20" string="Thomas" />
            <token id="21" string="is" />
            <token id="22" string="expected" />
            <token id="23" string="to" />
            <token id="24" string="continue" />
            <token id="25" string="testifying" />
            <token id="26" string="through" />
            <token id="27" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="14" string="is expected to continue testifying through Friday" type="VP">
          <tokens>
            <token id="21" string="is" />
            <token id="22" string="expected" />
            <token id="23" string="to" />
            <token id="24" string="continue" />
            <token id="25" string="testifying" />
            <token id="26" string="through" />
            <token id="27" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="15" string="the best qualified" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="best" />
            <token id="14" string="qualified" />
          </tokens>
        </chunking>
        <chunking id="16" string="expected to continue testifying through Friday" type="VP">
          <tokens>
            <token id="22" string="expected" />
            <token id="23" string="to" />
            <token id="24" string="continue" />
            <token id="25" string="testifying" />
            <token id="26" string="through" />
            <token id="27" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="17" string="him" type="NP">
          <tokens>
            <token id="5" string="him" />
          </tokens>
        </chunking>
        <chunking id="18" string="was the best qualified of those potential nominees considered Thomas is expected to continue testifying through Friday" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="the" />
            <token id="13" string="best" />
            <token id="14" string="qualified" />
            <token id="15" string="of" />
            <token id="16" string="those" />
            <token id="17" string="potential" />
            <token id="18" string="nominees" />
            <token id="19" string="considered" />
            <token id="20" string="Thomas" />
            <token id="21" string="is" />
            <token id="22" string="expected" />
            <token id="23" string="to" />
            <token id="24" string="continue" />
            <token id="25" string="testifying" />
            <token id="26" string="through" />
            <token id="27" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="19" string="best qualified" type="ADJP">
          <tokens>
            <token id="13" string="best" />
            <token id="14" string="qualified" />
          </tokens>
        </chunking>
        <chunking id="20" string="he was picked because he was the best qualified of those potential nominees considered Thomas is expected to continue testifying through Friday" type="SBAR">
          <tokens>
            <token id="6" string="he" />
            <token id="7" string="was" />
            <token id="8" string="picked" />
            <token id="9" string="because" />
            <token id="10" string="he" />
            <token id="11" string="was" />
            <token id="12" string="the" />
            <token id="13" string="best" />
            <token id="14" string="qualified" />
            <token id="15" string="of" />
            <token id="16" string="those" />
            <token id="17" string="potential" />
            <token id="18" string="nominees" />
            <token id="19" string="considered" />
            <token id="20" string="Thomas" />
            <token id="21" string="is" />
            <token id="22" string="expected" />
            <token id="23" string="to" />
            <token id="24" string="continue" />
            <token id="25" string="testifying" />
            <token id="26" string="through" />
            <token id="27" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="21" string="was picked because he was the best qualified of those potential nominees considered Thomas is expected to continue testifying through Friday" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="picked" />
            <token id="9" string="because" />
            <token id="10" string="he" />
            <token id="11" string="was" />
            <token id="12" string="the" />
            <token id="13" string="best" />
            <token id="14" string="qualified" />
            <token id="15" string="of" />
            <token id="16" string="those" />
            <token id="17" string="potential" />
            <token id="18" string="nominees" />
            <token id="19" string="considered" />
            <token id="20" string="Thomas" />
            <token id="21" string="is" />
            <token id="22" string="expected" />
            <token id="23" string="to" />
            <token id="24" string="continue" />
            <token id="25" string="testifying" />
            <token id="26" string="through" />
            <token id="27" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="22" string="Friday" type="NP">
          <tokens>
            <token id="27" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="23" string="those potential nominees" type="NP">
          <tokens>
            <token id="16" string="those" />
            <token id="17" string="potential" />
            <token id="18" string="nominees" />
          </tokens>
        </chunking>
        <chunking id="24" string="Bush" type="NP">
          <tokens>
            <token id="3" string="Bush" />
          </tokens>
        </chunking>
        <chunking id="25" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="26" string="continue testifying through Friday" type="VP">
          <tokens>
            <token id="24" string="continue" />
            <token id="25" string="testifying" />
            <token id="26" string="through" />
            <token id="27" string="Friday" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">assured</governor>
          <dependent id="3">Bush</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="4">assured</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">assured</governor>
          <dependent id="5">him</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">picked</governor>
          <dependent id="6">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">picked</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">assured</governor>
          <dependent id="8">picked</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">qualified</governor>
          <dependent id="9">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">qualified</governor>
          <dependent id="10">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">qualified</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">qualified</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">qualified</governor>
          <dependent id="13">best</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">picked</governor>
          <dependent id="14">qualified</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">nominees</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">nominees</governor>
          <dependent id="16">those</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">nominees</governor>
          <dependent id="17">potential</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">qualified</governor>
          <dependent id="18">nominees</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="18">nominees</governor>
          <dependent id="19">considered</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="22">expected</governor>
          <dependent id="20">Thomas</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="22">expected</governor>
          <dependent id="21">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">considered</governor>
          <dependent id="22">expected</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">continue</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="22">expected</governor>
          <dependent id="24">continue</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="24">continue</governor>
          <dependent id="25">testifying</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">Friday</governor>
          <dependent id="26">through</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">testifying</governor>
          <dependent id="27">Friday</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Friday" type="DATE" score="0.0">
          <tokens>
            <token id="27" string="Friday" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Thomas" />
          </tokens>
        </entity>
        <entity id="3" string="Bush" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Bush" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>The committee next week will hear from other witnesses Two pivotal members of the 14-member committee -- Howell Heflin, D-Ala., and Arlen Specter, R-Pa.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="committee" lemma="committee" stem="committe" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="next" lemma="next" stem="next" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="hear" lemma="hear" stem="hear" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="witnesses" lemma="witness" stem="wit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="11" string="pivotal" lemma="pivotal" stem="pivot" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="members" lemma="member" stem="member" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="14-member" lemma="14-member" stem="14-member" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="committee" lemma="committee" stem="committe" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Howell" lemma="Howell" stem="howel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="19" string="Heflin" lemma="Heflin" stem="heflin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="D-Ala." lemma="D-Ala." stem="d-ala." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Arlen" lemma="Arlen" stem="arlen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="25" string="Specter" lemma="Specter" stem="specter" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="R-Pa" lemma="R-Pa" stem="r-pa" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN committee)) (NP-TMP (JJ next) (NN week)) (VP (MD will) (VP (VB hear) (PP (IN from) (NP (JJ other) (NNS witnesses))) (NP (NP (NP (CD Two) (JJ pivotal) (NNS members)) (PP (IN of) (NP (DT the) (JJ 14-member) (NN committee)))) (: --) (NP (NP (NNP Howell) (NNP Heflin)) (, ,) (NP (NNP D-Ala.))) (, ,) (CC and) (NP (NP (NNP Arlen) (NNP Specter)) (, ,) (NP (NNP R-Pa)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="D-Ala." type="NP">
          <tokens>
            <token id="21" string="D-Ala." />
          </tokens>
        </chunking>
        <chunking id="2" string="Arlen Specter , R-Pa" type="NP">
          <tokens>
            <token id="24" string="Arlen" />
            <token id="25" string="Specter" />
            <token id="26" string="," />
            <token id="27" string="R-Pa" />
          </tokens>
        </chunking>
        <chunking id="3" string="other witnesses" type="NP">
          <tokens>
            <token id="8" string="other" />
            <token id="9" string="witnesses" />
          </tokens>
        </chunking>
        <chunking id="4" string="the 14-member committee" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="14-member" />
            <token id="16" string="committee" />
          </tokens>
        </chunking>
        <chunking id="5" string="Arlen Specter" type="NP">
          <tokens>
            <token id="24" string="Arlen" />
            <token id="25" string="Specter" />
          </tokens>
        </chunking>
        <chunking id="6" string="R-Pa" type="NP">
          <tokens>
            <token id="27" string="R-Pa" />
          </tokens>
        </chunking>
        <chunking id="7" string="Two pivotal members of the 14-member committee -- Howell Heflin , D-Ala. , and Arlen Specter , R-Pa" type="NP">
          <tokens>
            <token id="10" string="Two" />
            <token id="11" string="pivotal" />
            <token id="12" string="members" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="14-member" />
            <token id="16" string="committee" />
            <token id="17" string="--" />
            <token id="18" string="Howell" />
            <token id="19" string="Heflin" />
            <token id="20" string="," />
            <token id="21" string="D-Ala." />
            <token id="22" string="," />
            <token id="23" string="and" />
            <token id="24" string="Arlen" />
            <token id="25" string="Specter" />
            <token id="26" string="," />
            <token id="27" string="R-Pa" />
          </tokens>
        </chunking>
        <chunking id="8" string="Two pivotal members" type="NP">
          <tokens>
            <token id="10" string="Two" />
            <token id="11" string="pivotal" />
            <token id="12" string="members" />
          </tokens>
        </chunking>
        <chunking id="9" string="Howell Heflin , D-Ala." type="NP">
          <tokens>
            <token id="18" string="Howell" />
            <token id="19" string="Heflin" />
            <token id="20" string="," />
            <token id="21" string="D-Ala." />
          </tokens>
        </chunking>
        <chunking id="10" string="Howell Heflin" type="NP">
          <tokens>
            <token id="18" string="Howell" />
            <token id="19" string="Heflin" />
          </tokens>
        </chunking>
        <chunking id="11" string="Two pivotal members of the 14-member committee" type="NP">
          <tokens>
            <token id="10" string="Two" />
            <token id="11" string="pivotal" />
            <token id="12" string="members" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="14-member" />
            <token id="16" string="committee" />
          </tokens>
        </chunking>
        <chunking id="12" string="The committee" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="committee" />
          </tokens>
        </chunking>
        <chunking id="13" string="will hear from other witnesses Two pivotal members of the 14-member committee -- Howell Heflin , D-Ala. , and Arlen Specter , R-Pa" type="VP">
          <tokens>
            <token id="5" string="will" />
            <token id="6" string="hear" />
            <token id="7" string="from" />
            <token id="8" string="other" />
            <token id="9" string="witnesses" />
            <token id="10" string="Two" />
            <token id="11" string="pivotal" />
            <token id="12" string="members" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="14-member" />
            <token id="16" string="committee" />
            <token id="17" string="--" />
            <token id="18" string="Howell" />
            <token id="19" string="Heflin" />
            <token id="20" string="," />
            <token id="21" string="D-Ala." />
            <token id="22" string="," />
            <token id="23" string="and" />
            <token id="24" string="Arlen" />
            <token id="25" string="Specter" />
            <token id="26" string="," />
            <token id="27" string="R-Pa" />
          </tokens>
        </chunking>
        <chunking id="14" string="hear from other witnesses Two pivotal members of the 14-member committee -- Howell Heflin , D-Ala. , and Arlen Specter , R-Pa" type="VP">
          <tokens>
            <token id="6" string="hear" />
            <token id="7" string="from" />
            <token id="8" string="other" />
            <token id="9" string="witnesses" />
            <token id="10" string="Two" />
            <token id="11" string="pivotal" />
            <token id="12" string="members" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="14-member" />
            <token id="16" string="committee" />
            <token id="17" string="--" />
            <token id="18" string="Howell" />
            <token id="19" string="Heflin" />
            <token id="20" string="," />
            <token id="21" string="D-Ala." />
            <token id="22" string="," />
            <token id="23" string="and" />
            <token id="24" string="Arlen" />
            <token id="25" string="Specter" />
            <token id="26" string="," />
            <token id="27" string="R-Pa" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">committee</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">hear</governor>
          <dependent id="2">committee</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">week</governor>
          <dependent id="3">next</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="6">hear</governor>
          <dependent id="4">week</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">hear</governor>
          <dependent id="5">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">hear</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">witnesses</governor>
          <dependent id="7">from</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">witnesses</governor>
          <dependent id="8">other</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">hear</governor>
          <dependent id="9">witnesses</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">members</governor>
          <dependent id="10">Two</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">members</governor>
          <dependent id="11">pivotal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">hear</governor>
          <dependent id="12">members</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">committee</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">committee</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">committee</governor>
          <dependent id="15">14-member</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">members</governor>
          <dependent id="16">committee</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Heflin</governor>
          <dependent id="18">Howell</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">members</governor>
          <dependent id="19">Heflin</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="19">Heflin</governor>
          <dependent id="21">D-Ala.</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">members</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Specter</governor>
          <dependent id="24">Arlen</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">members</governor>
          <dependent id="25">Specter</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="25">Specter</governor>
          <dependent id="27">R-Pa</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="D-Ala." type="LOCATION" score="0.0">
          <tokens>
            <token id="21" string="D-Ala." />
          </tokens>
        </entity>
        <entity id="2" string="next week" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="next" />
            <token id="4" string="week" />
          </tokens>
        </entity>
        <entity id="3" string="Howell Heflin" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Howell" />
            <token id="19" string="Heflin" />
          </tokens>
        </entity>
        <entity id="4" string="Two" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="Two" />
          </tokens>
        </entity>
        <entity id="5" string="Arlen Specter" type="PERSON" score="0.0">
          <tokens>
            <token id="24" string="Arlen" />
            <token id="25" string="Specter" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>-- also voiced concern about Thomas&amp;apost; answers.</content>
      <tokens>
        <token id="1" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="voiced" lemma="voice" stem="voic" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="concern" lemma="concern" stem="concern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="answers" lemma="answer" stem="answer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (: --) (VP (ADVP (RB also)) (VBD voiced) (NP (NN concern)) (PP (IN about) (NP (NP (NNP Thomas) (POS ')) (NNS answers)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="concern" type="NP">
          <tokens>
            <token id="4" string="concern" />
          </tokens>
        </chunking>
        <chunking id="2" string="Thomas ' answers" type="NP">
          <tokens>
            <token id="6" string="Thomas" />
            <token id="7" string="'" />
            <token id="8" string="answers" />
          </tokens>
        </chunking>
        <chunking id="3" string="Thomas '" type="NP">
          <tokens>
            <token id="6" string="Thomas" />
            <token id="7" string="'" />
          </tokens>
        </chunking>
        <chunking id="4" string="also voiced concern about Thomas ' answers" type="VP">
          <tokens>
            <token id="2" string="also" />
            <token id="3" string="voiced" />
            <token id="4" string="concern" />
            <token id="5" string="about" />
            <token id="6" string="Thomas" />
            <token id="7" string="'" />
            <token id="8" string="answers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">voiced</governor>
          <dependent id="2">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">voiced</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">voiced</governor>
          <dependent id="4">concern</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">answers</governor>
          <dependent id="5">about</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">answers</governor>
          <dependent id="6">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Thomas</governor>
          <dependent id="7">'</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">voiced</governor>
          <dependent id="8">answers</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>But the panel&amp;apost;s traditional third swing vote, Dennis DeConcini, D-Ariz., said Thomas was doing well Thomas&amp;apost; opponents believe Republicans Strom Thurmond of South Carolina, Hatch, Charles Grassley of Iowa, Alan Simpson of Wyoming and Hank Brown of Colorado are solid Thomas backers But they hope Sens. Edward M. Kennedy, D-Mass., and Howard Metzenbaum, D-Ohio, will be joined by the three swing-vote senators and Biden, Patrick Leahy of Vermont, Simon and Kohl in voting against the nominee THOMAS&amp;apost; VIEWS; Excerpts from Clarence Thomas&amp;apost; testimony:; On abortion: &amp;quot;I have no reason or agenda to prejudge the issue . . . or a predilection to rule one way or another on the issue of abortion.&amp;quot;</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="panel" lemma="panel" stem="panel" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="traditional" lemma="traditional" stem="tradit" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="third" lemma="third" stem="third" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="7" string="swing" lemma="swing" stem="swing" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="vote" lemma="vote" stem="vote" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Dennis" lemma="Dennis" stem="denni" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="DeConcini" lemma="DeConcini" stem="deconcini" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="D-Ariz." lemma="D-Ariz." stem="d-ariz." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="17" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="doing" lemma="do" stem="do" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="21" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="22" string="opponents" lemma="opponent" stem="oppon" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="believe" lemma="believe" stem="believ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="Republicans" lemma="republican" stem="republican" pos="NNS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="25" string="Strom" lemma="Strom" stem="strom" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="26" string="Thurmond" lemma="Thurmond" stem="thurmond" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="South" lemma="South" stem="south" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="29" string="Carolina" lemma="Carolina" stem="carolina" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="Hatch" lemma="Hatch" stem="hatch" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="32" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="Charles" lemma="Charles" stem="charl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="34" string="Grassley" lemma="Grassley" stem="grasslei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="35" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="Iowa" lemma="Iowa" stem="iowa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="37" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="Alan" lemma="Alan" stem="alan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="39" string="Simpson" lemma="Simpson" stem="simpson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="40" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="Wyoming" lemma="Wyoming" stem="wyom" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="42" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="Hank" lemma="Hank" stem="hank" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="44" string="Brown" lemma="Brown" stem="brown" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="45" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="Colorado" lemma="Colorado" stem="colorado" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="47" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="solid" lemma="solid" stem="solid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="50" string="backers" lemma="backer" stem="backer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="51" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="52" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="53" string="hope" lemma="hope" stem="hope" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="54" string="Sens." lemma="Sens." stem="sens." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="55" string="Edward" lemma="Edward" stem="edward" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="56" string="M." lemma="M." stem="m." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="57" string="Kennedy" lemma="Kennedy" stem="kennedi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="58" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="59" string="D-Mass." lemma="D-Mass." stem="d-mass." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="60" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="61" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="62" string="Howard" lemma="Howard" stem="howard" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="63" string="Metzenbaum" lemma="Metzenbaum" stem="metzenbaum" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="64" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="65" string="D-Ohio" lemma="D-Ohio" stem="d-ohio" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="66" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="67" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="68" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="69" string="joined" lemma="join" stem="join" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="70" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="71" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="72" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="73" string="swing-vote" lemma="swing-vote" stem="swing-vot" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="74" string="senators" lemma="senator" stem="senat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="75" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="76" string="Biden" lemma="Biden" stem="biden" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="77" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="78" string="Patrick" lemma="Patrick" stem="patrick" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="79" string="Leahy" lemma="Leahy" stem="leahi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="80" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="81" string="Vermont" lemma="Vermont" stem="vermont" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="82" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="83" string="Simon" lemma="Simon" stem="simon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="84" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="85" string="Kohl" lemma="Kohl" stem="kohl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="86" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="87" string="voting" lemma="vote" stem="vote" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="88" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="89" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="90" string="nominee" lemma="nominee" stem="nomine" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="91" string="THOMAS" lemma="THOMAS" stem="thomas" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="92" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="93" string="VIEWS" lemma="view" stem="views" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="94" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="95" string="Excerpts" lemma="excerpt" stem="excerpt" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="96" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="97" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="98" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="99" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="100" string="testimony" lemma="testimony" stem="testimoni" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="101" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="102" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="103" string="On" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="104" string="abortion" lemma="abortion" stem="abort" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="105" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="106" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="107" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="108" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="109" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="110" string="reason" lemma="reason" stem="reason" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="111" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="112" string="agenda" lemma="agenda" stem="agenda" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="113" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="114" string="prejudge" lemma="prejudge" stem="prejudg" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="115" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="116" string="issue" lemma="issue" stem="issu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="117" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="118" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="119" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="120" string="predilection" lemma="predilection" stem="predilect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="121" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="122" string="rule" lemma="rule" stem="rule" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="123" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="124" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="125" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="126" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="127" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="128" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="129" string="issue" lemma="issue" stem="issu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="130" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="131" string="abortion" lemma="abortion" stem="abort" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="132" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="133" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NP (NP (DT the) (NN panel) (POS 's)) (JJ traditional) (JJ third) (NN swing) (NN vote)) (, ,) (NP (NNP Dennis) (NNP DeConcini)) (, ,) (NP (NNP D-Ariz.)) (, ,)) (VP (VBD said) (S (S (NP (NNP Thomas)) (VP (VBD was) (VP (VBG doing) (ADVP (RB well))))) (S (NP (NP (NNP Thomas) (POS ')) (NNS opponents)) (VP (VBP believe) (NP (NNS Republicans)))) (S (NP (NP (NNP Strom) (NNP Thurmond)) (PP (IN of) (NP (NP (NP (NNP South) (NNP Carolina) (, ,) (NNP Hatch) (, ,) (NNP Charles) (NNP Grassley)) (PP (IN of) (NP (NNP Iowa)))) (, ,) (NP (NP (NNP Alan) (NNP Simpson)) (PP (IN of) (NP (NNP Wyoming)))) (CC and) (NP (NP (NNP Hank) (NNP Brown)) (PP (IN of) (NP (NNP Colorado))))))) (VP (VBP are) (NP (JJ solid) (NNP Thomas) (NNS backers)))) (CC But) (S (NP (PRP they)) (VP (VBP hope) (NP (NP (NP (NNP Sens.) (NNP Edward) (NNP M.)) (SBAR (S (NP (NP (NNP Kennedy) (, ,) (NNP D-Mass.) (, ,) (CC and) (NNP Howard) (NNP Metzenbaum)) (, ,) (NP (NNP D-Ohio)) (, ,)) (VP (MD will) (VP (VB be) (VP (VBN joined) (PP (IN by) (NP (NP (DT the) (CD three) (JJ swing-vote) (NNS senators)) (CC and) (NP (NNP Biden)))))))))) (, ,) (NP (NP (NNP Patrick) (NNP Leahy)) (PP (IN of) (NP (NNP Vermont) (, ,) (NNP Simon) (CC and) (NNP Kohl))) (PP (IN in) (S (VP (VBG voting) (PP (IN against) (NP (NP (NP (DT the) (NN nominee)) (NP (NP (NNP THOMAS) (POS ')) (NNS VIEWS))) (: ;) (NP (NP (NNS Excerpts)) (PP (IN from) (NP (NP (NNP Clarence) (NNP Thomas) (POS ')) (NN testimony)))) (: :))))))) (: ;) (NP (NP (IN On) (NP (NN abortion))) (: :) (S (`` ``) (NP (PRP I)) (VP (VBP have) (NP (DT no) (NN reason) (CC or) (NN agenda) (S (VP (TO to) (VP (VB prejudge) (NP (DT the) (NN issue))))))))) (: ...) (CC or) (NP (DT a) (NN predilection) (S (VP (TO to) (VP (VB rule) (NP (NP (CD one) (NN way)) (CC or) (NP (DT another))) (PP (IN on) (NP (NP (DT the) (NN issue)) (PP (IN of) (NP (NN abortion)))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Excerpts" type="NP">
          <tokens>
            <token id="95" string="Excerpts" />
          </tokens>
        </chunking>
        <chunking id="2" string="Kennedy , D-Mass. , and Howard Metzenbaum , D-Ohio , will be joined by the three swing-vote senators and Biden" type="SBAR">
          <tokens>
            <token id="57" string="Kennedy" />
            <token id="58" string="," />
            <token id="59" string="D-Mass." />
            <token id="60" string="," />
            <token id="61" string="and" />
            <token id="62" string="Howard" />
            <token id="63" string="Metzenbaum" />
            <token id="64" string="," />
            <token id="65" string="D-Ohio" />
            <token id="66" string="," />
            <token id="67" string="will" />
            <token id="68" string="be" />
            <token id="69" string="joined" />
            <token id="70" string="by" />
            <token id="71" string="the" />
            <token id="72" string="three" />
            <token id="73" string="swing-vote" />
            <token id="74" string="senators" />
            <token id="75" string="and" />
            <token id="76" string="Biden" />
          </tokens>
        </chunking>
        <chunking id="3" string="Thomas" type="NP">
          <tokens>
            <token id="16" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="4" string="was doing well" type="VP">
          <tokens>
            <token id="17" string="was" />
            <token id="18" string="doing" />
            <token id="19" string="well" />
          </tokens>
        </chunking>
        <chunking id="5" string="prejudge the issue" type="VP">
          <tokens>
            <token id="114" string="prejudge" />
            <token id="115" string="the" />
            <token id="116" string="issue" />
          </tokens>
        </chunking>
        <chunking id="6" string="Iowa" type="NP">
          <tokens>
            <token id="36" string="Iowa" />
          </tokens>
        </chunking>
        <chunking id="7" string="are solid Thomas backers" type="VP">
          <tokens>
            <token id="47" string="are" />
            <token id="48" string="solid" />
            <token id="49" string="Thomas" />
            <token id="50" string="backers" />
          </tokens>
        </chunking>
        <chunking id="8" string="one way or another" type="NP">
          <tokens>
            <token id="123" string="one" />
            <token id="124" string="way" />
            <token id="125" string="or" />
            <token id="126" string="another" />
          </tokens>
        </chunking>
        <chunking id="9" string="Dennis DeConcini" type="NP">
          <tokens>
            <token id="10" string="Dennis" />
            <token id="11" string="DeConcini" />
          </tokens>
        </chunking>
        <chunking id="10" string="the panel 's traditional third swing vote , Dennis DeConcini , D-Ariz. ," type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="panel" />
            <token id="4" string="'s" />
            <token id="5" string="traditional" />
            <token id="6" string="third" />
            <token id="7" string="swing" />
            <token id="8" string="vote" />
            <token id="9" string="," />
            <token id="10" string="Dennis" />
            <token id="11" string="DeConcini" />
            <token id="12" string="," />
            <token id="13" string="D-Ariz." />
            <token id="14" string="," />
          </tokens>
        </chunking>
        <chunking id="11" string="On abortion : `` I have no reason or agenda to prejudge the issue" type="NP">
          <tokens>
            <token id="103" string="On" />
            <token id="104" string="abortion" />
            <token id="105" string=":" />
            <token id="106" string="&quot;" />
            <token id="107" string="I" />
            <token id="108" string="have" />
            <token id="109" string="no" />
            <token id="110" string="reason" />
            <token id="111" string="or" />
            <token id="112" string="agenda" />
            <token id="113" string="to" />
            <token id="114" string="prejudge" />
            <token id="115" string="the" />
            <token id="116" string="issue" />
          </tokens>
        </chunking>
        <chunking id="12" string="the panel 's" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="panel" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="Strom Thurmond" type="NP">
          <tokens>
            <token id="25" string="Strom" />
            <token id="26" string="Thurmond" />
          </tokens>
        </chunking>
        <chunking id="14" string="no reason or agenda to prejudge the issue" type="NP">
          <tokens>
            <token id="109" string="no" />
            <token id="110" string="reason" />
            <token id="111" string="or" />
            <token id="112" string="agenda" />
            <token id="113" string="to" />
            <token id="114" string="prejudge" />
            <token id="115" string="the" />
            <token id="116" string="issue" />
          </tokens>
        </chunking>
        <chunking id="15" string="doing well" type="VP">
          <tokens>
            <token id="18" string="doing" />
            <token id="19" string="well" />
          </tokens>
        </chunking>
        <chunking id="16" string="will be joined by the three swing-vote senators and Biden" type="VP">
          <tokens>
            <token id="67" string="will" />
            <token id="68" string="be" />
            <token id="69" string="joined" />
            <token id="70" string="by" />
            <token id="71" string="the" />
            <token id="72" string="three" />
            <token id="73" string="swing-vote" />
            <token id="74" string="senators" />
            <token id="75" string="and" />
            <token id="76" string="Biden" />
          </tokens>
        </chunking>
        <chunking id="17" string="the three swing-vote senators" type="NP">
          <tokens>
            <token id="71" string="the" />
            <token id="72" string="three" />
            <token id="73" string="swing-vote" />
            <token id="74" string="senators" />
          </tokens>
        </chunking>
        <chunking id="18" string="Sens. Edward M. Kennedy , D-Mass. , and Howard Metzenbaum , D-Ohio , will be joined by the three swing-vote senators and Biden" type="NP">
          <tokens>
            <token id="54" string="Sens." />
            <token id="55" string="Edward" />
            <token id="56" string="M." />
            <token id="57" string="Kennedy" />
            <token id="58" string="," />
            <token id="59" string="D-Mass." />
            <token id="60" string="," />
            <token id="61" string="and" />
            <token id="62" string="Howard" />
            <token id="63" string="Metzenbaum" />
            <token id="64" string="," />
            <token id="65" string="D-Ohio" />
            <token id="66" string="," />
            <token id="67" string="will" />
            <token id="68" string="be" />
            <token id="69" string="joined" />
            <token id="70" string="by" />
            <token id="71" string="the" />
            <token id="72" string="three" />
            <token id="73" string="swing-vote" />
            <token id="74" string="senators" />
            <token id="75" string="and" />
            <token id="76" string="Biden" />
          </tokens>
        </chunking>
        <chunking id="19" string="Thomas ' opponents" type="NP">
          <tokens>
            <token id="20" string="Thomas" />
            <token id="21" string="'" />
            <token id="22" string="opponents" />
          </tokens>
        </chunking>
        <chunking id="20" string="the panel 's traditional third swing vote" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="panel" />
            <token id="4" string="'s" />
            <token id="5" string="traditional" />
            <token id="6" string="third" />
            <token id="7" string="swing" />
            <token id="8" string="vote" />
          </tokens>
        </chunking>
        <chunking id="21" string="Clarence Thomas '" type="NP">
          <tokens>
            <token id="97" string="Clarence" />
            <token id="98" string="Thomas" />
            <token id="99" string="'" />
          </tokens>
        </chunking>
        <chunking id="22" string="Wyoming" type="NP">
          <tokens>
            <token id="41" string="Wyoming" />
          </tokens>
        </chunking>
        <chunking id="23" string="Sens. Edward M. Kennedy , D-Mass. , and Howard Metzenbaum , D-Ohio , will be joined by the three swing-vote senators and Biden , Patrick Leahy of Vermont , Simon and Kohl in voting against the nominee THOMAS ' VIEWS ; Excerpts from Clarence Thomas ' testimony : ; On abortion : `` I have no reason or agenda to prejudge the issue ... or a predilection to rule one way or another on the issue of abortion" type="NP">
          <tokens>
            <token id="54" string="Sens." />
            <token id="55" string="Edward" />
            <token id="56" string="M." />
            <token id="57" string="Kennedy" />
            <token id="58" string="," />
            <token id="59" string="D-Mass." />
            <token id="60" string="," />
            <token id="61" string="and" />
            <token id="62" string="Howard" />
            <token id="63" string="Metzenbaum" />
            <token id="64" string="," />
            <token id="65" string="D-Ohio" />
            <token id="66" string="," />
            <token id="67" string="will" />
            <token id="68" string="be" />
            <token id="69" string="joined" />
            <token id="70" string="by" />
            <token id="71" string="the" />
            <token id="72" string="three" />
            <token id="73" string="swing-vote" />
            <token id="74" string="senators" />
            <token id="75" string="and" />
            <token id="76" string="Biden" />
            <token id="77" string="," />
            <token id="78" string="Patrick" />
            <token id="79" string="Leahy" />
            <token id="80" string="of" />
            <token id="81" string="Vermont" />
            <token id="82" string="," />
            <token id="83" string="Simon" />
            <token id="84" string="and" />
            <token id="85" string="Kohl" />
            <token id="86" string="in" />
            <token id="87" string="voting" />
            <token id="88" string="against" />
            <token id="89" string="the" />
            <token id="90" string="nominee" />
            <token id="91" string="THOMAS" />
            <token id="92" string="'" />
            <token id="93" string="VIEWS" />
            <token id="94" string=";" />
            <token id="95" string="Excerpts" />
            <token id="96" string="from" />
            <token id="97" string="Clarence" />
            <token id="98" string="Thomas" />
            <token id="99" string="'" />
            <token id="100" string="testimony" />
            <token id="101" string=":" />
            <token id="102" string=";" />
            <token id="103" string="On" />
            <token id="104" string="abortion" />
            <token id="105" string=":" />
            <token id="106" string="&quot;" />
            <token id="107" string="I" />
            <token id="108" string="have" />
            <token id="109" string="no" />
            <token id="110" string="reason" />
            <token id="111" string="or" />
            <token id="112" string="agenda" />
            <token id="113" string="to" />
            <token id="114" string="prejudge" />
            <token id="115" string="the" />
            <token id="116" string="issue" />
            <token id="117" string=". . ." />
            <token id="118" string="or" />
            <token id="119" string="a" />
            <token id="120" string="predilection" />
            <token id="121" string="to" />
            <token id="122" string="rule" />
            <token id="123" string="one" />
            <token id="124" string="way" />
            <token id="125" string="or" />
            <token id="126" string="another" />
            <token id="127" string="on" />
            <token id="128" string="the" />
            <token id="129" string="issue" />
            <token id="130" string="of" />
            <token id="131" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="24" string="Patrick Leahy" type="NP">
          <tokens>
            <token id="78" string="Patrick" />
            <token id="79" string="Leahy" />
          </tokens>
        </chunking>
        <chunking id="25" string="abortion" type="NP">
          <tokens>
            <token id="104" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="26" string="Hank Brown" type="NP">
          <tokens>
            <token id="43" string="Hank" />
            <token id="44" string="Brown" />
          </tokens>
        </chunking>
        <chunking id="27" string="Kennedy , D-Mass. , and Howard Metzenbaum , D-Ohio ," type="NP">
          <tokens>
            <token id="57" string="Kennedy" />
            <token id="58" string="," />
            <token id="59" string="D-Mass." />
            <token id="60" string="," />
            <token id="61" string="and" />
            <token id="62" string="Howard" />
            <token id="63" string="Metzenbaum" />
            <token id="64" string="," />
            <token id="65" string="D-Ohio" />
            <token id="66" string="," />
          </tokens>
        </chunking>
        <chunking id="28" string="to rule one way or another on the issue of abortion" type="VP">
          <tokens>
            <token id="121" string="to" />
            <token id="122" string="rule" />
            <token id="123" string="one" />
            <token id="124" string="way" />
            <token id="125" string="or" />
            <token id="126" string="another" />
            <token id="127" string="on" />
            <token id="128" string="the" />
            <token id="129" string="issue" />
            <token id="130" string="of" />
            <token id="131" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="29" string="Vermont , Simon and Kohl" type="NP">
          <tokens>
            <token id="81" string="Vermont" />
            <token id="82" string="," />
            <token id="83" string="Simon" />
            <token id="84" string="and" />
            <token id="85" string="Kohl" />
          </tokens>
        </chunking>
        <chunking id="30" string="the issue of abortion" type="NP">
          <tokens>
            <token id="128" string="the" />
            <token id="129" string="issue" />
            <token id="130" string="of" />
            <token id="131" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="31" string="Biden" type="NP">
          <tokens>
            <token id="76" string="Biden" />
          </tokens>
        </chunking>
        <chunking id="32" string="D-Ariz." type="NP">
          <tokens>
            <token id="13" string="D-Ariz." />
          </tokens>
        </chunking>
        <chunking id="33" string="the nominee THOMAS ' VIEWS" type="NP">
          <tokens>
            <token id="89" string="the" />
            <token id="90" string="nominee" />
            <token id="91" string="THOMAS" />
            <token id="92" string="'" />
            <token id="93" string="VIEWS" />
          </tokens>
        </chunking>
        <chunking id="34" string="Strom Thurmond of South Carolina , Hatch , Charles Grassley of Iowa , Alan Simpson of Wyoming and Hank Brown of Colorado" type="NP">
          <tokens>
            <token id="25" string="Strom" />
            <token id="26" string="Thurmond" />
            <token id="27" string="of" />
            <token id="28" string="South" />
            <token id="29" string="Carolina" />
            <token id="30" string="," />
            <token id="31" string="Hatch" />
            <token id="32" string="," />
            <token id="33" string="Charles" />
            <token id="34" string="Grassley" />
            <token id="35" string="of" />
            <token id="36" string="Iowa" />
            <token id="37" string="," />
            <token id="38" string="Alan" />
            <token id="39" string="Simpson" />
            <token id="40" string="of" />
            <token id="41" string="Wyoming" />
            <token id="42" string="and" />
            <token id="43" string="Hank" />
            <token id="44" string="Brown" />
            <token id="45" string="of" />
            <token id="46" string="Colorado" />
          </tokens>
        </chunking>
        <chunking id="35" string="Clarence Thomas ' testimony" type="NP">
          <tokens>
            <token id="97" string="Clarence" />
            <token id="98" string="Thomas" />
            <token id="99" string="'" />
            <token id="100" string="testimony" />
          </tokens>
        </chunking>
        <chunking id="36" string="South Carolina , Hatch , Charles Grassley of Iowa" type="NP">
          <tokens>
            <token id="28" string="South" />
            <token id="29" string="Carolina" />
            <token id="30" string="," />
            <token id="31" string="Hatch" />
            <token id="32" string="," />
            <token id="33" string="Charles" />
            <token id="34" string="Grassley" />
            <token id="35" string="of" />
            <token id="36" string="Iowa" />
          </tokens>
        </chunking>
        <chunking id="37" string="the three swing-vote senators and Biden" type="NP">
          <tokens>
            <token id="71" string="the" />
            <token id="72" string="three" />
            <token id="73" string="swing-vote" />
            <token id="74" string="senators" />
            <token id="75" string="and" />
            <token id="76" string="Biden" />
          </tokens>
        </chunking>
        <chunking id="38" string="the nominee THOMAS ' VIEWS ; Excerpts from Clarence Thomas ' testimony :" type="NP">
          <tokens>
            <token id="89" string="the" />
            <token id="90" string="nominee" />
            <token id="91" string="THOMAS" />
            <token id="92" string="'" />
            <token id="93" string="VIEWS" />
            <token id="94" string=";" />
            <token id="95" string="Excerpts" />
            <token id="96" string="from" />
            <token id="97" string="Clarence" />
            <token id="98" string="Thomas" />
            <token id="99" string="'" />
            <token id="100" string="testimony" />
            <token id="101" string=":" />
          </tokens>
        </chunking>
        <chunking id="39" string="Thomas '" type="NP">
          <tokens>
            <token id="20" string="Thomas" />
            <token id="21" string="'" />
          </tokens>
        </chunking>
        <chunking id="40" string="joined by the three swing-vote senators and Biden" type="VP">
          <tokens>
            <token id="69" string="joined" />
            <token id="70" string="by" />
            <token id="71" string="the" />
            <token id="72" string="three" />
            <token id="73" string="swing-vote" />
            <token id="74" string="senators" />
            <token id="75" string="and" />
            <token id="76" string="Biden" />
          </tokens>
        </chunking>
        <chunking id="41" string="hope Sens. Edward M. Kennedy , D-Mass. , and Howard Metzenbaum , D-Ohio , will be joined by the three swing-vote senators and Biden , Patrick Leahy of Vermont , Simon and Kohl in voting against the nominee THOMAS ' VIEWS ; Excerpts from Clarence Thomas ' testimony : ; On abortion : `` I have no reason or agenda to prejudge the issue ... or a predilection to rule one way or another on the issue of abortion" type="VP">
          <tokens>
            <token id="53" string="hope" />
            <token id="54" string="Sens." />
            <token id="55" string="Edward" />
            <token id="56" string="M." />
            <token id="57" string="Kennedy" />
            <token id="58" string="," />
            <token id="59" string="D-Mass." />
            <token id="60" string="," />
            <token id="61" string="and" />
            <token id="62" string="Howard" />
            <token id="63" string="Metzenbaum" />
            <token id="64" string="," />
            <token id="65" string="D-Ohio" />
            <token id="66" string="," />
            <token id="67" string="will" />
            <token id="68" string="be" />
            <token id="69" string="joined" />
            <token id="70" string="by" />
            <token id="71" string="the" />
            <token id="72" string="three" />
            <token id="73" string="swing-vote" />
            <token id="74" string="senators" />
            <token id="75" string="and" />
            <token id="76" string="Biden" />
            <token id="77" string="," />
            <token id="78" string="Patrick" />
            <token id="79" string="Leahy" />
            <token id="80" string="of" />
            <token id="81" string="Vermont" />
            <token id="82" string="," />
            <token id="83" string="Simon" />
            <token id="84" string="and" />
            <token id="85" string="Kohl" />
            <token id="86" string="in" />
            <token id="87" string="voting" />
            <token id="88" string="against" />
            <token id="89" string="the" />
            <token id="90" string="nominee" />
            <token id="91" string="THOMAS" />
            <token id="92" string="'" />
            <token id="93" string="VIEWS" />
            <token id="94" string=";" />
            <token id="95" string="Excerpts" />
            <token id="96" string="from" />
            <token id="97" string="Clarence" />
            <token id="98" string="Thomas" />
            <token id="99" string="'" />
            <token id="100" string="testimony" />
            <token id="101" string=":" />
            <token id="102" string=";" />
            <token id="103" string="On" />
            <token id="104" string="abortion" />
            <token id="105" string=":" />
            <token id="106" string="&quot;" />
            <token id="107" string="I" />
            <token id="108" string="have" />
            <token id="109" string="no" />
            <token id="110" string="reason" />
            <token id="111" string="or" />
            <token id="112" string="agenda" />
            <token id="113" string="to" />
            <token id="114" string="prejudge" />
            <token id="115" string="the" />
            <token id="116" string="issue" />
            <token id="117" string=". . ." />
            <token id="118" string="or" />
            <token id="119" string="a" />
            <token id="120" string="predilection" />
            <token id="121" string="to" />
            <token id="122" string="rule" />
            <token id="123" string="one" />
            <token id="124" string="way" />
            <token id="125" string="or" />
            <token id="126" string="another" />
            <token id="127" string="on" />
            <token id="128" string="the" />
            <token id="129" string="issue" />
            <token id="130" string="of" />
            <token id="131" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="42" string="a predilection to rule one way or another on the issue of abortion" type="NP">
          <tokens>
            <token id="119" string="a" />
            <token id="120" string="predilection" />
            <token id="121" string="to" />
            <token id="122" string="rule" />
            <token id="123" string="one" />
            <token id="124" string="way" />
            <token id="125" string="or" />
            <token id="126" string="another" />
            <token id="127" string="on" />
            <token id="128" string="the" />
            <token id="129" string="issue" />
            <token id="130" string="of" />
            <token id="131" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="43" string="believe Republicans" type="VP">
          <tokens>
            <token id="23" string="believe" />
            <token id="24" string="Republicans" />
          </tokens>
        </chunking>
        <chunking id="44" string="D-Ohio" type="NP">
          <tokens>
            <token id="65" string="D-Ohio" />
          </tokens>
        </chunking>
        <chunking id="45" string="said Thomas was doing well Thomas ' opponents believe Republicans Strom Thurmond of South Carolina , Hatch , Charles Grassley of Iowa , Alan Simpson of Wyoming and Hank Brown of Colorado are solid Thomas backers But they hope Sens. Edward M. Kennedy , D-Mass. , and Howard Metzenbaum , D-Ohio , will be joined by the three swing-vote senators and Biden , Patrick Leahy of Vermont , Simon and Kohl in voting against the nominee THOMAS ' VIEWS ; Excerpts from Clarence Thomas ' testimony : ; On abortion : `` I have no reason or agenda to prejudge the issue ... or a predilection to rule one way or another on the issue of abortion" type="VP">
          <tokens>
            <token id="15" string="said" />
            <token id="16" string="Thomas" />
            <token id="17" string="was" />
            <token id="18" string="doing" />
            <token id="19" string="well" />
            <token id="20" string="Thomas" />
            <token id="21" string="'" />
            <token id="22" string="opponents" />
            <token id="23" string="believe" />
            <token id="24" string="Republicans" />
            <token id="25" string="Strom" />
            <token id="26" string="Thurmond" />
            <token id="27" string="of" />
            <token id="28" string="South" />
            <token id="29" string="Carolina" />
            <token id="30" string="," />
            <token id="31" string="Hatch" />
            <token id="32" string="," />
            <token id="33" string="Charles" />
            <token id="34" string="Grassley" />
            <token id="35" string="of" />
            <token id="36" string="Iowa" />
            <token id="37" string="," />
            <token id="38" string="Alan" />
            <token id="39" string="Simpson" />
            <token id="40" string="of" />
            <token id="41" string="Wyoming" />
            <token id="42" string="and" />
            <token id="43" string="Hank" />
            <token id="44" string="Brown" />
            <token id="45" string="of" />
            <token id="46" string="Colorado" />
            <token id="47" string="are" />
            <token id="48" string="solid" />
            <token id="49" string="Thomas" />
            <token id="50" string="backers" />
            <token id="51" string="But" />
            <token id="52" string="they" />
            <token id="53" string="hope" />
            <token id="54" string="Sens." />
            <token id="55" string="Edward" />
            <token id="56" string="M." />
            <token id="57" string="Kennedy" />
            <token id="58" string="," />
            <token id="59" string="D-Mass." />
            <token id="60" string="," />
            <token id="61" string="and" />
            <token id="62" string="Howard" />
            <token id="63" string="Metzenbaum" />
            <token id="64" string="," />
            <token id="65" string="D-Ohio" />
            <token id="66" string="," />
            <token id="67" string="will" />
            <token id="68" string="be" />
            <token id="69" string="joined" />
            <token id="70" string="by" />
            <token id="71" string="the" />
            <token id="72" string="three" />
            <token id="73" string="swing-vote" />
            <token id="74" string="senators" />
            <token id="75" string="and" />
            <token id="76" string="Biden" />
            <token id="77" string="," />
            <token id="78" string="Patrick" />
            <token id="79" string="Leahy" />
            <token id="80" string="of" />
            <token id="81" string="Vermont" />
            <token id="82" string="," />
            <token id="83" string="Simon" />
            <token id="84" string="and" />
            <token id="85" string="Kohl" />
            <token id="86" string="in" />
            <token id="87" string="voting" />
            <token id="88" string="against" />
            <token id="89" string="the" />
            <token id="90" string="nominee" />
            <token id="91" string="THOMAS" />
            <token id="92" string="'" />
            <token id="93" string="VIEWS" />
            <token id="94" string=";" />
            <token id="95" string="Excerpts" />
            <token id="96" string="from" />
            <token id="97" string="Clarence" />
            <token id="98" string="Thomas" />
            <token id="99" string="'" />
            <token id="100" string="testimony" />
            <token id="101" string=":" />
            <token id="102" string=";" />
            <token id="103" string="On" />
            <token id="104" string="abortion" />
            <token id="105" string=":" />
            <token id="106" string="&quot;" />
            <token id="107" string="I" />
            <token id="108" string="have" />
            <token id="109" string="no" />
            <token id="110" string="reason" />
            <token id="111" string="or" />
            <token id="112" string="agenda" />
            <token id="113" string="to" />
            <token id="114" string="prejudge" />
            <token id="115" string="the" />
            <token id="116" string="issue" />
            <token id="117" string=". . ." />
            <token id="118" string="or" />
            <token id="119" string="a" />
            <token id="120" string="predilection" />
            <token id="121" string="to" />
            <token id="122" string="rule" />
            <token id="123" string="one" />
            <token id="124" string="way" />
            <token id="125" string="or" />
            <token id="126" string="another" />
            <token id="127" string="on" />
            <token id="128" string="the" />
            <token id="129" string="issue" />
            <token id="130" string="of" />
            <token id="131" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="46" string="South Carolina , Hatch , Charles Grassley" type="NP">
          <tokens>
            <token id="28" string="South" />
            <token id="29" string="Carolina" />
            <token id="30" string="," />
            <token id="31" string="Hatch" />
            <token id="32" string="," />
            <token id="33" string="Charles" />
            <token id="34" string="Grassley" />
          </tokens>
        </chunking>
        <chunking id="47" string="Hank Brown of Colorado" type="NP">
          <tokens>
            <token id="43" string="Hank" />
            <token id="44" string="Brown" />
            <token id="45" string="of" />
            <token id="46" string="Colorado" />
          </tokens>
        </chunking>
        <chunking id="48" string="Kennedy , D-Mass. , and Howard Metzenbaum" type="NP">
          <tokens>
            <token id="57" string="Kennedy" />
            <token id="58" string="," />
            <token id="59" string="D-Mass." />
            <token id="60" string="," />
            <token id="61" string="and" />
            <token id="62" string="Howard" />
            <token id="63" string="Metzenbaum" />
          </tokens>
        </chunking>
        <chunking id="49" string="THOMAS ' VIEWS" type="NP">
          <tokens>
            <token id="91" string="THOMAS" />
            <token id="92" string="'" />
            <token id="93" string="VIEWS" />
          </tokens>
        </chunking>
        <chunking id="50" string="South Carolina , Hatch , Charles Grassley of Iowa , Alan Simpson of Wyoming and Hank Brown of Colorado" type="NP">
          <tokens>
            <token id="28" string="South" />
            <token id="29" string="Carolina" />
            <token id="30" string="," />
            <token id="31" string="Hatch" />
            <token id="32" string="," />
            <token id="33" string="Charles" />
            <token id="34" string="Grassley" />
            <token id="35" string="of" />
            <token id="36" string="Iowa" />
            <token id="37" string="," />
            <token id="38" string="Alan" />
            <token id="39" string="Simpson" />
            <token id="40" string="of" />
            <token id="41" string="Wyoming" />
            <token id="42" string="and" />
            <token id="43" string="Hank" />
            <token id="44" string="Brown" />
            <token id="45" string="of" />
            <token id="46" string="Colorado" />
          </tokens>
        </chunking>
        <chunking id="51" string="have no reason or agenda to prejudge the issue" type="VP">
          <tokens>
            <token id="108" string="have" />
            <token id="109" string="no" />
            <token id="110" string="reason" />
            <token id="111" string="or" />
            <token id="112" string="agenda" />
            <token id="113" string="to" />
            <token id="114" string="prejudge" />
            <token id="115" string="the" />
            <token id="116" string="issue" />
          </tokens>
        </chunking>
        <chunking id="52" string="Patrick Leahy of Vermont , Simon and Kohl in voting against the nominee THOMAS ' VIEWS ; Excerpts from Clarence Thomas ' testimony :" type="NP">
          <tokens>
            <token id="78" string="Patrick" />
            <token id="79" string="Leahy" />
            <token id="80" string="of" />
            <token id="81" string="Vermont" />
            <token id="82" string="," />
            <token id="83" string="Simon" />
            <token id="84" string="and" />
            <token id="85" string="Kohl" />
            <token id="86" string="in" />
            <token id="87" string="voting" />
            <token id="88" string="against" />
            <token id="89" string="the" />
            <token id="90" string="nominee" />
            <token id="91" string="THOMAS" />
            <token id="92" string="'" />
            <token id="93" string="VIEWS" />
            <token id="94" string=";" />
            <token id="95" string="Excerpts" />
            <token id="96" string="from" />
            <token id="97" string="Clarence" />
            <token id="98" string="Thomas" />
            <token id="99" string="'" />
            <token id="100" string="testimony" />
            <token id="101" string=":" />
          </tokens>
        </chunking>
        <chunking id="53" string="Excerpts from Clarence Thomas ' testimony" type="NP">
          <tokens>
            <token id="95" string="Excerpts" />
            <token id="96" string="from" />
            <token id="97" string="Clarence" />
            <token id="98" string="Thomas" />
            <token id="99" string="'" />
            <token id="100" string="testimony" />
          </tokens>
        </chunking>
        <chunking id="54" string="Alan Simpson of Wyoming" type="NP">
          <tokens>
            <token id="38" string="Alan" />
            <token id="39" string="Simpson" />
            <token id="40" string="of" />
            <token id="41" string="Wyoming" />
          </tokens>
        </chunking>
        <chunking id="55" string="the issue" type="NP">
          <tokens>
            <token id="115" string="the" />
            <token id="116" string="issue" />
          </tokens>
        </chunking>
        <chunking id="56" string="the nominee" type="NP">
          <tokens>
            <token id="89" string="the" />
            <token id="90" string="nominee" />
          </tokens>
        </chunking>
        <chunking id="57" string="THOMAS '" type="NP">
          <tokens>
            <token id="91" string="THOMAS" />
            <token id="92" string="'" />
          </tokens>
        </chunking>
        <chunking id="58" string="another" type="NP">
          <tokens>
            <token id="126" string="another" />
          </tokens>
        </chunking>
        <chunking id="59" string="I" type="NP">
          <tokens>
            <token id="107" string="I" />
          </tokens>
        </chunking>
        <chunking id="60" string="Alan Simpson" type="NP">
          <tokens>
            <token id="38" string="Alan" />
            <token id="39" string="Simpson" />
          </tokens>
        </chunking>
        <chunking id="61" string="be joined by the three swing-vote senators and Biden" type="VP">
          <tokens>
            <token id="68" string="be" />
            <token id="69" string="joined" />
            <token id="70" string="by" />
            <token id="71" string="the" />
            <token id="72" string="three" />
            <token id="73" string="swing-vote" />
            <token id="74" string="senators" />
            <token id="75" string="and" />
            <token id="76" string="Biden" />
          </tokens>
        </chunking>
        <chunking id="62" string="Republicans" type="NP">
          <tokens>
            <token id="24" string="Republicans" />
          </tokens>
        </chunking>
        <chunking id="63" string="they" type="NP">
          <tokens>
            <token id="52" string="they" />
          </tokens>
        </chunking>
        <chunking id="64" string="On abortion" type="NP">
          <tokens>
            <token id="103" string="On" />
            <token id="104" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="65" string="rule one way or another on the issue of abortion" type="VP">
          <tokens>
            <token id="122" string="rule" />
            <token id="123" string="one" />
            <token id="124" string="way" />
            <token id="125" string="or" />
            <token id="126" string="another" />
            <token id="127" string="on" />
            <token id="128" string="the" />
            <token id="129" string="issue" />
            <token id="130" string="of" />
            <token id="131" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="66" string="Colorado" type="NP">
          <tokens>
            <token id="46" string="Colorado" />
          </tokens>
        </chunking>
        <chunking id="67" string="solid Thomas backers" type="NP">
          <tokens>
            <token id="48" string="solid" />
            <token id="49" string="Thomas" />
            <token id="50" string="backers" />
          </tokens>
        </chunking>
        <chunking id="68" string="Sens. Edward M." type="NP">
          <tokens>
            <token id="54" string="Sens." />
            <token id="55" string="Edward" />
            <token id="56" string="M." />
          </tokens>
        </chunking>
        <chunking id="69" string="to prejudge the issue" type="VP">
          <tokens>
            <token id="113" string="to" />
            <token id="114" string="prejudge" />
            <token id="115" string="the" />
            <token id="116" string="issue" />
          </tokens>
        </chunking>
        <chunking id="70" string="one way" type="NP">
          <tokens>
            <token id="123" string="one" />
            <token id="124" string="way" />
          </tokens>
        </chunking>
        <chunking id="71" string="voting against the nominee THOMAS ' VIEWS ; Excerpts from Clarence Thomas ' testimony :" type="VP">
          <tokens>
            <token id="87" string="voting" />
            <token id="88" string="against" />
            <token id="89" string="the" />
            <token id="90" string="nominee" />
            <token id="91" string="THOMAS" />
            <token id="92" string="'" />
            <token id="93" string="VIEWS" />
            <token id="94" string=";" />
            <token id="95" string="Excerpts" />
            <token id="96" string="from" />
            <token id="97" string="Clarence" />
            <token id="98" string="Thomas" />
            <token id="99" string="'" />
            <token id="100" string="testimony" />
            <token id="101" string=":" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="15">said</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">panel</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">vote</governor>
          <dependent id="3">panel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">panel</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">vote</governor>
          <dependent id="5">traditional</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">vote</governor>
          <dependent id="6">third</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">vote</governor>
          <dependent id="7">swing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">said</governor>
          <dependent id="8">vote</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">DeConcini</governor>
          <dependent id="10">Dennis</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">vote</governor>
          <dependent id="11">DeConcini</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">vote</governor>
          <dependent id="13">D-Ariz.</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">doing</governor>
          <dependent id="16">Thomas</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">doing</governor>
          <dependent id="17">was</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">said</governor>
          <dependent id="18">doing</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">doing</governor>
          <dependent id="19">well</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">opponents</governor>
          <dependent id="20">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Thomas</governor>
          <dependent id="21">'</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">believe</governor>
          <dependent id="22">opponents</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="18">doing</governor>
          <dependent id="23">believe</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">believe</governor>
          <dependent id="24">Republicans</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Thurmond</governor>
          <dependent id="25">Strom</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="50">backers</governor>
          <dependent id="26">Thurmond</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">Grassley</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">Grassley</governor>
          <dependent id="28">South</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">Grassley</governor>
          <dependent id="29">Carolina</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="34">Grassley</governor>
          <dependent id="31">Hatch</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="34">Grassley</governor>
          <dependent id="33">Charles</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">Thurmond</governor>
          <dependent id="34">Grassley</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">Iowa</governor>
          <dependent id="35">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">Grassley</governor>
          <dependent id="36">Iowa</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="39">Simpson</governor>
          <dependent id="38">Alan</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="34">Grassley</governor>
          <dependent id="39">Simpson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">Wyoming</governor>
          <dependent id="40">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="39">Simpson</governor>
          <dependent id="41">Wyoming</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="34">Grassley</governor>
          <dependent id="42">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="44">Brown</governor>
          <dependent id="43">Hank</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="34">Grassley</governor>
          <dependent id="44">Brown</dependent>
        </dependency>
        <dependency type="case">
          <governor id="46">Colorado</governor>
          <dependent id="45">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="44">Brown</governor>
          <dependent id="46">Colorado</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="50">backers</governor>
          <dependent id="47">are</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="50">backers</governor>
          <dependent id="48">solid</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="50">backers</governor>
          <dependent id="49">Thomas</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="18">doing</governor>
          <dependent id="50">backers</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">doing</governor>
          <dependent id="51">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="53">hope</governor>
          <dependent id="52">they</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">doing</governor>
          <dependent id="53">hope</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="56">M.</governor>
          <dependent id="54">Sens.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="56">M.</governor>
          <dependent id="55">Edward</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="53">hope</governor>
          <dependent id="56">M.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="59">D-Mass.</governor>
          <dependent id="57">Kennedy</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="69">joined</governor>
          <dependent id="59">D-Mass.</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="59">D-Mass.</governor>
          <dependent id="61">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="63">Metzenbaum</governor>
          <dependent id="62">Howard</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="59">D-Mass.</governor>
          <dependent id="63">Metzenbaum</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="59">D-Mass.</governor>
          <dependent id="65">D-Ohio</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="69">joined</governor>
          <dependent id="67">will</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="69">joined</governor>
          <dependent id="68">be</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="56">M.</governor>
          <dependent id="69">joined</dependent>
        </dependency>
        <dependency type="case">
          <governor id="74">senators</governor>
          <dependent id="70">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="74">senators</governor>
          <dependent id="71">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="74">senators</governor>
          <dependent id="72">three</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="74">senators</governor>
          <dependent id="73">swing-vote</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="69">joined</governor>
          <dependent id="74">senators</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="74">senators</governor>
          <dependent id="75">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="74">senators</governor>
          <dependent id="76">Biden</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="79">Leahy</governor>
          <dependent id="78">Patrick</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="56">M.</governor>
          <dependent id="79">Leahy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="81">Vermont</governor>
          <dependent id="80">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="79">Leahy</governor>
          <dependent id="81">Vermont</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="81">Vermont</governor>
          <dependent id="83">Simon</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="81">Vermont</governor>
          <dependent id="84">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="81">Vermont</governor>
          <dependent id="85">Kohl</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="87">voting</governor>
          <dependent id="86">in</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="79">Leahy</governor>
          <dependent id="87">voting</dependent>
        </dependency>
        <dependency type="case">
          <governor id="90">nominee</governor>
          <dependent id="88">against</dependent>
        </dependency>
        <dependency type="det">
          <governor id="90">nominee</governor>
          <dependent id="89">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="87">voting</governor>
          <dependent id="90">nominee</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="93">VIEWS</governor>
          <dependent id="91">THOMAS</dependent>
        </dependency>
        <dependency type="case">
          <governor id="91">THOMAS</governor>
          <dependent id="92">'</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="90">nominee</governor>
          <dependent id="93">VIEWS</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="90">nominee</governor>
          <dependent id="95">Excerpts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="100">testimony</governor>
          <dependent id="96">from</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="98">Thomas</governor>
          <dependent id="97">Clarence</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="100">testimony</governor>
          <dependent id="98">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="98">Thomas</governor>
          <dependent id="99">'</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="95">Excerpts</governor>
          <dependent id="100">testimony</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="104">abortion</governor>
          <dependent id="103">On</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="56">M.</governor>
          <dependent id="104">abortion</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="108">have</governor>
          <dependent id="107">I</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="104">abortion</governor>
          <dependent id="108">have</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="110">reason</governor>
          <dependent id="109">no</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="108">have</governor>
          <dependent id="110">reason</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="110">reason</governor>
          <dependent id="111">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="110">reason</governor>
          <dependent id="112">agenda</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="114">prejudge</governor>
          <dependent id="113">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="110">reason</governor>
          <dependent id="114">prejudge</dependent>
        </dependency>
        <dependency type="det">
          <governor id="116">issue</governor>
          <dependent id="115">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="114">prejudge</governor>
          <dependent id="116">issue</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="56">M.</governor>
          <dependent id="118">or</dependent>
        </dependency>
        <dependency type="det">
          <governor id="120">predilection</governor>
          <dependent id="119">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="56">M.</governor>
          <dependent id="120">predilection</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="122">rule</governor>
          <dependent id="121">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="120">predilection</governor>
          <dependent id="122">rule</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="124">way</governor>
          <dependent id="123">one</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="122">rule</governor>
          <dependent id="124">way</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="124">way</governor>
          <dependent id="125">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="124">way</governor>
          <dependent id="126">another</dependent>
        </dependency>
        <dependency type="case">
          <governor id="129">issue</governor>
          <dependent id="127">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="129">issue</governor>
          <dependent id="128">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="122">rule</governor>
          <dependent id="129">issue</dependent>
        </dependency>
        <dependency type="case">
          <governor id="131">abortion</governor>
          <dependent id="130">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="129">issue</governor>
          <dependent id="131">abortion</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Kohl" type="PERSON" score="0.0">
          <tokens>
            <token id="85" string="Kohl" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="123" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Thomas" />
          </tokens>
        </entity>
        <entity id="4" string="Iowa" type="LOCATION" score="0.0">
          <tokens>
            <token id="36" string="Iowa" />
          </tokens>
        </entity>
        <entity id="5" string="D-Ohio" type="LOCATION" score="0.0">
          <tokens>
            <token id="65" string="D-Ohio" />
          </tokens>
        </entity>
        <entity id="6" string="Dennis DeConcini" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Dennis" />
            <token id="11" string="DeConcini" />
          </tokens>
        </entity>
        <entity id="7" string="Charles Grassley" type="PERSON" score="0.0">
          <tokens>
            <token id="33" string="Charles" />
            <token id="34" string="Grassley" />
          </tokens>
        </entity>
        <entity id="8" string="Strom Thurmond" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Strom" />
            <token id="26" string="Thurmond" />
          </tokens>
        </entity>
        <entity id="9" string="third" type="ORDINAL" score="0.0">
          <tokens>
            <token id="6" string="third" />
          </tokens>
        </entity>
        <entity id="10" string="Hatch" type="PERSON" score="0.0">
          <tokens>
            <token id="31" string="Hatch" />
          </tokens>
        </entity>
        <entity id="11" string="Clarence Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="97" string="Clarence" />
            <token id="98" string="Thomas" />
          </tokens>
        </entity>
        <entity id="12" string="Vermont" type="LOCATION" score="0.0">
          <tokens>
            <token id="81" string="Vermont" />
          </tokens>
        </entity>
        <entity id="13" string="Wyoming" type="LOCATION" score="0.0">
          <tokens>
            <token id="41" string="Wyoming" />
          </tokens>
        </entity>
        <entity id="14" string="Patrick Leahy" type="PERSON" score="0.0">
          <tokens>
            <token id="78" string="Patrick" />
            <token id="79" string="Leahy" />
          </tokens>
        </entity>
        <entity id="15" string="D-Mass." type="LOCATION" score="0.0">
          <tokens>
            <token id="59" string="D-Mass." />
          </tokens>
        </entity>
        <entity id="16" string="South Carolina" type="LOCATION" score="0.0">
          <tokens>
            <token id="28" string="South" />
            <token id="29" string="Carolina" />
          </tokens>
        </entity>
        <entity id="17" string="Alan Simpson" type="PERSON" score="0.0">
          <tokens>
            <token id="38" string="Alan" />
            <token id="39" string="Simpson" />
          </tokens>
        </entity>
        <entity id="18" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="72" string="three" />
          </tokens>
        </entity>
        <entity id="19" string="Hank Brown" type="PERSON" score="0.0">
          <tokens>
            <token id="43" string="Hank" />
            <token id="44" string="Brown" />
          </tokens>
        </entity>
        <entity id="20" string="Republicans" type="MISC" score="0.0">
          <tokens>
            <token id="24" string="Republicans" />
          </tokens>
        </entity>
        <entity id="21" string="Edward M. Kennedy" type="PERSON" score="0.0">
          <tokens>
            <token id="55" string="Edward" />
            <token id="56" string="M." />
            <token id="57" string="Kennedy" />
          </tokens>
        </entity>
        <entity id="22" string="Howard Metzenbaum" type="PERSON" score="0.0">
          <tokens>
            <token id="62" string="Howard" />
            <token id="63" string="Metzenbaum" />
          </tokens>
        </entity>
        <entity id="23" string="Biden" type="PERSON" score="0.0">
          <tokens>
            <token id="76" string="Biden" />
          </tokens>
        </entity>
        <entity id="24" string="Simon" type="PERSON" score="0.0">
          <tokens>
            <token id="83" string="Simon" />
          </tokens>
        </entity>
        <entity id="25" string="Colorado" type="LOCATION" score="0.0">
          <tokens>
            <token id="46" string="Colorado" />
          </tokens>
        </entity>
        <entity id="26" string="D-Ariz." type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="D-Ariz." />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>; On affirmative action: &amp;quot;The line that I drew was a line that said that we shouldn&amp;apost;t have preferences, or goals, or timetables or quotas.&amp;quot;</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="On" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="affirmative" lemma="affirmative" stem="affirm" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="action" lemma="action" stem="action" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="line" lemma="line" stem="line" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="drew" lemma="draw" stem="drew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="line" lemma="line" stem="line" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="preferences" lemma="preference" stem="prefer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="goals" lemma="goal" stem="goal" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="timetables" lemma="timetable" stem="timet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="quotas" lemma="quota" stem="quota" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PRN (: ;) (PP (IN On) (NP (JJ affirmative) (NN action)))) (: :) (S (NP (`` ``) (NP (DT The) (NN line)) (SBAR (IN that) (S (NP (PRP I)) (VP (VBD drew)))))) (VP (VBD was) (NP (NP (DT a) (NN line)) (SBAR (WHNP (WDT that)) (S (VP (VBD said) (SBAR (IN that) (S (NP (PRP we)) (VP (MD should) (RB n't) (VP (VB have) (NP (NP (NP (NNS preferences)) (, ,) (CC or) (NP (NNS goals)) (, ,)) (CC or) (NP (NNS timetables) (CC or) (NNS quotas)))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="a line that said that we should n't have preferences , or goals , or timetables or quotas" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="line" />
            <token id="15" string="that" />
            <token id="16" string="said" />
            <token id="17" string="that" />
            <token id="18" string="we" />
            <token id="19" string="should" />
            <token id="20" string="n't" />
            <token id="21" string="have" />
            <token id="22" string="preferences" />
            <token id="23" string="," />
            <token id="24" string="or" />
            <token id="25" string="goals" />
            <token id="26" string="," />
            <token id="27" string="or" />
            <token id="28" string="timetables" />
            <token id="29" string="or" />
            <token id="30" string="quotas" />
          </tokens>
        </chunking>
        <chunking id="2" string="goals" type="NP">
          <tokens>
            <token id="25" string="goals" />
          </tokens>
        </chunking>
        <chunking id="3" string="have preferences , or goals , or timetables or quotas" type="VP">
          <tokens>
            <token id="21" string="have" />
            <token id="22" string="preferences" />
            <token id="23" string="," />
            <token id="24" string="or" />
            <token id="25" string="goals" />
            <token id="26" string="," />
            <token id="27" string="or" />
            <token id="28" string="timetables" />
            <token id="29" string="or" />
            <token id="30" string="quotas" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="10" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="a line" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="line" />
          </tokens>
        </chunking>
        <chunking id="6" string="we" type="NP">
          <tokens>
            <token id="18" string="we" />
          </tokens>
        </chunking>
        <chunking id="7" string="preferences" type="NP">
          <tokens>
            <token id="22" string="preferences" />
          </tokens>
        </chunking>
        <chunking id="8" string="preferences , or goals ," type="NP">
          <tokens>
            <token id="22" string="preferences" />
            <token id="23" string="," />
            <token id="24" string="or" />
            <token id="25" string="goals" />
            <token id="26" string="," />
          </tokens>
        </chunking>
        <chunking id="9" string="drew" type="VP">
          <tokens>
            <token id="11" string="drew" />
          </tokens>
        </chunking>
        <chunking id="10" string="preferences , or goals , or timetables or quotas" type="NP">
          <tokens>
            <token id="22" string="preferences" />
            <token id="23" string="," />
            <token id="24" string="or" />
            <token id="25" string="goals" />
            <token id="26" string="," />
            <token id="27" string="or" />
            <token id="28" string="timetables" />
            <token id="29" string="or" />
            <token id="30" string="quotas" />
          </tokens>
        </chunking>
        <chunking id="11" string="was a line that said that we should n't have preferences , or goals , or timetables or quotas" type="VP">
          <tokens>
            <token id="12" string="was" />
            <token id="13" string="a" />
            <token id="14" string="line" />
            <token id="15" string="that" />
            <token id="16" string="said" />
            <token id="17" string="that" />
            <token id="18" string="we" />
            <token id="19" string="should" />
            <token id="20" string="n't" />
            <token id="21" string="have" />
            <token id="22" string="preferences" />
            <token id="23" string="," />
            <token id="24" string="or" />
            <token id="25" string="goals" />
            <token id="26" string="," />
            <token id="27" string="or" />
            <token id="28" string="timetables" />
            <token id="29" string="or" />
            <token id="30" string="quotas" />
          </tokens>
        </chunking>
        <chunking id="12" string="that we should n't have preferences , or goals , or timetables or quotas" type="SBAR">
          <tokens>
            <token id="17" string="that" />
            <token id="18" string="we" />
            <token id="19" string="should" />
            <token id="20" string="n't" />
            <token id="21" string="have" />
            <token id="22" string="preferences" />
            <token id="23" string="," />
            <token id="24" string="or" />
            <token id="25" string="goals" />
            <token id="26" string="," />
            <token id="27" string="or" />
            <token id="28" string="timetables" />
            <token id="29" string="or" />
            <token id="30" string="quotas" />
          </tokens>
        </chunking>
        <chunking id="13" string="that I drew" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="I" />
            <token id="11" string="drew" />
          </tokens>
        </chunking>
        <chunking id="14" string="should n't have preferences , or goals , or timetables or quotas" type="VP">
          <tokens>
            <token id="19" string="should" />
            <token id="20" string="n't" />
            <token id="21" string="have" />
            <token id="22" string="preferences" />
            <token id="23" string="," />
            <token id="24" string="or" />
            <token id="25" string="goals" />
            <token id="26" string="," />
            <token id="27" string="or" />
            <token id="28" string="timetables" />
            <token id="29" string="or" />
            <token id="30" string="quotas" />
          </tokens>
        </chunking>
        <chunking id="15" string="affirmative action" type="NP">
          <tokens>
            <token id="3" string="affirmative" />
            <token id="4" string="action" />
          </tokens>
        </chunking>
        <chunking id="16" string="The line" type="NP">
          <tokens>
            <token id="7" string="The" />
            <token id="8" string="line" />
          </tokens>
        </chunking>
        <chunking id="17" string="that said that we should n't have preferences , or goals , or timetables or quotas" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="said" />
            <token id="17" string="that" />
            <token id="18" string="we" />
            <token id="19" string="should" />
            <token id="20" string="n't" />
            <token id="21" string="have" />
            <token id="22" string="preferences" />
            <token id="23" string="," />
            <token id="24" string="or" />
            <token id="25" string="goals" />
            <token id="26" string="," />
            <token id="27" string="or" />
            <token id="28" string="timetables" />
            <token id="29" string="or" />
            <token id="30" string="quotas" />
          </tokens>
        </chunking>
        <chunking id="18" string="said that we should n't have preferences , or goals , or timetables or quotas" type="VP">
          <tokens>
            <token id="16" string="said" />
            <token id="17" string="that" />
            <token id="18" string="we" />
            <token id="19" string="should" />
            <token id="20" string="n't" />
            <token id="21" string="have" />
            <token id="22" string="preferences" />
            <token id="23" string="," />
            <token id="24" string="or" />
            <token id="25" string="goals" />
            <token id="26" string="," />
            <token id="27" string="or" />
            <token id="28" string="timetables" />
            <token id="29" string="or" />
            <token id="30" string="quotas" />
          </tokens>
        </chunking>
        <chunking id="19" string="timetables or quotas" type="NP">
          <tokens>
            <token id="28" string="timetables" />
            <token id="29" string="or" />
            <token id="30" string="quotas" />
          </tokens>
        </chunking>
        <chunking id="20" string="`` The line that I drew" type="NP">
          <tokens>
            <token id="6" string="&quot;" />
            <token id="7" string="The" />
            <token id="8" string="line" />
            <token id="9" string="that" />
            <token id="10" string="I" />
            <token id="11" string="drew" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">action</governor>
          <dependent id="2">On</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">action</governor>
          <dependent id="3">affirmative</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">line</governor>
          <dependent id="4">action</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">line</governor>
          <dependent id="7">The</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="14">line</governor>
          <dependent id="8">line</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">drew</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">drew</governor>
          <dependent id="10">I</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">line</governor>
          <dependent id="11">drew</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">line</governor>
          <dependent id="12">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">line</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">line</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">said</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="14">line</governor>
          <dependent id="16">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">have</governor>
          <dependent id="17">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">have</governor>
          <dependent id="18">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">have</governor>
          <dependent id="19">should</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="21">have</governor>
          <dependent id="20">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">said</governor>
          <dependent id="21">have</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">have</governor>
          <dependent id="22">preferences</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">preferences</governor>
          <dependent id="24">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">preferences</governor>
          <dependent id="25">goals</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">preferences</governor>
          <dependent id="27">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">preferences</governor>
          <dependent id="28">timetables</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="28">timetables</governor>
          <dependent id="29">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="28">timetables</governor>
          <dependent id="30">quotas</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>; On natural law: &amp;quot;At no time did I feel, nor do I feel now, that natural law is anything more than the background to our Constitution.&amp;quot;</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="On" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="natural" lemma="natural" stem="natur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="12" string="feel" lemma="feel" stem="feel" pos="VBP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="nor" lemma="nor" stem="nor" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="feel" lemma="feel" stem="feel" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="natural" lemma="natural" stem="natur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="anything" lemma="anything" stem="anyth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="background" lemma="background" stem="background" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="Constitution" lemma="Constitution" stem="constitut" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (PRN (: ;) (PP (IN On) (NP (NP (JJ natural) (NN law)) (: :) (`` ``) (S (PP (IN At) (NP (NP (DT no) (NN time)) (SBAR (S (VP (VBD did) (SBAR (S (NP (PRP I)) (VP (VBP feel))))))))) (, ,) (NP (CC nor)) (VP (VBP do) (S (NP (PRP I)) (VP (VB feel) (ADVP (RB now)))) (, ,) (SBAR (IN that) (S (NP (JJ natural) (NN law)) (VP (VBZ is) (ADJP (ADJP (NN anything) (JJR more)) (PP (IN than) (NP (NP (DT the) (NN background)) (PP (TO to) (NP (PRP$ our) (NNP Constitution)))))))))) (. .)) ('' '')))))</syntactictree>
      <chunkings>
        <chunking id="1" string="natural law : `` At no time did I feel , nor do I feel now , that natural law is anything more than the background to our Constitution . ''" type="NP">
          <tokens>
            <token id="3" string="natural" />
            <token id="4" string="law" />
            <token id="5" string=":" />
            <token id="6" string="&quot;" />
            <token id="7" string="At" />
            <token id="8" string="no" />
            <token id="9" string="time" />
            <token id="10" string="did" />
            <token id="11" string="I" />
            <token id="12" string="feel" />
            <token id="13" string="," />
            <token id="14" string="nor" />
            <token id="15" string="do" />
            <token id="16" string="I" />
            <token id="17" string="feel" />
            <token id="18" string="now" />
            <token id="19" string="," />
            <token id="20" string="that" />
            <token id="21" string="natural" />
            <token id="22" string="law" />
            <token id="23" string="is" />
            <token id="24" string="anything" />
            <token id="25" string="more" />
            <token id="26" string="than" />
            <token id="27" string="the" />
            <token id="28" string="background" />
            <token id="29" string="to" />
            <token id="30" string="our" />
            <token id="31" string="Constitution" />
            <token id="32" string="." />
            <token id="33" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="2" string="anything more than the background to our Constitution" type="ADJP">
          <tokens>
            <token id="24" string="anything" />
            <token id="25" string="more" />
            <token id="26" string="than" />
            <token id="27" string="the" />
            <token id="28" string="background" />
            <token id="29" string="to" />
            <token id="30" string="our" />
            <token id="31" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="3" string="our Constitution" type="NP">
          <tokens>
            <token id="30" string="our" />
            <token id="31" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="4" string="that natural law is anything more than the background to our Constitution" type="SBAR">
          <tokens>
            <token id="20" string="that" />
            <token id="21" string="natural" />
            <token id="22" string="law" />
            <token id="23" string="is" />
            <token id="24" string="anything" />
            <token id="25" string="more" />
            <token id="26" string="than" />
            <token id="27" string="the" />
            <token id="28" string="background" />
            <token id="29" string="to" />
            <token id="30" string="our" />
            <token id="31" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="5" string="the background" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="background" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="11" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="feel" type="VP">
          <tokens>
            <token id="12" string="feel" />
          </tokens>
        </chunking>
        <chunking id="8" string="the background to our Constitution" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="background" />
            <token id="29" string="to" />
            <token id="30" string="our" />
            <token id="31" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="9" string="is anything more than the background to our Constitution" type="VP">
          <tokens>
            <token id="23" string="is" />
            <token id="24" string="anything" />
            <token id="25" string="more" />
            <token id="26" string="than" />
            <token id="27" string="the" />
            <token id="28" string="background" />
            <token id="29" string="to" />
            <token id="30" string="our" />
            <token id="31" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="10" string="nor" type="NP">
          <tokens>
            <token id="14" string="nor" />
          </tokens>
        </chunking>
        <chunking id="11" string="feel now" type="VP">
          <tokens>
            <token id="17" string="feel" />
            <token id="18" string="now" />
          </tokens>
        </chunking>
        <chunking id="12" string="do I feel now , that natural law is anything more than the background to our Constitution" type="VP">
          <tokens>
            <token id="15" string="do" />
            <token id="16" string="I" />
            <token id="17" string="feel" />
            <token id="18" string="now" />
            <token id="19" string="," />
            <token id="20" string="that" />
            <token id="21" string="natural" />
            <token id="22" string="law" />
            <token id="23" string="is" />
            <token id="24" string="anything" />
            <token id="25" string="more" />
            <token id="26" string="than" />
            <token id="27" string="the" />
            <token id="28" string="background" />
            <token id="29" string="to" />
            <token id="30" string="our" />
            <token id="31" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="13" string="I feel" type="SBAR">
          <tokens>
            <token id="11" string="I" />
            <token id="12" string="feel" />
          </tokens>
        </chunking>
        <chunking id="14" string="natural law" type="NP">
          <tokens>
            <token id="3" string="natural" />
            <token id="4" string="law" />
          </tokens>
        </chunking>
        <chunking id="15" string="no time" type="NP">
          <tokens>
            <token id="8" string="no" />
            <token id="9" string="time" />
          </tokens>
        </chunking>
        <chunking id="16" string="anything more" type="ADJP">
          <tokens>
            <token id="24" string="anything" />
            <token id="25" string="more" />
          </tokens>
        </chunking>
        <chunking id="17" string="no time did I feel" type="NP">
          <tokens>
            <token id="8" string="no" />
            <token id="9" string="time" />
            <token id="10" string="did" />
            <token id="11" string="I" />
            <token id="12" string="feel" />
          </tokens>
        </chunking>
        <chunking id="18" string="did I feel" type="SBAR">
          <tokens>
            <token id="10" string="did" />
            <token id="11" string="I" />
            <token id="12" string="feel" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">law</governor>
          <dependent id="2">On</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">law</governor>
          <dependent id="3">natural</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">law</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">time</governor>
          <dependent id="7">At</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="9">time</governor>
          <dependent id="8">no</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">do</governor>
          <dependent id="9">time</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">time</governor>
          <dependent id="10">did</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">feel</governor>
          <dependent id="11">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">did</governor>
          <dependent id="12">feel</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">do</governor>
          <dependent id="14">nor</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">law</governor>
          <dependent id="15">do</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">feel</governor>
          <dependent id="16">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">do</governor>
          <dependent id="17">feel</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">feel</governor>
          <dependent id="18">now</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">anything</governor>
          <dependent id="20">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">law</governor>
          <dependent id="21">natural</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">anything</governor>
          <dependent id="22">law</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="24">anything</governor>
          <dependent id="23">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">do</governor>
          <dependent id="24">anything</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="24">anything</governor>
          <dependent id="25">more</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">background</governor>
          <dependent id="26">than</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">background</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">anything</governor>
          <dependent id="28">background</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">Constitution</governor>
          <dependent id="29">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="31">Constitution</governor>
          <dependent id="30">our</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">background</governor>
          <dependent id="31">Constitution</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="18" string="now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>; HEAR IT, SEE IT; Senate confirmation hearings for Supreme Court nominee Clarence Thomas are scheduled to run through Friday this week and every weekday except Wednesday next week RADIO; (box) KQED, 88.5 FM Tape delay beginning at 9 a.m repeated at 9:30 p.m (box) KPFA, 94.1 FM Live coverage begins at 6:30 a.m TELEVISION; (box) C-SPAN Live coverage begins at 7 a.m repeated at 5 p.m (box) CNN Intermittent coverage.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="HEAR" lemma="hear" stem="hear" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="IT" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="SEE" lemma="see" stem="see" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="IT" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="9" string="confirmation" lemma="confirmation" stem="confirm" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="hearings" lemma="hearing" stem="hear" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Supreme" lemma="Supreme" stem="suprem" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="13" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="14" string="nominee" lemma="nominee" stem="nomine" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="16" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="17" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="scheduled" lemma="schedule" stem="schedul" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="run" lemma="run" stem="run" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Friday" lemma="Friday" stem="fridai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="24" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="weekday" lemma="weekday" stem="weekdai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="except" lemma="except" stem="except" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="Wednesday" lemma="Wednesday" stem="wednesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="30" string="next" lemma="next" stem="next" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="31" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="32" string="RADIO" lemma="radio" stem="radio" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="box" lemma="box" stem="box" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="KQED" lemma="kqed" stem="kqed" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="38" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="88.5" lemma="88.5" stem="88.5" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="40" string="FM" lemma="FM" stem="fm" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="41" string="Tape" lemma="Tape" stem="tape" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="42" string="delay" lemma="delay" stem="delai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="beginning" lemma="begin" stem="begin" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="9" lemma="9" stem="9" pos="CD" type="Number" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="46" string="a.m" lemma="a.m" stem="a.m" pos="RB" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="47" string="repeated" lemma="repeat" stem="repeat" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="9:30" lemma="9:30" stem="9:30" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="50" string="p.m" lemma="p.m" stem="p.m" pos="RB" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="51" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="52" string="box" lemma="box" stem="box" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="53" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="54" string="KPFA" lemma="kpfa" stem="kpfa" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="55" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="56" string="94.1" lemma="94.1" stem="94.1" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="57" string="FM" lemma="FM" stem="fm" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="58" string="Live" lemma="Live" stem="live" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="59" string="coverage" lemma="coverage" stem="coverag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="60" string="begins" lemma="begin" stem="begin" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="61" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="62" string="6:30" lemma="6:30" stem="6:30" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="63" string="a.m" lemma="a.m" stem="a.m" pos="RB" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="64" string="TELEVISION" lemma="television" stem="television" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="65" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="66" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="67" string="box" lemma="box" stem="box" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="68" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="69" string="C-SPAN" lemma="C-SPAN" stem="c-span" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="70" string="Live" lemma="Live" stem="live" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="71" string="coverage" lemma="coverage" stem="coverag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="72" string="begins" lemma="begin" stem="begin" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="73" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="74" string="7" lemma="7" stem="7" pos="CD" type="Number" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="75" string="a.m" lemma="a.m" stem="a.m" pos="RB" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="76" string="repeated" lemma="repeat" stem="repeat" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="77" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="78" string="5" lemma="5" stem="5" pos="CD" type="Number" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="79" string="p.m" lemma="p.m" stem="p.m" pos="RB" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="80" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="81" string="box" lemma="box" stem="box" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="82" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="83" string="CNN" lemma="CNN" stem="cnn" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="84" string="Intermittent" lemma="intermittent" stem="intermitt" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="85" string="coverage" lemma="coverage" stem="coverag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="86" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (S (VP (VBP HEAR) (NP (PRP IT)))) (, ,) (VP (VBP SEE) (NP (PRP IT)) (: ;) (S (NP (NP (NNP Senate) (NN confirmation) (NNS hearings)) (SBAR (S (SBAR (IN for) (S (NP (NNP Supreme) (NNP Court) (NN nominee) (NNP Clarence) (NNP Thomas)) (VP (VBP are) (VP (VBN scheduled) (S (VP (TO to) (VP (VB run) (PP (IN through) (NP (NP (NP (NNP Friday)) (NP (DT this) (NN week))) (CC and) (NP (NP (DT every) (NN weekday)) (PP (IN except) (NP (NNP Wednesday) (JJ next) (NN week) (NN RADIO)))))) (: ;) (PRN (-LRB- -LRB-) (NP (NN box)) (-RRB- -RRB-)) (NP (NP (NN KQED)) (, ,) (NP (CD 88.5) (NNP FM) (NNP Tape) (NN delay))) (PP (VBG beginning) (PP (IN at) (NP (NP (CD 9) (RB a.m)) (VP (VBN repeated) (PP (IN at) (NP (CD 9:30) (RB p.m)) (NP (PRN (-LRB- -LRB-) (NP (NN box)) (-RRB- -RRB-)) (NN KPFA)))))))))))))) (, ,) (NP (CD 94.1) (NNP FM) (NNP Live) (NN coverage)) (VP (VBZ begins) (PP (IN at) (NP (NP (CD 6:30) (RB a.m) (NN TELEVISION)) (: ;) (NP (NP (PRN (-LRB- -LRB-) (NP (NN box)) (-RRB- -RRB-)) (NNP C-SPAN) (NNP Live)) (SBAR (S (NP (NN coverage)) (VP (VBZ begins) (PP (IN at) (NP (NP (CD 7) (RB a.m)) (VP (VBN repeated) (PP (IN at) (NP (CD 5) (RB p.m))))))))))))))) (PRN (-LRB- -LRB-) (NP (NN box)) (-RRB- -RRB-))) (NP (NNP CNN) (JJ Intermittent) (NN coverage)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="7 a.m" type="NP">
          <tokens>
            <token id="74" string="7" />
            <token id="75" string="a.m" />
          </tokens>
        </chunking>
        <chunking id="2" string="Friday this week" type="NP">
          <tokens>
            <token id="22" string="Friday" />
            <token id="23" string="this" />
            <token id="24" string="week" />
          </tokens>
        </chunking>
        <chunking id="3" string="HEAR IT" type="VP">
          <tokens>
            <token id="2" string="HEAR" />
            <token id="3" string="IT" />
          </tokens>
        </chunking>
        <chunking id="4" string="are scheduled to run through Friday this week and every weekday except Wednesday next week RADIO ; -LRB- box -RRB- KQED , 88.5 FM Tape delay beginning at 9 a.m repeated at 9:30 p.m -LRB- box -RRB- KPFA" type="VP">
          <tokens>
            <token id="17" string="are" />
            <token id="18" string="scheduled" />
            <token id="19" string="to" />
            <token id="20" string="run" />
            <token id="21" string="through" />
            <token id="22" string="Friday" />
            <token id="23" string="this" />
            <token id="24" string="week" />
            <token id="25" string="and" />
            <token id="26" string="every" />
            <token id="27" string="weekday" />
            <token id="28" string="except" />
            <token id="29" string="Wednesday" />
            <token id="30" string="next" />
            <token id="31" string="week" />
            <token id="32" string="RADIO" />
            <token id="33" string=";" />
            <token id="34" string="(" />
            <token id="35" string="box" />
            <token id="36" string=")" />
            <token id="37" string="KQED" />
            <token id="38" string="," />
            <token id="39" string="88.5" />
            <token id="40" string="FM" />
            <token id="41" string="Tape" />
            <token id="42" string="delay" />
            <token id="43" string="beginning" />
            <token id="44" string="at" />
            <token id="45" string="9" />
            <token id="46" string="a.m" />
            <token id="47" string="repeated" />
            <token id="48" string="at" />
            <token id="49" string="9:30" />
            <token id="50" string="p.m" />
            <token id="51" string="(" />
            <token id="52" string="box" />
            <token id="53" string=")" />
            <token id="54" string="KPFA" />
          </tokens>
        </chunking>
        <chunking id="5" string="KQED" type="NP">
          <tokens>
            <token id="37" string="KQED" />
          </tokens>
        </chunking>
        <chunking id="6" string="IT" type="NP">
          <tokens>
            <token id="3" string="IT" />
          </tokens>
        </chunking>
        <chunking id="7" string="7 a.m repeated at 5 p.m" type="NP">
          <tokens>
            <token id="74" string="7" />
            <token id="75" string="a.m" />
            <token id="76" string="repeated" />
            <token id="77" string="at" />
            <token id="78" string="5" />
            <token id="79" string="p.m" />
          </tokens>
        </chunking>
        <chunking id="8" string="begins at 6:30 a.m TELEVISION ; -LRB- box -RRB- C-SPAN Live coverage begins at 7 a.m repeated at 5 p.m" type="VP">
          <tokens>
            <token id="60" string="begins" />
            <token id="61" string="at" />
            <token id="62" string="6:30" />
            <token id="63" string="a.m" />
            <token id="64" string="TELEVISION" />
            <token id="65" string=";" />
            <token id="66" string="(" />
            <token id="67" string="box" />
            <token id="68" string=")" />
            <token id="69" string="C-SPAN" />
            <token id="70" string="Live" />
            <token id="71" string="coverage" />
            <token id="72" string="begins" />
            <token id="73" string="at" />
            <token id="74" string="7" />
            <token id="75" string="a.m" />
            <token id="76" string="repeated" />
            <token id="77" string="at" />
            <token id="78" string="5" />
            <token id="79" string="p.m" />
          </tokens>
        </chunking>
        <chunking id="9" string="SEE IT ; Senate confirmation hearings for Supreme Court nominee Clarence Thomas are scheduled to run through Friday this week and every weekday except Wednesday next week RADIO ; -LRB- box -RRB- KQED , 88.5 FM Tape delay beginning at 9 a.m repeated at 9:30 p.m -LRB- box -RRB- KPFA , 94.1 FM Live coverage begins at 6:30 a.m TELEVISION ; -LRB- box -RRB- C-SPAN Live coverage begins at 7 a.m repeated at 5 p.m -LRB- box -RRB- CNN Intermittent coverage" type="VP">
          <tokens>
            <token id="5" string="SEE" />
            <token id="6" string="IT" />
            <token id="7" string=";" />
            <token id="8" string="Senate" />
            <token id="9" string="confirmation" />
            <token id="10" string="hearings" />
            <token id="11" string="for" />
            <token id="12" string="Supreme" />
            <token id="13" string="Court" />
            <token id="14" string="nominee" />
            <token id="15" string="Clarence" />
            <token id="16" string="Thomas" />
            <token id="17" string="are" />
            <token id="18" string="scheduled" />
            <token id="19" string="to" />
            <token id="20" string="run" />
            <token id="21" string="through" />
            <token id="22" string="Friday" />
            <token id="23" string="this" />
            <token id="24" string="week" />
            <token id="25" string="and" />
            <token id="26" string="every" />
            <token id="27" string="weekday" />
            <token id="28" string="except" />
            <token id="29" string="Wednesday" />
            <token id="30" string="next" />
            <token id="31" string="week" />
            <token id="32" string="RADIO" />
            <token id="33" string=";" />
            <token id="34" string="(" />
            <token id="35" string="box" />
            <token id="36" string=")" />
            <token id="37" string="KQED" />
            <token id="38" string="," />
            <token id="39" string="88.5" />
            <token id="40" string="FM" />
            <token id="41" string="Tape" />
            <token id="42" string="delay" />
            <token id="43" string="beginning" />
            <token id="44" string="at" />
            <token id="45" string="9" />
            <token id="46" string="a.m" />
            <token id="47" string="repeated" />
            <token id="48" string="at" />
            <token id="49" string="9:30" />
            <token id="50" string="p.m" />
            <token id="51" string="(" />
            <token id="52" string="box" />
            <token id="53" string=")" />
            <token id="54" string="KPFA" />
            <token id="55" string="," />
            <token id="56" string="94.1" />
            <token id="57" string="FM" />
            <token id="58" string="Live" />
            <token id="59" string="coverage" />
            <token id="60" string="begins" />
            <token id="61" string="at" />
            <token id="62" string="6:30" />
            <token id="63" string="a.m" />
            <token id="64" string="TELEVISION" />
            <token id="65" string=";" />
            <token id="66" string="(" />
            <token id="67" string="box" />
            <token id="68" string=")" />
            <token id="69" string="C-SPAN" />
            <token id="70" string="Live" />
            <token id="71" string="coverage" />
            <token id="72" string="begins" />
            <token id="73" string="at" />
            <token id="74" string="7" />
            <token id="75" string="a.m" />
            <token id="76" string="repeated" />
            <token id="77" string="at" />
            <token id="78" string="5" />
            <token id="79" string="p.m" />
            <token id="80" string="(" />
            <token id="81" string="box" />
            <token id="82" string=")" />
            <token id="83" string="CNN" />
            <token id="84" string="Intermittent" />
            <token id="85" string="coverage" />
          </tokens>
        </chunking>
        <chunking id="10" string="Friday this week and every weekday except Wednesday next week RADIO" type="NP">
          <tokens>
            <token id="22" string="Friday" />
            <token id="23" string="this" />
            <token id="24" string="week" />
            <token id="25" string="and" />
            <token id="26" string="every" />
            <token id="27" string="weekday" />
            <token id="28" string="except" />
            <token id="29" string="Wednesday" />
            <token id="30" string="next" />
            <token id="31" string="week" />
            <token id="32" string="RADIO" />
          </tokens>
        </chunking>
        <chunking id="11" string="Wednesday next week RADIO" type="NP">
          <tokens>
            <token id="29" string="Wednesday" />
            <token id="30" string="next" />
            <token id="31" string="week" />
            <token id="32" string="RADIO" />
          </tokens>
        </chunking>
        <chunking id="12" string="-LRB- box -RRB- KPFA" type="NP">
          <tokens>
            <token id="51" string="(" />
            <token id="52" string="box" />
            <token id="53" string=")" />
            <token id="54" string="KPFA" />
          </tokens>
        </chunking>
        <chunking id="13" string="94.1 FM Live coverage" type="NP">
          <tokens>
            <token id="56" string="94.1" />
            <token id="57" string="FM" />
            <token id="58" string="Live" />
            <token id="59" string="coverage" />
          </tokens>
        </chunking>
        <chunking id="14" string="coverage" type="NP">
          <tokens>
            <token id="71" string="coverage" />
          </tokens>
        </chunking>
        <chunking id="15" string="Supreme Court nominee Clarence Thomas" type="NP">
          <tokens>
            <token id="12" string="Supreme" />
            <token id="13" string="Court" />
            <token id="14" string="nominee" />
            <token id="15" string="Clarence" />
            <token id="16" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="16" string="scheduled to run through Friday this week and every weekday except Wednesday next week RADIO ; -LRB- box -RRB- KQED , 88.5 FM Tape delay beginning at 9 a.m repeated at 9:30 p.m -LRB- box -RRB- KPFA" type="VP">
          <tokens>
            <token id="18" string="scheduled" />
            <token id="19" string="to" />
            <token id="20" string="run" />
            <token id="21" string="through" />
            <token id="22" string="Friday" />
            <token id="23" string="this" />
            <token id="24" string="week" />
            <token id="25" string="and" />
            <token id="26" string="every" />
            <token id="27" string="weekday" />
            <token id="28" string="except" />
            <token id="29" string="Wednesday" />
            <token id="30" string="next" />
            <token id="31" string="week" />
            <token id="32" string="RADIO" />
            <token id="33" string=";" />
            <token id="34" string="(" />
            <token id="35" string="box" />
            <token id="36" string=")" />
            <token id="37" string="KQED" />
            <token id="38" string="," />
            <token id="39" string="88.5" />
            <token id="40" string="FM" />
            <token id="41" string="Tape" />
            <token id="42" string="delay" />
            <token id="43" string="beginning" />
            <token id="44" string="at" />
            <token id="45" string="9" />
            <token id="46" string="a.m" />
            <token id="47" string="repeated" />
            <token id="48" string="at" />
            <token id="49" string="9:30" />
            <token id="50" string="p.m" />
            <token id="51" string="(" />
            <token id="52" string="box" />
            <token id="53" string=")" />
            <token id="54" string="KPFA" />
          </tokens>
        </chunking>
        <chunking id="17" string="to run through Friday this week and every weekday except Wednesday next week RADIO ; -LRB- box -RRB- KQED , 88.5 FM Tape delay beginning at 9 a.m repeated at 9:30 p.m -LRB- box -RRB- KPFA" type="VP">
          <tokens>
            <token id="19" string="to" />
            <token id="20" string="run" />
            <token id="21" string="through" />
            <token id="22" string="Friday" />
            <token id="23" string="this" />
            <token id="24" string="week" />
            <token id="25" string="and" />
            <token id="26" string="every" />
            <token id="27" string="weekday" />
            <token id="28" string="except" />
            <token id="29" string="Wednesday" />
            <token id="30" string="next" />
            <token id="31" string="week" />
            <token id="32" string="RADIO" />
            <token id="33" string=";" />
            <token id="34" string="(" />
            <token id="35" string="box" />
            <token id="36" string=")" />
            <token id="37" string="KQED" />
            <token id="38" string="," />
            <token id="39" string="88.5" />
            <token id="40" string="FM" />
            <token id="41" string="Tape" />
            <token id="42" string="delay" />
            <token id="43" string="beginning" />
            <token id="44" string="at" />
            <token id="45" string="9" />
            <token id="46" string="a.m" />
            <token id="47" string="repeated" />
            <token id="48" string="at" />
            <token id="49" string="9:30" />
            <token id="50" string="p.m" />
            <token id="51" string="(" />
            <token id="52" string="box" />
            <token id="53" string=")" />
            <token id="54" string="KPFA" />
          </tokens>
        </chunking>
        <chunking id="18" string="repeated at 5 p.m" type="VP">
          <tokens>
            <token id="76" string="repeated" />
            <token id="77" string="at" />
            <token id="78" string="5" />
            <token id="79" string="p.m" />
          </tokens>
        </chunking>
        <chunking id="19" string="88.5 FM Tape delay" type="NP">
          <tokens>
            <token id="39" string="88.5" />
            <token id="40" string="FM" />
            <token id="41" string="Tape" />
            <token id="42" string="delay" />
          </tokens>
        </chunking>
        <chunking id="20" string="6:30 a.m TELEVISION" type="NP">
          <tokens>
            <token id="62" string="6:30" />
            <token id="63" string="a.m" />
            <token id="64" string="TELEVISION" />
          </tokens>
        </chunking>
        <chunking id="21" string="5 p.m" type="NP">
          <tokens>
            <token id="78" string="5" />
            <token id="79" string="p.m" />
          </tokens>
        </chunking>
        <chunking id="22" string="9 a.m repeated at 9:30 p.m -LRB- box -RRB- KPFA" type="NP">
          <tokens>
            <token id="45" string="9" />
            <token id="46" string="a.m" />
            <token id="47" string="repeated" />
            <token id="48" string="at" />
            <token id="49" string="9:30" />
            <token id="50" string="p.m" />
            <token id="51" string="(" />
            <token id="52" string="box" />
            <token id="53" string=")" />
            <token id="54" string="KPFA" />
          </tokens>
        </chunking>
        <chunking id="23" string="-LRB- box -RRB- C-SPAN Live coverage begins at 7 a.m repeated at 5 p.m" type="NP">
          <tokens>
            <token id="66" string="(" />
            <token id="67" string="box" />
            <token id="68" string=")" />
            <token id="69" string="C-SPAN" />
            <token id="70" string="Live" />
            <token id="71" string="coverage" />
            <token id="72" string="begins" />
            <token id="73" string="at" />
            <token id="74" string="7" />
            <token id="75" string="a.m" />
            <token id="76" string="repeated" />
            <token id="77" string="at" />
            <token id="78" string="5" />
            <token id="79" string="p.m" />
          </tokens>
        </chunking>
        <chunking id="24" string="Senate confirmation hearings for Supreme Court nominee Clarence Thomas are scheduled to run through Friday this week and every weekday except Wednesday next week RADIO ; -LRB- box -RRB- KQED , 88.5 FM Tape delay beginning at 9 a.m repeated at 9:30 p.m -LRB- box -RRB- KPFA , 94.1 FM Live coverage begins at 6:30 a.m TELEVISION ; -LRB- box -RRB- C-SPAN Live coverage begins at 7 a.m repeated at 5 p.m -LRB- box -RRB-" type="NP">
          <tokens>
            <token id="8" string="Senate" />
            <token id="9" string="confirmation" />
            <token id="10" string="hearings" />
            <token id="11" string="for" />
            <token id="12" string="Supreme" />
            <token id="13" string="Court" />
            <token id="14" string="nominee" />
            <token id="15" string="Clarence" />
            <token id="16" string="Thomas" />
            <token id="17" string="are" />
            <token id="18" string="scheduled" />
            <token id="19" string="to" />
            <token id="20" string="run" />
            <token id="21" string="through" />
            <token id="22" string="Friday" />
            <token id="23" string="this" />
            <token id="24" string="week" />
            <token id="25" string="and" />
            <token id="26" string="every" />
            <token id="27" string="weekday" />
            <token id="28" string="except" />
            <token id="29" string="Wednesday" />
            <token id="30" string="next" />
            <token id="31" string="week" />
            <token id="32" string="RADIO" />
            <token id="33" string=";" />
            <token id="34" string="(" />
            <token id="35" string="box" />
            <token id="36" string=")" />
            <token id="37" string="KQED" />
            <token id="38" string="," />
            <token id="39" string="88.5" />
            <token id="40" string="FM" />
            <token id="41" string="Tape" />
            <token id="42" string="delay" />
            <token id="43" string="beginning" />
            <token id="44" string="at" />
            <token id="45" string="9" />
            <token id="46" string="a.m" />
            <token id="47" string="repeated" />
            <token id="48" string="at" />
            <token id="49" string="9:30" />
            <token id="50" string="p.m" />
            <token id="51" string="(" />
            <token id="52" string="box" />
            <token id="53" string=")" />
            <token id="54" string="KPFA" />
            <token id="55" string="," />
            <token id="56" string="94.1" />
            <token id="57" string="FM" />
            <token id="58" string="Live" />
            <token id="59" string="coverage" />
            <token id="60" string="begins" />
            <token id="61" string="at" />
            <token id="62" string="6:30" />
            <token id="63" string="a.m" />
            <token id="64" string="TELEVISION" />
            <token id="65" string=";" />
            <token id="66" string="(" />
            <token id="67" string="box" />
            <token id="68" string=")" />
            <token id="69" string="C-SPAN" />
            <token id="70" string="Live" />
            <token id="71" string="coverage" />
            <token id="72" string="begins" />
            <token id="73" string="at" />
            <token id="74" string="7" />
            <token id="75" string="a.m" />
            <token id="76" string="repeated" />
            <token id="77" string="at" />
            <token id="78" string="5" />
            <token id="79" string="p.m" />
            <token id="80" string="(" />
            <token id="81" string="box" />
            <token id="82" string=")" />
          </tokens>
        </chunking>
        <chunking id="25" string="for Supreme Court nominee Clarence Thomas are scheduled to run through Friday this week and every weekday except Wednesday next week RADIO ; -LRB- box -RRB- KQED , 88.5 FM Tape delay beginning at 9 a.m repeated at 9:30 p.m -LRB- box -RRB- KPFA" type="SBAR">
          <tokens>
            <token id="11" string="for" />
            <token id="12" string="Supreme" />
            <token id="13" string="Court" />
            <token id="14" string="nominee" />
            <token id="15" string="Clarence" />
            <token id="16" string="Thomas" />
            <token id="17" string="are" />
            <token id="18" string="scheduled" />
            <token id="19" string="to" />
            <token id="20" string="run" />
            <token id="21" string="through" />
            <token id="22" string="Friday" />
            <token id="23" string="this" />
            <token id="24" string="week" />
            <token id="25" string="and" />
            <token id="26" string="every" />
            <token id="27" string="weekday" />
            <token id="28" string="except" />
            <token id="29" string="Wednesday" />
            <token id="30" string="next" />
            <token id="31" string="week" />
            <token id="32" string="RADIO" />
            <token id="33" string=";" />
            <token id="34" string="(" />
            <token id="35" string="box" />
            <token id="36" string=")" />
            <token id="37" string="KQED" />
            <token id="38" string="," />
            <token id="39" string="88.5" />
            <token id="40" string="FM" />
            <token id="41" string="Tape" />
            <token id="42" string="delay" />
            <token id="43" string="beginning" />
            <token id="44" string="at" />
            <token id="45" string="9" />
            <token id="46" string="a.m" />
            <token id="47" string="repeated" />
            <token id="48" string="at" />
            <token id="49" string="9:30" />
            <token id="50" string="p.m" />
            <token id="51" string="(" />
            <token id="52" string="box" />
            <token id="53" string=")" />
            <token id="54" string="KPFA" />
          </tokens>
        </chunking>
        <chunking id="26" string="begins at 7 a.m repeated at 5 p.m" type="VP">
          <tokens>
            <token id="72" string="begins" />
            <token id="73" string="at" />
            <token id="74" string="7" />
            <token id="75" string="a.m" />
            <token id="76" string="repeated" />
            <token id="77" string="at" />
            <token id="78" string="5" />
            <token id="79" string="p.m" />
          </tokens>
        </chunking>
        <chunking id="27" string="6:30 a.m TELEVISION ; -LRB- box -RRB- C-SPAN Live coverage begins at 7 a.m repeated at 5 p.m" type="NP">
          <tokens>
            <token id="62" string="6:30" />
            <token id="63" string="a.m" />
            <token id="64" string="TELEVISION" />
            <token id="65" string=";" />
            <token id="66" string="(" />
            <token id="67" string="box" />
            <token id="68" string=")" />
            <token id="69" string="C-SPAN" />
            <token id="70" string="Live" />
            <token id="71" string="coverage" />
            <token id="72" string="begins" />
            <token id="73" string="at" />
            <token id="74" string="7" />
            <token id="75" string="a.m" />
            <token id="76" string="repeated" />
            <token id="77" string="at" />
            <token id="78" string="5" />
            <token id="79" string="p.m" />
          </tokens>
        </chunking>
        <chunking id="28" string="Senate confirmation hearings" type="NP">
          <tokens>
            <token id="8" string="Senate" />
            <token id="9" string="confirmation" />
            <token id="10" string="hearings" />
          </tokens>
        </chunking>
        <chunking id="29" string="every weekday" type="NP">
          <tokens>
            <token id="26" string="every" />
            <token id="27" string="weekday" />
          </tokens>
        </chunking>
        <chunking id="30" string="KQED , 88.5 FM Tape delay" type="NP">
          <tokens>
            <token id="37" string="KQED" />
            <token id="38" string="," />
            <token id="39" string="88.5" />
            <token id="40" string="FM" />
            <token id="41" string="Tape" />
            <token id="42" string="delay" />
          </tokens>
        </chunking>
        <chunking id="31" string="repeated at 9:30 p.m -LRB- box -RRB- KPFA" type="VP">
          <tokens>
            <token id="47" string="repeated" />
            <token id="48" string="at" />
            <token id="49" string="9:30" />
            <token id="50" string="p.m" />
            <token id="51" string="(" />
            <token id="52" string="box" />
            <token id="53" string=")" />
            <token id="54" string="KPFA" />
          </tokens>
        </chunking>
        <chunking id="32" string="9:30 p.m" type="NP">
          <tokens>
            <token id="49" string="9:30" />
            <token id="50" string="p.m" />
          </tokens>
        </chunking>
        <chunking id="33" string="CNN Intermittent coverage" type="NP">
          <tokens>
            <token id="83" string="CNN" />
            <token id="84" string="Intermittent" />
            <token id="85" string="coverage" />
          </tokens>
        </chunking>
        <chunking id="34" string="coverage begins at 7 a.m repeated at 5 p.m" type="SBAR">
          <tokens>
            <token id="71" string="coverage" />
            <token id="72" string="begins" />
            <token id="73" string="at" />
            <token id="74" string="7" />
            <token id="75" string="a.m" />
            <token id="76" string="repeated" />
            <token id="77" string="at" />
            <token id="78" string="5" />
            <token id="79" string="p.m" />
          </tokens>
        </chunking>
        <chunking id="35" string="box" type="NP">
          <tokens>
            <token id="35" string="box" />
          </tokens>
        </chunking>
        <chunking id="36" string="9 a.m" type="NP">
          <tokens>
            <token id="45" string="9" />
            <token id="46" string="a.m" />
          </tokens>
        </chunking>
        <chunking id="37" string="every weekday except Wednesday next week RADIO" type="NP">
          <tokens>
            <token id="26" string="every" />
            <token id="27" string="weekday" />
            <token id="28" string="except" />
            <token id="29" string="Wednesday" />
            <token id="30" string="next" />
            <token id="31" string="week" />
            <token id="32" string="RADIO" />
          </tokens>
        </chunking>
        <chunking id="38" string="-LRB- box -RRB- C-SPAN Live" type="NP">
          <tokens>
            <token id="66" string="(" />
            <token id="67" string="box" />
            <token id="68" string=")" />
            <token id="69" string="C-SPAN" />
            <token id="70" string="Live" />
          </tokens>
        </chunking>
        <chunking id="39" string="run through Friday this week and every weekday except Wednesday next week RADIO ; -LRB- box -RRB- KQED , 88.5 FM Tape delay beginning at 9 a.m repeated at 9:30 p.m -LRB- box -RRB- KPFA" type="VP">
          <tokens>
            <token id="20" string="run" />
            <token id="21" string="through" />
            <token id="22" string="Friday" />
            <token id="23" string="this" />
            <token id="24" string="week" />
            <token id="25" string="and" />
            <token id="26" string="every" />
            <token id="27" string="weekday" />
            <token id="28" string="except" />
            <token id="29" string="Wednesday" />
            <token id="30" string="next" />
            <token id="31" string="week" />
            <token id="32" string="RADIO" />
            <token id="33" string=";" />
            <token id="34" string="(" />
            <token id="35" string="box" />
            <token id="36" string=")" />
            <token id="37" string="KQED" />
            <token id="38" string="," />
            <token id="39" string="88.5" />
            <token id="40" string="FM" />
            <token id="41" string="Tape" />
            <token id="42" string="delay" />
            <token id="43" string="beginning" />
            <token id="44" string="at" />
            <token id="45" string="9" />
            <token id="46" string="a.m" />
            <token id="47" string="repeated" />
            <token id="48" string="at" />
            <token id="49" string="9:30" />
            <token id="50" string="p.m" />
            <token id="51" string="(" />
            <token id="52" string="box" />
            <token id="53" string=")" />
            <token id="54" string="KPFA" />
          </tokens>
        </chunking>
        <chunking id="40" string="for Supreme Court nominee Clarence Thomas are scheduled to run through Friday this week and every weekday except Wednesday next week RADIO ; -LRB- box -RRB- KQED , 88.5 FM Tape delay beginning at 9 a.m repeated at 9:30 p.m -LRB- box -RRB- KPFA , 94.1 FM Live coverage begins at 6:30 a.m TELEVISION ; -LRB- box -RRB- C-SPAN Live coverage begins at 7 a.m repeated at 5 p.m" type="SBAR">
          <tokens>
            <token id="11" string="for" />
            <token id="12" string="Supreme" />
            <token id="13" string="Court" />
            <token id="14" string="nominee" />
            <token id="15" string="Clarence" />
            <token id="16" string="Thomas" />
            <token id="17" string="are" />
            <token id="18" string="scheduled" />
            <token id="19" string="to" />
            <token id="20" string="run" />
            <token id="21" string="through" />
            <token id="22" string="Friday" />
            <token id="23" string="this" />
            <token id="24" string="week" />
            <token id="25" string="and" />
            <token id="26" string="every" />
            <token id="27" string="weekday" />
            <token id="28" string="except" />
            <token id="29" string="Wednesday" />
            <token id="30" string="next" />
            <token id="31" string="week" />
            <token id="32" string="RADIO" />
            <token id="33" string=";" />
            <token id="34" string="(" />
            <token id="35" string="box" />
            <token id="36" string=")" />
            <token id="37" string="KQED" />
            <token id="38" string="," />
            <token id="39" string="88.5" />
            <token id="40" string="FM" />
            <token id="41" string="Tape" />
            <token id="42" string="delay" />
            <token id="43" string="beginning" />
            <token id="44" string="at" />
            <token id="45" string="9" />
            <token id="46" string="a.m" />
            <token id="47" string="repeated" />
            <token id="48" string="at" />
            <token id="49" string="9:30" />
            <token id="50" string="p.m" />
            <token id="51" string="(" />
            <token id="52" string="box" />
            <token id="53" string=")" />
            <token id="54" string="KPFA" />
            <token id="55" string="," />
            <token id="56" string="94.1" />
            <token id="57" string="FM" />
            <token id="58" string="Live" />
            <token id="59" string="coverage" />
            <token id="60" string="begins" />
            <token id="61" string="at" />
            <token id="62" string="6:30" />
            <token id="63" string="a.m" />
            <token id="64" string="TELEVISION" />
            <token id="65" string=";" />
            <token id="66" string="(" />
            <token id="67" string="box" />
            <token id="68" string=")" />
            <token id="69" string="C-SPAN" />
            <token id="70" string="Live" />
            <token id="71" string="coverage" />
            <token id="72" string="begins" />
            <token id="73" string="at" />
            <token id="74" string="7" />
            <token id="75" string="a.m" />
            <token id="76" string="repeated" />
            <token id="77" string="at" />
            <token id="78" string="5" />
            <token id="79" string="p.m" />
          </tokens>
        </chunking>
        <chunking id="41" string="Friday" type="NP">
          <tokens>
            <token id="22" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="42" string="this week" type="NP">
          <tokens>
            <token id="23" string="this" />
            <token id="24" string="week" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="parataxis">
          <governor id="5">SEE</governor>
          <dependent id="2">HEAR</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">HEAR</governor>
          <dependent id="3">IT</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">SEE</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">SEE</governor>
          <dependent id="6">IT</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">hearings</governor>
          <dependent id="8">Senate</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">hearings</governor>
          <dependent id="9">confirmation</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="85">coverage</governor>
          <dependent id="10">hearings</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">scheduled</governor>
          <dependent id="11">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Thomas</governor>
          <dependent id="12">Supreme</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Thomas</governor>
          <dependent id="13">Court</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Thomas</governor>
          <dependent id="14">nominee</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Thomas</governor>
          <dependent id="15">Clarence</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="18">scheduled</governor>
          <dependent id="16">Thomas</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="18">scheduled</governor>
          <dependent id="17">are</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="60">begins</governor>
          <dependent id="18">scheduled</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">run</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">scheduled</governor>
          <dependent id="20">run</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">Friday</governor>
          <dependent id="21">through</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">run</governor>
          <dependent id="22">Friday</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">week</governor>
          <dependent id="23">this</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="22">Friday</governor>
          <dependent id="24">week</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">Friday</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">weekday</governor>
          <dependent id="26">every</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">Friday</governor>
          <dependent id="27">weekday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">RADIO</governor>
          <dependent id="28">except</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">RADIO</governor>
          <dependent id="29">Wednesday</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">RADIO</governor>
          <dependent id="30">next</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">RADIO</governor>
          <dependent id="31">week</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">weekday</governor>
          <dependent id="32">RADIO</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="20">run</governor>
          <dependent id="35">box</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">run</governor>
          <dependent id="37">KQED</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="42">delay</governor>
          <dependent id="39">88.5</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="42">delay</governor>
          <dependent id="40">FM</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="42">delay</governor>
          <dependent id="41">Tape</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="37">KQED</governor>
          <dependent id="42">delay</dependent>
        </dependency>
        <dependency type="case">
          <governor id="45">9</governor>
          <dependent id="43">beginning</dependent>
        </dependency>
        <dependency type="case">
          <governor id="45">9</governor>
          <dependent id="44">at</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="20">run</governor>
          <dependent id="45">9</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="45">9</governor>
          <dependent id="46">a.m</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="45">9</governor>
          <dependent id="47">repeated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="49">9:30</governor>
          <dependent id="48">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="47">repeated</governor>
          <dependent id="49">9:30</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="49">9:30</governor>
          <dependent id="50">p.m</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="54">KPFA</governor>
          <dependent id="52">box</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="49">9:30</governor>
          <dependent id="54">KPFA</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="59">coverage</governor>
          <dependent id="56">94.1</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="59">coverage</governor>
          <dependent id="57">FM</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="59">coverage</governor>
          <dependent id="58">Live</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="60">begins</governor>
          <dependent id="59">coverage</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">hearings</governor>
          <dependent id="60">begins</dependent>
        </dependency>
        <dependency type="case">
          <governor id="64">TELEVISION</governor>
          <dependent id="61">at</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="64">TELEVISION</governor>
          <dependent id="62">6:30</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="64">TELEVISION</governor>
          <dependent id="63">a.m</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="60">begins</governor>
          <dependent id="64">TELEVISION</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="70">Live</governor>
          <dependent id="67">box</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="70">Live</governor>
          <dependent id="69">C-SPAN</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="64">TELEVISION</governor>
          <dependent id="70">Live</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="72">begins</governor>
          <dependent id="71">coverage</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="70">Live</governor>
          <dependent id="72">begins</dependent>
        </dependency>
        <dependency type="case">
          <governor id="74">7</governor>
          <dependent id="73">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="72">begins</governor>
          <dependent id="74">7</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="74">7</governor>
          <dependent id="75">a.m</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="74">7</governor>
          <dependent id="76">repeated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="78">5</governor>
          <dependent id="77">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="76">repeated</governor>
          <dependent id="78">5</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="78">5</governor>
          <dependent id="79">p.m</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="10">hearings</governor>
          <dependent id="81">box</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="85">coverage</governor>
          <dependent id="83">CNN</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="85">coverage</governor>
          <dependent id="84">Intermittent</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="5">SEE</governor>
          <dependent id="85">coverage</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Supreme Court" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="12" string="Supreme" />
            <token id="13" string="Court" />
          </tokens>
        </entity>
        <entity id="2" string="7 a.m" type="TIME" score="0.0">
          <tokens>
            <token id="74" string="7" />
            <token id="75" string="a.m" />
          </tokens>
        </entity>
        <entity id="3" string="Friday this week" type="DATE" score="0.0">
          <tokens>
            <token id="22" string="Friday" />
            <token id="23" string="this" />
            <token id="24" string="week" />
          </tokens>
        </entity>
        <entity id="4" string="9:30 p.m" type="TIME" score="0.0">
          <tokens>
            <token id="49" string="9:30" />
            <token id="50" string="p.m" />
          </tokens>
        </entity>
        <entity id="5" string="FM Live" type="MISC" score="0.0">
          <tokens>
            <token id="57" string="FM" />
            <token id="58" string="Live" />
          </tokens>
        </entity>
        <entity id="6" string="6:30 a.m" type="TIME" score="0.0">
          <tokens>
            <token id="62" string="6:30" />
            <token id="63" string="a.m" />
          </tokens>
        </entity>
        <entity id="7" string="KQED" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="37" string="KQED" />
          </tokens>
        </entity>
        <entity id="8" string="94.1" type="NUMBER" score="0.0">
          <tokens>
            <token id="56" string="94.1" />
          </tokens>
        </entity>
        <entity id="9" string="9 a.m" type="TIME" score="0.0">
          <tokens>
            <token id="45" string="9" />
            <token id="46" string="a.m" />
          </tokens>
        </entity>
        <entity id="10" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="Senate" />
          </tokens>
        </entity>
        <entity id="11" string="5 p.m" type="TIME" score="0.0">
          <tokens>
            <token id="78" string="5" />
            <token id="79" string="p.m" />
          </tokens>
        </entity>
        <entity id="12" string="FM Tape" type="MISC" score="0.0">
          <tokens>
            <token id="40" string="FM" />
            <token id="41" string="Tape" />
          </tokens>
        </entity>
        <entity id="13" string="88.5" type="NUMBER" score="0.0">
          <tokens>
            <token id="39" string="88.5" />
          </tokens>
        </entity>
        <entity id="14" string="KPFA" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="54" string="KPFA" />
          </tokens>
        </entity>
        <entity id="15" string="Wednesday next week" type="DATE" score="0.0">
          <tokens>
            <token id="29" string="Wednesday" />
            <token id="30" string="next" />
            <token id="31" string="week" />
          </tokens>
        </entity>
        <entity id="16" string="Clarence Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Clarence" />
            <token id="16" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="1-2" string="Supreme Court" id_sentence="1" />
      <mentions>
        <mention ids_tokens="28-29" string="the court" id_sentence="16" />
        <mention ids_tokens="17-18" string="the court" id_sentence="17" />
        <mention ids_tokens="48" string="that" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="15-16" string="the Democrats" id_sentence="11" />
      <mentions>
        <mention ids_tokens="33" string="Democrats" id_sentence="1" />
        <mention ids_tokens="10" string="Democrats" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="1-2-3-4-5" string="Supreme Court nominee Clarence Thomas" id_sentence="1" />
      <mentions>
        <mention ids_tokens="20" string="Thomas" id_sentence="2" />
        <mention ids_tokens="11-12" string="Thomas'" id_sentence="3" />
        <mention ids_tokens="2-3" string="Thomas'" id_sentence="7" />
        <mention ids_tokens="14" string="he" id_sentence="7" />
        <mention ids_tokens="16-18" string="an evasive witness" id_sentence="7" />
        <mention ids_tokens="7" string="his" id_sentence="8" />
        <mention ids_tokens="12" string="he" id_sentence="8" />
        <mention ids_tokens="3" string="he" id_sentence="9" />
        <mention ids_tokens="4" string="Thomas" id_sentence="10" />
        <mention ids_tokens="16" string="I" id_sentence="10" />
        <mention ids_tokens="8-9" string="Thomas'" id_sentence="11" />
        <mention ids_tokens="3" string="Thomas" id_sentence="12" />
        <mention ids_tokens="12" string="his" id_sentence="12" />
        <mention ids_tokens="2" string="Thomas" id_sentence="16" />
        <mention ids_tokens="7" string="his" id_sentence="16" />
        <mention ids_tokens="11" string="him" id_sentence="16" />
        <mention ids_tokens="22" string="Thomas" id_sentence="17" />
        <mention ids_tokens="31-32" string="Thomas'" id_sentence="17" />
        <mention ids_tokens="35" string="he" id_sentence="17" />
        <mention ids_tokens="60" string="he" id_sentence="17" />
        <mention ids_tokens="62-74" string="the only person gathered in the room who does not have an opinion" id_sentence="17" />
        <mention ids_tokens="9" string="Thomas" id_sentence="21" />
        <mention ids_tokens="20" string="Thomas" id_sentence="22" />
        <mention ids_tokens="6-7" string="Thomas'" id_sentence="24" />
        <mention ids_tokens="16" string="Thomas" id_sentence="25" />
        <mention ids_tokens="20-21" string="Thomas'" id_sentence="25" />
        <mention ids_tokens="49" string="Thomas" id_sentence="25" />
        <mention ids_tokens="91-92" string="THOMAS'" id_sentence="25" />
        <mention ids_tokens="97-99" string="Clarence Thomas'" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="4" type="PROPER">
      <referenced ids_tokens="7-8-9-10" string="the Senate Judiciary Committee" id_sentence="1" />
      <mentions>
        <mention ids_tokens="32-33" string="the Senate" id_sentence="3" />
        <mention ids_tokens="7-9" string="the committee's" id_sentence="7" />
        <mention ids_tokens="19" string="Committee" id_sentence="8" />
        <mention ids_tokens="4" string="Senate" id_sentence="16" />
        <mention ids_tokens="1-2" string="The committee" id_sentence="23" />
        <mention ids_tokens="8" string="Senate" id_sentence="28" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="30-31-32-33" string="the committee 's Democrats" id_sentence="1" />
      <mentions>
        <mention ids_tokens="7-18" string="the committee's Democrats , who say he is an evasive witness" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="8-9-10-11-12" string="no time did I feel" id_sentence="27" />
      <mentions>
        <mention ids_tokens="3" string="IT" id_sentence="28" />
        <mention ids_tokens="6" string="IT" id_sentence="28" />
      </mentions>
    </coreference>
    <coreference id="7" type="PROPER">
      <referenced ids_tokens="6-7" string="Herb Kohl" id_sentence="2" />
      <mentions>
        <mention ids_tokens="2" string="Kohl" id_sentence="18" />
        <mention ids_tokens="10" string="his" id_sentence="18" />
        <mention ids_tokens="13" string="his" id_sentence="18" />
        <mention ids_tokens="4" string="Kohl" id_sentence="19" />
        <mention ids_tokens="27" string="me" id_sentence="19" />
        <mention ids_tokens="30" string="I" id_sentence="19" />
        <mention ids_tokens="2" string="Kohl" id_sentence="20" />
        <mention ids_tokens="9" string="he" id_sentence="20" />
        <mention ids_tokens="16" string="his" id_sentence="20" />
        <mention ids_tokens="85" string="Kohl" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="10" type="NOMINAL">
      <referenced ids_tokens="29-30-31-32" string="a view is irrelevant" id_sentence="2" />
      <mentions>
        <mention ids_tokens="22-23" string="my view" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="11" type="PROPER">
      <referenced ids_tokens="3" string="Bush" id_sentence="3" />
      <mentions>
        <mention ids_tokens="6" string="himself" id_sentence="4" />
        <mention ids_tokens="2" string="I" id_sentence="5" />
        <mention ids_tokens="1" string="I" id_sentence="6" />
        <mention ids_tokens="5" string="him" id_sentence="22" />
        <mention ids_tokens="6" string="he" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="12" type="PROPER">
      <referenced ids_tokens="2-3" string="President Bush" id_sentence="3" />
      <mentions>
        <mention ids_tokens="3" string="He" id_sentence="4" />
        <mention ids_tokens="11-12" string="the president" id_sentence="4" />
        <mention ids_tokens="4" string="he" id_sentence="5" />
        <mention ids_tokens="8" string="he" id_sentence="6" />
        <mention ids_tokens="19" string="President" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="15" type="PROPER">
      <referenced ids_tokens="21-22" string="Joseph Biden" id_sentence="8" />
      <mentions>
        <mention ids_tokens="7" string="Biden" id_sentence="10" />
        <mention ids_tokens="18-20" string="you , judge" id_sentence="10" />
        <mention ids_tokens="76" string="Biden" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="16" type="NOMINAL">
      <referenced ids_tokens="37-38-39" string="the nominee 's" id_sentence="8" />
      <mentions>
        <mention ids_tokens="6-37" string="the nominee , &quot; Is it fair of you to say to us , for the most part , just view me on what I'm saying here this week ? &quot;" id_sentence="19" />
        <mention ids_tokens="6-7" string="the nominee" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="17" type="PROPER">
      <referenced ids_tokens="63-64-65-66-67-68" string="Thomas of using &quot; tortuous logic" id_sentence="8" />
      <mentions>
        <mention ids_tokens="17" string="I" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="19" type="PROPER">
      <referenced ids_tokens="2" string="Republicans" id_sentence="11" />
      <mentions>
        <mention ids_tokens="1" string="He" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="20" type="PROPER">
      <referenced ids_tokens="33-34-35-36-37" string="Sen. Orrin Hatch , R-Utah" id_sentence="11" />
      <mentions>
        <mention ids_tokens="1" string="Hatch" id_sentence="14" />
        <mention ids_tokens="31" string="Hatch" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="21" type="NOMINAL">
      <referenced ids_tokens="28" string="this" id_sentence="11" />
      <mentions>
        <mention ids_tokens="36" string="we" id_sentence="12" />
        <mention ids_tokens="6" string="we" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="23" type="PROPER">
      <referenced ids_tokens="54-55" string="Paul Simon" id_sentence="17" />
      <mentions>
        <mention ids_tokens="83" string="Simon" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="25" type="NOMINAL">
      <referenced ids_tokens="10-11-12-13-14-15-16-17-18-19" string="the people who are affected by what the court does" id_sentence="17" />
      <mentions>
        <mention ids_tokens="18" string="us" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="26" type="NOMINAL">
      <referenced ids_tokens="73-74" string="an opinion" id_sentence="17" />
      <mentions>
        <mention ids_tokens="6" string="I" id_sentence="18" />
        <mention ids_tokens="11" string="it" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="29" type="NOMINAL">
      <referenced ids_tokens="13-14-15-16-17-18-19-20-21-22-23" string="published comments calling his appointment by President Bush a &quot; quota" id_sentence="20" />
      <mentions>
        <mention ids_tokens="3" string="That" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="30" type="NOMINAL">
      <referenced ids_tokens="16-17" string="his appointment" id_sentence="20" />
      <mentions>
        <mention ids_tokens="19" string="it" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="31" type="NOMINAL">
      <referenced ids_tokens="21-22-23" string="a &quot; quota" id_sentence="20" />
      <mentions>
        <mention ids_tokens="15" string="I" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="32" type="NOMINAL">
      <referenced ids_tokens="12-13-14-15-16-17-18-19-20-21-22-23-24-25-26-27" string="the best qualified of those potential nominees considered Thomas is expected to continue testifying through Friday" id_sentence="22" />
      <mentions>
        <mention ids_tokens="5-6" string="trouble anyone" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="33" type="NOMINAL">
      <referenced ids_tokens="2-3-4-5-6-7-8" string="the panel 's traditional third swing vote" id_sentence="25" />
      <mentions>
        <mention ids_tokens="10" string="I" id_sentence="26" />
        <mention ids_tokens="11" string="I" id_sentence="27" />
        <mention ids_tokens="16" string="I" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="34" type="NOMINAL">
      <referenced ids_tokens="20-21-22" string="Thomas ' opponents" id_sentence="25" />
      <mentions>
        <mention ids_tokens="18" string="we" id_sentence="26" />
        <mention ids_tokens="30" string="our" id_sentence="27" />
      </mentions>
    </coreference>
  </coreferences>
</document>
