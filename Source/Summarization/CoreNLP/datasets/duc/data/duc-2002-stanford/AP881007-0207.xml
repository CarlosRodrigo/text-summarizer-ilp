<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP881007-0207">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>``I believe in fairies, the myths, dragons.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="believe" lemma="believe" stem="believ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="fairies" lemma="fairy" stem="fairi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="myths" lemma="myth" stem="myth" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="dragons" lemma="dragon" stem="dragon" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBP believe) (PP (IN in) (NP (NP (NNS fairies)) (, ,) (NP (NP (DT the) (NNS myths)) (, ,) (NP (NNS dragons)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="dragons" type="NP">
          <tokens>
            <token id="10" string="dragons" />
          </tokens>
        </chunking>
        <chunking id="2" string="believe in fairies , the myths , dragons" type="VP">
          <tokens>
            <token id="3" string="believe" />
            <token id="4" string="in" />
            <token id="5" string="fairies" />
            <token id="6" string="," />
            <token id="7" string="the" />
            <token id="8" string="myths" />
            <token id="9" string="," />
            <token id="10" string="dragons" />
          </tokens>
        </chunking>
        <chunking id="3" string="the myths" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="myths" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="fairies , the myths , dragons" type="NP">
          <tokens>
            <token id="5" string="fairies" />
            <token id="6" string="," />
            <token id="7" string="the" />
            <token id="8" string="myths" />
            <token id="9" string="," />
            <token id="10" string="dragons" />
          </tokens>
        </chunking>
        <chunking id="6" string="the myths , dragons" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="myths" />
            <token id="9" string="," />
            <token id="10" string="dragons" />
          </tokens>
        </chunking>
        <chunking id="7" string="fairies" type="NP">
          <tokens>
            <token id="5" string="fairies" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">believe</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">believe</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">fairies</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">believe</governor>
          <dependent id="5">fairies</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">myths</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">fairies</governor>
          <dependent id="8">myths</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">myths</governor>
          <dependent id="10">dragons</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="2" has_coreference="false">
      <content>It all exists, even if it&amp;apost;s in your mind.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="exists" lemma="exist" stem="exist" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="your" lemma="you" stem="your" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="mind" lemma="mind" stem="mind" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (ADVP (DT all)) (VP (VBZ exists) (, ,) (SBAR (RB even) (IN if) (S (NP (PRP it)) (VP (VBZ 's) (PP (IN in) (NP (PRP$ your) (NN mind))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="'s in your mind" type="VP">
          <tokens>
            <token id="8" string="'s" />
            <token id="9" string="in" />
            <token id="10" string="your" />
            <token id="11" string="mind" />
          </tokens>
        </chunking>
        <chunking id="2" string="exists , even if it 's in your mind" type="VP">
          <tokens>
            <token id="3" string="exists" />
            <token id="4" string="," />
            <token id="5" string="even" />
            <token id="6" string="if" />
            <token id="7" string="it" />
            <token id="8" string="'s" />
            <token id="9" string="in" />
            <token id="10" string="your" />
            <token id="11" string="mind" />
          </tokens>
        </chunking>
        <chunking id="3" string="even if it 's in your mind" type="SBAR">
          <tokens>
            <token id="5" string="even" />
            <token id="6" string="if" />
            <token id="7" string="it" />
            <token id="8" string="'s" />
            <token id="9" string="in" />
            <token id="10" string="your" />
            <token id="11" string="mind" />
          </tokens>
        </chunking>
        <chunking id="4" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="your mind" type="NP">
          <tokens>
            <token id="10" string="your" />
            <token id="11" string="mind" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">exists</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">exists</governor>
          <dependent id="2">all</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">exists</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">mind</governor>
          <dependent id="5">even</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">mind</governor>
          <dependent id="6">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">mind</governor>
          <dependent id="7">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">mind</governor>
          <dependent id="8">'s</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">mind</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">mind</governor>
          <dependent id="10">your</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">exists</governor>
          <dependent id="11">mind</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="3" has_coreference="false">
      <content>Who&amp;apost;s to say that dreams and nightmares aren&amp;apost;t as real as the here and now?</content>
      <tokens>
        <token id="1" string="Who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="dreams" lemma="dream" stem="dream" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="nightmares" lemma="nightmare" stem="nightmar" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="real" lemma="real" stem="real" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="here" lemma="here" stem="here" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SBARQ (WHNP (WP Who)) (SQ (VBZ 's) (S (VP (TO to) (VP (VB say) (SBAR (IN that) (S (NP (NNS dreams) (CC and) (NNS nightmares)) (VP (VBP are) (RB n't) (ADJP (RB as) (JJ real)) (PP (IN as) (NP (DT the) (NP (RB here)) (CC and) (NP (RB now))))))))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the here and now" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="here" />
            <token id="16" string="and" />
            <token id="17" string="now" />
          </tokens>
        </chunking>
        <chunking id="2" string="now" type="NP">
          <tokens>
            <token id="17" string="now" />
          </tokens>
        </chunking>
        <chunking id="3" string="dreams and nightmares" type="NP">
          <tokens>
            <token id="6" string="dreams" />
            <token id="7" string="and" />
            <token id="8" string="nightmares" />
          </tokens>
        </chunking>
        <chunking id="4" string="say that dreams and nightmares are n't as real as the here and now" type="VP">
          <tokens>
            <token id="4" string="say" />
            <token id="5" string="that" />
            <token id="6" string="dreams" />
            <token id="7" string="and" />
            <token id="8" string="nightmares" />
            <token id="9" string="are" />
            <token id="10" string="n't" />
            <token id="11" string="as" />
            <token id="12" string="real" />
            <token id="13" string="as" />
            <token id="14" string="the" />
            <token id="15" string="here" />
            <token id="16" string="and" />
            <token id="17" string="now" />
          </tokens>
        </chunking>
        <chunking id="5" string="as real" type="ADJP">
          <tokens>
            <token id="11" string="as" />
            <token id="12" string="real" />
          </tokens>
        </chunking>
        <chunking id="6" string="to say that dreams and nightmares are n't as real as the here and now" type="VP">
          <tokens>
            <token id="3" string="to" />
            <token id="4" string="say" />
            <token id="5" string="that" />
            <token id="6" string="dreams" />
            <token id="7" string="and" />
            <token id="8" string="nightmares" />
            <token id="9" string="are" />
            <token id="10" string="n't" />
            <token id="11" string="as" />
            <token id="12" string="real" />
            <token id="13" string="as" />
            <token id="14" string="the" />
            <token id="15" string="here" />
            <token id="16" string="and" />
            <token id="17" string="now" />
          </tokens>
        </chunking>
        <chunking id="7" string="that dreams and nightmares are n't as real as the here and now" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="dreams" />
            <token id="7" string="and" />
            <token id="8" string="nightmares" />
            <token id="9" string="are" />
            <token id="10" string="n't" />
            <token id="11" string="as" />
            <token id="12" string="real" />
            <token id="13" string="as" />
            <token id="14" string="the" />
            <token id="15" string="here" />
            <token id="16" string="and" />
            <token id="17" string="now" />
          </tokens>
        </chunking>
        <chunking id="8" string="are n't as real as the here and now" type="VP">
          <tokens>
            <token id="9" string="are" />
            <token id="10" string="n't" />
            <token id="11" string="as" />
            <token id="12" string="real" />
            <token id="13" string="as" />
            <token id="14" string="the" />
            <token id="15" string="here" />
            <token id="16" string="and" />
            <token id="17" string="now" />
          </tokens>
        </chunking>
        <chunking id="9" string="here" type="NP">
          <tokens>
            <token id="15" string="here" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dobj">
          <governor id="4">say</governor>
          <dependent id="1">Who</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">say</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="4">say</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">say</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">real</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">real</governor>
          <dependent id="6">dreams</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">dreams</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">dreams</governor>
          <dependent id="8">nightmares</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">real</governor>
          <dependent id="9">are</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="12">real</governor>
          <dependent id="10">n't</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">real</governor>
          <dependent id="11">as</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">say</governor>
          <dependent id="12">real</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">here</governor>
          <dependent id="13">as</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="15">here</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">real</governor>
          <dependent id="15">here</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">here</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">here</governor>
          <dependent id="17">now</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="17" string="now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="false">
      <content>Reality leaves a lot to the imagination.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="Reality" lemma="reality" stem="realiti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="leaves" lemma="leave" stem="leav" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="imagination" lemma="imagination" stem="imagin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN Reality)) (VP (VBZ leaves) (NP (DT a) (NN lot)) (PP (TO to) (NP (DT the) (NN imagination)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the imagination" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="imagination" />
          </tokens>
        </chunking>
        <chunking id="2" string="leaves a lot to the imagination" type="VP">
          <tokens>
            <token id="2" string="leaves" />
            <token id="3" string="a" />
            <token id="4" string="lot" />
            <token id="5" string="to" />
            <token id="6" string="the" />
            <token id="7" string="imagination" />
          </tokens>
        </chunking>
        <chunking id="3" string="a lot" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="lot" />
          </tokens>
        </chunking>
        <chunking id="4" string="Reality" type="NP">
          <tokens>
            <token id="1" string="Reality" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">leaves</governor>
          <dependent id="1">Reality</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">leaves</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">lot</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">leaves</governor>
          <dependent id="4">lot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">imagination</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">imagination</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">leaves</governor>
          <dependent id="7">imagination</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>_ John Lennon.</content>
      <tokens>
        <token id="1" string="_" lemma="_" stem="_" pos="NNP" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NNP _) (NNP John) (NNP Lennon) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="_ John Lennon ." type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="John" />
            <token id="3" string="Lennon" />
            <token id="4" string="." />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Lennon</governor>
          <dependent id="1">_</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Lennon</governor>
          <dependent id="2">John</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">Lennon</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="John" />
            <token id="3" string="Lennon" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>Watching the new movie, ``Imagine: John Lennon,&amp;apost;&amp;apost; was very painful for the late Beatle&amp;apost;s wife, Yoko Ono.</content>
      <tokens>
        <token id="1" string="Watching" lemma="watch" stem="watch" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="movie" lemma="movie" stem="movi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="Imagine" lemma="imagine" stem="imagin" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="10" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="painful" lemma="painful" stem="pain" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="late" lemma="late" stem="late" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="Beatle" lemma="Beatle" stem="beatl" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="wife" lemma="wife" stem="wife" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Yoko" lemma="Yoko" stem="yoko" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="24" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (VP (VBG Watching) (NP (NP (DT the) (JJ new) (NN movie)) (, ,) (NP (VP (`` ``) (VB Imagine) (: :) (NP (NNP John) (NNP Lennon))))))) (, ,) ('' '') (VP (VBD was) (ADJP (RB very) (JJ painful)) (PP (IN for) (NP (DT the) (JJ late)))) (NP (NP (NP (NNP Beatle) (POS 's)) (NN wife)) (, ,) (NP (NNP Yoko) (NNP Ono))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="John Lennon" type="NP">
          <tokens>
            <token id="9" string="John" />
            <token id="10" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="2" string="Beatle 's wife , Yoko Ono" type="NP">
          <tokens>
            <token id="19" string="Beatle" />
            <token id="20" string="'s" />
            <token id="21" string="wife" />
            <token id="22" string="," />
            <token id="23" string="Yoko" />
            <token id="24" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="3" string="Watching the new movie , `` Imagine : John Lennon" type="VP">
          <tokens>
            <token id="1" string="Watching" />
            <token id="2" string="the" />
            <token id="3" string="new" />
            <token id="4" string="movie" />
            <token id="5" string="," />
            <token id="6" string="``" />
            <token id="7" string="Imagine" />
            <token id="8" string=":" />
            <token id="9" string="John" />
            <token id="10" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="4" string="the new movie" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="new" />
            <token id="4" string="movie" />
          </tokens>
        </chunking>
        <chunking id="5" string="was very painful for the late" type="VP">
          <tokens>
            <token id="13" string="was" />
            <token id="14" string="very" />
            <token id="15" string="painful" />
            <token id="16" string="for" />
            <token id="17" string="the" />
            <token id="18" string="late" />
          </tokens>
        </chunking>
        <chunking id="6" string="very painful" type="ADJP">
          <tokens>
            <token id="14" string="very" />
            <token id="15" string="painful" />
          </tokens>
        </chunking>
        <chunking id="7" string="Beatle 's" type="NP">
          <tokens>
            <token id="19" string="Beatle" />
            <token id="20" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="Yoko Ono" type="NP">
          <tokens>
            <token id="23" string="Yoko" />
            <token id="24" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="9" string="the new movie , `` Imagine : John Lennon" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="new" />
            <token id="4" string="movie" />
            <token id="5" string="," />
            <token id="6" string="``" />
            <token id="7" string="Imagine" />
            <token id="8" string=":" />
            <token id="9" string="John" />
            <token id="10" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="10" string="the late" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="late" />
          </tokens>
        </chunking>
        <chunking id="11" string="`` Imagine : John Lennon" type="NP">
          <tokens>
            <token id="6" string="``" />
            <token id="7" string="Imagine" />
            <token id="8" string=":" />
            <token id="9" string="John" />
            <token id="10" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="12" string="Beatle 's wife" type="NP">
          <tokens>
            <token id="19" string="Beatle" />
            <token id="20" string="'s" />
            <token id="21" string="wife" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="15">painful</governor>
          <dependent id="1">Watching</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">movie</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">movie</governor>
          <dependent id="3">new</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Watching</governor>
          <dependent id="4">movie</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="4">movie</governor>
          <dependent id="7">Imagine</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Lennon</governor>
          <dependent id="9">John</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">Imagine</governor>
          <dependent id="10">Lennon</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">painful</governor>
          <dependent id="13">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">painful</governor>
          <dependent id="14">very</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">painful</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">late</governor>
          <dependent id="16">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">late</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">painful</governor>
          <dependent id="18">late</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">wife</governor>
          <dependent id="19">Beatle</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Beatle</governor>
          <dependent id="20">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">painful</governor>
          <dependent id="21">wife</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Ono</governor>
          <dependent id="23">Yoko</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="21">wife</governor>
          <dependent id="24">Ono</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="John" />
            <token id="10" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="Yoko Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Yoko" />
            <token id="24" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>``The only reason why I did watch it to the end is because I&amp;apost;m responsible for it, even though somebody else made it,&amp;apost;&amp;apost; she said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="only" lemma="only" stem="onli" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="reason" lemma="reason" stem="reason" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="why" lemma="why" stem="why" pos="WRB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="7" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="watch" lemma="watch" stem="watch" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="end" lemma="end" stem="end" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="responsible" lemma="responsible" stem="respons" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="though" lemma="though" stem="though" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="somebody" lemma="somebody" stem="somebodi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="else" lemma="else" stem="els" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (NP (DT The) (JJ only) (NN reason)) (SBAR (WHADVP (WRB why)) (S (NP (PRP I)) (VP (VBD did) (VP (VB watch) (NP (PRP it)) (PP (TO to) (NP (DT the) (NN end)))))))) (VP (VBZ is) (SBAR (IN because) (S (NP (PRP I)) (VP (VBP 'm) (ADJP (JJ responsible) (PP (IN for) (NP (PRP it)))) (, ,) (SBAR (RB even) (IN though) (S (NP (NN somebody) (RB else)) (VP (VBD made) (NP (PRP it)))))))))) (, ,) ('' '') (NP (PRP she)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="responsible for it" type="ADJP">
          <tokens>
            <token id="17" string="responsible" />
            <token id="18" string="for" />
            <token id="19" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="the end" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="end" />
          </tokens>
        </chunking>
        <chunking id="3" string="is because I 'm responsible for it , even though somebody else made it" type="VP">
          <tokens>
            <token id="13" string="is" />
            <token id="14" string="because" />
            <token id="15" string="I" />
            <token id="16" string="'m" />
            <token id="17" string="responsible" />
            <token id="18" string="for" />
            <token id="19" string="it" />
            <token id="20" string="," />
            <token id="21" string="even" />
            <token id="22" string="though" />
            <token id="23" string="somebody" />
            <token id="24" string="else" />
            <token id="25" string="made" />
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="watch it to the end" type="VP">
          <tokens>
            <token id="8" string="watch" />
            <token id="9" string="it" />
            <token id="10" string="to" />
            <token id="11" string="the" />
            <token id="12" string="end" />
          </tokens>
        </chunking>
        <chunking id="5" string="why" type="WHADVP">
          <tokens>
            <token id="5" string="why" />
          </tokens>
        </chunking>
        <chunking id="6" string="because I 'm responsible for it , even though somebody else made it" type="SBAR">
          <tokens>
            <token id="14" string="because" />
            <token id="15" string="I" />
            <token id="16" string="'m" />
            <token id="17" string="responsible" />
            <token id="18" string="for" />
            <token id="19" string="it" />
            <token id="20" string="," />
            <token id="21" string="even" />
            <token id="22" string="though" />
            <token id="23" string="somebody" />
            <token id="24" string="else" />
            <token id="25" string="made" />
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="I" type="NP">
          <tokens>
            <token id="6" string="I" />
          </tokens>
        </chunking>
        <chunking id="8" string="even though somebody else made it" type="SBAR">
          <tokens>
            <token id="21" string="even" />
            <token id="22" string="though" />
            <token id="23" string="somebody" />
            <token id="24" string="else" />
            <token id="25" string="made" />
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="made it" type="VP">
          <tokens>
            <token id="25" string="made" />
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="The only reason why I did watch it to the end" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="only" />
            <token id="4" string="reason" />
            <token id="5" string="why" />
            <token id="6" string="I" />
            <token id="7" string="did" />
            <token id="8" string="watch" />
            <token id="9" string="it" />
            <token id="10" string="to" />
            <token id="11" string="the" />
            <token id="12" string="end" />
          </tokens>
        </chunking>
        <chunking id="11" string="it" type="NP">
          <tokens>
            <token id="9" string="it" />
          </tokens>
        </chunking>
        <chunking id="12" string="did watch it to the end" type="VP">
          <tokens>
            <token id="7" string="did" />
            <token id="8" string="watch" />
            <token id="9" string="it" />
            <token id="10" string="to" />
            <token id="11" string="the" />
            <token id="12" string="end" />
          </tokens>
        </chunking>
        <chunking id="13" string="she" type="NP">
          <tokens>
            <token id="29" string="she" />
          </tokens>
        </chunking>
        <chunking id="14" string="somebody else" type="NP">
          <tokens>
            <token id="23" string="somebody" />
            <token id="24" string="else" />
          </tokens>
        </chunking>
        <chunking id="15" string="'m responsible for it , even though somebody else made it" type="VP">
          <tokens>
            <token id="16" string="'m" />
            <token id="17" string="responsible" />
            <token id="18" string="for" />
            <token id="19" string="it" />
            <token id="20" string="," />
            <token id="21" string="even" />
            <token id="22" string="though" />
            <token id="23" string="somebody" />
            <token id="24" string="else" />
            <token id="25" string="made" />
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="16" string="The only reason" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="only" />
            <token id="4" string="reason" />
          </tokens>
        </chunking>
        <chunking id="17" string="why I did watch it to the end" type="SBAR">
          <tokens>
            <token id="5" string="why" />
            <token id="6" string="I" />
            <token id="7" string="did" />
            <token id="8" string="watch" />
            <token id="9" string="it" />
            <token id="10" string="to" />
            <token id="11" string="the" />
            <token id="12" string="end" />
          </tokens>
        </chunking>
        <chunking id="18" string="said" type="VP">
          <tokens>
            <token id="30" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">reason</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">reason</governor>
          <dependent id="3">only</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">is</governor>
          <dependent id="4">reason</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">watch</governor>
          <dependent id="5">why</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">watch</governor>
          <dependent id="6">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">watch</governor>
          <dependent id="7">did</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">reason</governor>
          <dependent id="8">watch</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">watch</governor>
          <dependent id="9">it</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">end</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">end</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">watch</governor>
          <dependent id="12">end</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="30">said</governor>
          <dependent id="13">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">responsible</governor>
          <dependent id="14">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">responsible</governor>
          <dependent id="15">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">responsible</governor>
          <dependent id="16">'m</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">is</governor>
          <dependent id="17">responsible</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">it</governor>
          <dependent id="18">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">responsible</governor>
          <dependent id="19">it</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">made</governor>
          <dependent id="21">even</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">made</governor>
          <dependent id="22">though</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">made</governor>
          <dependent id="23">somebody</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">somebody</governor>
          <dependent id="24">else</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">responsible</governor>
          <dependent id="25">made</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">made</governor>
          <dependent id="26">it</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">said</governor>
          <dependent id="29">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="30">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>Cassettes, film footage and other elements of the acclaimed movie were collected by Ono.</content>
      <tokens>
        <token id="1" string="Cassettes" lemma="cassette" stem="cassett" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="film" lemma="film" stem="film" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="footage" lemma="footage" stem="footag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="elements" lemma="element" stem="element" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="acclaimed" lemma="acclaimed" stem="acclaim" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="movie" lemma="movie" stem="movi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="collected" lemma="collect" stem="collect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNS Cassettes)) (, ,) (NP (NN film) (NN footage)) (CC and) (NP (NP (JJ other) (NNS elements)) (PP (IN of) (NP (DT the) (JJ acclaimed) (NN movie))))) (VP (VBD were) (VP (VBN collected) (PP (IN by) (NP (NNP Ono))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Cassettes , film footage and other elements of the acclaimed movie" type="NP">
          <tokens>
            <token id="1" string="Cassettes" />
            <token id="2" string="," />
            <token id="3" string="film" />
            <token id="4" string="footage" />
            <token id="5" string="and" />
            <token id="6" string="other" />
            <token id="7" string="elements" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="acclaimed" />
            <token id="11" string="movie" />
          </tokens>
        </chunking>
        <chunking id="2" string="other elements of the acclaimed movie" type="NP">
          <tokens>
            <token id="6" string="other" />
            <token id="7" string="elements" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="acclaimed" />
            <token id="11" string="movie" />
          </tokens>
        </chunking>
        <chunking id="3" string="other elements" type="NP">
          <tokens>
            <token id="6" string="other" />
            <token id="7" string="elements" />
          </tokens>
        </chunking>
        <chunking id="4" string="the acclaimed movie" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="acclaimed" />
            <token id="11" string="movie" />
          </tokens>
        </chunking>
        <chunking id="5" string="film footage" type="NP">
          <tokens>
            <token id="3" string="film" />
            <token id="4" string="footage" />
          </tokens>
        </chunking>
        <chunking id="6" string="were collected by Ono" type="VP">
          <tokens>
            <token id="12" string="were" />
            <token id="13" string="collected" />
            <token id="14" string="by" />
            <token id="15" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="7" string="Cassettes" type="NP">
          <tokens>
            <token id="1" string="Cassettes" />
          </tokens>
        </chunking>
        <chunking id="8" string="Ono" type="NP">
          <tokens>
            <token id="15" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="9" string="collected by Ono" type="VP">
          <tokens>
            <token id="13" string="collected" />
            <token id="14" string="by" />
            <token id="15" string="Ono" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="13">collected</governor>
          <dependent id="1">Cassettes</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">footage</governor>
          <dependent id="3">film</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Cassettes</governor>
          <dependent id="4">footage</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Cassettes</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">elements</governor>
          <dependent id="6">other</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Cassettes</governor>
          <dependent id="7">elements</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">movie</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">movie</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">movie</governor>
          <dependent id="10">acclaimed</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">elements</governor>
          <dependent id="11">movie</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">collected</governor>
          <dependent id="12">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">collected</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Ono</governor>
          <dependent id="14">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">collected</governor>
          <dependent id="15">Ono</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>She also took cassettes of interviews by Lennon, which were edited in such a way that he narrates the picture.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="cassettes" lemma="cassette" stem="cassett" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="interviews" lemma="interview" stem="interview" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="edited" lemma="edit" stem="edit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="narrates" lemma="narrate" stem="narrat" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="picture" lemma="picture" stem="pictur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (ADVP (RB also)) (VP (VBD took) (NP (NP (NNS cassettes)) (PP (IN of) (NP (NNS interviews)))) (PP (IN by) (NP (NP (NNP Lennon)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBD were) (VP (VBN edited) (PP (IN in) (NP (JJ such) (DT a) (NN way))) (SBAR (IN that) (S (NP (PRP he)) (VP (VBZ narrates) (NP (DT the) (NN picture)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="were edited in such a way that he narrates the picture" type="VP">
          <tokens>
            <token id="11" string="were" />
            <token id="12" string="edited" />
            <token id="13" string="in" />
            <token id="14" string="such" />
            <token id="15" string="a" />
            <token id="16" string="way" />
            <token id="17" string="that" />
            <token id="18" string="he" />
            <token id="19" string="narrates" />
            <token id="20" string="the" />
            <token id="21" string="picture" />
          </tokens>
        </chunking>
        <chunking id="2" string="narrates the picture" type="VP">
          <tokens>
            <token id="19" string="narrates" />
            <token id="20" string="the" />
            <token id="21" string="picture" />
          </tokens>
        </chunking>
        <chunking id="3" string="the picture" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="picture" />
          </tokens>
        </chunking>
        <chunking id="4" string="Lennon" type="NP">
          <tokens>
            <token id="8" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="5" string="edited in such a way that he narrates the picture" type="VP">
          <tokens>
            <token id="12" string="edited" />
            <token id="13" string="in" />
            <token id="14" string="such" />
            <token id="15" string="a" />
            <token id="16" string="way" />
            <token id="17" string="that" />
            <token id="18" string="he" />
            <token id="19" string="narrates" />
            <token id="20" string="the" />
            <token id="21" string="picture" />
          </tokens>
        </chunking>
        <chunking id="6" string="cassettes" type="NP">
          <tokens>
            <token id="4" string="cassettes" />
          </tokens>
        </chunking>
        <chunking id="7" string="interviews" type="NP">
          <tokens>
            <token id="6" string="interviews" />
          </tokens>
        </chunking>
        <chunking id="8" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="9" string="that he narrates the picture" type="SBAR">
          <tokens>
            <token id="17" string="that" />
            <token id="18" string="he" />
            <token id="19" string="narrates" />
            <token id="20" string="the" />
            <token id="21" string="picture" />
          </tokens>
        </chunking>
        <chunking id="10" string="took cassettes of interviews by Lennon , which were edited in such a way that he narrates the picture" type="VP">
          <tokens>
            <token id="3" string="took" />
            <token id="4" string="cassettes" />
            <token id="5" string="of" />
            <token id="6" string="interviews" />
            <token id="7" string="by" />
            <token id="8" string="Lennon" />
            <token id="9" string="," />
            <token id="10" string="which" />
            <token id="11" string="were" />
            <token id="12" string="edited" />
            <token id="13" string="in" />
            <token id="14" string="such" />
            <token id="15" string="a" />
            <token id="16" string="way" />
            <token id="17" string="that" />
            <token id="18" string="he" />
            <token id="19" string="narrates" />
            <token id="20" string="the" />
            <token id="21" string="picture" />
          </tokens>
        </chunking>
        <chunking id="11" string="such a way" type="NP">
          <tokens>
            <token id="14" string="such" />
            <token id="15" string="a" />
            <token id="16" string="way" />
          </tokens>
        </chunking>
        <chunking id="12" string="which were edited in such a way that he narrates the picture" type="SBAR">
          <tokens>
            <token id="10" string="which" />
            <token id="11" string="were" />
            <token id="12" string="edited" />
            <token id="13" string="in" />
            <token id="14" string="such" />
            <token id="15" string="a" />
            <token id="16" string="way" />
            <token id="17" string="that" />
            <token id="18" string="he" />
            <token id="19" string="narrates" />
            <token id="20" string="the" />
            <token id="21" string="picture" />
          </tokens>
        </chunking>
        <chunking id="13" string="Lennon , which were edited in such a way that he narrates the picture" type="NP">
          <tokens>
            <token id="8" string="Lennon" />
            <token id="9" string="," />
            <token id="10" string="which" />
            <token id="11" string="were" />
            <token id="12" string="edited" />
            <token id="13" string="in" />
            <token id="14" string="such" />
            <token id="15" string="a" />
            <token id="16" string="way" />
            <token id="17" string="that" />
            <token id="18" string="he" />
            <token id="19" string="narrates" />
            <token id="20" string="the" />
            <token id="21" string="picture" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="18" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="cassettes of interviews" type="NP">
          <tokens>
            <token id="4" string="cassettes" />
            <token id="5" string="of" />
            <token id="6" string="interviews" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">took</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">took</governor>
          <dependent id="2">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">took</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">took</governor>
          <dependent id="4">cassettes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">interviews</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">cassettes</governor>
          <dependent id="6">interviews</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Lennon</governor>
          <dependent id="7">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">took</governor>
          <dependent id="8">Lennon</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">edited</governor>
          <dependent id="10">which</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">edited</governor>
          <dependent id="11">were</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">Lennon</governor>
          <dependent id="12">edited</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">way</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">way</governor>
          <dependent id="14">such</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">way</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">edited</governor>
          <dependent id="16">way</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">narrates</governor>
          <dependent id="17">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">narrates</governor>
          <dependent id="18">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">edited</governor>
          <dependent id="19">narrates</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">picture</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">narrates</governor>
          <dependent id="21">picture</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Lennon" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Andrew Solt (``This Is Elvis&amp;apost;&amp;apost;) directed, Solt and David L. Wolper produced and Solt and Sam Egan wrote it.</content>
      <tokens>
        <token id="1" string="Andrew" lemma="Andrew" stem="andrew" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Solt" lemma="Solt" stem="solt" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="6" string="Is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="Elvis" lemma="Elvis" stem="elvi" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="directed" lemma="direct" stem="direct" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Solt" lemma="Solt" stem="solt" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="David" lemma="David" stem="david" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="15" string="L." lemma="L." stem="l." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="16" string="Wolper" lemma="Wolper" stem="wolper" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="17" string="produced" lemma="produce" stem="produc" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Solt" lemma="Solt" stem="solt" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Sam" lemma="Sam" stem="sam" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="22" string="Egan" lemma="Egan" stem="egan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="23" string="wrote" lemma="write" stem="wrote" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NNP Andrew) (NNP Solt)) (PRN (-LRB- -LRB-) (`` ``) (S (NP (DT This)) (VP (VBZ Is) (NP (NNP Elvis)))) ('' '') (-RRB- -RRB-))) (VP (VBN directed))) (, ,) (S (NP (NNP Solt) (CC and) (NNP David) (NNP L.) (NNP Wolper)) (VP (VBD produced))) (CC and) (S (NP (NNP Solt) (CC and) (NNP Sam) (NNP Egan)) (VP (VBD wrote) (NP (PRP it)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Solt and David L. Wolper" type="NP">
          <tokens>
            <token id="12" string="Solt" />
            <token id="13" string="and" />
            <token id="14" string="David" />
            <token id="15" string="L." />
            <token id="16" string="Wolper" />
          </tokens>
        </chunking>
        <chunking id="2" string="Solt and Sam Egan" type="NP">
          <tokens>
            <token id="19" string="Solt" />
            <token id="20" string="and" />
            <token id="21" string="Sam" />
            <token id="22" string="Egan" />
          </tokens>
        </chunking>
        <chunking id="3" string="Andrew Solt" type="NP">
          <tokens>
            <token id="1" string="Andrew" />
            <token id="2" string="Solt" />
          </tokens>
        </chunking>
        <chunking id="4" string="Elvis" type="NP">
          <tokens>
            <token id="7" string="Elvis" />
          </tokens>
        </chunking>
        <chunking id="5" string="produced" type="VP">
          <tokens>
            <token id="17" string="produced" />
          </tokens>
        </chunking>
        <chunking id="6" string="wrote it" type="VP">
          <tokens>
            <token id="23" string="wrote" />
            <token id="24" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="This" type="NP">
          <tokens>
            <token id="5" string="This" />
          </tokens>
        </chunking>
        <chunking id="8" string="it" type="NP">
          <tokens>
            <token id="24" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="Andrew Solt -LRB- `` This Is Elvis '' -RRB-" type="NP">
          <tokens>
            <token id="1" string="Andrew" />
            <token id="2" string="Solt" />
            <token id="3" string="(" />
            <token id="4" string="``" />
            <token id="5" string="This" />
            <token id="6" string="Is" />
            <token id="7" string="Elvis" />
            <token id="8" string="''" />
            <token id="9" string=")" />
          </tokens>
        </chunking>
        <chunking id="10" string="directed" type="VP">
          <tokens>
            <token id="10" string="directed" />
          </tokens>
        </chunking>
        <chunking id="11" string="Is Elvis" type="VP">
          <tokens>
            <token id="6" string="Is" />
            <token id="7" string="Elvis" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Solt</governor>
          <dependent id="1">Andrew</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">directed</governor>
          <dependent id="2">Solt</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">Elvis</governor>
          <dependent id="5">This</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">Elvis</governor>
          <dependent id="6">Is</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">Solt</governor>
          <dependent id="7">Elvis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">directed</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Wolper</governor>
          <dependent id="12">Solt</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">Solt</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">Solt</governor>
          <dependent id="14">David</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Wolper</governor>
          <dependent id="15">L.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">produced</governor>
          <dependent id="16">Wolper</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">directed</governor>
          <dependent id="17">produced</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">directed</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Egan</governor>
          <dependent id="19">Solt</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">Solt</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">Solt</governor>
          <dependent id="21">Sam</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">wrote</governor>
          <dependent id="22">Egan</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">directed</governor>
          <dependent id="23">wrote</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">wrote</governor>
          <dependent id="24">it</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="David L. Wolper" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="David" />
            <token id="15" string="L." />
            <token id="16" string="Wolper" />
          </tokens>
        </entity>
        <entity id="2" string="Solt" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Solt" />
          </tokens>
        </entity>
        <entity id="3" string="Andrew Solt" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Andrew" />
            <token id="2" string="Solt" />
          </tokens>
        </entity>
        <entity id="4" string="Sam Egan" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Sam" />
            <token id="22" string="Egan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>``I think this is really the definitive documentary of John Lennon&amp;apost;s life,&amp;apost;&amp;apost; Ono said in an interview.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="definitive" lemma="definitive" stem="definit" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="documentary" lemma="documentary" stem="documentari" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="12" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="13" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="14" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="18" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="interview" lemma="interview" stem="interview" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBP think) (SBAR (S (NP (DT this)) (VP (VBZ is) (ADVP (RB really)) (NP (NP (DT the) (JJ definitive) (NN documentary)) (PP (IN of) (NP (NP (NNP John) (NNP Lennon) (POS 's)) (NN life))))))))) (, ,) ('' '') (NP (NNP Ono)) (VP (VBD said) (PP (IN in) (NP (DT an) (NN interview)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="John Lennon 's life" type="NP">
          <tokens>
            <token id="11" string="John" />
            <token id="12" string="Lennon" />
            <token id="13" string="'s" />
            <token id="14" string="life" />
          </tokens>
        </chunking>
        <chunking id="2" string="an interview" type="NP">
          <tokens>
            <token id="20" string="an" />
            <token id="21" string="interview" />
          </tokens>
        </chunking>
        <chunking id="3" string="think this is really the definitive documentary of John Lennon 's life" type="VP">
          <tokens>
            <token id="3" string="think" />
            <token id="4" string="this" />
            <token id="5" string="is" />
            <token id="6" string="really" />
            <token id="7" string="the" />
            <token id="8" string="definitive" />
            <token id="9" string="documentary" />
            <token id="10" string="of" />
            <token id="11" string="John" />
            <token id="12" string="Lennon" />
            <token id="13" string="'s" />
            <token id="14" string="life" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="the definitive documentary of John Lennon 's life" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="definitive" />
            <token id="9" string="documentary" />
            <token id="10" string="of" />
            <token id="11" string="John" />
            <token id="12" string="Lennon" />
            <token id="13" string="'s" />
            <token id="14" string="life" />
          </tokens>
        </chunking>
        <chunking id="6" string="said in an interview" type="VP">
          <tokens>
            <token id="18" string="said" />
            <token id="19" string="in" />
            <token id="20" string="an" />
            <token id="21" string="interview" />
          </tokens>
        </chunking>
        <chunking id="7" string="this is really the definitive documentary of John Lennon 's life" type="SBAR">
          <tokens>
            <token id="4" string="this" />
            <token id="5" string="is" />
            <token id="6" string="really" />
            <token id="7" string="the" />
            <token id="8" string="definitive" />
            <token id="9" string="documentary" />
            <token id="10" string="of" />
            <token id="11" string="John" />
            <token id="12" string="Lennon" />
            <token id="13" string="'s" />
            <token id="14" string="life" />
          </tokens>
        </chunking>
        <chunking id="8" string="this" type="NP">
          <tokens>
            <token id="4" string="this" />
          </tokens>
        </chunking>
        <chunking id="9" string="the definitive documentary" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="definitive" />
            <token id="9" string="documentary" />
          </tokens>
        </chunking>
        <chunking id="10" string="John Lennon 's" type="NP">
          <tokens>
            <token id="11" string="John" />
            <token id="12" string="Lennon" />
            <token id="13" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="Ono" type="NP">
          <tokens>
            <token id="17" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="12" string="is really the definitive documentary of John Lennon 's life" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="really" />
            <token id="7" string="the" />
            <token id="8" string="definitive" />
            <token id="9" string="documentary" />
            <token id="10" string="of" />
            <token id="11" string="John" />
            <token id="12" string="Lennon" />
            <token id="13" string="'s" />
            <token id="14" string="life" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">think</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">said</governor>
          <dependent id="3">think</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">documentary</governor>
          <dependent id="4">this</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">documentary</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">documentary</governor>
          <dependent id="6">really</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">documentary</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">documentary</governor>
          <dependent id="8">definitive</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">think</governor>
          <dependent id="9">documentary</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">life</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Lennon</governor>
          <dependent id="11">John</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">life</governor>
          <dependent id="12">Lennon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Lennon</governor>
          <dependent id="13">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">documentary</governor>
          <dependent id="14">life</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">said</governor>
          <dependent id="17">Ono</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">interview</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">interview</governor>
          <dependent id="20">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">said</governor>
          <dependent id="21">interview</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="John" />
            <token id="12" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>``What John was really about is depicted in this film, very accurately and without whitewashing.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="What" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="about" lemma="about" stem="about" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="depicted" lemma="depict" stem="depict" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="film" lemma="film" stem="film" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="accurately" lemma="accurately" stem="accur" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="whitewashing" lemma="whitewashing" stem="whitewash" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (SBAR (WHNP (WP What)) (S (NP (NNP John)) (VP (VBD was) (ADJP (RB really) (RB about))))) (VP (VBZ is) (VP (VBN depicted) (PP (IN in) (NP (DT this) (NN film))) (, ,) (ADVP (ADVP (RB very) (RB accurately)) (CC and) (PP (IN without) (NP (NN whitewashing)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is depicted in this film , very accurately and without whitewashing" type="VP">
          <tokens>
            <token id="7" string="is" />
            <token id="8" string="depicted" />
            <token id="9" string="in" />
            <token id="10" string="this" />
            <token id="11" string="film" />
            <token id="12" string="," />
            <token id="13" string="very" />
            <token id="14" string="accurately" />
            <token id="15" string="and" />
            <token id="16" string="without" />
            <token id="17" string="whitewashing" />
          </tokens>
        </chunking>
        <chunking id="2" string="depicted in this film , very accurately and without whitewashing" type="VP">
          <tokens>
            <token id="8" string="depicted" />
            <token id="9" string="in" />
            <token id="10" string="this" />
            <token id="11" string="film" />
            <token id="12" string="," />
            <token id="13" string="very" />
            <token id="14" string="accurately" />
            <token id="15" string="and" />
            <token id="16" string="without" />
            <token id="17" string="whitewashing" />
          </tokens>
        </chunking>
        <chunking id="3" string="What John was really about" type="SBAR">
          <tokens>
            <token id="2" string="What" />
            <token id="3" string="John" />
            <token id="4" string="was" />
            <token id="5" string="really" />
            <token id="6" string="about" />
          </tokens>
        </chunking>
        <chunking id="4" string="was really about" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="really" />
            <token id="6" string="about" />
          </tokens>
        </chunking>
        <chunking id="5" string="John" type="NP">
          <tokens>
            <token id="3" string="John" />
          </tokens>
        </chunking>
        <chunking id="6" string="whitewashing" type="NP">
          <tokens>
            <token id="17" string="whitewashing" />
          </tokens>
        </chunking>
        <chunking id="7" string="really about" type="ADJP">
          <tokens>
            <token id="5" string="really" />
            <token id="6" string="about" />
          </tokens>
        </chunking>
        <chunking id="8" string="this film" type="NP">
          <tokens>
            <token id="10" string="this" />
            <token id="11" string="film" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dobj">
          <governor id="6">about</governor>
          <dependent id="2">What</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">about</governor>
          <dependent id="3">John</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">about</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">about</governor>
          <dependent id="5">really</dependent>
        </dependency>
        <dependency type="csubjpass">
          <governor id="8">depicted</governor>
          <dependent id="6">about</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">depicted</governor>
          <dependent id="7">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">depicted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">film</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">film</governor>
          <dependent id="10">this</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">depicted</governor>
          <dependent id="11">film</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">accurately</governor>
          <dependent id="13">very</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">and</governor>
          <dependent id="14">accurately</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">depicted</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">whitewashing</governor>
          <dependent id="16">without</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">and</governor>
          <dependent id="17">whitewashing</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="John" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>``I did view it.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="view" lemma="view" stem="view" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBD did) (VP (VB view) (NP (PRP it)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="view it" type="VP">
          <tokens>
            <token id="4" string="view" />
            <token id="5" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="it" type="NP">
          <tokens>
            <token id="5" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="did view it" type="VP">
          <tokens>
            <token id="3" string="did" />
            <token id="4" string="view" />
            <token id="5" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">view</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">view</governor>
          <dependent id="3">did</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">view</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">view</governor>
          <dependent id="5">it</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>I didn&amp;apost;t have them take any footage out.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="footage" lemma="footage" stem="footag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBD did) (RB n't) (VP (VB have) (S (NP (PRP them)) (VP (VB take) (NP (DT any) (NN footage)) (PRT (RP out)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="any footage" type="NP">
          <tokens>
            <token id="7" string="any" />
            <token id="8" string="footage" />
          </tokens>
        </chunking>
        <chunking id="2" string="have them take any footage out" type="VP">
          <tokens>
            <token id="4" string="have" />
            <token id="5" string="them" />
            <token id="6" string="take" />
            <token id="7" string="any" />
            <token id="8" string="footage" />
            <token id="9" string="out" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="did n't have them take any footage out" type="VP">
          <tokens>
            <token id="2" string="did" />
            <token id="3" string="n't" />
            <token id="4" string="have" />
            <token id="5" string="them" />
            <token id="6" string="take" />
            <token id="7" string="any" />
            <token id="8" string="footage" />
            <token id="9" string="out" />
          </tokens>
        </chunking>
        <chunking id="5" string="take any footage out" type="VP">
          <tokens>
            <token id="6" string="take" />
            <token id="7" string="any" />
            <token id="8" string="footage" />
            <token id="9" string="out" />
          </tokens>
        </chunking>
        <chunking id="6" string="them" type="NP">
          <tokens>
            <token id="5" string="them" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">have</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">have</governor>
          <dependent id="2">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">have</governor>
          <dependent id="3">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">have</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">take</governor>
          <dependent id="5">them</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">have</governor>
          <dependent id="6">take</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">footage</governor>
          <dependent id="7">any</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">take</governor>
          <dependent id="8">footage</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="6">take</governor>
          <dependent id="9">out</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>``I wanted the truth.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="truth" lemma="truth" stem="truth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBD wanted) (NP (DT the) (NN truth))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="wanted the truth" type="VP">
          <tokens>
            <token id="3" string="wanted" />
            <token id="4" string="the" />
            <token id="5" string="truth" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="the truth" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="truth" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">wanted</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">wanted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">truth</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">wanted</governor>
          <dependent id="5">truth</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>In the sense you had to put a 40-year life into an hour and a half; balance is a very serious consideration.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="sense" lemma="sense" stem="sens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="put" lemma="put" stem="put" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="40-year" lemma="40-year" stem="40-year" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="10" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="13" string="hour" lemma="hour" stem="hour" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="half" lemma="half" stem="half" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="balance" lemma="balance" stem="balanc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="serious" lemma="serious" stem="seriou" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="consideration" lemma="consideration" stem="consider" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (PP (IN In) (NP (DT the) (NN sense))) (NP (PRP you)) (VP (VBD had) (S (VP (TO to) (VP (VB put) (NP (DT a) (JJ 40-year) (NN life)) (PP (IN into) (NP (NP (DT an) (NN hour)) (CC and) (NP (DT a) (NN half))))))))) (: ;) (S (NP (NN balance)) (VP (VBZ is) (NP (DT a) (ADJP (RB very) (JJ serious)) (NN consideration)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a very serious consideration" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="very" />
            <token id="22" string="serious" />
            <token id="23" string="consideration" />
          </tokens>
        </chunking>
        <chunking id="2" string="a half" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="half" />
          </tokens>
        </chunking>
        <chunking id="3" string="put a 40-year life into an hour and a half" type="VP">
          <tokens>
            <token id="7" string="put" />
            <token id="8" string="a" />
            <token id="9" string="40-year" />
            <token id="10" string="life" />
            <token id="11" string="into" />
            <token id="12" string="an" />
            <token id="13" string="hour" />
            <token id="14" string="and" />
            <token id="15" string="a" />
            <token id="16" string="half" />
          </tokens>
        </chunking>
        <chunking id="4" string="the sense" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="sense" />
          </tokens>
        </chunking>
        <chunking id="5" string="an hour and a half" type="NP">
          <tokens>
            <token id="12" string="an" />
            <token id="13" string="hour" />
            <token id="14" string="and" />
            <token id="15" string="a" />
            <token id="16" string="half" />
          </tokens>
        </chunking>
        <chunking id="6" string="is a very serious consideration" type="VP">
          <tokens>
            <token id="19" string="is" />
            <token id="20" string="a" />
            <token id="21" string="very" />
            <token id="22" string="serious" />
            <token id="23" string="consideration" />
          </tokens>
        </chunking>
        <chunking id="7" string="an hour" type="NP">
          <tokens>
            <token id="12" string="an" />
            <token id="13" string="hour" />
          </tokens>
        </chunking>
        <chunking id="8" string="balance" type="NP">
          <tokens>
            <token id="18" string="balance" />
          </tokens>
        </chunking>
        <chunking id="9" string="very serious" type="ADJP">
          <tokens>
            <token id="21" string="very" />
            <token id="22" string="serious" />
          </tokens>
        </chunking>
        <chunking id="10" string="had to put a 40-year life into an hour and a half" type="VP">
          <tokens>
            <token id="5" string="had" />
            <token id="6" string="to" />
            <token id="7" string="put" />
            <token id="8" string="a" />
            <token id="9" string="40-year" />
            <token id="10" string="life" />
            <token id="11" string="into" />
            <token id="12" string="an" />
            <token id="13" string="hour" />
            <token id="14" string="and" />
            <token id="15" string="a" />
            <token id="16" string="half" />
          </tokens>
        </chunking>
        <chunking id="11" string="to put a 40-year life into an hour and a half" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="put" />
            <token id="8" string="a" />
            <token id="9" string="40-year" />
            <token id="10" string="life" />
            <token id="11" string="into" />
            <token id="12" string="an" />
            <token id="13" string="hour" />
            <token id="14" string="and" />
            <token id="15" string="a" />
            <token id="16" string="half" />
          </tokens>
        </chunking>
        <chunking id="12" string="you" type="NP">
          <tokens>
            <token id="4" string="you" />
          </tokens>
        </chunking>
        <chunking id="13" string="a 40-year life" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="40-year" />
            <token id="10" string="life" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">sense</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">sense</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">had</governor>
          <dependent id="3">sense</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">had</governor>
          <dependent id="4">you</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">had</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">put</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">had</governor>
          <dependent id="7">put</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">life</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">life</governor>
          <dependent id="9">40-year</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">put</governor>
          <dependent id="10">life</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">hour</governor>
          <dependent id="11">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">hour</governor>
          <dependent id="12">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">put</governor>
          <dependent id="13">hour</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">hour</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">half</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">hour</governor>
          <dependent id="16">half</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">consideration</governor>
          <dependent id="18">balance</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="23">consideration</governor>
          <dependent id="19">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">consideration</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">serious</governor>
          <dependent id="21">very</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">consideration</governor>
          <dependent id="22">serious</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="5">had</governor>
          <dependent id="23">consideration</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="40-year" type="DURATION" score="0.0">
          <tokens>
            <token id="9" string="40-year" />
          </tokens>
        </entity>
        <entity id="2" string="an hour" type="DURATION" score="0.0">
          <tokens>
            <token id="12" string="an" />
            <token id="13" string="hour" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>I think they did a remarkable job and very tastefully so.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="remarkable" lemma="remarkable" stem="remark" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="job" lemma="job" stem="job" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="tastefully" lemma="tastefully" stem="tastefulli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP think) (SBAR (S (NP (PRP they)) (VP (VBD did) (VP (FRAG (ADJP (NP (DT a) (JJ remarkable) (NN job)) (CC and) (ADJP (RB very) (RB tastefully) (RB so))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="think they did a remarkable job and very tastefully so" type="VP">
          <tokens>
            <token id="2" string="think" />
            <token id="3" string="they" />
            <token id="4" string="did" />
            <token id="5" string="a" />
            <token id="6" string="remarkable" />
            <token id="7" string="job" />
            <token id="8" string="and" />
            <token id="9" string="very" />
            <token id="10" string="tastefully" />
            <token id="11" string="so" />
          </tokens>
        </chunking>
        <chunking id="2" string="they" type="NP">
          <tokens>
            <token id="3" string="they" />
          </tokens>
        </chunking>
        <chunking id="3" string="very tastefully so" type="ADJP">
          <tokens>
            <token id="9" string="very" />
            <token id="10" string="tastefully" />
            <token id="11" string="so" />
          </tokens>
        </chunking>
        <chunking id="4" string="a remarkable job" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="remarkable" />
            <token id="7" string="job" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="they did a remarkable job and very tastefully so" type="SBAR">
          <tokens>
            <token id="3" string="they" />
            <token id="4" string="did" />
            <token id="5" string="a" />
            <token id="6" string="remarkable" />
            <token id="7" string="job" />
            <token id="8" string="and" />
            <token id="9" string="very" />
            <token id="10" string="tastefully" />
            <token id="11" string="so" />
          </tokens>
        </chunking>
        <chunking id="7" string="did a remarkable job and very tastefully so" type="VP">
          <tokens>
            <token id="4" string="did" />
            <token id="5" string="a" />
            <token id="6" string="remarkable" />
            <token id="7" string="job" />
            <token id="8" string="and" />
            <token id="9" string="very" />
            <token id="10" string="tastefully" />
            <token id="11" string="so" />
          </tokens>
        </chunking>
        <chunking id="8" string="a remarkable job and very tastefully so" type="VP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="remarkable" />
            <token id="7" string="job" />
            <token id="8" string="and" />
            <token id="9" string="very" />
            <token id="10" string="tastefully" />
            <token id="11" string="so" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">think</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">think</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">job</governor>
          <dependent id="3">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">job</governor>
          <dependent id="4">did</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">job</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">job</governor>
          <dependent id="6">remarkable</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">think</governor>
          <dependent id="7">job</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">job</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">so</governor>
          <dependent id="9">very</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">so</governor>
          <dependent id="10">tastefully</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">job</governor>
          <dependent id="11">so</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>There is a soundtrack album and a coffeetable book with comments primarily by Lennon, tied in with the film and using the same title.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="soundtrack" lemma="soundtrack" stem="soundtrack" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="album" lemma="album" stem="album" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="coffeetable" lemma="coffeetable" stem="coffeet" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="comments" lemma="comment" stem="comment" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="primarily" lemma="primarily" stem="primarili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="tied" lemma="tie" stem="ti" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="in" lemma="in" stem="in" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="film" lemma="film" stem="film" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="using" lemma="use" stem="us" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="same" lemma="same" stem="same" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="title" lemma="title" stem="titl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (EX There)) (VP (VBZ is) (NP (NP (DT a) (NN soundtrack) (NN album)) (CC and) (NP (NP (DT a) (JJ coffeetable) (NN book)) (PP (IN with) (NP (NNS comments))) (UCP (PP (ADVP (RB primarily)) (IN by) (NP (NP (NNP Lennon)) (, ,) (VP (VBN tied) (PRT (RP in)) (PP (IN with) (NP (DT the) (NN film)))))) (CC and) (S (VP (VBG using) (NP (DT the) (JJ same) (NN title)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="using the same title" type="VP">
          <tokens>
            <token id="22" string="using" />
            <token id="23" string="the" />
            <token id="24" string="same" />
            <token id="25" string="title" />
          </tokens>
        </chunking>
        <chunking id="2" string="tied in with the film" type="VP">
          <tokens>
            <token id="16" string="tied" />
            <token id="17" string="in" />
            <token id="18" string="with" />
            <token id="19" string="the" />
            <token id="20" string="film" />
          </tokens>
        </chunking>
        <chunking id="3" string="a coffeetable book" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="coffeetable" />
            <token id="9" string="book" />
          </tokens>
        </chunking>
        <chunking id="4" string="comments" type="NP">
          <tokens>
            <token id="11" string="comments" />
          </tokens>
        </chunking>
        <chunking id="5" string="Lennon" type="NP">
          <tokens>
            <token id="14" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="6" string="the film" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="film" />
          </tokens>
        </chunking>
        <chunking id="7" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="8" string="Lennon , tied in with the film" type="NP">
          <tokens>
            <token id="14" string="Lennon" />
            <token id="15" string="," />
            <token id="16" string="tied" />
            <token id="17" string="in" />
            <token id="18" string="with" />
            <token id="19" string="the" />
            <token id="20" string="film" />
          </tokens>
        </chunking>
        <chunking id="9" string="a soundtrack album" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="soundtrack" />
            <token id="5" string="album" />
          </tokens>
        </chunking>
        <chunking id="10" string="is a soundtrack album and a coffeetable book with comments primarily by Lennon , tied in with the film and using the same title" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="a" />
            <token id="4" string="soundtrack" />
            <token id="5" string="album" />
            <token id="6" string="and" />
            <token id="7" string="a" />
            <token id="8" string="coffeetable" />
            <token id="9" string="book" />
            <token id="10" string="with" />
            <token id="11" string="comments" />
            <token id="12" string="primarily" />
            <token id="13" string="by" />
            <token id="14" string="Lennon" />
            <token id="15" string="," />
            <token id="16" string="tied" />
            <token id="17" string="in" />
            <token id="18" string="with" />
            <token id="19" string="the" />
            <token id="20" string="film" />
            <token id="21" string="and" />
            <token id="22" string="using" />
            <token id="23" string="the" />
            <token id="24" string="same" />
            <token id="25" string="title" />
          </tokens>
        </chunking>
        <chunking id="11" string="the same title" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="same" />
            <token id="25" string="title" />
          </tokens>
        </chunking>
        <chunking id="12" string="a soundtrack album and a coffeetable book with comments primarily by Lennon , tied in with the film and using the same title" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="soundtrack" />
            <token id="5" string="album" />
            <token id="6" string="and" />
            <token id="7" string="a" />
            <token id="8" string="coffeetable" />
            <token id="9" string="book" />
            <token id="10" string="with" />
            <token id="11" string="comments" />
            <token id="12" string="primarily" />
            <token id="13" string="by" />
            <token id="14" string="Lennon" />
            <token id="15" string="," />
            <token id="16" string="tied" />
            <token id="17" string="in" />
            <token id="18" string="with" />
            <token id="19" string="the" />
            <token id="20" string="film" />
            <token id="21" string="and" />
            <token id="22" string="using" />
            <token id="23" string="the" />
            <token id="24" string="same" />
            <token id="25" string="title" />
          </tokens>
        </chunking>
        <chunking id="13" string="a coffeetable book with comments primarily by Lennon , tied in with the film and using the same title" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="coffeetable" />
            <token id="9" string="book" />
            <token id="10" string="with" />
            <token id="11" string="comments" />
            <token id="12" string="primarily" />
            <token id="13" string="by" />
            <token id="14" string="Lennon" />
            <token id="15" string="," />
            <token id="16" string="tied" />
            <token id="17" string="in" />
            <token id="18" string="with" />
            <token id="19" string="the" />
            <token id="20" string="film" />
            <token id="21" string="and" />
            <token id="22" string="using" />
            <token id="23" string="the" />
            <token id="24" string="same" />
            <token id="25" string="title" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="2">is</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">album</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">album</governor>
          <dependent id="4">soundtrack</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="2">is</governor>
          <dependent id="5">album</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">album</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">book</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">book</governor>
          <dependent id="8">coffeetable</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">album</governor>
          <dependent id="9">book</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">comments</governor>
          <dependent id="10">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">book</governor>
          <dependent id="11">comments</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">Lennon</governor>
          <dependent id="12">primarily</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Lennon</governor>
          <dependent id="13">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">book</governor>
          <dependent id="14">Lennon</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">Lennon</governor>
          <dependent id="16">tied</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="16">tied</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">film</governor>
          <dependent id="18">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">film</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">tied</governor>
          <dependent id="20">film</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">Lennon</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">Lennon</governor>
          <dependent id="22">using</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">title</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">title</governor>
          <dependent id="24">same</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">using</governor>
          <dependent id="25">title</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Lennon" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>``Imagine there&amp;apost;s no heaven ``It&amp;apost;s easy if you try ``No hell below us ``Above us only sky ``Imagine all the people ``Living for today.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Imagine" lemma="imagine" stem="imagin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="heaven" lemma="heaven" stem="heaven" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="easy" lemma="easy" stem="easi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="try" lemma="try" stem="try" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="No" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="hell" lemma="hell" stem="hell" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="below" lemma="below" stem="below" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="us" lemma="we" stem="u" pos="PRP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Above" lemma="above" stem="above" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="us" lemma="we" stem="u" pos="PRP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="sky" lemma="sky" stem="sky" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Imagine" lemma="imagine" stem="imagin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="all" lemma="all" stem="all" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="Living" lemma="live" stem="live" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (VP (VB Imagine) (SBAR (S (NP (EX there)) (VP (VBZ 's) (NP (NP (DT no) (NN heaven)) (SBAR (`` ``) (S (NP (PRP It)) (VP (VBZ 's) (ADJP (JJ easy)) (SBAR (IN if) (S (NP (PRP you)) (VP (VBP try)))))))) (`` ``) (NP (NP (DT No) (NN hell)) (PP (IN below) (NP (PRP us))) (S (`` ``) (PP (IN Above) (NP (NP (PRP us)) (PP (RB only) (ADVP (NN sky))))) (VP (`` ``) (VB Imagine) (S (NP (PDT all) (DT the) (NNS people)) (`` ``) (VP (VBG Living) (PP (IN for) (NP (NN today)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="there 's no heaven `` It 's easy if you try `` No hell below us `` Above us only sky `` Imagine all the people `` Living for today" type="SBAR">
          <tokens>
            <token id="3" string="there" />
            <token id="4" string="'s" />
            <token id="5" string="no" />
            <token id="6" string="heaven" />
            <token id="7" string="``" />
            <token id="8" string="It" />
            <token id="9" string="'s" />
            <token id="10" string="easy" />
            <token id="11" string="if" />
            <token id="12" string="you" />
            <token id="13" string="try" />
            <token id="14" string="``" />
            <token id="15" string="No" />
            <token id="16" string="hell" />
            <token id="17" string="below" />
            <token id="18" string="us" />
            <token id="19" string="``" />
            <token id="20" string="Above" />
            <token id="21" string="us" />
            <token id="22" string="only" />
            <token id="23" string="sky" />
            <token id="24" string="``" />
            <token id="25" string="Imagine" />
            <token id="26" string="all" />
            <token id="27" string="the" />
            <token id="28" string="people" />
            <token id="29" string="``" />
            <token id="30" string="Living" />
            <token id="31" string="for" />
            <token id="32" string="today" />
          </tokens>
        </chunking>
        <chunking id="2" string="`` It 's easy if you try" type="SBAR">
          <tokens>
            <token id="7" string="``" />
            <token id="8" string="It" />
            <token id="9" string="'s" />
            <token id="10" string="easy" />
            <token id="11" string="if" />
            <token id="12" string="you" />
            <token id="13" string="try" />
          </tokens>
        </chunking>
        <chunking id="3" string="`` Imagine all the people `` Living for today" type="VP">
          <tokens>
            <token id="24" string="``" />
            <token id="25" string="Imagine" />
            <token id="26" string="all" />
            <token id="27" string="the" />
            <token id="28" string="people" />
            <token id="29" string="``" />
            <token id="30" string="Living" />
            <token id="31" string="for" />
            <token id="32" string="today" />
          </tokens>
        </chunking>
        <chunking id="4" string="us only sky" type="NP">
          <tokens>
            <token id="21" string="us" />
            <token id="22" string="only" />
            <token id="23" string="sky" />
          </tokens>
        </chunking>
        <chunking id="5" string="'s no heaven `` It 's easy if you try `` No hell below us `` Above us only sky `` Imagine all the people `` Living for today" type="VP">
          <tokens>
            <token id="4" string="'s" />
            <token id="5" string="no" />
            <token id="6" string="heaven" />
            <token id="7" string="``" />
            <token id="8" string="It" />
            <token id="9" string="'s" />
            <token id="10" string="easy" />
            <token id="11" string="if" />
            <token id="12" string="you" />
            <token id="13" string="try" />
            <token id="14" string="``" />
            <token id="15" string="No" />
            <token id="16" string="hell" />
            <token id="17" string="below" />
            <token id="18" string="us" />
            <token id="19" string="``" />
            <token id="20" string="Above" />
            <token id="21" string="us" />
            <token id="22" string="only" />
            <token id="23" string="sky" />
            <token id="24" string="``" />
            <token id="25" string="Imagine" />
            <token id="26" string="all" />
            <token id="27" string="the" />
            <token id="28" string="people" />
            <token id="29" string="``" />
            <token id="30" string="Living" />
            <token id="31" string="for" />
            <token id="32" string="today" />
          </tokens>
        </chunking>
        <chunking id="6" string="It" type="NP">
          <tokens>
            <token id="8" string="It" />
          </tokens>
        </chunking>
        <chunking id="7" string="'s easy if you try" type="VP">
          <tokens>
            <token id="9" string="'s" />
            <token id="10" string="easy" />
            <token id="11" string="if" />
            <token id="12" string="you" />
            <token id="13" string="try" />
          </tokens>
        </chunking>
        <chunking id="8" string="easy" type="ADJP">
          <tokens>
            <token id="10" string="easy" />
          </tokens>
        </chunking>
        <chunking id="9" string="Imagine there 's no heaven `` It 's easy if you try `` No hell below us `` Above us only sky `` Imagine all the people `` Living for today" type="VP">
          <tokens>
            <token id="2" string="Imagine" />
            <token id="3" string="there" />
            <token id="4" string="'s" />
            <token id="5" string="no" />
            <token id="6" string="heaven" />
            <token id="7" string="``" />
            <token id="8" string="It" />
            <token id="9" string="'s" />
            <token id="10" string="easy" />
            <token id="11" string="if" />
            <token id="12" string="you" />
            <token id="13" string="try" />
            <token id="14" string="``" />
            <token id="15" string="No" />
            <token id="16" string="hell" />
            <token id="17" string="below" />
            <token id="18" string="us" />
            <token id="19" string="``" />
            <token id="20" string="Above" />
            <token id="21" string="us" />
            <token id="22" string="only" />
            <token id="23" string="sky" />
            <token id="24" string="``" />
            <token id="25" string="Imagine" />
            <token id="26" string="all" />
            <token id="27" string="the" />
            <token id="28" string="people" />
            <token id="29" string="``" />
            <token id="30" string="Living" />
            <token id="31" string="for" />
            <token id="32" string="today" />
          </tokens>
        </chunking>
        <chunking id="10" string="there" type="NP">
          <tokens>
            <token id="3" string="there" />
          </tokens>
        </chunking>
        <chunking id="11" string="if you try" type="SBAR">
          <tokens>
            <token id="11" string="if" />
            <token id="12" string="you" />
            <token id="13" string="try" />
          </tokens>
        </chunking>
        <chunking id="12" string="No hell below us `` Above us only sky `` Imagine all the people `` Living for today" type="NP">
          <tokens>
            <token id="15" string="No" />
            <token id="16" string="hell" />
            <token id="17" string="below" />
            <token id="18" string="us" />
            <token id="19" string="``" />
            <token id="20" string="Above" />
            <token id="21" string="us" />
            <token id="22" string="only" />
            <token id="23" string="sky" />
            <token id="24" string="``" />
            <token id="25" string="Imagine" />
            <token id="26" string="all" />
            <token id="27" string="the" />
            <token id="28" string="people" />
            <token id="29" string="``" />
            <token id="30" string="Living" />
            <token id="31" string="for" />
            <token id="32" string="today" />
          </tokens>
        </chunking>
        <chunking id="13" string="all the people" type="NP">
          <tokens>
            <token id="26" string="all" />
            <token id="27" string="the" />
            <token id="28" string="people" />
          </tokens>
        </chunking>
        <chunking id="14" string="today" type="NP">
          <tokens>
            <token id="32" string="today" />
          </tokens>
        </chunking>
        <chunking id="15" string="no heaven `` It 's easy if you try" type="NP">
          <tokens>
            <token id="5" string="no" />
            <token id="6" string="heaven" />
            <token id="7" string="``" />
            <token id="8" string="It" />
            <token id="9" string="'s" />
            <token id="10" string="easy" />
            <token id="11" string="if" />
            <token id="12" string="you" />
            <token id="13" string="try" />
          </tokens>
        </chunking>
        <chunking id="16" string="No hell" type="NP">
          <tokens>
            <token id="15" string="No" />
            <token id="16" string="hell" />
          </tokens>
        </chunking>
        <chunking id="17" string="Living for today" type="VP">
          <tokens>
            <token id="30" string="Living" />
            <token id="31" string="for" />
            <token id="32" string="today" />
          </tokens>
        </chunking>
        <chunking id="18" string="try" type="VP">
          <tokens>
            <token id="13" string="try" />
          </tokens>
        </chunking>
        <chunking id="19" string="us" type="NP">
          <tokens>
            <token id="18" string="us" />
          </tokens>
        </chunking>
        <chunking id="20" string="no heaven" type="NP">
          <tokens>
            <token id="5" string="no" />
            <token id="6" string="heaven" />
          </tokens>
        </chunking>
        <chunking id="21" string="you" type="NP">
          <tokens>
            <token id="12" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">Imagine</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="4">'s</governor>
          <dependent id="3">there</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">Imagine</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">heaven</governor>
          <dependent id="5">no</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">'s</governor>
          <dependent id="6">heaven</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">easy</governor>
          <dependent id="8">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">easy</governor>
          <dependent id="9">'s</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">heaven</governor>
          <dependent id="10">easy</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">try</governor>
          <dependent id="11">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">try</governor>
          <dependent id="12">you</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">easy</governor>
          <dependent id="13">try</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="16">hell</governor>
          <dependent id="15">No</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">'s</governor>
          <dependent id="16">hell</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">us</governor>
          <dependent id="17">below</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">hell</governor>
          <dependent id="18">us</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">us</governor>
          <dependent id="20">Above</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">Imagine</governor>
          <dependent id="21">us</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">sky</governor>
          <dependent id="22">only</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="21">us</governor>
          <dependent id="23">sky</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">hell</governor>
          <dependent id="25">Imagine</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="28">people</governor>
          <dependent id="26">all</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">people</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">Living</governor>
          <dependent id="28">people</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="25">Imagine</governor>
          <dependent id="30">Living</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">today</governor>
          <dependent id="31">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">Living</governor>
          <dependent id="32">today</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="today" type="DATE" score="0.0">
          <tokens>
            <token id="32" string="today" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>...&amp;apost;&amp;apost;  ``Imagine&amp;apost;&amp;apost; is more than a Lennon elegy.</content>
      <tokens>
        <token id="1" string="..." lemma="..." stem="..." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Imagine" lemma="imagine" stem="imagin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="11" string="elegy" lemma="elegy" stem="elegi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (: ...) ('' '') (VP (`` ``) (VB Imagine) ('' '')))) (VP (VBZ is) (ADJP (ADJP (JJR more)) (PP (IN than) (NP (DT a) (NNP Lennon) (NN elegy))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="`` Imagine ''" type="VP">
          <tokens>
            <token id="3" string="``" />
            <token id="4" string="Imagine" />
            <token id="5" string="''" />
          </tokens>
        </chunking>
        <chunking id="2" string="a Lennon elegy" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="Lennon" />
            <token id="11" string="elegy" />
          </tokens>
        </chunking>
        <chunking id="3" string="... '' `` Imagine ''" type="VP">
          <tokens>
            <token id="1" string="..." />
            <token id="2" string="''" />
            <token id="3" string="``" />
            <token id="4" string="Imagine" />
            <token id="5" string="''" />
          </tokens>
        </chunking>
        <chunking id="4" string="more" type="ADJP">
          <tokens>
            <token id="7" string="more" />
          </tokens>
        </chunking>
        <chunking id="5" string="is more than a Lennon elegy" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="more" />
            <token id="8" string="than" />
            <token id="9" string="a" />
            <token id="10" string="Lennon" />
            <token id="11" string="elegy" />
          </tokens>
        </chunking>
        <chunking id="6" string="more than a Lennon elegy" type="ADJP">
          <tokens>
            <token id="7" string="more" />
            <token id="8" string="than" />
            <token id="9" string="a" />
            <token id="10" string="Lennon" />
            <token id="11" string="elegy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="csubj">
          <governor id="7">more</governor>
          <dependent id="4">Imagine</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">more</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">more</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">elegy</governor>
          <dependent id="8">than</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">elegy</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">elegy</governor>
          <dependent id="10">Lennon</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">more</governor>
          <dependent id="11">elegy</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Lennon" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>Though it fails to delve too deeply into the darker side of Lennon and the Beatles (drug use, abusive tempers, manager Brian Epstein&amp;apost;s death), it does capture the music and the times in which Lennon lived.</content>
      <tokens>
        <token id="1" string="Though" lemma="though" stem="though" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="fails" lemma="fail" stem="fail" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="delve" lemma="delve" stem="delv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="deeply" lemma="deeply" stem="deepli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="darker" lemma="darker" stem="darker" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="side" lemma="side" stem="side" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Beatles" lemma="beatle" stem="beatl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="use" lemma="use" stem="us" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="abusive" lemma="abusive" stem="abus" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="tempers" lemma="temper" stem="temper" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="manager" lemma="manager" stem="manag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="Brian" lemma="Brian" stem="brian" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="26" string="Epstein" lemma="epstein" stem="epstein" pos="NN" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="27" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="death" lemma="death" stem="death" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="capture" lemma="capture" stem="captur" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="music" lemma="music" stem="music" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="times" lemma="time" stem="time" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="42" string="lived" lemma="live" stem="live" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Though) (S (NP (PRP it)) (VP (VBZ fails) (S (VP (TO to) (VP (VB delve) (ADVP (RB too) (RB deeply)) (PP (IN into) (NP (NP (NP (DT the) (JJR darker) (NN side)) (PP (IN of) (NP (NNP Lennon)))) (CC and) (NP (NP (DT the) (NNS Beatles)) (PRN (-LRB- -LRB-) (NP (NP (NN drug) (NN use)) (, ,) (NP (NP (JJ abusive) (NNS tempers)) (, ,) (NP (NP (NN manager)) (NP (NP (NNP Brian) (NN Epstein) (POS 's)) (NN death))))) (-RRB- -RRB-))))))))))) (, ,) (NP (PRP it)) (VP (VBZ does) (VP (VB capture) (NP (NP (DT the) (NN music)) (CC and) (NP (NP (DT the) (NNS times)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (NNP Lennon)) (VP (VBD lived)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="drug use , abusive tempers , manager Brian Epstein 's death" type="NP">
          <tokens>
            <token id="18" string="drug" />
            <token id="19" string="use" />
            <token id="20" string="," />
            <token id="21" string="abusive" />
            <token id="22" string="tempers" />
            <token id="23" string="," />
            <token id="24" string="manager" />
            <token id="25" string="Brian" />
            <token id="26" string="Epstein" />
            <token id="27" string="'s" />
            <token id="28" string="death" />
          </tokens>
        </chunking>
        <chunking id="2" string="manager" type="NP">
          <tokens>
            <token id="24" string="manager" />
          </tokens>
        </chunking>
        <chunking id="3" string="it" type="NP">
          <tokens>
            <token id="2" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="the darker side of Lennon" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="darker" />
            <token id="11" string="side" />
            <token id="12" string="of" />
            <token id="13" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="5" string="manager Brian Epstein 's death" type="NP">
          <tokens>
            <token id="24" string="manager" />
            <token id="25" string="Brian" />
            <token id="26" string="Epstein" />
            <token id="27" string="'s" />
            <token id="28" string="death" />
          </tokens>
        </chunking>
        <chunking id="6" string="Brian Epstein 's death" type="NP">
          <tokens>
            <token id="25" string="Brian" />
            <token id="26" string="Epstein" />
            <token id="27" string="'s" />
            <token id="28" string="death" />
          </tokens>
        </chunking>
        <chunking id="7" string="capture the music and the times in which Lennon lived" type="VP">
          <tokens>
            <token id="33" string="capture" />
            <token id="34" string="the" />
            <token id="35" string="music" />
            <token id="36" string="and" />
            <token id="37" string="the" />
            <token id="38" string="times" />
            <token id="39" string="in" />
            <token id="40" string="which" />
            <token id="41" string="Lennon" />
            <token id="42" string="lived" />
          </tokens>
        </chunking>
        <chunking id="8" string="fails to delve too deeply into the darker side of Lennon and the Beatles -LRB- drug use , abusive tempers , manager Brian Epstein 's death -RRB-" type="VP">
          <tokens>
            <token id="3" string="fails" />
            <token id="4" string="to" />
            <token id="5" string="delve" />
            <token id="6" string="too" />
            <token id="7" string="deeply" />
            <token id="8" string="into" />
            <token id="9" string="the" />
            <token id="10" string="darker" />
            <token id="11" string="side" />
            <token id="12" string="of" />
            <token id="13" string="Lennon" />
            <token id="14" string="and" />
            <token id="15" string="the" />
            <token id="16" string="Beatles" />
            <token id="17" string="(" />
            <token id="18" string="drug" />
            <token id="19" string="use" />
            <token id="20" string="," />
            <token id="21" string="abusive" />
            <token id="22" string="tempers" />
            <token id="23" string="," />
            <token id="24" string="manager" />
            <token id="25" string="Brian" />
            <token id="26" string="Epstein" />
            <token id="27" string="'s" />
            <token id="28" string="death" />
            <token id="29" string=")" />
          </tokens>
        </chunking>
        <chunking id="9" string="delve too deeply into the darker side of Lennon and the Beatles -LRB- drug use , abusive tempers , manager Brian Epstein 's death -RRB-" type="VP">
          <tokens>
            <token id="5" string="delve" />
            <token id="6" string="too" />
            <token id="7" string="deeply" />
            <token id="8" string="into" />
            <token id="9" string="the" />
            <token id="10" string="darker" />
            <token id="11" string="side" />
            <token id="12" string="of" />
            <token id="13" string="Lennon" />
            <token id="14" string="and" />
            <token id="15" string="the" />
            <token id="16" string="Beatles" />
            <token id="17" string="(" />
            <token id="18" string="drug" />
            <token id="19" string="use" />
            <token id="20" string="," />
            <token id="21" string="abusive" />
            <token id="22" string="tempers" />
            <token id="23" string="," />
            <token id="24" string="manager" />
            <token id="25" string="Brian" />
            <token id="26" string="Epstein" />
            <token id="27" string="'s" />
            <token id="28" string="death" />
            <token id="29" string=")" />
          </tokens>
        </chunking>
        <chunking id="10" string="the Beatles -LRB- drug use , abusive tempers , manager Brian Epstein 's death -RRB-" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="Beatles" />
            <token id="17" string="(" />
            <token id="18" string="drug" />
            <token id="19" string="use" />
            <token id="20" string="," />
            <token id="21" string="abusive" />
            <token id="22" string="tempers" />
            <token id="23" string="," />
            <token id="24" string="manager" />
            <token id="25" string="Brian" />
            <token id="26" string="Epstein" />
            <token id="27" string="'s" />
            <token id="28" string="death" />
            <token id="29" string=")" />
          </tokens>
        </chunking>
        <chunking id="11" string="Lennon" type="NP">
          <tokens>
            <token id="13" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="12" string="Brian Epstein 's" type="NP">
          <tokens>
            <token id="25" string="Brian" />
            <token id="26" string="Epstein" />
            <token id="27" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="Though it fails to delve too deeply into the darker side of Lennon and the Beatles -LRB- drug use , abusive tempers , manager Brian Epstein 's death -RRB-" type="SBAR">
          <tokens>
            <token id="1" string="Though" />
            <token id="2" string="it" />
            <token id="3" string="fails" />
            <token id="4" string="to" />
            <token id="5" string="delve" />
            <token id="6" string="too" />
            <token id="7" string="deeply" />
            <token id="8" string="into" />
            <token id="9" string="the" />
            <token id="10" string="darker" />
            <token id="11" string="side" />
            <token id="12" string="of" />
            <token id="13" string="Lennon" />
            <token id="14" string="and" />
            <token id="15" string="the" />
            <token id="16" string="Beatles" />
            <token id="17" string="(" />
            <token id="18" string="drug" />
            <token id="19" string="use" />
            <token id="20" string="," />
            <token id="21" string="abusive" />
            <token id="22" string="tempers" />
            <token id="23" string="," />
            <token id="24" string="manager" />
            <token id="25" string="Brian" />
            <token id="26" string="Epstein" />
            <token id="27" string="'s" />
            <token id="28" string="death" />
            <token id="29" string=")" />
          </tokens>
        </chunking>
        <chunking id="14" string="the darker side" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="darker" />
            <token id="11" string="side" />
          </tokens>
        </chunking>
        <chunking id="15" string="in which Lennon lived" type="SBAR">
          <tokens>
            <token id="39" string="in" />
            <token id="40" string="which" />
            <token id="41" string="Lennon" />
            <token id="42" string="lived" />
          </tokens>
        </chunking>
        <chunking id="16" string="the darker side of Lennon and the Beatles -LRB- drug use , abusive tempers , manager Brian Epstein 's death -RRB-" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="darker" />
            <token id="11" string="side" />
            <token id="12" string="of" />
            <token id="13" string="Lennon" />
            <token id="14" string="and" />
            <token id="15" string="the" />
            <token id="16" string="Beatles" />
            <token id="17" string="(" />
            <token id="18" string="drug" />
            <token id="19" string="use" />
            <token id="20" string="," />
            <token id="21" string="abusive" />
            <token id="22" string="tempers" />
            <token id="23" string="," />
            <token id="24" string="manager" />
            <token id="25" string="Brian" />
            <token id="26" string="Epstein" />
            <token id="27" string="'s" />
            <token id="28" string="death" />
            <token id="29" string=")" />
          </tokens>
        </chunking>
        <chunking id="17" string="the Beatles" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="Beatles" />
          </tokens>
        </chunking>
        <chunking id="18" string="abusive tempers , manager Brian Epstein 's death" type="NP">
          <tokens>
            <token id="21" string="abusive" />
            <token id="22" string="tempers" />
            <token id="23" string="," />
            <token id="24" string="manager" />
            <token id="25" string="Brian" />
            <token id="26" string="Epstein" />
            <token id="27" string="'s" />
            <token id="28" string="death" />
          </tokens>
        </chunking>
        <chunking id="19" string="abusive tempers" type="NP">
          <tokens>
            <token id="21" string="abusive" />
            <token id="22" string="tempers" />
          </tokens>
        </chunking>
        <chunking id="20" string="does capture the music and the times in which Lennon lived" type="VP">
          <tokens>
            <token id="32" string="does" />
            <token id="33" string="capture" />
            <token id="34" string="the" />
            <token id="35" string="music" />
            <token id="36" string="and" />
            <token id="37" string="the" />
            <token id="38" string="times" />
            <token id="39" string="in" />
            <token id="40" string="which" />
            <token id="41" string="Lennon" />
            <token id="42" string="lived" />
          </tokens>
        </chunking>
        <chunking id="21" string="lived" type="VP">
          <tokens>
            <token id="42" string="lived" />
          </tokens>
        </chunking>
        <chunking id="22" string="the music" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="music" />
          </tokens>
        </chunking>
        <chunking id="23" string="the times" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="times" />
          </tokens>
        </chunking>
        <chunking id="24" string="drug use" type="NP">
          <tokens>
            <token id="18" string="drug" />
            <token id="19" string="use" />
          </tokens>
        </chunking>
        <chunking id="25" string="the times in which Lennon lived" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="times" />
            <token id="39" string="in" />
            <token id="40" string="which" />
            <token id="41" string="Lennon" />
            <token id="42" string="lived" />
          </tokens>
        </chunking>
        <chunking id="26" string="the music and the times in which Lennon lived" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="music" />
            <token id="36" string="and" />
            <token id="37" string="the" />
            <token id="38" string="times" />
            <token id="39" string="in" />
            <token id="40" string="which" />
            <token id="41" string="Lennon" />
            <token id="42" string="lived" />
          </tokens>
        </chunking>
        <chunking id="27" string="to delve too deeply into the darker side of Lennon and the Beatles -LRB- drug use , abusive tempers , manager Brian Epstein 's death -RRB-" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="delve" />
            <token id="6" string="too" />
            <token id="7" string="deeply" />
            <token id="8" string="into" />
            <token id="9" string="the" />
            <token id="10" string="darker" />
            <token id="11" string="side" />
            <token id="12" string="of" />
            <token id="13" string="Lennon" />
            <token id="14" string="and" />
            <token id="15" string="the" />
            <token id="16" string="Beatles" />
            <token id="17" string="(" />
            <token id="18" string="drug" />
            <token id="19" string="use" />
            <token id="20" string="," />
            <token id="21" string="abusive" />
            <token id="22" string="tempers" />
            <token id="23" string="," />
            <token id="24" string="manager" />
            <token id="25" string="Brian" />
            <token id="26" string="Epstein" />
            <token id="27" string="'s" />
            <token id="28" string="death" />
            <token id="29" string=")" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="3">fails</governor>
          <dependent id="1">Though</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">fails</governor>
          <dependent id="2">it</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="33">capture</governor>
          <dependent id="3">fails</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">delve</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">fails</governor>
          <dependent id="5">delve</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">deeply</governor>
          <dependent id="6">too</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">delve</governor>
          <dependent id="7">deeply</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">side</governor>
          <dependent id="8">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">side</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">side</governor>
          <dependent id="10">darker</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">delve</governor>
          <dependent id="11">side</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Lennon</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">side</governor>
          <dependent id="13">Lennon</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">side</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">Beatles</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">side</governor>
          <dependent id="16">Beatles</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">use</governor>
          <dependent id="18">drug</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">Beatles</governor>
          <dependent id="19">use</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">tempers</governor>
          <dependent id="21">abusive</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="19">use</governor>
          <dependent id="22">tempers</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="22">tempers</governor>
          <dependent id="24">manager</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Epstein</governor>
          <dependent id="25">Brian</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="28">death</governor>
          <dependent id="26">Epstein</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">Epstein</governor>
          <dependent id="27">'s</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="24">manager</governor>
          <dependent id="28">death</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">capture</governor>
          <dependent id="31">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="33">capture</governor>
          <dependent id="32">does</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="33">capture</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">music</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="33">capture</governor>
          <dependent id="35">music</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="35">music</governor>
          <dependent id="36">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">times</governor>
          <dependent id="37">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="35">music</governor>
          <dependent id="38">times</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">which</governor>
          <dependent id="39">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="42">lived</governor>
          <dependent id="40">which</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="42">lived</governor>
          <dependent id="41">Lennon</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="38">times</governor>
          <dependent id="42">lived</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="Brian Epstein" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Brian" />
            <token id="26" string="Epstein" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>One intriguing episode in ``Imagine&amp;apost;&amp;apost; shows cartoonist Al Capp (``L&amp;apost;il Abner&amp;apost;&amp;apost;) being antagonistic toward the Lennons during their bed-in, when they stayed in bed for a week to publicize their concern for peace.</content>
      <tokens>
        <token id="1" string="One" lemma="one" stem="one" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="2" string="intriguing" lemma="intriguing" stem="intrigu" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="episode" lemma="episode" stem="episod" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Imagine" lemma="imagine" stem="imagin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="shows" lemma="show" stem="show" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="cartoonist" lemma="cartoonist" stem="cartoonist" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="Al" lemma="Al" stem="al" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="Capp" lemma="Capp" stem="capp" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="L'il" lemma="L'il" stem="l'il" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="Abner" lemma="Abner" stem="abner" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="antagonistic" lemma="antagonistic" stem="antagonist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="toward" lemma="toward" stem="toward" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Lennons" lemma="Lennons" stem="lennon" pos="NNPS" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="23" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="bed-in" lemma="bed-in" stem="bed-in" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="stayed" lemma="stay" stem="stai" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="bed" lemma="bed" stem="bed" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="34" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="35" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="publicize" lemma="publicize" stem="public" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="38" string="concern" lemma="concern" stem="concern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="peace" lemma="peace" stem="peac" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (CD One) (JJ intriguing) (NN episode)) (PP (IN in) (`` ``) (S (VP (VB Imagine))) ('' ''))) (VP (VBZ shows) (NP (NP (NN cartoonist) (NNP Al) (NNP Capp)) (PRN (-LRB- -LRB-) (`` ``) (NP (NNP L'il) (NNP Abner)) ('' '') (-RRB- -RRB-))) (S (VP (VBG being) (ADJP (JJ antagonistic) (PP (IN toward) (NP (DT the) (NNPS Lennons)))) (PP (IN during) (NP (PRP$ their) (NN bed-in))))) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (PRP they)) (VP (VBD stayed) (PP (IN in) (NP (NP (NN bed)) (PP (IN for) (NP (DT a) (NN week))))) (S (VP (TO to) (VP (VB publicize) (NP (PRP$ their) (NN concern)) (PP (IN for) (NP (NN peace)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="cartoonist Al Capp" type="NP">
          <tokens>
            <token id="9" string="cartoonist" />
            <token id="10" string="Al" />
            <token id="11" string="Capp" />
          </tokens>
        </chunking>
        <chunking id="2" string="bed" type="NP">
          <tokens>
            <token id="31" string="bed" />
          </tokens>
        </chunking>
        <chunking id="3" string="One intriguing episode" type="NP">
          <tokens>
            <token id="1" string="One" />
            <token id="2" string="intriguing" />
            <token id="3" string="episode" />
          </tokens>
        </chunking>
        <chunking id="4" string="L'il Abner" type="NP">
          <tokens>
            <token id="14" string="L'il" />
            <token id="15" string="Abner" />
          </tokens>
        </chunking>
        <chunking id="5" string="cartoonist Al Capp -LRB- `` L'il Abner '' -RRB-" type="NP">
          <tokens>
            <token id="9" string="cartoonist" />
            <token id="10" string="Al" />
            <token id="11" string="Capp" />
            <token id="12" string="(" />
            <token id="13" string="``" />
            <token id="14" string="L'il" />
            <token id="15" string="Abner" />
            <token id="16" string="''" />
            <token id="17" string=")" />
          </tokens>
        </chunking>
        <chunking id="6" string="when they stayed in bed for a week to publicize their concern for peace" type="SBAR">
          <tokens>
            <token id="27" string="when" />
            <token id="28" string="they" />
            <token id="29" string="stayed" />
            <token id="30" string="in" />
            <token id="31" string="bed" />
            <token id="32" string="for" />
            <token id="33" string="a" />
            <token id="34" string="week" />
            <token id="35" string="to" />
            <token id="36" string="publicize" />
            <token id="37" string="their" />
            <token id="38" string="concern" />
            <token id="39" string="for" />
            <token id="40" string="peace" />
          </tokens>
        </chunking>
        <chunking id="7" string="publicize their concern for peace" type="VP">
          <tokens>
            <token id="36" string="publicize" />
            <token id="37" string="their" />
            <token id="38" string="concern" />
            <token id="39" string="for" />
            <token id="40" string="peace" />
          </tokens>
        </chunking>
        <chunking id="8" string="shows cartoonist Al Capp -LRB- `` L'il Abner '' -RRB- being antagonistic toward the Lennons during their bed-in , when they stayed in bed for a week to publicize their concern for peace" type="VP">
          <tokens>
            <token id="8" string="shows" />
            <token id="9" string="cartoonist" />
            <token id="10" string="Al" />
            <token id="11" string="Capp" />
            <token id="12" string="(" />
            <token id="13" string="``" />
            <token id="14" string="L'il" />
            <token id="15" string="Abner" />
            <token id="16" string="''" />
            <token id="17" string=")" />
            <token id="18" string="being" />
            <token id="19" string="antagonistic" />
            <token id="20" string="toward" />
            <token id="21" string="the" />
            <token id="22" string="Lennons" />
            <token id="23" string="during" />
            <token id="24" string="their" />
            <token id="25" string="bed-in" />
            <token id="26" string="," />
            <token id="27" string="when" />
            <token id="28" string="they" />
            <token id="29" string="stayed" />
            <token id="30" string="in" />
            <token id="31" string="bed" />
            <token id="32" string="for" />
            <token id="33" string="a" />
            <token id="34" string="week" />
            <token id="35" string="to" />
            <token id="36" string="publicize" />
            <token id="37" string="their" />
            <token id="38" string="concern" />
            <token id="39" string="for" />
            <token id="40" string="peace" />
          </tokens>
        </chunking>
        <chunking id="9" string="their concern" type="NP">
          <tokens>
            <token id="37" string="their" />
            <token id="38" string="concern" />
          </tokens>
        </chunking>
        <chunking id="10" string="their bed-in" type="NP">
          <tokens>
            <token id="24" string="their" />
            <token id="25" string="bed-in" />
          </tokens>
        </chunking>
        <chunking id="11" string="when" type="WHADVP">
          <tokens>
            <token id="27" string="when" />
          </tokens>
        </chunking>
        <chunking id="12" string="they" type="NP">
          <tokens>
            <token id="28" string="they" />
          </tokens>
        </chunking>
        <chunking id="13" string="a week" type="NP">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="week" />
          </tokens>
        </chunking>
        <chunking id="14" string="peace" type="NP">
          <tokens>
            <token id="40" string="peace" />
          </tokens>
        </chunking>
        <chunking id="15" string="stayed in bed for a week to publicize their concern for peace" type="VP">
          <tokens>
            <token id="29" string="stayed" />
            <token id="30" string="in" />
            <token id="31" string="bed" />
            <token id="32" string="for" />
            <token id="33" string="a" />
            <token id="34" string="week" />
            <token id="35" string="to" />
            <token id="36" string="publicize" />
            <token id="37" string="their" />
            <token id="38" string="concern" />
            <token id="39" string="for" />
            <token id="40" string="peace" />
          </tokens>
        </chunking>
        <chunking id="16" string="bed for a week" type="NP">
          <tokens>
            <token id="31" string="bed" />
            <token id="32" string="for" />
            <token id="33" string="a" />
            <token id="34" string="week" />
          </tokens>
        </chunking>
        <chunking id="17" string="the Lennons" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="Lennons" />
          </tokens>
        </chunking>
        <chunking id="18" string="Imagine" type="VP">
          <tokens>
            <token id="6" string="Imagine" />
          </tokens>
        </chunking>
        <chunking id="19" string="One intriguing episode in `` Imagine ''" type="NP">
          <tokens>
            <token id="1" string="One" />
            <token id="2" string="intriguing" />
            <token id="3" string="episode" />
            <token id="4" string="in" />
            <token id="5" string="``" />
            <token id="6" string="Imagine" />
            <token id="7" string="''" />
          </tokens>
        </chunking>
        <chunking id="20" string="to publicize their concern for peace" type="VP">
          <tokens>
            <token id="35" string="to" />
            <token id="36" string="publicize" />
            <token id="37" string="their" />
            <token id="38" string="concern" />
            <token id="39" string="for" />
            <token id="40" string="peace" />
          </tokens>
        </chunking>
        <chunking id="21" string="antagonistic toward the Lennons" type="ADJP">
          <tokens>
            <token id="19" string="antagonistic" />
            <token id="20" string="toward" />
            <token id="21" string="the" />
            <token id="22" string="Lennons" />
          </tokens>
        </chunking>
        <chunking id="22" string="being antagonistic toward the Lennons during their bed-in" type="VP">
          <tokens>
            <token id="18" string="being" />
            <token id="19" string="antagonistic" />
            <token id="20" string="toward" />
            <token id="21" string="the" />
            <token id="22" string="Lennons" />
            <token id="23" string="during" />
            <token id="24" string="their" />
            <token id="25" string="bed-in" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nummod">
          <governor id="3">episode</governor>
          <dependent id="1">One</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">episode</governor>
          <dependent id="2">intriguing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">shows</governor>
          <dependent id="3">episode</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Imagine</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="3">episode</governor>
          <dependent id="6">Imagine</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">shows</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Capp</governor>
          <dependent id="9">cartoonist</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Capp</governor>
          <dependent id="10">Al</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">shows</governor>
          <dependent id="11">Capp</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Abner</governor>
          <dependent id="14">L'il</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">Capp</governor>
          <dependent id="15">Abner</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">antagonistic</governor>
          <dependent id="18">being</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">shows</governor>
          <dependent id="19">antagonistic</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">Lennons</governor>
          <dependent id="20">toward</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">Lennons</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">antagonistic</governor>
          <dependent id="22">Lennons</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">bed-in</governor>
          <dependent id="23">during</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="25">bed-in</governor>
          <dependent id="24">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">antagonistic</governor>
          <dependent id="25">bed-in</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">stayed</governor>
          <dependent id="27">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">stayed</governor>
          <dependent id="28">they</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">shows</governor>
          <dependent id="29">stayed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">bed</governor>
          <dependent id="30">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">stayed</governor>
          <dependent id="31">bed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">week</governor>
          <dependent id="32">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">week</governor>
          <dependent id="33">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">bed</governor>
          <dependent id="34">week</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="36">publicize</governor>
          <dependent id="35">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="29">stayed</governor>
          <dependent id="36">publicize</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="38">concern</governor>
          <dependent id="37">their</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="36">publicize</governor>
          <dependent id="38">concern</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">peace</governor>
          <dependent id="39">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">publicize</governor>
          <dependent id="40">peace</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Al Capp" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Al" />
            <token id="11" string="Capp" />
          </tokens>
        </entity>
        <entity id="2" string="a week" type="DURATION" score="0.0">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="week" />
          </tokens>
        </entity>
        <entity id="3" string="One" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="One" />
          </tokens>
        </entity>
        <entity id="4" string="Lennons" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="22" string="Lennons" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>``We were naive,&amp;apost;&amp;apost; Ono said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="naive" lemma="naive" stem="naiv" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP We)) (VP (VBD were) (ADJP (JJ naive)))) (, ,) ('' '') (NP (NNP Ono)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="were naive" type="VP">
          <tokens>
            <token id="3" string="were" />
            <token id="4" string="naive" />
          </tokens>
        </chunking>
        <chunking id="2" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="3" string="said" type="VP">
          <tokens>
            <token id="8" string="said" />
          </tokens>
        </chunking>
        <chunking id="4" string="Ono" type="NP">
          <tokens>
            <token id="7" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="5" string="naive" type="ADJP">
          <tokens>
            <token id="4" string="naive" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">naive</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">naive</governor>
          <dependent id="3">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">said</governor>
          <dependent id="4">naive</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">said</governor>
          <dependent id="7">Ono</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>``A lot of things happened because we were naive.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="things" lemma="thing" stem="thing" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="happened" lemma="happen" stem="happen" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="naive" lemma="naive" stem="naiv" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NP (DT A) (NN lot)) (PP (IN of) (NP (NNS things)))) (VP (VBD happened) (SBAR (IN because) (S (NP (PRP we)) (VP (VBD were) (ADJP (JJ naive)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="were naive" type="VP">
          <tokens>
            <token id="9" string="were" />
            <token id="10" string="naive" />
          </tokens>
        </chunking>
        <chunking id="2" string="because we were naive" type="SBAR">
          <tokens>
            <token id="7" string="because" />
            <token id="8" string="we" />
            <token id="9" string="were" />
            <token id="10" string="naive" />
          </tokens>
        </chunking>
        <chunking id="3" string="A lot" type="NP">
          <tokens>
            <token id="2" string="A" />
            <token id="3" string="lot" />
          </tokens>
        </chunking>
        <chunking id="4" string="happened because we were naive" type="VP">
          <tokens>
            <token id="6" string="happened" />
            <token id="7" string="because" />
            <token id="8" string="we" />
            <token id="9" string="were" />
            <token id="10" string="naive" />
          </tokens>
        </chunking>
        <chunking id="5" string="things" type="NP">
          <tokens>
            <token id="5" string="things" />
          </tokens>
        </chunking>
        <chunking id="6" string="A lot of things" type="NP">
          <tokens>
            <token id="2" string="A" />
            <token id="3" string="lot" />
            <token id="4" string="of" />
            <token id="5" string="things" />
          </tokens>
        </chunking>
        <chunking id="7" string="we" type="NP">
          <tokens>
            <token id="8" string="we" />
          </tokens>
        </chunking>
        <chunking id="8" string="naive" type="ADJP">
          <tokens>
            <token id="10" string="naive" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">lot</governor>
          <dependent id="2">A</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">happened</governor>
          <dependent id="3">lot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">things</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">lot</governor>
          <dependent id="5">things</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">happened</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">naive</governor>
          <dependent id="7">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">naive</governor>
          <dependent id="8">we</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">naive</governor>
          <dependent id="9">were</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">happened</governor>
          <dependent id="10">naive</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>Maybe that was our strength.</content>
      <tokens>
        <token id="1" string="Maybe" lemma="maybe" stem="mayb" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="strength" lemma="strength" stem="strength" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Maybe)) (NP (DT that)) (VP (VBD was) (NP (PRP$ our) (NN strength))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that" type="NP">
          <tokens>
            <token id="2" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="our strength" type="NP">
          <tokens>
            <token id="4" string="our" />
            <token id="5" string="strength" />
          </tokens>
        </chunking>
        <chunking id="3" string="was our strength" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="our" />
            <token id="5" string="strength" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">strength</governor>
          <dependent id="1">Maybe</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">strength</governor>
          <dependent id="2">that</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">strength</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">strength</governor>
          <dependent id="4">our</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">strength</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>To us, Al Capp was just a cartoonist and you naturally assume a cartoonist is liberal, with a sense of humor.</content>
      <tokens>
        <token id="1" string="To" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="us" lemma="we" stem="u" pos="PRP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Al" lemma="Al" stem="al" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="Capp" lemma="Capp" stem="capp" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="cartoonist" lemma="cartoonist" stem="cartoonist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="naturally" lemma="naturally" stem="natur" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="assume" lemma="assume" stem="assum" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="cartoonist" lemma="cartoonist" stem="cartoonist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="liberal" lemma="liberal" stem="liber" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="sense" lemma="sense" stem="sens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="humor" lemma="humor" stem="humor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (TO To) (NP (PRP us))) (, ,) (S (NP (NNP Al) (NNP Capp)) (VP (VBD was) (ADVP (RB just)) (NP (DT a) (NN cartoonist)))) (CC and) (S (NP (PRP you)) (ADVP (RB naturally)) (VP (VB assume) (SBAR (S (NP (DT a) (NN cartoonist)) (VP (VBZ is) (ADJP (JJ liberal)) (, ,) (PP (IN with) (NP (NP (DT a) (NN sense)) (PP (IN of) (NP (NN humor)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Al Capp" type="NP">
          <tokens>
            <token id="4" string="Al" />
            <token id="5" string="Capp" />
          </tokens>
        </chunking>
        <chunking id="2" string="is liberal , with a sense of humor" type="VP">
          <tokens>
            <token id="16" string="is" />
            <token id="17" string="liberal" />
            <token id="18" string="," />
            <token id="19" string="with" />
            <token id="20" string="a" />
            <token id="21" string="sense" />
            <token id="22" string="of" />
            <token id="23" string="humor" />
          </tokens>
        </chunking>
        <chunking id="3" string="humor" type="NP">
          <tokens>
            <token id="23" string="humor" />
          </tokens>
        </chunking>
        <chunking id="4" string="a sense" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="sense" />
          </tokens>
        </chunking>
        <chunking id="5" string="was just a cartoonist" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="just" />
            <token id="8" string="a" />
            <token id="9" string="cartoonist" />
          </tokens>
        </chunking>
        <chunking id="6" string="a cartoonist is liberal , with a sense of humor" type="SBAR">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="cartoonist" />
            <token id="16" string="is" />
            <token id="17" string="liberal" />
            <token id="18" string="," />
            <token id="19" string="with" />
            <token id="20" string="a" />
            <token id="21" string="sense" />
            <token id="22" string="of" />
            <token id="23" string="humor" />
          </tokens>
        </chunking>
        <chunking id="7" string="a cartoonist" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="cartoonist" />
          </tokens>
        </chunking>
        <chunking id="8" string="assume a cartoonist is liberal , with a sense of humor" type="VP">
          <tokens>
            <token id="13" string="assume" />
            <token id="14" string="a" />
            <token id="15" string="cartoonist" />
            <token id="16" string="is" />
            <token id="17" string="liberal" />
            <token id="18" string="," />
            <token id="19" string="with" />
            <token id="20" string="a" />
            <token id="21" string="sense" />
            <token id="22" string="of" />
            <token id="23" string="humor" />
          </tokens>
        </chunking>
        <chunking id="9" string="us" type="NP">
          <tokens>
            <token id="2" string="us" />
          </tokens>
        </chunking>
        <chunking id="10" string="a sense of humor" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="sense" />
            <token id="22" string="of" />
            <token id="23" string="humor" />
          </tokens>
        </chunking>
        <chunking id="11" string="liberal" type="ADJP">
          <tokens>
            <token id="17" string="liberal" />
          </tokens>
        </chunking>
        <chunking id="12" string="you" type="NP">
          <tokens>
            <token id="11" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">us</governor>
          <dependent id="1">To</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">cartoonist</governor>
          <dependent id="2">us</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Capp</governor>
          <dependent id="4">Al</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">cartoonist</governor>
          <dependent id="5">Capp</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">cartoonist</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">cartoonist</governor>
          <dependent id="7">just</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">cartoonist</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">cartoonist</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">cartoonist</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">assume</governor>
          <dependent id="11">you</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">assume</governor>
          <dependent id="12">naturally</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">cartoonist</governor>
          <dependent id="13">assume</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">cartoonist</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">liberal</governor>
          <dependent id="15">cartoonist</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">liberal</governor>
          <dependent id="16">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">assume</governor>
          <dependent id="17">liberal</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">sense</governor>
          <dependent id="19">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">sense</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">liberal</governor>
          <dependent id="21">sense</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">humor</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">sense</governor>
          <dependent id="23">humor</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Al Capp" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Al" />
            <token id="5" string="Capp" />
          </tokens>
        </entity>
        <entity id="2" string="liberal" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="17" string="liberal" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="false">
      <content>We didn&amp;apost;t expect hostility.</content>
      <tokens>
        <token id="1" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="expect" lemma="expect" stem="expect" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="hostility" lemma="hostility" stem="hostil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP We)) (VP (VBD did) (RB n't) (VP (VB expect) (NP (NN hostility)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="expect hostility" type="VP">
          <tokens>
            <token id="4" string="expect" />
            <token id="5" string="hostility" />
          </tokens>
        </chunking>
        <chunking id="2" string="hostility" type="NP">
          <tokens>
            <token id="5" string="hostility" />
          </tokens>
        </chunking>
        <chunking id="3" string="We" type="NP">
          <tokens>
            <token id="1" string="We" />
          </tokens>
        </chunking>
        <chunking id="4" string="did n't expect hostility" type="VP">
          <tokens>
            <token id="2" string="did" />
            <token id="3" string="n't" />
            <token id="4" string="expect" />
            <token id="5" string="hostility" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">expect</governor>
          <dependent id="1">We</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">expect</governor>
          <dependent id="2">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">expect</governor>
          <dependent id="3">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">expect</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">expect</governor>
          <dependent id="5">hostility</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>``Al Capp is one incident that was filmed.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Al" lemma="Al" stem="al" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="Capp" lemma="Capp" stem="capp" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="6" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="filmed" lemma="film" stem="film" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NNP Al) (NNP Capp)) (VP (VBZ is) (NP (NP (CD one) (NN incident)) (SBAR (WHNP (WDT that)) (S (VP (VBD was) (VP (VBN filmed))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Al Capp" type="NP">
          <tokens>
            <token id="2" string="Al" />
            <token id="3" string="Capp" />
          </tokens>
        </chunking>
        <chunking id="2" string="was filmed" type="VP">
          <tokens>
            <token id="8" string="was" />
            <token id="9" string="filmed" />
          </tokens>
        </chunking>
        <chunking id="3" string="one incident" type="NP">
          <tokens>
            <token id="5" string="one" />
            <token id="6" string="incident" />
          </tokens>
        </chunking>
        <chunking id="4" string="filmed" type="VP">
          <tokens>
            <token id="9" string="filmed" />
          </tokens>
        </chunking>
        <chunking id="5" string="that was filmed" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="was" />
            <token id="9" string="filmed" />
          </tokens>
        </chunking>
        <chunking id="6" string="one incident that was filmed" type="NP">
          <tokens>
            <token id="5" string="one" />
            <token id="6" string="incident" />
            <token id="7" string="that" />
            <token id="8" string="was" />
            <token id="9" string="filmed" />
          </tokens>
        </chunking>
        <chunking id="7" string="is one incident that was filmed" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="one" />
            <token id="6" string="incident" />
            <token id="7" string="that" />
            <token id="8" string="was" />
            <token id="9" string="filmed" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Capp</governor>
          <dependent id="2">Al</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">incident</governor>
          <dependent id="3">Capp</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">incident</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">incident</governor>
          <dependent id="5">one</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">incident</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">filmed</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">filmed</governor>
          <dependent id="8">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">incident</governor>
          <dependent id="9">filmed</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Al Capp" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Al" />
            <token id="3" string="Capp" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>In those days we did numerous interviews because of our stand for world peace.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="days" lemma="day" stem="dai" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="4" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="numerous" lemma="numerous" stem="numer" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="interviews" lemma="interview" stem="interview" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="stand" lemma="stand" stem="stand" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="peace" lemma="peace" stem="peac" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (DT those) (NNS days))) (NP (PRP we)) (VP (VBD did) (NP (JJ numerous) (NNS interviews)) (PP (IN because) (PP (IN of) (NP (PRP$ our) (NN stand)))) (PP (IN for) (NP (NN world) (NN peace)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="our stand" type="NP">
          <tokens>
            <token id="10" string="our" />
            <token id="11" string="stand" />
          </tokens>
        </chunking>
        <chunking id="2" string="numerous interviews" type="NP">
          <tokens>
            <token id="6" string="numerous" />
            <token id="7" string="interviews" />
          </tokens>
        </chunking>
        <chunking id="3" string="those days" type="NP">
          <tokens>
            <token id="2" string="those" />
            <token id="3" string="days" />
          </tokens>
        </chunking>
        <chunking id="4" string="world peace" type="NP">
          <tokens>
            <token id="13" string="world" />
            <token id="14" string="peace" />
          </tokens>
        </chunking>
        <chunking id="5" string="we" type="NP">
          <tokens>
            <token id="4" string="we" />
          </tokens>
        </chunking>
        <chunking id="6" string="did numerous interviews because of our stand for world peace" type="VP">
          <tokens>
            <token id="5" string="did" />
            <token id="6" string="numerous" />
            <token id="7" string="interviews" />
            <token id="8" string="because" />
            <token id="9" string="of" />
            <token id="10" string="our" />
            <token id="11" string="stand" />
            <token id="12" string="for" />
            <token id="13" string="world" />
            <token id="14" string="peace" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">days</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">days</governor>
          <dependent id="2">those</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">did</governor>
          <dependent id="3">days</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">did</governor>
          <dependent id="4">we</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">did</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">interviews</governor>
          <dependent id="6">numerous</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">did</governor>
          <dependent id="7">interviews</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">stand</governor>
          <dependent id="8">because</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">stand</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">stand</governor>
          <dependent id="10">our</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">did</governor>
          <dependent id="11">stand</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">peace</governor>
          <dependent id="12">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">peace</governor>
          <dependent id="13">world</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">did</governor>
          <dependent id="14">peace</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="days" type="DURATION" score="0.0">
          <tokens>
            <token id="3" string="days" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="false">
      <content>... There were some very rough interviews.</content>
      <tokens>
        <token id="1" string="..." lemma="..." stem="..." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="rough" lemma="rough" stem="rough" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="interviews" lemma="interview" stem="interview" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ...) (NP (EX There)) (VP (VBD were) (NP (DT some) (ADJP (RB very) (JJ rough)) (NNS interviews))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="There" type="NP">
          <tokens>
            <token id="2" string="There" />
          </tokens>
        </chunking>
        <chunking id="2" string="were some very rough interviews" type="VP">
          <tokens>
            <token id="3" string="were" />
            <token id="4" string="some" />
            <token id="5" string="very" />
            <token id="6" string="rough" />
            <token id="7" string="interviews" />
          </tokens>
        </chunking>
        <chunking id="3" string="very rough" type="ADJP">
          <tokens>
            <token id="5" string="very" />
            <token id="6" string="rough" />
          </tokens>
        </chunking>
        <chunking id="4" string="some very rough interviews" type="NP">
          <tokens>
            <token id="4" string="some" />
            <token id="5" string="very" />
            <token id="6" string="rough" />
            <token id="7" string="interviews" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="3">were</governor>
          <dependent id="2">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">were</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">interviews</governor>
          <dependent id="4">some</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">rough</governor>
          <dependent id="5">very</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">interviews</governor>
          <dependent id="6">rough</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">were</governor>
          <dependent id="7">interviews</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>The hostility that was shown to us bluntly by reporters in those days was incredible.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="hostility" lemma="hostility" stem="hostil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="shown" lemma="show" stem="shown" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="us" lemma="we" stem="u" pos="PRP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="bluntly" lemma="bluntly" stem="bluntli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="reporters" lemma="reporter" stem="report" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="days" lemma="day" stem="dai" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="14" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="incredible" lemma="incredible" stem="incred" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN hostility)) (SBAR (WHNP (WDT that)) (S (VP (VBD was) (VP (VBN shown) (PP (TO to) (NP (PRP us))) (PP (ADVP (RB bluntly)) (IN by) (NP (NP (NNS reporters)) (PP (IN in) (NP (DT those) (NNS days)))))))))) (VP (VBD was) (ADJP (JJ incredible))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="reporters" type="NP">
          <tokens>
            <token id="10" string="reporters" />
          </tokens>
        </chunking>
        <chunking id="2" string="reporters in those days" type="NP">
          <tokens>
            <token id="10" string="reporters" />
            <token id="11" string="in" />
            <token id="12" string="those" />
            <token id="13" string="days" />
          </tokens>
        </chunking>
        <chunking id="3" string="was incredible" type="VP">
          <tokens>
            <token id="14" string="was" />
            <token id="15" string="incredible" />
          </tokens>
        </chunking>
        <chunking id="4" string="those days" type="NP">
          <tokens>
            <token id="12" string="those" />
            <token id="13" string="days" />
          </tokens>
        </chunking>
        <chunking id="5" string="The hostility" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="hostility" />
          </tokens>
        </chunking>
        <chunking id="6" string="incredible" type="ADJP">
          <tokens>
            <token id="15" string="incredible" />
          </tokens>
        </chunking>
        <chunking id="7" string="The hostility that was shown to us bluntly by reporters in those days" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="hostility" />
            <token id="3" string="that" />
            <token id="4" string="was" />
            <token id="5" string="shown" />
            <token id="6" string="to" />
            <token id="7" string="us" />
            <token id="8" string="bluntly" />
            <token id="9" string="by" />
            <token id="10" string="reporters" />
            <token id="11" string="in" />
            <token id="12" string="those" />
            <token id="13" string="days" />
          </tokens>
        </chunking>
        <chunking id="8" string="shown to us bluntly by reporters in those days" type="VP">
          <tokens>
            <token id="5" string="shown" />
            <token id="6" string="to" />
            <token id="7" string="us" />
            <token id="8" string="bluntly" />
            <token id="9" string="by" />
            <token id="10" string="reporters" />
            <token id="11" string="in" />
            <token id="12" string="those" />
            <token id="13" string="days" />
          </tokens>
        </chunking>
        <chunking id="9" string="us" type="NP">
          <tokens>
            <token id="7" string="us" />
          </tokens>
        </chunking>
        <chunking id="10" string="that was shown to us bluntly by reporters in those days" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="was" />
            <token id="5" string="shown" />
            <token id="6" string="to" />
            <token id="7" string="us" />
            <token id="8" string="bluntly" />
            <token id="9" string="by" />
            <token id="10" string="reporters" />
            <token id="11" string="in" />
            <token id="12" string="those" />
            <token id="13" string="days" />
          </tokens>
        </chunking>
        <chunking id="11" string="was shown to us bluntly by reporters in those days" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="shown" />
            <token id="6" string="to" />
            <token id="7" string="us" />
            <token id="8" string="bluntly" />
            <token id="9" string="by" />
            <token id="10" string="reporters" />
            <token id="11" string="in" />
            <token id="12" string="those" />
            <token id="13" string="days" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">hostility</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">incredible</governor>
          <dependent id="2">hostility</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">shown</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">shown</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">hostility</governor>
          <dependent id="5">shown</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">us</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">shown</governor>
          <dependent id="7">us</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">reporters</governor>
          <dependent id="8">bluntly</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">reporters</governor>
          <dependent id="9">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">shown</governor>
          <dependent id="10">reporters</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">days</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">days</governor>
          <dependent id="12">those</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">reporters</governor>
          <dependent id="13">days</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">incredible</governor>
          <dependent id="14">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">incredible</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="days" type="DURATION" score="0.0">
          <tokens>
            <token id="13" string="days" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>Each time, I think we were hurt.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="Each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="hurt" lemma="hurt" stem="hurt" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP-TMP (DT Each) (NN time)) (, ,) (NP (PRP I)) (VP (VBP think) (SBAR (S (NP (PRP we)) (VP (VBD were) (VP (VBN hurt)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="were hurt" type="VP">
          <tokens>
            <token id="7" string="were" />
            <token id="8" string="hurt" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="4" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="think we were hurt" type="VP">
          <tokens>
            <token id="5" string="think" />
            <token id="6" string="we" />
            <token id="7" string="were" />
            <token id="8" string="hurt" />
          </tokens>
        </chunking>
        <chunking id="4" string="we were hurt" type="SBAR">
          <tokens>
            <token id="6" string="we" />
            <token id="7" string="were" />
            <token id="8" string="hurt" />
          </tokens>
        </chunking>
        <chunking id="5" string="we" type="NP">
          <tokens>
            <token id="6" string="we" />
          </tokens>
        </chunking>
        <chunking id="6" string="hurt" type="VP">
          <tokens>
            <token id="8" string="hurt" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">time</governor>
          <dependent id="1">Each</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="5">think</governor>
          <dependent id="2">time</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">think</governor>
          <dependent id="4">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">think</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">hurt</governor>
          <dependent id="6">we</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">hurt</governor>
          <dependent id="7">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">think</governor>
          <dependent id="8">hurt</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>Ono said Lennon wrote the song ``Imagine&amp;apost;&amp;apost; in 1969 or &amp;apost;70.</content>
      <tokens>
        <token id="1" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="wrote" lemma="write" stem="wrote" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="song" lemma="song" stem="song" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Imagine" lemma="imagine" stem="imagin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="1969" lemma="1969" stem="1969" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="14" string="70" lemma="70" stem="70" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Ono)) (VP (VBD said) (SBAR (S (NP (NNP Lennon)) (VP (VP (VBD wrote) (NP (NP (DT the) (NN song) (`` ``) (NX (S (VP (VB Imagine)))) ('' '')) (PP (IN in) (NP (CD 1969))))) (CC or) (VP ('' ') (NP-TMP (CD 70))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="' 70" type="VP">
          <tokens>
            <token id="13" string="'" />
            <token id="14" string="70" />
          </tokens>
        </chunking>
        <chunking id="2" string="Lennon" type="NP">
          <tokens>
            <token id="3" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="3" string="wrote the song `` Imagine '' in 1969" type="VP">
          <tokens>
            <token id="4" string="wrote" />
            <token id="5" string="the" />
            <token id="6" string="song" />
            <token id="7" string="``" />
            <token id="8" string="Imagine" />
            <token id="9" string="''" />
            <token id="10" string="in" />
            <token id="11" string="1969" />
          </tokens>
        </chunking>
        <chunking id="4" string="the song `` Imagine ''" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="song" />
            <token id="7" string="``" />
            <token id="8" string="Imagine" />
            <token id="9" string="''" />
          </tokens>
        </chunking>
        <chunking id="5" string="wrote the song `` Imagine '' in 1969 or ' 70" type="VP">
          <tokens>
            <token id="4" string="wrote" />
            <token id="5" string="the" />
            <token id="6" string="song" />
            <token id="7" string="``" />
            <token id="8" string="Imagine" />
            <token id="9" string="''" />
            <token id="10" string="in" />
            <token id="11" string="1969" />
            <token id="12" string="or" />
            <token id="13" string="'" />
            <token id="14" string="70" />
          </tokens>
        </chunking>
        <chunking id="6" string="Lennon wrote the song `` Imagine '' in 1969 or ' 70" type="SBAR">
          <tokens>
            <token id="3" string="Lennon" />
            <token id="4" string="wrote" />
            <token id="5" string="the" />
            <token id="6" string="song" />
            <token id="7" string="``" />
            <token id="8" string="Imagine" />
            <token id="9" string="''" />
            <token id="10" string="in" />
            <token id="11" string="1969" />
            <token id="12" string="or" />
            <token id="13" string="'" />
            <token id="14" string="70" />
          </tokens>
        </chunking>
        <chunking id="7" string="the song `` Imagine '' in 1969" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="song" />
            <token id="7" string="``" />
            <token id="8" string="Imagine" />
            <token id="9" string="''" />
            <token id="10" string="in" />
            <token id="11" string="1969" />
          </tokens>
        </chunking>
        <chunking id="8" string="Imagine" type="VP">
          <tokens>
            <token id="8" string="Imagine" />
          </tokens>
        </chunking>
        <chunking id="9" string="said Lennon wrote the song `` Imagine '' in 1969 or ' 70" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="Lennon" />
            <token id="4" string="wrote" />
            <token id="5" string="the" />
            <token id="6" string="song" />
            <token id="7" string="``" />
            <token id="8" string="Imagine" />
            <token id="9" string="''" />
            <token id="10" string="in" />
            <token id="11" string="1969" />
            <token id="12" string="or" />
            <token id="13" string="'" />
            <token id="14" string="70" />
          </tokens>
        </chunking>
        <chunking id="10" string="1969" type="NP">
          <tokens>
            <token id="11" string="1969" />
          </tokens>
        </chunking>
        <chunking id="11" string="Ono" type="NP">
          <tokens>
            <token id="1" string="Ono" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Ono</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">wrote</governor>
          <dependent id="3">Lennon</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="4">wrote</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">Imagine</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">Imagine</governor>
          <dependent id="6">song</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">wrote</governor>
          <dependent id="8">Imagine</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">1969</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">Imagine</governor>
          <dependent id="11">1969</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">wrote</governor>
          <dependent id="12">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">wrote</governor>
          <dependent id="14">70</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="' 70" type="DATE" score="0.0">
          <tokens>
            <token id="13" string="'" />
            <token id="14" string="70" />
          </tokens>
        </entity>
        <entity id="2" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Lennon" />
          </tokens>
        </entity>
        <entity id="3" string="1969" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="1969" />
          </tokens>
        </entity>
        <entity id="4" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>``We did the bed-in, the Toronto Peace Festival, the `War&amp;apost;s Over&amp;apost; billboard.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="bed-in" lemma="bed-in" stem="bed-in" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="Toronto" lemma="Toronto" stem="toronto" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="9" string="Peace" lemma="Peace" stem="peac" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="Festival" lemma="Festival" stem="festiv" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="`" lemma="`" stem="`" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="War" lemma="War" stem="war" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="Over" lemma="Over" stem="over" pos="NNP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="billboard" lemma="billboard" stem="billboard" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP We)) (VP (VBD did) (NP (NP (DT the) (NN bed-in)) (, ,) (NP (DT the) (NP (NP (NP (NNP Toronto) (NNP Peace) (NNP Festival)) (, ,) (NP (DT the) (`` `) (NX (NP (NNP War) (POS 's)) (NNP Over)))) (POS ')) (NN billboard)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the ` War 's Over" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="`" />
            <token id="14" string="War" />
            <token id="15" string="'s" />
            <token id="16" string="Over" />
          </tokens>
        </chunking>
        <chunking id="2" string="Toronto Peace Festival , the ` War 's Over" type="NP">
          <tokens>
            <token id="8" string="Toronto" />
            <token id="9" string="Peace" />
            <token id="10" string="Festival" />
            <token id="11" string="," />
            <token id="12" string="the" />
            <token id="13" string="`" />
            <token id="14" string="War" />
            <token id="15" string="'s" />
            <token id="16" string="Over" />
          </tokens>
        </chunking>
        <chunking id="3" string="Toronto Peace Festival" type="NP">
          <tokens>
            <token id="8" string="Toronto" />
            <token id="9" string="Peace" />
            <token id="10" string="Festival" />
          </tokens>
        </chunking>
        <chunking id="4" string="War 's" type="NP">
          <tokens>
            <token id="14" string="War" />
            <token id="15" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Toronto Peace Festival , the ` War 's Over ' billboard" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Toronto" />
            <token id="9" string="Peace" />
            <token id="10" string="Festival" />
            <token id="11" string="," />
            <token id="12" string="the" />
            <token id="13" string="`" />
            <token id="14" string="War" />
            <token id="15" string="'s" />
            <token id="16" string="Over" />
            <token id="17" string="'" />
            <token id="18" string="billboard" />
          </tokens>
        </chunking>
        <chunking id="6" string="the bed-in" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="bed-in" />
          </tokens>
        </chunking>
        <chunking id="7" string="did the bed-in , the Toronto Peace Festival , the ` War 's Over ' billboard" type="VP">
          <tokens>
            <token id="3" string="did" />
            <token id="4" string="the" />
            <token id="5" string="bed-in" />
            <token id="6" string="," />
            <token id="7" string="the" />
            <token id="8" string="Toronto" />
            <token id="9" string="Peace" />
            <token id="10" string="Festival" />
            <token id="11" string="," />
            <token id="12" string="the" />
            <token id="13" string="`" />
            <token id="14" string="War" />
            <token id="15" string="'s" />
            <token id="16" string="Over" />
            <token id="17" string="'" />
            <token id="18" string="billboard" />
          </tokens>
        </chunking>
        <chunking id="8" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="9" string="Toronto Peace Festival , the ` War 's Over '" type="NP">
          <tokens>
            <token id="8" string="Toronto" />
            <token id="9" string="Peace" />
            <token id="10" string="Festival" />
            <token id="11" string="," />
            <token id="12" string="the" />
            <token id="13" string="`" />
            <token id="14" string="War" />
            <token id="15" string="'s" />
            <token id="16" string="Over" />
            <token id="17" string="'" />
          </tokens>
        </chunking>
        <chunking id="10" string="the bed-in , the Toronto Peace Festival , the ` War 's Over ' billboard" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="bed-in" />
            <token id="6" string="," />
            <token id="7" string="the" />
            <token id="8" string="Toronto" />
            <token id="9" string="Peace" />
            <token id="10" string="Festival" />
            <token id="11" string="," />
            <token id="12" string="the" />
            <token id="13" string="`" />
            <token id="14" string="War" />
            <token id="15" string="'s" />
            <token id="16" string="Over" />
            <token id="17" string="'" />
            <token id="18" string="billboard" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">did</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">did</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">bed-in</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">did</governor>
          <dependent id="5">bed-in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">billboard</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Festival</governor>
          <dependent id="8">Toronto</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Festival</governor>
          <dependent id="9">Peace</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">billboard</governor>
          <dependent id="10">Festival</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">Over</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">Over</governor>
          <dependent id="14">War</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">War</governor>
          <dependent id="15">'s</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="10">Festival</governor>
          <dependent id="16">Over</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Festival</governor>
          <dependent id="17">'</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">bed-in</governor>
          <dependent id="18">billboard</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Toronto" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="Toronto" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>He was saying we need an anthem for this whole concept of world peace.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="need" lemma="need" stem="need" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="anthem" lemma="anthem" stem="anthem" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="whole" lemma="whole" stem="whole" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="concept" lemma="concept" stem="concept" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="peace" lemma="peace" stem="peac" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD was) (VP (VBG saying) (SBAR (S (NP (PRP we)) (VP (VBP need) (NP (NP (DT an) (NN anthem)) (PP (IN for) (NP (NP (DT this) (JJ whole) (NN concept)) (PP (IN of) (NP (NN world) (NN peace))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was saying we need an anthem for this whole concept of world peace" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="saying" />
            <token id="4" string="we" />
            <token id="5" string="need" />
            <token id="6" string="an" />
            <token id="7" string="anthem" />
            <token id="8" string="for" />
            <token id="9" string="this" />
            <token id="10" string="whole" />
            <token id="11" string="concept" />
            <token id="12" string="of" />
            <token id="13" string="world" />
            <token id="14" string="peace" />
          </tokens>
        </chunking>
        <chunking id="2" string="we need an anthem for this whole concept of world peace" type="SBAR">
          <tokens>
            <token id="4" string="we" />
            <token id="5" string="need" />
            <token id="6" string="an" />
            <token id="7" string="anthem" />
            <token id="8" string="for" />
            <token id="9" string="this" />
            <token id="10" string="whole" />
            <token id="11" string="concept" />
            <token id="12" string="of" />
            <token id="13" string="world" />
            <token id="14" string="peace" />
          </tokens>
        </chunking>
        <chunking id="3" string="need an anthem for this whole concept of world peace" type="VP">
          <tokens>
            <token id="5" string="need" />
            <token id="6" string="an" />
            <token id="7" string="anthem" />
            <token id="8" string="for" />
            <token id="9" string="this" />
            <token id="10" string="whole" />
            <token id="11" string="concept" />
            <token id="12" string="of" />
            <token id="13" string="world" />
            <token id="14" string="peace" />
          </tokens>
        </chunking>
        <chunking id="4" string="this whole concept of world peace" type="NP">
          <tokens>
            <token id="9" string="this" />
            <token id="10" string="whole" />
            <token id="11" string="concept" />
            <token id="12" string="of" />
            <token id="13" string="world" />
            <token id="14" string="peace" />
          </tokens>
        </chunking>
        <chunking id="5" string="an anthem for this whole concept of world peace" type="NP">
          <tokens>
            <token id="6" string="an" />
            <token id="7" string="anthem" />
            <token id="8" string="for" />
            <token id="9" string="this" />
            <token id="10" string="whole" />
            <token id="11" string="concept" />
            <token id="12" string="of" />
            <token id="13" string="world" />
            <token id="14" string="peace" />
          </tokens>
        </chunking>
        <chunking id="6" string="saying we need an anthem for this whole concept of world peace" type="VP">
          <tokens>
            <token id="3" string="saying" />
            <token id="4" string="we" />
            <token id="5" string="need" />
            <token id="6" string="an" />
            <token id="7" string="anthem" />
            <token id="8" string="for" />
            <token id="9" string="this" />
            <token id="10" string="whole" />
            <token id="11" string="concept" />
            <token id="12" string="of" />
            <token id="13" string="world" />
            <token id="14" string="peace" />
          </tokens>
        </chunking>
        <chunking id="7" string="an anthem" type="NP">
          <tokens>
            <token id="6" string="an" />
            <token id="7" string="anthem" />
          </tokens>
        </chunking>
        <chunking id="8" string="this whole concept" type="NP">
          <tokens>
            <token id="9" string="this" />
            <token id="10" string="whole" />
            <token id="11" string="concept" />
          </tokens>
        </chunking>
        <chunking id="9" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="10" string="world peace" type="NP">
          <tokens>
            <token id="13" string="world" />
            <token id="14" string="peace" />
          </tokens>
        </chunking>
        <chunking id="11" string="we" type="NP">
          <tokens>
            <token id="4" string="we" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">saying</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">saying</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">saying</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">need</governor>
          <dependent id="4">we</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">saying</governor>
          <dependent id="5">need</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">anthem</governor>
          <dependent id="6">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">need</governor>
          <dependent id="7">anthem</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">concept</governor>
          <dependent id="8">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">concept</governor>
          <dependent id="9">this</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">concept</governor>
          <dependent id="10">whole</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">anthem</governor>
          <dependent id="11">concept</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">peace</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">peace</governor>
          <dependent id="13">world</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">concept</governor>
          <dependent id="14">peace</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>I think it&amp;apost;s one of the songs that will really go on forever in people&amp;apost;s minds.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="songs" lemma="song" stem="song" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="go" lemma="go" stem="go" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="forever" lemma="forever" stem="forev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="minds" lemma="mind" stem="mind" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP think) (SBAR (S (NP (PRP it)) (VP (VBZ 's) (NP (NP (CD one)) (PP (IN of) (NP (NP (DT the) (NNS songs)) (SBAR (WHNP (WDT that)) (S (VP (MD will) (ADVP (RB really)) (VP (VB go) (PP (IN on) (ADVP (RB forever))) (PP (IN in) (NP (NP (NNS people) (POS 's)) (NNS minds)))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="one" type="NP">
          <tokens>
            <token id="5" string="one" />
          </tokens>
        </chunking>
        <chunking id="2" string="people 's" type="NP">
          <tokens>
            <token id="16" string="people" />
            <token id="17" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="the songs that will really go on forever in people 's minds" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="songs" />
            <token id="9" string="that" />
            <token id="10" string="will" />
            <token id="11" string="really" />
            <token id="12" string="go" />
            <token id="13" string="on" />
            <token id="14" string="forever" />
            <token id="15" string="in" />
            <token id="16" string="people" />
            <token id="17" string="'s" />
            <token id="18" string="minds" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="3" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="people 's minds" type="NP">
          <tokens>
            <token id="16" string="people" />
            <token id="17" string="'s" />
            <token id="18" string="minds" />
          </tokens>
        </chunking>
        <chunking id="7" string="go on forever in people 's minds" type="VP">
          <tokens>
            <token id="12" string="go" />
            <token id="13" string="on" />
            <token id="14" string="forever" />
            <token id="15" string="in" />
            <token id="16" string="people" />
            <token id="17" string="'s" />
            <token id="18" string="minds" />
          </tokens>
        </chunking>
        <chunking id="8" string="that will really go on forever in people 's minds" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="will" />
            <token id="11" string="really" />
            <token id="12" string="go" />
            <token id="13" string="on" />
            <token id="14" string="forever" />
            <token id="15" string="in" />
            <token id="16" string="people" />
            <token id="17" string="'s" />
            <token id="18" string="minds" />
          </tokens>
        </chunking>
        <chunking id="9" string="will really go on forever in people 's minds" type="VP">
          <tokens>
            <token id="10" string="will" />
            <token id="11" string="really" />
            <token id="12" string="go" />
            <token id="13" string="on" />
            <token id="14" string="forever" />
            <token id="15" string="in" />
            <token id="16" string="people" />
            <token id="17" string="'s" />
            <token id="18" string="minds" />
          </tokens>
        </chunking>
        <chunking id="10" string="think it 's one of the songs that will really go on forever in people 's minds" type="VP">
          <tokens>
            <token id="2" string="think" />
            <token id="3" string="it" />
            <token id="4" string="'s" />
            <token id="5" string="one" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="songs" />
            <token id="9" string="that" />
            <token id="10" string="will" />
            <token id="11" string="really" />
            <token id="12" string="go" />
            <token id="13" string="on" />
            <token id="14" string="forever" />
            <token id="15" string="in" />
            <token id="16" string="people" />
            <token id="17" string="'s" />
            <token id="18" string="minds" />
          </tokens>
        </chunking>
        <chunking id="11" string="'s one of the songs that will really go on forever in people 's minds" type="VP">
          <tokens>
            <token id="4" string="'s" />
            <token id="5" string="one" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="songs" />
            <token id="9" string="that" />
            <token id="10" string="will" />
            <token id="11" string="really" />
            <token id="12" string="go" />
            <token id="13" string="on" />
            <token id="14" string="forever" />
            <token id="15" string="in" />
            <token id="16" string="people" />
            <token id="17" string="'s" />
            <token id="18" string="minds" />
          </tokens>
        </chunking>
        <chunking id="12" string="one of the songs that will really go on forever in people 's minds" type="NP">
          <tokens>
            <token id="5" string="one" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="songs" />
            <token id="9" string="that" />
            <token id="10" string="will" />
            <token id="11" string="really" />
            <token id="12" string="go" />
            <token id="13" string="on" />
            <token id="14" string="forever" />
            <token id="15" string="in" />
            <token id="16" string="people" />
            <token id="17" string="'s" />
            <token id="18" string="minds" />
          </tokens>
        </chunking>
        <chunking id="13" string="the songs" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="songs" />
          </tokens>
        </chunking>
        <chunking id="14" string="it 's one of the songs that will really go on forever in people 's minds" type="SBAR">
          <tokens>
            <token id="3" string="it" />
            <token id="4" string="'s" />
            <token id="5" string="one" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="songs" />
            <token id="9" string="that" />
            <token id="10" string="will" />
            <token id="11" string="really" />
            <token id="12" string="go" />
            <token id="13" string="on" />
            <token id="14" string="forever" />
            <token id="15" string="in" />
            <token id="16" string="people" />
            <token id="17" string="'s" />
            <token id="18" string="minds" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">think</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">think</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">one</governor>
          <dependent id="3">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">one</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">think</governor>
          <dependent id="5">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">songs</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">songs</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">one</governor>
          <dependent id="8">songs</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">go</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">go</governor>
          <dependent id="10">will</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">go</governor>
          <dependent id="11">really</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">songs</governor>
          <dependent id="12">go</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">forever</governor>
          <dependent id="13">on</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">go</governor>
          <dependent id="14">forever</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">minds</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">minds</governor>
          <dependent id="16">people</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">people</governor>
          <dependent id="17">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">go</governor>
          <dependent id="18">minds</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>``Imagine there&amp;apost;s no countries ``It isn&amp;apost;t hard to do ``Nothing to kill or die for ``And no religion too ``Imagine all the people ``Living life in peace ... ``You may say i&amp;apost;m a dreamer ``But i&amp;apost;m not the only one ``i hope someday you&amp;apost;ll join us ``and the world be as one.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Imagine" lemma="imagine" stem="imagin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="countries" lemma="country" stem="countri" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="hard" lemma="hard" stem="hard" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Nothing" lemma="nothing" stem="noth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="kill" lemma="kill" stem="kill" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="die" lemma="die" stem="die" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="religion" lemma="religion" stem="religion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="Imagine" lemma="imagine" stem="imagin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="all" lemma="all" stem="all" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="Living" lemma="live" stem="live" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="peace" lemma="peace" stem="peac" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="..." lemma="..." stem="..." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="You" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="39" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="i" lemma="i" stem="i" pos="FW" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="42" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="dreamer" lemma="dreamer" stem="dreamer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="i" lemma="i" stem="i" pos="FW" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="51" string="only" lemma="only" stem="onli" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="52" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="53" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="54" string="i" lemma="i" stem="i" pos="FW" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="55" string="hope" lemma="hope" stem="hope" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="56" string="someday" lemma="someday" stem="somedai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="57" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="58" string="'ll" lemma="will" stem="'ll" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="59" string="join" lemma="join" stem="join" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="60" string="us" lemma="we" stem="u" pos="PRP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="61" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="62" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="63" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="64" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="65" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="66" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="67" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="68" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="69" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (VP (VB Imagine) (SBAR (S (NP (EX there)) (VP (VBZ 's) (NP (NP (DT no) (NNS countries)) (`` ``) (SBAR (S (NP (PRP It)) (VP (VBZ is) (RB n't) (ADJP (JJ hard) (S (VP (TO to) (VP (VB do) (`` ``) (NP (NN Nothing)) (S (VP (TO to) (VP (VB kill) (CC or) (VB die))))))))))) (PP (IN for) (`` ``) (SBAR (CC And) (S (NP (DT no) (NN religion)) (ADVP (RB too)) (VP (`` ``) (VB Imagine) (S (NP (PDT all) (DT the) (NNS people)) (`` ``) (VP (VBG Living) (NP (NN life)) (PP (IN in) (NP (NN peace))) (: ...) (`` ``) (S (NP (PRP You)) (VP (MD may) (VP (VB say) (NP (FW i))))))))))))))))) (VP (VBP 'm) (NP (DT a) (NN dreamer)) (S (`` ``) (S (CC But) (NP (FW i)) (VP (VBP 'm) (RB not) (NP (DT the) (JJ only) (CD one)) (SBAR (`` ``) (S (NP (FW i)) (VP (VBP hope) (ADVP (RB someday)))))))))) (PRN (NP (PRP you)) (VP (MD 'll) (VP (VB join) (NP (PRP us))))) (`` ``) (CC and) (S (NP (DT the) (NN world)) (VP (VB be) (PP (IN as) (NP (CD one))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="hope someday" type="VP">
          <tokens>
            <token id="55" string="hope" />
            <token id="56" string="someday" />
          </tokens>
        </chunking>
        <chunking id="2" string="to do `` Nothing to kill or die" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="do" />
            <token id="14" string="``" />
            <token id="15" string="Nothing" />
            <token id="16" string="to" />
            <token id="17" string="kill" />
            <token id="18" string="or" />
            <token id="19" string="die" />
          </tokens>
        </chunking>
        <chunking id="3" string="one" type="NP">
          <tokens>
            <token id="67" string="one" />
          </tokens>
        </chunking>
        <chunking id="4" string="no religion" type="NP">
          <tokens>
            <token id="23" string="no" />
            <token id="24" string="religion" />
          </tokens>
        </chunking>
        <chunking id="5" string="i" type="NP">
          <tokens>
            <token id="41" string="i" />
          </tokens>
        </chunking>
        <chunking id="6" string="'s no countries `` It is n't hard to do `` Nothing to kill or die for `` And no religion too `` Imagine all the people `` Living life in peace ... `` You may say i" type="VP">
          <tokens>
            <token id="4" string="'s" />
            <token id="5" string="no" />
            <token id="6" string="countries" />
            <token id="7" string="``" />
            <token id="8" string="It" />
            <token id="9" string="is" />
            <token id="10" string="n't" />
            <token id="11" string="hard" />
            <token id="12" string="to" />
            <token id="13" string="do" />
            <token id="14" string="``" />
            <token id="15" string="Nothing" />
            <token id="16" string="to" />
            <token id="17" string="kill" />
            <token id="18" string="or" />
            <token id="19" string="die" />
            <token id="20" string="for" />
            <token id="21" string="``" />
            <token id="22" string="And" />
            <token id="23" string="no" />
            <token id="24" string="religion" />
            <token id="25" string="too" />
            <token id="26" string="``" />
            <token id="27" string="Imagine" />
            <token id="28" string="all" />
            <token id="29" string="the" />
            <token id="30" string="people" />
            <token id="31" string="``" />
            <token id="32" string="Living" />
            <token id="33" string="life" />
            <token id="34" string="in" />
            <token id="35" string="peace" />
            <token id="36" string="..." />
            <token id="37" string="``" />
            <token id="38" string="You" />
            <token id="39" string="may" />
            <token id="40" string="say" />
            <token id="41" string="i" />
          </tokens>
        </chunking>
        <chunking id="7" string="join us" type="VP">
          <tokens>
            <token id="59" string="join" />
            <token id="60" string="us" />
          </tokens>
        </chunking>
        <chunking id="8" string="hard to do `` Nothing to kill or die" type="ADJP">
          <tokens>
            <token id="11" string="hard" />
            <token id="12" string="to" />
            <token id="13" string="do" />
            <token id="14" string="``" />
            <token id="15" string="Nothing" />
            <token id="16" string="to" />
            <token id="17" string="kill" />
            <token id="18" string="or" />
            <token id="19" string="die" />
          </tokens>
        </chunking>
        <chunking id="9" string="there" type="NP">
          <tokens>
            <token id="3" string="there" />
          </tokens>
        </chunking>
        <chunking id="10" string="say i" type="VP">
          <tokens>
            <token id="40" string="say" />
            <token id="41" string="i" />
          </tokens>
        </chunking>
        <chunking id="11" string="'m not the only one `` i hope someday" type="VP">
          <tokens>
            <token id="48" string="'m" />
            <token id="49" string="not" />
            <token id="50" string="the" />
            <token id="51" string="only" />
            <token id="52" string="one" />
            <token id="53" string="``" />
            <token id="54" string="i" />
            <token id="55" string="hope" />
            <token id="56" string="someday" />
          </tokens>
        </chunking>
        <chunking id="12" string="there 's no countries `` It is n't hard to do `` Nothing to kill or die for `` And no religion too `` Imagine all the people `` Living life in peace ... `` You may say i" type="SBAR">
          <tokens>
            <token id="3" string="there" />
            <token id="4" string="'s" />
            <token id="5" string="no" />
            <token id="6" string="countries" />
            <token id="7" string="``" />
            <token id="8" string="It" />
            <token id="9" string="is" />
            <token id="10" string="n't" />
            <token id="11" string="hard" />
            <token id="12" string="to" />
            <token id="13" string="do" />
            <token id="14" string="``" />
            <token id="15" string="Nothing" />
            <token id="16" string="to" />
            <token id="17" string="kill" />
            <token id="18" string="or" />
            <token id="19" string="die" />
            <token id="20" string="for" />
            <token id="21" string="``" />
            <token id="22" string="And" />
            <token id="23" string="no" />
            <token id="24" string="religion" />
            <token id="25" string="too" />
            <token id="26" string="``" />
            <token id="27" string="Imagine" />
            <token id="28" string="all" />
            <token id="29" string="the" />
            <token id="30" string="people" />
            <token id="31" string="``" />
            <token id="32" string="Living" />
            <token id="33" string="life" />
            <token id="34" string="in" />
            <token id="35" string="peace" />
            <token id="36" string="..." />
            <token id="37" string="``" />
            <token id="38" string="You" />
            <token id="39" string="may" />
            <token id="40" string="say" />
            <token id="41" string="i" />
          </tokens>
        </chunking>
        <chunking id="13" string="peace" type="NP">
          <tokens>
            <token id="35" string="peace" />
          </tokens>
        </chunking>
        <chunking id="14" string="do `` Nothing to kill or die" type="VP">
          <tokens>
            <token id="13" string="do" />
            <token id="14" string="``" />
            <token id="15" string="Nothing" />
            <token id="16" string="to" />
            <token id="17" string="kill" />
            <token id="18" string="or" />
            <token id="19" string="die" />
          </tokens>
        </chunking>
        <chunking id="15" string="`` i hope someday" type="SBAR">
          <tokens>
            <token id="53" string="``" />
            <token id="54" string="i" />
            <token id="55" string="hope" />
            <token id="56" string="someday" />
          </tokens>
        </chunking>
        <chunking id="16" string="a dreamer" type="NP">
          <tokens>
            <token id="43" string="a" />
            <token id="44" string="dreamer" />
          </tokens>
        </chunking>
        <chunking id="17" string="You" type="NP">
          <tokens>
            <token id="38" string="You" />
          </tokens>
        </chunking>
        <chunking id="18" string="to kill or die" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="kill" />
            <token id="18" string="or" />
            <token id="19" string="die" />
          </tokens>
        </chunking>
        <chunking id="19" string="the only one" type="NP">
          <tokens>
            <token id="50" string="the" />
            <token id="51" string="only" />
            <token id="52" string="one" />
          </tokens>
        </chunking>
        <chunking id="20" string="no countries `` It is n't hard to do `` Nothing to kill or die for `` And no religion too `` Imagine all the people `` Living life in peace ... `` You may say i" type="NP">
          <tokens>
            <token id="5" string="no" />
            <token id="6" string="countries" />
            <token id="7" string="``" />
            <token id="8" string="It" />
            <token id="9" string="is" />
            <token id="10" string="n't" />
            <token id="11" string="hard" />
            <token id="12" string="to" />
            <token id="13" string="do" />
            <token id="14" string="``" />
            <token id="15" string="Nothing" />
            <token id="16" string="to" />
            <token id="17" string="kill" />
            <token id="18" string="or" />
            <token id="19" string="die" />
            <token id="20" string="for" />
            <token id="21" string="``" />
            <token id="22" string="And" />
            <token id="23" string="no" />
            <token id="24" string="religion" />
            <token id="25" string="too" />
            <token id="26" string="``" />
            <token id="27" string="Imagine" />
            <token id="28" string="all" />
            <token id="29" string="the" />
            <token id="30" string="people" />
            <token id="31" string="``" />
            <token id="32" string="Living" />
            <token id="33" string="life" />
            <token id="34" string="in" />
            <token id="35" string="peace" />
            <token id="36" string="..." />
            <token id="37" string="``" />
            <token id="38" string="You" />
            <token id="39" string="may" />
            <token id="40" string="say" />
            <token id="41" string="i" />
          </tokens>
        </chunking>
        <chunking id="21" string="`` Imagine all the people `` Living life in peace ... `` You may say i" type="VP">
          <tokens>
            <token id="26" string="``" />
            <token id="27" string="Imagine" />
            <token id="28" string="all" />
            <token id="29" string="the" />
            <token id="30" string="people" />
            <token id="31" string="``" />
            <token id="32" string="Living" />
            <token id="33" string="life" />
            <token id="34" string="in" />
            <token id="35" string="peace" />
            <token id="36" string="..." />
            <token id="37" string="``" />
            <token id="38" string="You" />
            <token id="39" string="may" />
            <token id="40" string="say" />
            <token id="41" string="i" />
          </tokens>
        </chunking>
        <chunking id="22" string="life" type="NP">
          <tokens>
            <token id="33" string="life" />
          </tokens>
        </chunking>
        <chunking id="23" string="It" type="NP">
          <tokens>
            <token id="8" string="It" />
          </tokens>
        </chunking>
        <chunking id="24" string="is n't hard to do `` Nothing to kill or die" type="VP">
          <tokens>
            <token id="9" string="is" />
            <token id="10" string="n't" />
            <token id="11" string="hard" />
            <token id="12" string="to" />
            <token id="13" string="do" />
            <token id="14" string="``" />
            <token id="15" string="Nothing" />
            <token id="16" string="to" />
            <token id="17" string="kill" />
            <token id="18" string="or" />
            <token id="19" string="die" />
          </tokens>
        </chunking>
        <chunking id="25" string="'ll join us" type="VP">
          <tokens>
            <token id="58" string="'ll" />
            <token id="59" string="join" />
            <token id="60" string="us" />
          </tokens>
        </chunking>
        <chunking id="26" string="It is n't hard to do `` Nothing to kill or die" type="SBAR">
          <tokens>
            <token id="8" string="It" />
            <token id="9" string="is" />
            <token id="10" string="n't" />
            <token id="11" string="hard" />
            <token id="12" string="to" />
            <token id="13" string="do" />
            <token id="14" string="``" />
            <token id="15" string="Nothing" />
            <token id="16" string="to" />
            <token id="17" string="kill" />
            <token id="18" string="or" />
            <token id="19" string="die" />
          </tokens>
        </chunking>
        <chunking id="27" string="the world" type="NP">
          <tokens>
            <token id="63" string="the" />
            <token id="64" string="world" />
          </tokens>
        </chunking>
        <chunking id="28" string="Nothing" type="NP">
          <tokens>
            <token id="15" string="Nothing" />
          </tokens>
        </chunking>
        <chunking id="29" string="be as one" type="VP">
          <tokens>
            <token id="65" string="be" />
            <token id="66" string="as" />
            <token id="67" string="one" />
          </tokens>
        </chunking>
        <chunking id="30" string="all the people" type="NP">
          <tokens>
            <token id="28" string="all" />
            <token id="29" string="the" />
            <token id="30" string="people" />
          </tokens>
        </chunking>
        <chunking id="31" string="Imagine there 's no countries `` It is n't hard to do `` Nothing to kill or die for `` And no religion too `` Imagine all the people `` Living life in peace ... `` You may say i" type="VP">
          <tokens>
            <token id="2" string="Imagine" />
            <token id="3" string="there" />
            <token id="4" string="'s" />
            <token id="5" string="no" />
            <token id="6" string="countries" />
            <token id="7" string="``" />
            <token id="8" string="It" />
            <token id="9" string="is" />
            <token id="10" string="n't" />
            <token id="11" string="hard" />
            <token id="12" string="to" />
            <token id="13" string="do" />
            <token id="14" string="``" />
            <token id="15" string="Nothing" />
            <token id="16" string="to" />
            <token id="17" string="kill" />
            <token id="18" string="or" />
            <token id="19" string="die" />
            <token id="20" string="for" />
            <token id="21" string="``" />
            <token id="22" string="And" />
            <token id="23" string="no" />
            <token id="24" string="religion" />
            <token id="25" string="too" />
            <token id="26" string="``" />
            <token id="27" string="Imagine" />
            <token id="28" string="all" />
            <token id="29" string="the" />
            <token id="30" string="people" />
            <token id="31" string="``" />
            <token id="32" string="Living" />
            <token id="33" string="life" />
            <token id="34" string="in" />
            <token id="35" string="peace" />
            <token id="36" string="..." />
            <token id="37" string="``" />
            <token id="38" string="You" />
            <token id="39" string="may" />
            <token id="40" string="say" />
            <token id="41" string="i" />
          </tokens>
        </chunking>
        <chunking id="32" string="'m a dreamer `` But i 'm not the only one `` i hope someday" type="VP">
          <tokens>
            <token id="42" string="'m" />
            <token id="43" string="a" />
            <token id="44" string="dreamer" />
            <token id="45" string="``" />
            <token id="46" string="But" />
            <token id="47" string="i" />
            <token id="48" string="'m" />
            <token id="49" string="not" />
            <token id="50" string="the" />
            <token id="51" string="only" />
            <token id="52" string="one" />
            <token id="53" string="``" />
            <token id="54" string="i" />
            <token id="55" string="hope" />
            <token id="56" string="someday" />
          </tokens>
        </chunking>
        <chunking id="33" string="Living life in peace ... `` You may say i" type="VP">
          <tokens>
            <token id="32" string="Living" />
            <token id="33" string="life" />
            <token id="34" string="in" />
            <token id="35" string="peace" />
            <token id="36" string="..." />
            <token id="37" string="``" />
            <token id="38" string="You" />
            <token id="39" string="may" />
            <token id="40" string="say" />
            <token id="41" string="i" />
          </tokens>
        </chunking>
        <chunking id="34" string="no countries" type="NP">
          <tokens>
            <token id="5" string="no" />
            <token id="6" string="countries" />
          </tokens>
        </chunking>
        <chunking id="35" string="may say i" type="VP">
          <tokens>
            <token id="39" string="may" />
            <token id="40" string="say" />
            <token id="41" string="i" />
          </tokens>
        </chunking>
        <chunking id="36" string="And no religion too `` Imagine all the people `` Living life in peace ... `` You may say i" type="SBAR">
          <tokens>
            <token id="22" string="And" />
            <token id="23" string="no" />
            <token id="24" string="religion" />
            <token id="25" string="too" />
            <token id="26" string="``" />
            <token id="27" string="Imagine" />
            <token id="28" string="all" />
            <token id="29" string="the" />
            <token id="30" string="people" />
            <token id="31" string="``" />
            <token id="32" string="Living" />
            <token id="33" string="life" />
            <token id="34" string="in" />
            <token id="35" string="peace" />
            <token id="36" string="..." />
            <token id="37" string="``" />
            <token id="38" string="You" />
            <token id="39" string="may" />
            <token id="40" string="say" />
            <token id="41" string="i" />
          </tokens>
        </chunking>
        <chunking id="37" string="us" type="NP">
          <tokens>
            <token id="60" string="us" />
          </tokens>
        </chunking>
        <chunking id="38" string="kill or die" type="VP">
          <tokens>
            <token id="17" string="kill" />
            <token id="18" string="or" />
            <token id="19" string="die" />
          </tokens>
        </chunking>
        <chunking id="39" string="you" type="NP">
          <tokens>
            <token id="57" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="csubj">
          <governor id="42">'m</governor>
          <dependent id="2">Imagine</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="4">'s</governor>
          <dependent id="3">there</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">Imagine</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">countries</governor>
          <dependent id="5">no</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">'s</governor>
          <dependent id="6">countries</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">hard</governor>
          <dependent id="8">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">hard</governor>
          <dependent id="9">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">hard</governor>
          <dependent id="10">n't</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">countries</governor>
          <dependent id="11">hard</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">do</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">hard</governor>
          <dependent id="13">do</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">do</governor>
          <dependent id="15">Nothing</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">kill</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">do</governor>
          <dependent id="17">kill</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">kill</governor>
          <dependent id="18">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">kill</governor>
          <dependent id="19">die</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">Imagine</governor>
          <dependent id="20">for</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="27">Imagine</governor>
          <dependent id="22">And</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="24">religion</governor>
          <dependent id="23">no</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">Imagine</governor>
          <dependent id="24">religion</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="27">Imagine</governor>
          <dependent id="25">too</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="6">countries</governor>
          <dependent id="27">Imagine</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="30">people</governor>
          <dependent id="28">all</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">people</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">Living</governor>
          <dependent id="30">people</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="27">Imagine</governor>
          <dependent id="32">Living</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="32">Living</governor>
          <dependent id="33">life</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">peace</governor>
          <dependent id="34">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">Living</governor>
          <dependent id="35">peace</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="40">say</governor>
          <dependent id="38">You</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="40">say</governor>
          <dependent id="39">may</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="32">Living</governor>
          <dependent id="40">say</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="40">say</governor>
          <dependent id="41">i</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="42">'m</dependent>
        </dependency>
        <dependency type="det">
          <governor id="44">dreamer</governor>
          <dependent id="43">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="42">'m</governor>
          <dependent id="44">dreamer</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="52">one</governor>
          <dependent id="46">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="52">one</governor>
          <dependent id="47">i</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="52">one</governor>
          <dependent id="48">'m</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="52">one</governor>
          <dependent id="49">not</dependent>
        </dependency>
        <dependency type="det">
          <governor id="52">one</governor>
          <dependent id="50">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="52">one</governor>
          <dependent id="51">only</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="42">'m</governor>
          <dependent id="52">one</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="55">hope</governor>
          <dependent id="54">i</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="52">one</governor>
          <dependent id="55">hope</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="55">hope</governor>
          <dependent id="56">someday</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="59">join</governor>
          <dependent id="57">you</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="59">join</governor>
          <dependent id="58">'ll</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="42">'m</governor>
          <dependent id="59">join</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="59">join</governor>
          <dependent id="60">us</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="42">'m</governor>
          <dependent id="62">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="64">world</governor>
          <dependent id="63">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="67">one</governor>
          <dependent id="64">world</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="67">one</governor>
          <dependent id="65">be</dependent>
        </dependency>
        <dependency type="case">
          <governor id="67">one</governor>
          <dependent id="66">as</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="42">'m</governor>
          <dependent id="67">one</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="52" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>Lennon was born Oct. 9, 1940.</content>
      <tokens>
        <token id="1" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="born" lemma="bear" stem="born" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Oct." lemma="Oct." stem="oct." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="9" lemma="9" stem="9" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="1940" lemma="1940" stem="1940" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Lennon)) (VP (VBD was) (VP (VBN born) (NP-TMP (NNP Oct.) (CD 9) (, ,) (CD 1940)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was born Oct. 9 , 1940" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="born" />
            <token id="4" string="Oct." />
            <token id="5" string="9" />
            <token id="6" string="," />
            <token id="7" string="1940" />
          </tokens>
        </chunking>
        <chunking id="2" string="Lennon" type="NP">
          <tokens>
            <token id="1" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="3" string="born Oct. 9 , 1940" type="VP">
          <tokens>
            <token id="3" string="born" />
            <token id="4" string="Oct." />
            <token id="5" string="9" />
            <token id="6" string="," />
            <token id="7" string="1940" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="3">born</governor>
          <dependent id="1">Lennon</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="3">born</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">born</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="3">born</governor>
          <dependent id="4">Oct.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">Oct.</governor>
          <dependent id="5">9</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">Oct.</governor>
          <dependent id="7">1940</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="Oct. 9 , 1940" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="Oct." />
            <token id="5" string="9" />
            <token id="6" string="," />
            <token id="7" string="1940" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>He was shot and killed outside his Manhattan apartment on Dec. 8, 1980.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="shot" lemma="shoot" stem="shot" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="killed" lemma="kill" stem="kill" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="outside" lemma="outside" stem="outsid" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="Manhattan" lemma="Manhattan" stem="manhattan" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="9" string="apartment" lemma="apartment" stem="apart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="Dec." lemma="Dec." stem="dec." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="12" string="8" lemma="8" stem="8" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="14" string="1980" lemma="1980" stem="1980" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD was) (VP (VBN shot) (CC and) (VBN killed) (PP (IN outside) (NP (NP (PRP$ his) (NNP Manhattan) (NN apartment)) (PP (IN on) (NP (NNP Dec.) (CD 8) (, ,) (CD 1980))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Dec. 8 , 1980" type="NP">
          <tokens>
            <token id="11" string="Dec." />
            <token id="12" string="8" />
            <token id="13" string="," />
            <token id="14" string="1980" />
          </tokens>
        </chunking>
        <chunking id="2" string="his Manhattan apartment" type="NP">
          <tokens>
            <token id="7" string="his" />
            <token id="8" string="Manhattan" />
            <token id="9" string="apartment" />
          </tokens>
        </chunking>
        <chunking id="3" string="shot and killed outside his Manhattan apartment on Dec. 8 , 1980" type="VP">
          <tokens>
            <token id="3" string="shot" />
            <token id="4" string="and" />
            <token id="5" string="killed" />
            <token id="6" string="outside" />
            <token id="7" string="his" />
            <token id="8" string="Manhattan" />
            <token id="9" string="apartment" />
            <token id="10" string="on" />
            <token id="11" string="Dec." />
            <token id="12" string="8" />
            <token id="13" string="," />
            <token id="14" string="1980" />
          </tokens>
        </chunking>
        <chunking id="4" string="his Manhattan apartment on Dec. 8 , 1980" type="NP">
          <tokens>
            <token id="7" string="his" />
            <token id="8" string="Manhattan" />
            <token id="9" string="apartment" />
            <token id="10" string="on" />
            <token id="11" string="Dec." />
            <token id="12" string="8" />
            <token id="13" string="," />
            <token id="14" string="1980" />
          </tokens>
        </chunking>
        <chunking id="5" string="was shot and killed outside his Manhattan apartment on Dec. 8 , 1980" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="shot" />
            <token id="4" string="and" />
            <token id="5" string="killed" />
            <token id="6" string="outside" />
            <token id="7" string="his" />
            <token id="8" string="Manhattan" />
            <token id="9" string="apartment" />
            <token id="10" string="on" />
            <token id="11" string="Dec." />
            <token id="12" string="8" />
            <token id="13" string="," />
            <token id="14" string="1980" />
          </tokens>
        </chunking>
        <chunking id="6" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="3">shot</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="3">shot</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">shot</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">shot</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">shot</governor>
          <dependent id="5">killed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">apartment</governor>
          <dependent id="6">outside</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">apartment</governor>
          <dependent id="7">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">apartment</governor>
          <dependent id="8">Manhattan</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">shot</governor>
          <dependent id="9">apartment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Dec.</governor>
          <dependent id="10">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">apartment</governor>
          <dependent id="11">Dec.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">Dec.</governor>
          <dependent id="12">8</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">Dec.</governor>
          <dependent id="14">1980</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Dec. 8 , 1980" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="Dec." />
            <token id="12" string="8" />
            <token id="13" string="," />
            <token id="14" string="1980" />
          </tokens>
        </entity>
        <entity id="2" string="Manhattan" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="Manhattan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>Ono was a painter when Lennon met her.</content>
      <tokens>
        <token id="1" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="painter" lemma="painter" stem="painter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="met" lemma="meet" stem="met" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="her" lemma="she" stem="her" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Ono)) (VP (VBD was) (NP (NP (DT a) (NN painter)) (SBAR (WHADVP (WRB when)) (S (NP (NNP Lennon)) (VP (VBD met) (NP (PRP her))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a painter when Lennon met her" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="painter" />
            <token id="5" string="when" />
            <token id="6" string="Lennon" />
            <token id="7" string="met" />
            <token id="8" string="her" />
          </tokens>
        </chunking>
        <chunking id="2" string="was a painter when Lennon met her" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="a" />
            <token id="4" string="painter" />
            <token id="5" string="when" />
            <token id="6" string="Lennon" />
            <token id="7" string="met" />
            <token id="8" string="her" />
          </tokens>
        </chunking>
        <chunking id="3" string="met her" type="VP">
          <tokens>
            <token id="7" string="met" />
            <token id="8" string="her" />
          </tokens>
        </chunking>
        <chunking id="4" string="a painter" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="painter" />
          </tokens>
        </chunking>
        <chunking id="5" string="Lennon" type="NP">
          <tokens>
            <token id="6" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="6" string="her" type="NP">
          <tokens>
            <token id="8" string="her" />
          </tokens>
        </chunking>
        <chunking id="7" string="when Lennon met her" type="SBAR">
          <tokens>
            <token id="5" string="when" />
            <token id="6" string="Lennon" />
            <token id="7" string="met" />
            <token id="8" string="her" />
          </tokens>
        </chunking>
        <chunking id="8" string="Ono" type="NP">
          <tokens>
            <token id="1" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="9" string="when" type="WHADVP">
          <tokens>
            <token id="5" string="when" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">painter</governor>
          <dependent id="1">Ono</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">painter</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">painter</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">painter</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">met</governor>
          <dependent id="5">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">met</governor>
          <dependent id="6">Lennon</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">painter</governor>
          <dependent id="7">met</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">met</governor>
          <dependent id="8">her</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>She later joined him in music and in public demonstrations for peace.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="joined" lemma="join" stem="join" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="music" lemma="music" stem="music" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="demonstrations" lemma="demonstration" stem="demonstr" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="peace" lemma="peace" stem="peac" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (ADVP (RB later)) (VP (VBD joined) (NP (PRP him)) (PP (PP (IN in) (NP (NN music))) (CC and) (PP (IN in) (NP (JJ public) (NNS demonstrations)))) (PP (IN for) (NP (NN peace)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="music" type="NP">
          <tokens>
            <token id="6" string="music" />
          </tokens>
        </chunking>
        <chunking id="2" string="joined him in music and in public demonstrations for peace" type="VP">
          <tokens>
            <token id="3" string="joined" />
            <token id="4" string="him" />
            <token id="5" string="in" />
            <token id="6" string="music" />
            <token id="7" string="and" />
            <token id="8" string="in" />
            <token id="9" string="public" />
            <token id="10" string="demonstrations" />
            <token id="11" string="for" />
            <token id="12" string="peace" />
          </tokens>
        </chunking>
        <chunking id="3" string="peace" type="NP">
          <tokens>
            <token id="12" string="peace" />
          </tokens>
        </chunking>
        <chunking id="4" string="public demonstrations" type="NP">
          <tokens>
            <token id="9" string="public" />
            <token id="10" string="demonstrations" />
          </tokens>
        </chunking>
        <chunking id="5" string="him" type="NP">
          <tokens>
            <token id="4" string="him" />
          </tokens>
        </chunking>
        <chunking id="6" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">joined</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">joined</governor>
          <dependent id="2">later</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">joined</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">joined</governor>
          <dependent id="3">joined</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">joined</governor>
          <dependent id="4">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">music</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">joined</governor>
          <dependent id="6">music</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">joined</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">demonstrations</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">demonstrations</governor>
          <dependent id="9">public</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">joined</governor>
          <dependent id="10">demonstrations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">peace</governor>
          <dependent id="11">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">joined</governor>
          <dependent id="12">peace</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>``I think that for somebody like me, because I feel that I&amp;apost;m an artist and a creative artist, that it is a very strange turn of events that I&amp;apost;m known as a widow,&amp;apost;&amp;apost; she said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="somebody" lemma="somebody" stem="somebodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="feel" lemma="feel" stem="feel" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="artist" lemma="artist" stem="artist" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="creative" lemma="creative" stem="creativ" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="artist" lemma="artist" stem="artist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="strange" lemma="strange" stem="strang" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="turn" lemma="turn" stem="turn" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="events" lemma="event" stem="event" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="known" lemma="know" stem="known" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="38" string="widow" lemma="widow" stem="widow" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="39" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBP think) (ADVP (IN that) (PP (IN for) (NP (NN somebody)))) (PP (IN like) (NP (PRP me))) (, ,) (SBAR (IN because) (S (NP (PRP I)) (VP (VBP feel) (SBAR (IN that) (S (NP (PRP I)) (VP (VBP 'm) (NP (NP (DT an) (NN artist)) (CC and) (NP (DT a) (JJ creative) (NN artist))) (, ,) (SBAR (IN that) (S (NP (PRP it)) (VP (VBZ is) (NP (NP (DT a) (ADJP (RB very) (JJ strange)) (NN turn)) (PP (IN of) (NP (NNS events)))) (SBAR (IN that) (S (NP (PRP I)) (VP (VBP 'm) (VP (VBN known) (PP (IN as) (NP (DT a) (NN widow)))))))))))))))))) (, ,) ('' '') (NP (PRP she)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="an artist" type="NP">
          <tokens>
            <token id="16" string="an" />
            <token id="17" string="artist" />
          </tokens>
        </chunking>
        <chunking id="2" string="that I 'm known as a widow" type="SBAR">
          <tokens>
            <token id="32" string="that" />
            <token id="33" string="I" />
            <token id="34" string="'m" />
            <token id="35" string="known" />
            <token id="36" string="as" />
            <token id="37" string="a" />
            <token id="38" string="widow" />
          </tokens>
        </chunking>
        <chunking id="3" string="an artist and a creative artist" type="NP">
          <tokens>
            <token id="16" string="an" />
            <token id="17" string="artist" />
            <token id="18" string="and" />
            <token id="19" string="a" />
            <token id="20" string="creative" />
            <token id="21" string="artist" />
          </tokens>
        </chunking>
        <chunking id="4" string="known as a widow" type="VP">
          <tokens>
            <token id="35" string="known" />
            <token id="36" string="as" />
            <token id="37" string="a" />
            <token id="38" string="widow" />
          </tokens>
        </chunking>
        <chunking id="5" string="that I 'm an artist and a creative artist , that it is a very strange turn of events that I 'm known as a widow" type="SBAR">
          <tokens>
            <token id="13" string="that" />
            <token id="14" string="I" />
            <token id="15" string="'m" />
            <token id="16" string="an" />
            <token id="17" string="artist" />
            <token id="18" string="and" />
            <token id="19" string="a" />
            <token id="20" string="creative" />
            <token id="21" string="artist" />
            <token id="22" string="," />
            <token id="23" string="that" />
            <token id="24" string="it" />
            <token id="25" string="is" />
            <token id="26" string="a" />
            <token id="27" string="very" />
            <token id="28" string="strange" />
            <token id="29" string="turn" />
            <token id="30" string="of" />
            <token id="31" string="events" />
            <token id="32" string="that" />
            <token id="33" string="I" />
            <token id="34" string="'m" />
            <token id="35" string="known" />
            <token id="36" string="as" />
            <token id="37" string="a" />
            <token id="38" string="widow" />
          </tokens>
        </chunking>
        <chunking id="6" string="that it is a very strange turn of events that I 'm known as a widow" type="SBAR">
          <tokens>
            <token id="23" string="that" />
            <token id="24" string="it" />
            <token id="25" string="is" />
            <token id="26" string="a" />
            <token id="27" string="very" />
            <token id="28" string="strange" />
            <token id="29" string="turn" />
            <token id="30" string="of" />
            <token id="31" string="events" />
            <token id="32" string="that" />
            <token id="33" string="I" />
            <token id="34" string="'m" />
            <token id="35" string="known" />
            <token id="36" string="as" />
            <token id="37" string="a" />
            <token id="38" string="widow" />
          </tokens>
        </chunking>
        <chunking id="7" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="8" string="it" type="NP">
          <tokens>
            <token id="24" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="somebody" type="NP">
          <tokens>
            <token id="6" string="somebody" />
          </tokens>
        </chunking>
        <chunking id="10" string="because I feel that I 'm an artist and a creative artist , that it is a very strange turn of events that I 'm known as a widow" type="SBAR">
          <tokens>
            <token id="10" string="because" />
            <token id="11" string="I" />
            <token id="12" string="feel" />
            <token id="13" string="that" />
            <token id="14" string="I" />
            <token id="15" string="'m" />
            <token id="16" string="an" />
            <token id="17" string="artist" />
            <token id="18" string="and" />
            <token id="19" string="a" />
            <token id="20" string="creative" />
            <token id="21" string="artist" />
            <token id="22" string="," />
            <token id="23" string="that" />
            <token id="24" string="it" />
            <token id="25" string="is" />
            <token id="26" string="a" />
            <token id="27" string="very" />
            <token id="28" string="strange" />
            <token id="29" string="turn" />
            <token id="30" string="of" />
            <token id="31" string="events" />
            <token id="32" string="that" />
            <token id="33" string="I" />
            <token id="34" string="'m" />
            <token id="35" string="known" />
            <token id="36" string="as" />
            <token id="37" string="a" />
            <token id="38" string="widow" />
          </tokens>
        </chunking>
        <chunking id="11" string="she" type="NP">
          <tokens>
            <token id="41" string="she" />
          </tokens>
        </chunking>
        <chunking id="12" string="a widow" type="NP">
          <tokens>
            <token id="37" string="a" />
            <token id="38" string="widow" />
          </tokens>
        </chunking>
        <chunking id="13" string="feel that I 'm an artist and a creative artist , that it is a very strange turn of events that I 'm known as a widow" type="VP">
          <tokens>
            <token id="12" string="feel" />
            <token id="13" string="that" />
            <token id="14" string="I" />
            <token id="15" string="'m" />
            <token id="16" string="an" />
            <token id="17" string="artist" />
            <token id="18" string="and" />
            <token id="19" string="a" />
            <token id="20" string="creative" />
            <token id="21" string="artist" />
            <token id="22" string="," />
            <token id="23" string="that" />
            <token id="24" string="it" />
            <token id="25" string="is" />
            <token id="26" string="a" />
            <token id="27" string="very" />
            <token id="28" string="strange" />
            <token id="29" string="turn" />
            <token id="30" string="of" />
            <token id="31" string="events" />
            <token id="32" string="that" />
            <token id="33" string="I" />
            <token id="34" string="'m" />
            <token id="35" string="known" />
            <token id="36" string="as" />
            <token id="37" string="a" />
            <token id="38" string="widow" />
          </tokens>
        </chunking>
        <chunking id="14" string="is a very strange turn of events that I 'm known as a widow" type="VP">
          <tokens>
            <token id="25" string="is" />
            <token id="26" string="a" />
            <token id="27" string="very" />
            <token id="28" string="strange" />
            <token id="29" string="turn" />
            <token id="30" string="of" />
            <token id="31" string="events" />
            <token id="32" string="that" />
            <token id="33" string="I" />
            <token id="34" string="'m" />
            <token id="35" string="known" />
            <token id="36" string="as" />
            <token id="37" string="a" />
            <token id="38" string="widow" />
          </tokens>
        </chunking>
        <chunking id="15" string="very strange" type="ADJP">
          <tokens>
            <token id="27" string="very" />
            <token id="28" string="strange" />
          </tokens>
        </chunking>
        <chunking id="16" string="a very strange turn of events" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="very" />
            <token id="28" string="strange" />
            <token id="29" string="turn" />
            <token id="30" string="of" />
            <token id="31" string="events" />
          </tokens>
        </chunking>
        <chunking id="17" string="me" type="NP">
          <tokens>
            <token id="8" string="me" />
          </tokens>
        </chunking>
        <chunking id="18" string="think that for somebody like me , because I feel that I 'm an artist and a creative artist , that it is a very strange turn of events that I 'm known as a widow" type="VP">
          <tokens>
            <token id="3" string="think" />
            <token id="4" string="that" />
            <token id="5" string="for" />
            <token id="6" string="somebody" />
            <token id="7" string="like" />
            <token id="8" string="me" />
            <token id="9" string="," />
            <token id="10" string="because" />
            <token id="11" string="I" />
            <token id="12" string="feel" />
            <token id="13" string="that" />
            <token id="14" string="I" />
            <token id="15" string="'m" />
            <token id="16" string="an" />
            <token id="17" string="artist" />
            <token id="18" string="and" />
            <token id="19" string="a" />
            <token id="20" string="creative" />
            <token id="21" string="artist" />
            <token id="22" string="," />
            <token id="23" string="that" />
            <token id="24" string="it" />
            <token id="25" string="is" />
            <token id="26" string="a" />
            <token id="27" string="very" />
            <token id="28" string="strange" />
            <token id="29" string="turn" />
            <token id="30" string="of" />
            <token id="31" string="events" />
            <token id="32" string="that" />
            <token id="33" string="I" />
            <token id="34" string="'m" />
            <token id="35" string="known" />
            <token id="36" string="as" />
            <token id="37" string="a" />
            <token id="38" string="widow" />
          </tokens>
        </chunking>
        <chunking id="19" string="'m known as a widow" type="VP">
          <tokens>
            <token id="34" string="'m" />
            <token id="35" string="known" />
            <token id="36" string="as" />
            <token id="37" string="a" />
            <token id="38" string="widow" />
          </tokens>
        </chunking>
        <chunking id="20" string="a creative artist" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="creative" />
            <token id="21" string="artist" />
          </tokens>
        </chunking>
        <chunking id="21" string="said" type="VP">
          <tokens>
            <token id="42" string="said" />
          </tokens>
        </chunking>
        <chunking id="22" string="a very strange turn" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="very" />
            <token id="28" string="strange" />
            <token id="29" string="turn" />
          </tokens>
        </chunking>
        <chunking id="23" string="'m an artist and a creative artist , that it is a very strange turn of events that I 'm known as a widow" type="VP">
          <tokens>
            <token id="15" string="'m" />
            <token id="16" string="an" />
            <token id="17" string="artist" />
            <token id="18" string="and" />
            <token id="19" string="a" />
            <token id="20" string="creative" />
            <token id="21" string="artist" />
            <token id="22" string="," />
            <token id="23" string="that" />
            <token id="24" string="it" />
            <token id="25" string="is" />
            <token id="26" string="a" />
            <token id="27" string="very" />
            <token id="28" string="strange" />
            <token id="29" string="turn" />
            <token id="30" string="of" />
            <token id="31" string="events" />
            <token id="32" string="that" />
            <token id="33" string="I" />
            <token id="34" string="'m" />
            <token id="35" string="known" />
            <token id="36" string="as" />
            <token id="37" string="a" />
            <token id="38" string="widow" />
          </tokens>
        </chunking>
        <chunking id="24" string="events" type="NP">
          <tokens>
            <token id="31" string="events" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">think</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="42">said</governor>
          <dependent id="3">think</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">think</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">somebody</governor>
          <dependent id="5">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">that</governor>
          <dependent id="6">somebody</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">me</governor>
          <dependent id="7">like</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">think</governor>
          <dependent id="8">me</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">feel</governor>
          <dependent id="10">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">feel</governor>
          <dependent id="11">I</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">think</governor>
          <dependent id="12">feel</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">artist</governor>
          <dependent id="13">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">artist</governor>
          <dependent id="14">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">artist</governor>
          <dependent id="15">'m</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">artist</governor>
          <dependent id="16">an</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">feel</governor>
          <dependent id="17">artist</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">artist</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">artist</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">artist</governor>
          <dependent id="20">creative</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">artist</governor>
          <dependent id="21">artist</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">turn</governor>
          <dependent id="23">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">turn</governor>
          <dependent id="24">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="29">turn</governor>
          <dependent id="25">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">turn</governor>
          <dependent id="26">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">strange</governor>
          <dependent id="27">very</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">turn</governor>
          <dependent id="28">strange</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">artist</governor>
          <dependent id="29">turn</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">events</governor>
          <dependent id="30">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">turn</governor>
          <dependent id="31">events</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="35">known</governor>
          <dependent id="32">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="35">known</governor>
          <dependent id="33">I</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="35">known</governor>
          <dependent id="34">'m</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="29">turn</governor>
          <dependent id="35">known</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">widow</governor>
          <dependent id="36">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">widow</governor>
          <dependent id="37">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">known</governor>
          <dependent id="38">widow</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="42">said</governor>
          <dependent id="41">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="42">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>``But it is stranger to me that I&amp;apost;m not that disturbed by it.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="stranger" lemma="stranger" stem="stranger" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="disturbed" lemma="disturb" stem="disturb" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (CC But) (NP (PRP it)) (VP (VBZ is) (ADJP (NN stranger) (PP (TO to) (NP (PRP me)))) (SBAR (IN that) (S (NP (PRP I)) (VP (VBP 'm) (RB not) (VP (ADVP (IN that)) (VBN disturbed) (PP (IN by) (NP (PRP it)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that disturbed by it" type="VP">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="disturbed" />
            <token id="14" string="by" />
            <token id="15" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="'m not that disturbed by it" type="VP">
          <tokens>
            <token id="10" string="'m" />
            <token id="11" string="not" />
            <token id="12" string="that" />
            <token id="13" string="disturbed" />
            <token id="14" string="by" />
            <token id="15" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="me" type="NP">
          <tokens>
            <token id="7" string="me" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="9" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="3" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="stranger to me" type="ADJP">
          <tokens>
            <token id="5" string="stranger" />
            <token id="6" string="to" />
            <token id="7" string="me" />
          </tokens>
        </chunking>
        <chunking id="7" string="that I 'm not that disturbed by it" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="I" />
            <token id="10" string="'m" />
            <token id="11" string="not" />
            <token id="12" string="that" />
            <token id="13" string="disturbed" />
            <token id="14" string="by" />
            <token id="15" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="is stranger to me that I 'm not that disturbed by it" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="stranger" />
            <token id="6" string="to" />
            <token id="7" string="me" />
            <token id="8" string="that" />
            <token id="9" string="I" />
            <token id="10" string="'m" />
            <token id="11" string="not" />
            <token id="12" string="that" />
            <token id="13" string="disturbed" />
            <token id="14" string="by" />
            <token id="15" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="5">stranger</governor>
          <dependent id="2">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">stranger</governor>
          <dependent id="3">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">stranger</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">stranger</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">me</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">stranger</governor>
          <dependent id="7">me</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">disturbed</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">disturbed</governor>
          <dependent id="9">I</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">disturbed</governor>
          <dependent id="10">'m</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="13">disturbed</governor>
          <dependent id="11">not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">disturbed</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">stranger</governor>
          <dependent id="13">disturbed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">it</governor>
          <dependent id="14">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">disturbed</governor>
          <dependent id="15">it</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>I think that John promoted my work a lot in his lifetime and somehow it seems like it is a pleasure for me to sort of still work in a context of a partnership with him.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="promoted" lemma="promote" stem="promot" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="7" string="work" lemma="work" stem="work" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="lifetime" lemma="lifetime" stem="lifetim" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="somehow" lemma="somehow" stem="somehow" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="seems" lemma="seem" stem="seem" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="pleasure" lemma="pleasure" stem="pleasur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="sort" lemma="sort" stem="sort" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="work" lemma="work" stem="work" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="context" lemma="context" stem="context" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="partnership" lemma="partnership" stem="partnership" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP I)) (VP (VBP think) (SBAR (IN that) (S (NP (NNP John)) (VP (VBD promoted) (NP (NP (PRP$ my) (NN work)) (NP (DT a) (NN lot))) (PP (IN in) (NP (PRP$ his) (NN lifetime)))))))) (CC and) (S (ADVP (RB somehow)) (NP (PRP it)) (VP (VBZ seems) (SBAR (IN like) (S (NP (PRP it)) (VP (VBZ is) (NP (NP (DT a) (NN pleasure)) (PP (IN for) (NP (PRP me)))) (PP (TO to) (NP (NP (NN sort)) (PP (IN of) (NP (NP (RB still) (NN work)) (PP (IN in) (NP (NP (DT a) (NN context)) (PP (IN of) (NP (NP (DT a) (NN partnership)) (PP (IN with) (NP (PRP him)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="sort of still work in a context of a partnership with him" type="NP">
          <tokens>
            <token id="25" string="sort" />
            <token id="26" string="of" />
            <token id="27" string="still" />
            <token id="28" string="work" />
            <token id="29" string="in" />
            <token id="30" string="a" />
            <token id="31" string="context" />
            <token id="32" string="of" />
            <token id="33" string="a" />
            <token id="34" string="partnership" />
            <token id="35" string="with" />
            <token id="36" string="him" />
          </tokens>
        </chunking>
        <chunking id="2" string="promoted my work a lot in his lifetime" type="VP">
          <tokens>
            <token id="5" string="promoted" />
            <token id="6" string="my" />
            <token id="7" string="work" />
            <token id="8" string="a" />
            <token id="9" string="lot" />
            <token id="10" string="in" />
            <token id="11" string="his" />
            <token id="12" string="lifetime" />
          </tokens>
        </chunking>
        <chunking id="3" string="still work in a context of a partnership with him" type="NP">
          <tokens>
            <token id="27" string="still" />
            <token id="28" string="work" />
            <token id="29" string="in" />
            <token id="30" string="a" />
            <token id="31" string="context" />
            <token id="32" string="of" />
            <token id="33" string="a" />
            <token id="34" string="partnership" />
            <token id="35" string="with" />
            <token id="36" string="him" />
          </tokens>
        </chunking>
        <chunking id="4" string="a context" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="context" />
          </tokens>
        </chunking>
        <chunking id="5" string="like it is a pleasure for me to sort of still work in a context of a partnership with him" type="SBAR">
          <tokens>
            <token id="17" string="like" />
            <token id="18" string="it" />
            <token id="19" string="is" />
            <token id="20" string="a" />
            <token id="21" string="pleasure" />
            <token id="22" string="for" />
            <token id="23" string="me" />
            <token id="24" string="to" />
            <token id="25" string="sort" />
            <token id="26" string="of" />
            <token id="27" string="still" />
            <token id="28" string="work" />
            <token id="29" string="in" />
            <token id="30" string="a" />
            <token id="31" string="context" />
            <token id="32" string="of" />
            <token id="33" string="a" />
            <token id="34" string="partnership" />
            <token id="35" string="with" />
            <token id="36" string="him" />
          </tokens>
        </chunking>
        <chunking id="6" string="think that John promoted my work a lot in his lifetime" type="VP">
          <tokens>
            <token id="2" string="think" />
            <token id="3" string="that" />
            <token id="4" string="John" />
            <token id="5" string="promoted" />
            <token id="6" string="my" />
            <token id="7" string="work" />
            <token id="8" string="a" />
            <token id="9" string="lot" />
            <token id="10" string="in" />
            <token id="11" string="his" />
            <token id="12" string="lifetime" />
          </tokens>
        </chunking>
        <chunking id="7" string="a pleasure" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="pleasure" />
          </tokens>
        </chunking>
        <chunking id="8" string="sort" type="NP">
          <tokens>
            <token id="25" string="sort" />
          </tokens>
        </chunking>
        <chunking id="9" string="it" type="NP">
          <tokens>
            <token id="15" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="seems like it is a pleasure for me to sort of still work in a context of a partnership with him" type="VP">
          <tokens>
            <token id="16" string="seems" />
            <token id="17" string="like" />
            <token id="18" string="it" />
            <token id="19" string="is" />
            <token id="20" string="a" />
            <token id="21" string="pleasure" />
            <token id="22" string="for" />
            <token id="23" string="me" />
            <token id="24" string="to" />
            <token id="25" string="sort" />
            <token id="26" string="of" />
            <token id="27" string="still" />
            <token id="28" string="work" />
            <token id="29" string="in" />
            <token id="30" string="a" />
            <token id="31" string="context" />
            <token id="32" string="of" />
            <token id="33" string="a" />
            <token id="34" string="partnership" />
            <token id="35" string="with" />
            <token id="36" string="him" />
          </tokens>
        </chunking>
        <chunking id="11" string="a lot" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="lot" />
          </tokens>
        </chunking>
        <chunking id="12" string="a context of a partnership with him" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="context" />
            <token id="32" string="of" />
            <token id="33" string="a" />
            <token id="34" string="partnership" />
            <token id="35" string="with" />
            <token id="36" string="him" />
          </tokens>
        </chunking>
        <chunking id="13" string="my work" type="NP">
          <tokens>
            <token id="6" string="my" />
            <token id="7" string="work" />
          </tokens>
        </chunking>
        <chunking id="14" string="that John promoted my work a lot in his lifetime" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="John" />
            <token id="5" string="promoted" />
            <token id="6" string="my" />
            <token id="7" string="work" />
            <token id="8" string="a" />
            <token id="9" string="lot" />
            <token id="10" string="in" />
            <token id="11" string="his" />
            <token id="12" string="lifetime" />
          </tokens>
        </chunking>
        <chunking id="15" string="is a pleasure for me to sort of still work in a context of a partnership with him" type="VP">
          <tokens>
            <token id="19" string="is" />
            <token id="20" string="a" />
            <token id="21" string="pleasure" />
            <token id="22" string="for" />
            <token id="23" string="me" />
            <token id="24" string="to" />
            <token id="25" string="sort" />
            <token id="26" string="of" />
            <token id="27" string="still" />
            <token id="28" string="work" />
            <token id="29" string="in" />
            <token id="30" string="a" />
            <token id="31" string="context" />
            <token id="32" string="of" />
            <token id="33" string="a" />
            <token id="34" string="partnership" />
            <token id="35" string="with" />
            <token id="36" string="him" />
          </tokens>
        </chunking>
        <chunking id="16" string="a partnership" type="NP">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="partnership" />
          </tokens>
        </chunking>
        <chunking id="17" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="18" string="John" type="NP">
          <tokens>
            <token id="4" string="John" />
          </tokens>
        </chunking>
        <chunking id="19" string="still work" type="NP">
          <tokens>
            <token id="27" string="still" />
            <token id="28" string="work" />
          </tokens>
        </chunking>
        <chunking id="20" string="him" type="NP">
          <tokens>
            <token id="36" string="him" />
          </tokens>
        </chunking>
        <chunking id="21" string="a pleasure for me" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="pleasure" />
            <token id="22" string="for" />
            <token id="23" string="me" />
          </tokens>
        </chunking>
        <chunking id="22" string="his lifetime" type="NP">
          <tokens>
            <token id="11" string="his" />
            <token id="12" string="lifetime" />
          </tokens>
        </chunking>
        <chunking id="23" string="me" type="NP">
          <tokens>
            <token id="23" string="me" />
          </tokens>
        </chunking>
        <chunking id="24" string="a partnership with him" type="NP">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="partnership" />
            <token id="35" string="with" />
            <token id="36" string="him" />
          </tokens>
        </chunking>
        <chunking id="25" string="my work a lot" type="NP">
          <tokens>
            <token id="6" string="my" />
            <token id="7" string="work" />
            <token id="8" string="a" />
            <token id="9" string="lot" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">think</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">think</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">promoted</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">promoted</governor>
          <dependent id="4">John</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">think</governor>
          <dependent id="5">promoted</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">work</governor>
          <dependent id="6">my</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">promoted</governor>
          <dependent id="7">work</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">lot</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">work</governor>
          <dependent id="9">lot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">lifetime</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">lifetime</governor>
          <dependent id="11">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">promoted</governor>
          <dependent id="12">lifetime</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">think</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">seems</governor>
          <dependent id="14">somehow</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">seems</governor>
          <dependent id="15">it</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">think</governor>
          <dependent id="16">seems</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">pleasure</governor>
          <dependent id="17">like</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">pleasure</governor>
          <dependent id="18">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">pleasure</governor>
          <dependent id="19">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">pleasure</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">seems</governor>
          <dependent id="21">pleasure</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">me</governor>
          <dependent id="22">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">pleasure</governor>
          <dependent id="23">me</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">sort</governor>
          <dependent id="24">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">pleasure</governor>
          <dependent id="25">sort</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">work</governor>
          <dependent id="26">of</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">work</governor>
          <dependent id="27">still</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">sort</governor>
          <dependent id="28">work</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">context</governor>
          <dependent id="29">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">context</governor>
          <dependent id="30">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">work</governor>
          <dependent id="31">context</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">partnership</governor>
          <dependent id="32">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">partnership</governor>
          <dependent id="33">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">context</governor>
          <dependent id="34">partnership</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">him</governor>
          <dependent id="35">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">partnership</governor>
          <dependent id="36">him</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="John" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="45" has_coreference="true">
      <content>... I think it is my turn to promote him.</content>
      <tokens>
        <token id="1" string="..." lemma="..." stem="..." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="turn" lemma="turn" stem="turn" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="promote" lemma="promote" stem="promot" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ...) (NP (PRP I)) (VP (VBP think) (SBAR (S (NP (PRP it)) (VP (VBZ is) (NP (PRP$ my) (NN turn) (S (VP (TO to) (VP (VB promote) (NP (PRP him)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="it is my turn to promote him" type="SBAR">
          <tokens>
            <token id="4" string="it" />
            <token id="5" string="is" />
            <token id="6" string="my" />
            <token id="7" string="turn" />
            <token id="8" string="to" />
            <token id="9" string="promote" />
            <token id="10" string="him" />
          </tokens>
        </chunking>
        <chunking id="2" string="to promote him" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="promote" />
            <token id="10" string="him" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="4" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="my turn to promote him" type="NP">
          <tokens>
            <token id="6" string="my" />
            <token id="7" string="turn" />
            <token id="8" string="to" />
            <token id="9" string="promote" />
            <token id="10" string="him" />
          </tokens>
        </chunking>
        <chunking id="6" string="him" type="NP">
          <tokens>
            <token id="10" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="think it is my turn to promote him" type="VP">
          <tokens>
            <token id="3" string="think" />
            <token id="4" string="it" />
            <token id="5" string="is" />
            <token id="6" string="my" />
            <token id="7" string="turn" />
            <token id="8" string="to" />
            <token id="9" string="promote" />
            <token id="10" string="him" />
          </tokens>
        </chunking>
        <chunking id="8" string="is my turn to promote him" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="my" />
            <token id="7" string="turn" />
            <token id="8" string="to" />
            <token id="9" string="promote" />
            <token id="10" string="him" />
          </tokens>
        </chunking>
        <chunking id="9" string="promote him" type="VP">
          <tokens>
            <token id="9" string="promote" />
            <token id="10" string="him" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">think</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">think</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">turn</governor>
          <dependent id="4">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">turn</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">turn</governor>
          <dependent id="6">my</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">think</governor>
          <dependent id="7">turn</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">promote</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="7">turn</governor>
          <dependent id="9">promote</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">promote</governor>
          <dependent id="10">him</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="46" has_coreference="true">
      <content>He promoted me.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="promoted" lemma="promote" stem="promot" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD promoted) (NP (PRP me))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="promoted me" type="VP">
          <tokens>
            <token id="2" string="promoted" />
            <token id="3" string="me" />
          </tokens>
        </chunking>
        <chunking id="2" string="me" type="NP">
          <tokens>
            <token id="3" string="me" />
          </tokens>
        </chunking>
        <chunking id="3" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">promoted</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">promoted</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">promoted</governor>
          <dependent id="3">me</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="47" has_coreference="true">
      <content>When Albert Goldman&amp;apost;s ``The Lives of John Lennon&amp;apost;&amp;apost; was published in September, depicting the former Beatle as riddled with vices, faults and neuroses, Ono called it ``totally fiction.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Albert" lemma="Albert" stem="albert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Lives" lemma="life" stem="live" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="published" lemma="publish" stem="publish" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="September" lemma="September" stem="septemb" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="depicting" lemma="depict" stem="depict" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="Beatle" lemma="Beatle" stem="beatl" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="21" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="riddled" lemma="riddled" stem="riddl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="vices" lemma="vice" stem="vice" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="faults" lemma="fault" stem="fault" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="neuroses" lemma="neurosis" stem="neuros" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="31" string="called" lemma="call" stem="call" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="totally" lemma="totally" stem="total" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="fiction" lemma="fiction" stem="fiction" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHADVP (WRB When)) (S (NP (NP (NNP Albert) (NNP Goldman) (POS 's)) (`` ``) (NX (DT The) (NNS Lives) (PP (IN of) (NP (NNP John) (NNP Lennon)))) ('' '')) (VP (VBD was) (VP (VBN published) (PP (IN in) (NP (NNP September))) (, ,) (S (VP (VBG depicting) (NP (DT the) (JJ former) (NNP Beatle)) (PP (IN as) (S (VP (JJ riddled) (PP (IN with) (NP (NNS vices) (, ,) (NNS faults) (CC and) (NNS neuroses)))))))))))) (, ,) (NP (NNP Ono)) (VP (VBD called) (S (NP (PRP it)) (`` ``) (ADJP (RB totally) (NN fiction)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="riddled with vices , faults and neuroses" type="VP">
          <tokens>
            <token id="22" string="riddled" />
            <token id="23" string="with" />
            <token id="24" string="vices" />
            <token id="25" string="," />
            <token id="26" string="faults" />
            <token id="27" string="and" />
            <token id="28" string="neuroses" />
          </tokens>
        </chunking>
        <chunking id="2" string="published in September , depicting the former Beatle as riddled with vices , faults and neuroses" type="VP">
          <tokens>
            <token id="13" string="published" />
            <token id="14" string="in" />
            <token id="15" string="September" />
            <token id="16" string="," />
            <token id="17" string="depicting" />
            <token id="18" string="the" />
            <token id="19" string="former" />
            <token id="20" string="Beatle" />
            <token id="21" string="as" />
            <token id="22" string="riddled" />
            <token id="23" string="with" />
            <token id="24" string="vices" />
            <token id="25" string="," />
            <token id="26" string="faults" />
            <token id="27" string="and" />
            <token id="28" string="neuroses" />
          </tokens>
        </chunking>
        <chunking id="3" string="September" type="NP">
          <tokens>
            <token id="15" string="September" />
          </tokens>
        </chunking>
        <chunking id="4" string="totally fiction" type="ADJP">
          <tokens>
            <token id="34" string="totally" />
            <token id="35" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="5" string="the former Beatle" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="former" />
            <token id="20" string="Beatle" />
          </tokens>
        </chunking>
        <chunking id="6" string="called it `` totally fiction" type="VP">
          <tokens>
            <token id="31" string="called" />
            <token id="32" string="it" />
            <token id="33" string="``" />
            <token id="34" string="totally" />
            <token id="35" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="32" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="Ono" type="NP">
          <tokens>
            <token id="30" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="9" string="When" type="WHADVP">
          <tokens>
            <token id="1" string="When" />
          </tokens>
        </chunking>
        <chunking id="10" string="John Lennon" type="NP">
          <tokens>
            <token id="9" string="John" />
            <token id="10" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="11" string="Albert Goldman 's `` The Lives of John Lennon ''" type="NP">
          <tokens>
            <token id="2" string="Albert" />
            <token id="3" string="Goldman" />
            <token id="4" string="'s" />
            <token id="5" string="``" />
            <token id="6" string="The" />
            <token id="7" string="Lives" />
            <token id="8" string="of" />
            <token id="9" string="John" />
            <token id="10" string="Lennon" />
            <token id="11" string="''" />
          </tokens>
        </chunking>
        <chunking id="12" string="When Albert Goldman 's `` The Lives of John Lennon '' was published in September , depicting the former Beatle as riddled with vices , faults and neuroses" type="SBAR">
          <tokens>
            <token id="1" string="When" />
            <token id="2" string="Albert" />
            <token id="3" string="Goldman" />
            <token id="4" string="'s" />
            <token id="5" string="``" />
            <token id="6" string="The" />
            <token id="7" string="Lives" />
            <token id="8" string="of" />
            <token id="9" string="John" />
            <token id="10" string="Lennon" />
            <token id="11" string="''" />
            <token id="12" string="was" />
            <token id="13" string="published" />
            <token id="14" string="in" />
            <token id="15" string="September" />
            <token id="16" string="," />
            <token id="17" string="depicting" />
            <token id="18" string="the" />
            <token id="19" string="former" />
            <token id="20" string="Beatle" />
            <token id="21" string="as" />
            <token id="22" string="riddled" />
            <token id="23" string="with" />
            <token id="24" string="vices" />
            <token id="25" string="," />
            <token id="26" string="faults" />
            <token id="27" string="and" />
            <token id="28" string="neuroses" />
          </tokens>
        </chunking>
        <chunking id="13" string="depicting the former Beatle as riddled with vices , faults and neuroses" type="VP">
          <tokens>
            <token id="17" string="depicting" />
            <token id="18" string="the" />
            <token id="19" string="former" />
            <token id="20" string="Beatle" />
            <token id="21" string="as" />
            <token id="22" string="riddled" />
            <token id="23" string="with" />
            <token id="24" string="vices" />
            <token id="25" string="," />
            <token id="26" string="faults" />
            <token id="27" string="and" />
            <token id="28" string="neuroses" />
          </tokens>
        </chunking>
        <chunking id="14" string="vices , faults and neuroses" type="NP">
          <tokens>
            <token id="24" string="vices" />
            <token id="25" string="," />
            <token id="26" string="faults" />
            <token id="27" string="and" />
            <token id="28" string="neuroses" />
          </tokens>
        </chunking>
        <chunking id="15" string="Albert Goldman 's" type="NP">
          <tokens>
            <token id="2" string="Albert" />
            <token id="3" string="Goldman" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="16" string="was published in September , depicting the former Beatle as riddled with vices , faults and neuroses" type="VP">
          <tokens>
            <token id="12" string="was" />
            <token id="13" string="published" />
            <token id="14" string="in" />
            <token id="15" string="September" />
            <token id="16" string="," />
            <token id="17" string="depicting" />
            <token id="18" string="the" />
            <token id="19" string="former" />
            <token id="20" string="Beatle" />
            <token id="21" string="as" />
            <token id="22" string="riddled" />
            <token id="23" string="with" />
            <token id="24" string="vices" />
            <token id="25" string="," />
            <token id="26" string="faults" />
            <token id="27" string="and" />
            <token id="28" string="neuroses" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="13">published</governor>
          <dependent id="1">When</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Goldman</governor>
          <dependent id="2">Albert</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">Lives</governor>
          <dependent id="3">Goldman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">Goldman</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">Lives</governor>
          <dependent id="6">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">published</governor>
          <dependent id="7">Lives</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Lennon</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Lennon</governor>
          <dependent id="9">John</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">Lives</governor>
          <dependent id="10">Lennon</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">published</governor>
          <dependent id="12">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="31">called</governor>
          <dependent id="13">published</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">September</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">published</governor>
          <dependent id="15">September</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">published</governor>
          <dependent id="17">depicting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">Beatle</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">Beatle</governor>
          <dependent id="19">former</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">depicting</governor>
          <dependent id="20">Beatle</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">riddled</governor>
          <dependent id="21">as</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">depicting</governor>
          <dependent id="22">riddled</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">vices</governor>
          <dependent id="23">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">riddled</governor>
          <dependent id="24">vices</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">vices</governor>
          <dependent id="26">faults</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">vices</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">vices</governor>
          <dependent id="28">neuroses</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">called</governor>
          <dependent id="30">Ono</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="31">called</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="35">fiction</governor>
          <dependent id="32">it</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="35">fiction</governor>
          <dependent id="34">totally</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="31">called</governor>
          <dependent id="35">fiction</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="John" />
            <token id="10" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="Beatle" type="MISC" score="0.0">
          <tokens>
            <token id="20" string="Beatle" />
          </tokens>
        </entity>
        <entity id="3" string="September" type="DATE" score="0.0">
          <tokens>
            <token id="15" string="September" />
          </tokens>
        </entity>
        <entity id="4" string="Albert Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Albert" />
            <token id="3" string="Goldman" />
          </tokens>
        </entity>
        <entity id="5" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="30" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="48" has_coreference="true">
      <content>Since then she&amp;apost;s received a tremendous amount of support from friends and fans.</content>
      <tokens>
        <token id="1" string="Since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="received" lemma="receive" stem="receiv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="tremendous" lemma="tremendous" stem="tremend" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="amount" lemma="amount" stem="amount" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="support" lemma="support" stem="support" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="friends" lemma="friend" stem="friend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="fans" lemma="fan" stem="fan" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Since) (NP (RB then))) (NP (PRP she)) (VP (VBZ 's) (VP (VBN received) (NP (NP (DT a) (JJ tremendous) (NN amount)) (PP (IN of) (NP (NN support)))) (PP (IN from) (NP (NNS friends) (CC and) (NNS fans))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a tremendous amount of support" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="tremendous" />
            <token id="8" string="amount" />
            <token id="9" string="of" />
            <token id="10" string="support" />
          </tokens>
        </chunking>
        <chunking id="2" string="'s received a tremendous amount of support from friends and fans" type="VP">
          <tokens>
            <token id="4" string="'s" />
            <token id="5" string="received" />
            <token id="6" string="a" />
            <token id="7" string="tremendous" />
            <token id="8" string="amount" />
            <token id="9" string="of" />
            <token id="10" string="support" />
            <token id="11" string="from" />
            <token id="12" string="friends" />
            <token id="13" string="and" />
            <token id="14" string="fans" />
          </tokens>
        </chunking>
        <chunking id="3" string="friends and fans" type="NP">
          <tokens>
            <token id="12" string="friends" />
            <token id="13" string="and" />
            <token id="14" string="fans" />
          </tokens>
        </chunking>
        <chunking id="4" string="then" type="NP">
          <tokens>
            <token id="2" string="then" />
          </tokens>
        </chunking>
        <chunking id="5" string="a tremendous amount" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="tremendous" />
            <token id="8" string="amount" />
          </tokens>
        </chunking>
        <chunking id="6" string="support" type="NP">
          <tokens>
            <token id="10" string="support" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="3" string="she" />
          </tokens>
        </chunking>
        <chunking id="8" string="received a tremendous amount of support from friends and fans" type="VP">
          <tokens>
            <token id="5" string="received" />
            <token id="6" string="a" />
            <token id="7" string="tremendous" />
            <token id="8" string="amount" />
            <token id="9" string="of" />
            <token id="10" string="support" />
            <token id="11" string="from" />
            <token id="12" string="friends" />
            <token id="13" string="and" />
            <token id="14" string="fans" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">then</governor>
          <dependent id="1">Since</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">received</governor>
          <dependent id="2">then</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">received</governor>
          <dependent id="3">she</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">received</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">received</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">amount</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">amount</governor>
          <dependent id="7">tremendous</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">received</governor>
          <dependent id="8">amount</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">support</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">amount</governor>
          <dependent id="10">support</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">friends</governor>
          <dependent id="11">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">received</governor>
          <dependent id="12">friends</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">friends</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">friends</governor>
          <dependent id="14">fans</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="49" has_coreference="true">
      <content>``I was very touched and thankful that people sent letters to me and extended hands at this time, very warmly.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="touched" lemma="touch" stem="touch" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="thankful" lemma="thankful" stem="thank" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="sent" lemma="send" stem="sent" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="letters" lemma="letter" stem="letter" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="extended" lemma="extend" stem="extend" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="hands" lemma="hand" stem="hand" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="warmly" lemma="warmly" stem="warmli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VP (VBD was) (ADJP (ADJP (RB very) (VBN touched)) (CC and) (ADJP (JJ thankful) (SBAR (IN that) (S (NP (NNS people)) (VP (VBN sent) (NP (NNS letters)) (PP (TO to) (NP (PRP me))))))))) (CC and) (VP (VBD extended) (NP (NNS hands)) (PP (IN at) (NP (DT this) (NN time))) (, ,) (ADVP (RB very) (RB warmly)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="hands" type="NP">
          <tokens>
            <token id="16" string="hands" />
          </tokens>
        </chunking>
        <chunking id="2" string="was very touched and thankful that people sent letters to me" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="very" />
            <token id="5" string="touched" />
            <token id="6" string="and" />
            <token id="7" string="thankful" />
            <token id="8" string="that" />
            <token id="9" string="people" />
            <token id="10" string="sent" />
            <token id="11" string="letters" />
            <token id="12" string="to" />
            <token id="13" string="me" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="sent letters to me" type="VP">
          <tokens>
            <token id="10" string="sent" />
            <token id="11" string="letters" />
            <token id="12" string="to" />
            <token id="13" string="me" />
          </tokens>
        </chunking>
        <chunking id="5" string="people" type="NP">
          <tokens>
            <token id="9" string="people" />
          </tokens>
        </chunking>
        <chunking id="6" string="this time" type="NP">
          <tokens>
            <token id="18" string="this" />
            <token id="19" string="time" />
          </tokens>
        </chunking>
        <chunking id="7" string="extended hands at this time , very warmly" type="VP">
          <tokens>
            <token id="15" string="extended" />
            <token id="16" string="hands" />
            <token id="17" string="at" />
            <token id="18" string="this" />
            <token id="19" string="time" />
            <token id="20" string="," />
            <token id="21" string="very" />
            <token id="22" string="warmly" />
          </tokens>
        </chunking>
        <chunking id="8" string="thankful that people sent letters to me" type="ADJP">
          <tokens>
            <token id="7" string="thankful" />
            <token id="8" string="that" />
            <token id="9" string="people" />
            <token id="10" string="sent" />
            <token id="11" string="letters" />
            <token id="12" string="to" />
            <token id="13" string="me" />
          </tokens>
        </chunking>
        <chunking id="9" string="very touched and thankful that people sent letters to me" type="ADJP">
          <tokens>
            <token id="4" string="very" />
            <token id="5" string="touched" />
            <token id="6" string="and" />
            <token id="7" string="thankful" />
            <token id="8" string="that" />
            <token id="9" string="people" />
            <token id="10" string="sent" />
            <token id="11" string="letters" />
            <token id="12" string="to" />
            <token id="13" string="me" />
          </tokens>
        </chunking>
        <chunking id="10" string="me" type="NP">
          <tokens>
            <token id="13" string="me" />
          </tokens>
        </chunking>
        <chunking id="11" string="very touched" type="ADJP">
          <tokens>
            <token id="4" string="very" />
            <token id="5" string="touched" />
          </tokens>
        </chunking>
        <chunking id="12" string="that people sent letters to me" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="people" />
            <token id="10" string="sent" />
            <token id="11" string="letters" />
            <token id="12" string="to" />
            <token id="13" string="me" />
          </tokens>
        </chunking>
        <chunking id="13" string="was very touched and thankful that people sent letters to me and extended hands at this time , very warmly" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="very" />
            <token id="5" string="touched" />
            <token id="6" string="and" />
            <token id="7" string="thankful" />
            <token id="8" string="that" />
            <token id="9" string="people" />
            <token id="10" string="sent" />
            <token id="11" string="letters" />
            <token id="12" string="to" />
            <token id="13" string="me" />
            <token id="14" string="and" />
            <token id="15" string="extended" />
            <token id="16" string="hands" />
            <token id="17" string="at" />
            <token id="18" string="this" />
            <token id="19" string="time" />
            <token id="20" string="," />
            <token id="21" string="very" />
            <token id="22" string="warmly" />
          </tokens>
        </chunking>
        <chunking id="14" string="letters" type="NP">
          <tokens>
            <token id="11" string="letters" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="5">touched</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">touched</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">touched</governor>
          <dependent id="4">very</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">touched</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">touched</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">touched</governor>
          <dependent id="7">thankful</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">sent</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">sent</governor>
          <dependent id="9">people</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">thankful</governor>
          <dependent id="10">sent</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">sent</governor>
          <dependent id="11">letters</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">me</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">sent</governor>
          <dependent id="13">me</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">touched</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">touched</governor>
          <dependent id="15">extended</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">extended</governor>
          <dependent id="16">hands</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">time</governor>
          <dependent id="17">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">time</governor>
          <dependent id="18">this</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">extended</governor>
          <dependent id="19">time</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">warmly</governor>
          <dependent id="21">very</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">extended</governor>
          <dependent id="22">warmly</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="50" has_coreference="true">
      <content>I really appreciate that.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="appreciate" lemma="appreciate" stem="appreci" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (ADVP (RB really)) (VP (VBP appreciate) (ADVP (IN that))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="2" string="appreciate that" type="VP">
          <tokens>
            <token id="3" string="appreciate" />
            <token id="4" string="that" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">appreciate</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">appreciate</governor>
          <dependent id="2">really</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">appreciate</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">appreciate</governor>
          <dependent id="4">that</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="51" has_coreference="true">
      <content>I was also surprised that so many people stood up against it (the Goldman book).</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="surprised" lemma="surprise" stem="surpris" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="stood" lemma="stand" stem="stood" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="16" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBD was) (ADVP (RB also)) (VP (VBN surprised) (SBAR (IN that) (S (NP (RB so) (JJ many) (NNS people)) (VP (VBD stood) (PRT (RP up)) (PP (IN against) (NP (NP (PRP it)) (-LRB- -LRB-) (NP (DT the) (NNP Goldman) (NN book)) (-RRB- -RRB-)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that so many people stood up against it -LRB- the Goldman book -RRB-" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="so" />
            <token id="7" string="many" />
            <token id="8" string="people" />
            <token id="9" string="stood" />
            <token id="10" string="up" />
            <token id="11" string="against" />
            <token id="12" string="it" />
            <token id="13" string="(" />
            <token id="14" string="the" />
            <token id="15" string="Goldman" />
            <token id="16" string="book" />
            <token id="17" string=")" />
          </tokens>
        </chunking>
        <chunking id="2" string="it -LRB- the Goldman book -RRB-" type="NP">
          <tokens>
            <token id="12" string="it" />
            <token id="13" string="(" />
            <token id="14" string="the" />
            <token id="15" string="Goldman" />
            <token id="16" string="book" />
            <token id="17" string=")" />
          </tokens>
        </chunking>
        <chunking id="3" string="so many people" type="NP">
          <tokens>
            <token id="6" string="so" />
            <token id="7" string="many" />
            <token id="8" string="people" />
          </tokens>
        </chunking>
        <chunking id="4" string="was also surprised that so many people stood up against it -LRB- the Goldman book -RRB-" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="also" />
            <token id="4" string="surprised" />
            <token id="5" string="that" />
            <token id="6" string="so" />
            <token id="7" string="many" />
            <token id="8" string="people" />
            <token id="9" string="stood" />
            <token id="10" string="up" />
            <token id="11" string="against" />
            <token id="12" string="it" />
            <token id="13" string="(" />
            <token id="14" string="the" />
            <token id="15" string="Goldman" />
            <token id="16" string="book" />
            <token id="17" string=")" />
          </tokens>
        </chunking>
        <chunking id="5" string="surprised that so many people stood up against it -LRB- the Goldman book -RRB-" type="VP">
          <tokens>
            <token id="4" string="surprised" />
            <token id="5" string="that" />
            <token id="6" string="so" />
            <token id="7" string="many" />
            <token id="8" string="people" />
            <token id="9" string="stood" />
            <token id="10" string="up" />
            <token id="11" string="against" />
            <token id="12" string="it" />
            <token id="13" string="(" />
            <token id="14" string="the" />
            <token id="15" string="Goldman" />
            <token id="16" string="book" />
            <token id="17" string=")" />
          </tokens>
        </chunking>
        <chunking id="6" string="stood up against it -LRB- the Goldman book -RRB-" type="VP">
          <tokens>
            <token id="9" string="stood" />
            <token id="10" string="up" />
            <token id="11" string="against" />
            <token id="12" string="it" />
            <token id="13" string="(" />
            <token id="14" string="the" />
            <token id="15" string="Goldman" />
            <token id="16" string="book" />
            <token id="17" string=")" />
          </tokens>
        </chunking>
        <chunking id="7" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Goldman book" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="Goldman" />
            <token id="16" string="book" />
          </tokens>
        </chunking>
        <chunking id="9" string="it" type="NP">
          <tokens>
            <token id="12" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="4">surprised</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">surprised</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">surprised</governor>
          <dependent id="3">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">surprised</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">stood</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">people</governor>
          <dependent id="6">so</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">people</governor>
          <dependent id="7">many</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">stood</governor>
          <dependent id="8">people</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">surprised</governor>
          <dependent id="9">stood</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="9">stood</governor>
          <dependent id="10">up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">it</governor>
          <dependent id="11">against</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">stood</governor>
          <dependent id="12">it</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">book</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">book</governor>
          <dependent id="15">Goldman</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">it</governor>
          <dependent id="16">book</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Goldman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="52" has_coreference="true">
      <content>I didn&amp;apost;t expect that,&amp;apost;&amp;apost; Ono said.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="expect" lemma="expect" stem="expect" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP I)) (VP (VBD did) (RB n't) (VP (VB expect) (NP (DT that))))) (, ,) ('' '') (NP (NNP Ono)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that" type="NP">
          <tokens>
            <token id="5" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="did n't expect that" type="VP">
          <tokens>
            <token id="2" string="did" />
            <token id="3" string="n't" />
            <token id="4" string="expect" />
            <token id="5" string="that" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="said" type="VP">
          <tokens>
            <token id="9" string="said" />
          </tokens>
        </chunking>
        <chunking id="5" string="expect that" type="VP">
          <tokens>
            <token id="4" string="expect" />
            <token id="5" string="that" />
          </tokens>
        </chunking>
        <chunking id="6" string="Ono" type="NP">
          <tokens>
            <token id="8" string="Ono" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">expect</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">expect</governor>
          <dependent id="2">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">expect</governor>
          <dependent id="3">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">said</governor>
          <dependent id="4">expect</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">expect</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">said</governor>
          <dependent id="8">Ono</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="53" has_coreference="true">
      <content>Lennon&amp;apost;s half sister, Julia Baird, also has written a new book, ``John Lennon, My Brother.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="half" lemma="half" stem="half" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="sister" lemma="sister" stem="sister" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Julia" lemma="Julia" stem="julia" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="Baird" lemma="Baird" stem="baird" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="written" lemma="write" stem="written" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="18" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="My" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="Brother" lemma="Brother" stem="brother" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NNP Lennon) (POS 's)) (NN half) (NN sister)) (, ,) (NP (NNP Julia) (NNP Baird)) (, ,)) (ADVP (RB also)) (VP (VBZ has) (VP (VBN written) (NP (NP (DT a) (JJ new) (NN book)) (, ,) (`` ``) (NP (NP (NNP John) (NNP Lennon)) (, ,) (NP (PRP$ My) (NNP Brother)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="John Lennon" type="NP">
          <tokens>
            <token id="17" string="John" />
            <token id="18" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="2" string="My Brother" type="NP">
          <tokens>
            <token id="20" string="My" />
            <token id="21" string="Brother" />
          </tokens>
        </chunking>
        <chunking id="3" string="has written a new book , `` John Lennon , My Brother" type="VP">
          <tokens>
            <token id="10" string="has" />
            <token id="11" string="written" />
            <token id="12" string="a" />
            <token id="13" string="new" />
            <token id="14" string="book" />
            <token id="15" string="," />
            <token id="16" string="``" />
            <token id="17" string="John" />
            <token id="18" string="Lennon" />
            <token id="19" string="," />
            <token id="20" string="My" />
            <token id="21" string="Brother" />
          </tokens>
        </chunking>
        <chunking id="4" string="John Lennon , My Brother" type="NP">
          <tokens>
            <token id="17" string="John" />
            <token id="18" string="Lennon" />
            <token id="19" string="," />
            <token id="20" string="My" />
            <token id="21" string="Brother" />
          </tokens>
        </chunking>
        <chunking id="5" string="Julia Baird" type="NP">
          <tokens>
            <token id="6" string="Julia" />
            <token id="7" string="Baird" />
          </tokens>
        </chunking>
        <chunking id="6" string="Lennon 's half sister , Julia Baird ," type="NP">
          <tokens>
            <token id="1" string="Lennon" />
            <token id="2" string="'s" />
            <token id="3" string="half" />
            <token id="4" string="sister" />
            <token id="5" string="," />
            <token id="6" string="Julia" />
            <token id="7" string="Baird" />
            <token id="8" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="Lennon 's" type="NP">
          <tokens>
            <token id="1" string="Lennon" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="written a new book , `` John Lennon , My Brother" type="VP">
          <tokens>
            <token id="11" string="written" />
            <token id="12" string="a" />
            <token id="13" string="new" />
            <token id="14" string="book" />
            <token id="15" string="," />
            <token id="16" string="``" />
            <token id="17" string="John" />
            <token id="18" string="Lennon" />
            <token id="19" string="," />
            <token id="20" string="My" />
            <token id="21" string="Brother" />
          </tokens>
        </chunking>
        <chunking id="9" string="Lennon 's half sister" type="NP">
          <tokens>
            <token id="1" string="Lennon" />
            <token id="2" string="'s" />
            <token id="3" string="half" />
            <token id="4" string="sister" />
          </tokens>
        </chunking>
        <chunking id="10" string="a new book" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="new" />
            <token id="14" string="book" />
          </tokens>
        </chunking>
        <chunking id="11" string="a new book , `` John Lennon , My Brother" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="new" />
            <token id="14" string="book" />
            <token id="15" string="," />
            <token id="16" string="``" />
            <token id="17" string="John" />
            <token id="18" string="Lennon" />
            <token id="19" string="," />
            <token id="20" string="My" />
            <token id="21" string="Brother" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="4">sister</governor>
          <dependent id="1">Lennon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Lennon</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">sister</governor>
          <dependent id="3">half</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">written</governor>
          <dependent id="4">sister</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Baird</governor>
          <dependent id="6">Julia</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="4">sister</governor>
          <dependent id="7">Baird</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">written</governor>
          <dependent id="9">also</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">written</governor>
          <dependent id="10">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">written</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">book</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">book</governor>
          <dependent id="13">new</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">written</governor>
          <dependent id="14">book</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Lennon</governor>
          <dependent id="17">John</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">book</governor>
          <dependent id="18">Lennon</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">Brother</governor>
          <dependent id="20">My</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="18">Lennon</governor>
          <dependent id="21">Brother</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="John" />
            <token id="18" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Lennon" />
          </tokens>
        </entity>
        <entity id="3" string="Julia Baird" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Julia" />
            <token id="7" string="Baird" />
          </tokens>
        </entity>
        <entity id="4" string="Brother" type="TITLE" score="0.0">
          <tokens>
            <token id="21" string="Brother" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="54" has_coreference="true">
      <content>She has no idea how many books have been written about Lennon; she&amp;apost;s been sent some of them but hasn&amp;apost;t read them.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="idea" lemma="idea" stem="idea" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="written" lemma="write" stem="written" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="sent" lemma="send" stem="sent" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="21" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="read" lemma="read" stem="read" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP She)) (VP (VBZ has) (NP (NP (DT no) (NN idea)) (SBAR (WHADVP (WRB how)) (S (NP (JJ many) (NNS books)) (VP (VBP have) (VP (VBN been) (VP (VBN written) (PP (IN about) (NP (NNP Lennon))))))))))) (: ;) (S (NP (PRP she)) (VP (VP (VBZ 's) (VP (VBN been) (VP (VBN sent) (NP (NP (DT some)) (PP (IN of) (NP (PRP them))))))) (CC but) (VP (VBZ has) (RB n't) (VP (VB read) (NP (PRP them)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Lennon" type="NP">
          <tokens>
            <token id="12" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="2" string="some of them" type="NP">
          <tokens>
            <token id="18" string="some" />
            <token id="19" string="of" />
            <token id="20" string="them" />
          </tokens>
        </chunking>
        <chunking id="3" string="'s been sent some of them but has n't read them" type="VP">
          <tokens>
            <token id="15" string="'s" />
            <token id="16" string="been" />
            <token id="17" string="sent" />
            <token id="18" string="some" />
            <token id="19" string="of" />
            <token id="20" string="them" />
            <token id="21" string="but" />
            <token id="22" string="has" />
            <token id="23" string="n't" />
            <token id="24" string="read" />
            <token id="25" string="them" />
          </tokens>
        </chunking>
        <chunking id="4" string="have been written about Lennon" type="VP">
          <tokens>
            <token id="8" string="have" />
            <token id="9" string="been" />
            <token id="10" string="written" />
            <token id="11" string="about" />
            <token id="12" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="5" string="some" type="NP">
          <tokens>
            <token id="18" string="some" />
          </tokens>
        </chunking>
        <chunking id="6" string="them" type="NP">
          <tokens>
            <token id="20" string="them" />
          </tokens>
        </chunking>
        <chunking id="7" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="8" string="how" type="WHADVP">
          <tokens>
            <token id="5" string="how" />
          </tokens>
        </chunking>
        <chunking id="9" string="written about Lennon" type="VP">
          <tokens>
            <token id="10" string="written" />
            <token id="11" string="about" />
            <token id="12" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="10" string="she" type="NP">
          <tokens>
            <token id="14" string="she" />
          </tokens>
        </chunking>
        <chunking id="11" string="read them" type="VP">
          <tokens>
            <token id="24" string="read" />
            <token id="25" string="them" />
          </tokens>
        </chunking>
        <chunking id="12" string="many books" type="NP">
          <tokens>
            <token id="6" string="many" />
            <token id="7" string="books" />
          </tokens>
        </chunking>
        <chunking id="13" string="'s been sent some of them" type="VP">
          <tokens>
            <token id="15" string="'s" />
            <token id="16" string="been" />
            <token id="17" string="sent" />
            <token id="18" string="some" />
            <token id="19" string="of" />
            <token id="20" string="them" />
          </tokens>
        </chunking>
        <chunking id="14" string="no idea how many books have been written about Lennon" type="NP">
          <tokens>
            <token id="3" string="no" />
            <token id="4" string="idea" />
            <token id="5" string="how" />
            <token id="6" string="many" />
            <token id="7" string="books" />
            <token id="8" string="have" />
            <token id="9" string="been" />
            <token id="10" string="written" />
            <token id="11" string="about" />
            <token id="12" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="15" string="has no idea how many books have been written about Lennon" type="VP">
          <tokens>
            <token id="2" string="has" />
            <token id="3" string="no" />
            <token id="4" string="idea" />
            <token id="5" string="how" />
            <token id="6" string="many" />
            <token id="7" string="books" />
            <token id="8" string="have" />
            <token id="9" string="been" />
            <token id="10" string="written" />
            <token id="11" string="about" />
            <token id="12" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="16" string="been written about Lennon" type="VP">
          <tokens>
            <token id="9" string="been" />
            <token id="10" string="written" />
            <token id="11" string="about" />
            <token id="12" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="17" string="been sent some of them" type="VP">
          <tokens>
            <token id="16" string="been" />
            <token id="17" string="sent" />
            <token id="18" string="some" />
            <token id="19" string="of" />
            <token id="20" string="them" />
          </tokens>
        </chunking>
        <chunking id="18" string="how many books have been written about Lennon" type="SBAR">
          <tokens>
            <token id="5" string="how" />
            <token id="6" string="many" />
            <token id="7" string="books" />
            <token id="8" string="have" />
            <token id="9" string="been" />
            <token id="10" string="written" />
            <token id="11" string="about" />
            <token id="12" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="19" string="has n't read them" type="VP">
          <tokens>
            <token id="22" string="has" />
            <token id="23" string="n't" />
            <token id="24" string="read" />
            <token id="25" string="them" />
          </tokens>
        </chunking>
        <chunking id="20" string="no idea" type="NP">
          <tokens>
            <token id="3" string="no" />
            <token id="4" string="idea" />
          </tokens>
        </chunking>
        <chunking id="21" string="sent some of them" type="VP">
          <tokens>
            <token id="17" string="sent" />
            <token id="18" string="some" />
            <token id="19" string="of" />
            <token id="20" string="them" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">has</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">has</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">idea</governor>
          <dependent id="3">no</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">has</governor>
          <dependent id="4">idea</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">written</governor>
          <dependent id="5">how</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">books</governor>
          <dependent id="6">many</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="10">written</governor>
          <dependent id="7">books</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">written</governor>
          <dependent id="8">have</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">written</governor>
          <dependent id="9">been</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">idea</governor>
          <dependent id="10">written</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Lennon</governor>
          <dependent id="11">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">written</governor>
          <dependent id="12">Lennon</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="17">sent</governor>
          <dependent id="14">she</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="17">sent</governor>
          <dependent id="15">'s</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="17">sent</governor>
          <dependent id="16">been</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="2">has</governor>
          <dependent id="17">sent</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">sent</governor>
          <dependent id="18">some</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">them</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">some</governor>
          <dependent id="20">them</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">sent</governor>
          <dependent id="21">but</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">read</governor>
          <dependent id="22">has</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="24">read</governor>
          <dependent id="23">n't</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">sent</governor>
          <dependent id="24">read</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">read</governor>
          <dependent id="25">them</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Lennon" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="55" has_coreference="true">
      <content>``I know the life and it is too painful to read somebody else&amp;apost;s version.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="know" lemma="know" stem="know" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="painful" lemma="painful" stem="pain" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="read" lemma="read" stem="read" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="somebody" lemma="somebody" stem="somebodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="else" lemma="else" stem="els" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="version" lemma="version" stem="version" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBP know) (NP (DT the) (NN life)))) (CC and) (S (NP (PRP it)) (VP (VBZ is) (ADJP (RB too) (JJ painful)) (S (VP (TO to) (VP (VB read) (NP (NP (NN somebody) (RB else) (POS 's)) (NN version))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="read somebody else 's version" type="VP">
          <tokens>
            <token id="12" string="read" />
            <token id="13" string="somebody" />
            <token id="14" string="else" />
            <token id="15" string="'s" />
            <token id="16" string="version" />
          </tokens>
        </chunking>
        <chunking id="2" string="the life" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="life" />
          </tokens>
        </chunking>
        <chunking id="3" string="somebody else 's version" type="NP">
          <tokens>
            <token id="13" string="somebody" />
            <token id="14" string="else" />
            <token id="15" string="'s" />
            <token id="16" string="version" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="is too painful to read somebody else 's version" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="too" />
            <token id="10" string="painful" />
            <token id="11" string="to" />
            <token id="12" string="read" />
            <token id="13" string="somebody" />
            <token id="14" string="else" />
            <token id="15" string="'s" />
            <token id="16" string="version" />
          </tokens>
        </chunking>
        <chunking id="7" string="know the life" type="VP">
          <tokens>
            <token id="3" string="know" />
            <token id="4" string="the" />
            <token id="5" string="life" />
          </tokens>
        </chunking>
        <chunking id="8" string="somebody else 's" type="NP">
          <tokens>
            <token id="13" string="somebody" />
            <token id="14" string="else" />
            <token id="15" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="too painful" type="ADJP">
          <tokens>
            <token id="9" string="too" />
            <token id="10" string="painful" />
          </tokens>
        </chunking>
        <chunking id="10" string="to read somebody else 's version" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="read" />
            <token id="13" string="somebody" />
            <token id="14" string="else" />
            <token id="15" string="'s" />
            <token id="16" string="version" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">know</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">know</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">life</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">know</governor>
          <dependent id="5">life</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">know</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">painful</governor>
          <dependent id="7">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">painful</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">painful</governor>
          <dependent id="9">too</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">know</governor>
          <dependent id="10">painful</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">read</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">painful</governor>
          <dependent id="12">read</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">version</governor>
          <dependent id="13">somebody</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">somebody</governor>
          <dependent id="14">else</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">somebody</governor>
          <dependent id="15">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">read</governor>
          <dependent id="16">version</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="56" has_coreference="true">
      <content>There&amp;apost;s still enough footage, Ono said, for another movie _ perhaps a music or political or art film.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="enough" lemma="enough" stem="enough" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="footage" lemma="footage" stem="footag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="movie" lemma="movie" stem="movi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="perhaps" lemma="perhaps" stem="perhap" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="music" lemma="music" stem="music" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="art" lemma="art" stem="art" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="film" lemma="film" stem="film" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (EX There)) (VP (VBZ 's) (ADVP (RB still)) (NP (JJ enough) (NN footage)))) (, ,) (NP (NNP Ono)) (VP (VBD said) (, ,) (PP (IN for) (NP (DT another) (NN movie) (NN _))) (PP (RB perhaps) (NP (NP (DT a) (NN music)) (CC or) (NP (JJ political) (CC or) (NN art) (NN film))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="enough footage" type="NP">
          <tokens>
            <token id="4" string="enough" />
            <token id="5" string="footage" />
          </tokens>
        </chunking>
        <chunking id="2" string="another movie _" type="NP">
          <tokens>
            <token id="11" string="another" />
            <token id="12" string="movie" />
            <token id="13" string="_" />
          </tokens>
        </chunking>
        <chunking id="3" string="'s still enough footage" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="still" />
            <token id="4" string="enough" />
            <token id="5" string="footage" />
          </tokens>
        </chunking>
        <chunking id="4" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="5" string="a music or political or art film" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="music" />
            <token id="17" string="or" />
            <token id="18" string="political" />
            <token id="19" string="or" />
            <token id="20" string="art" />
            <token id="21" string="film" />
          </tokens>
        </chunking>
        <chunking id="6" string="said , for another movie _ perhaps a music or political or art film" type="VP">
          <tokens>
            <token id="8" string="said" />
            <token id="9" string="," />
            <token id="10" string="for" />
            <token id="11" string="another" />
            <token id="12" string="movie" />
            <token id="13" string="_" />
            <token id="14" string="perhaps" />
            <token id="15" string="a" />
            <token id="16" string="music" />
            <token id="17" string="or" />
            <token id="18" string="political" />
            <token id="19" string="or" />
            <token id="20" string="art" />
            <token id="21" string="film" />
          </tokens>
        </chunking>
        <chunking id="7" string="political or art film" type="NP">
          <tokens>
            <token id="18" string="political" />
            <token id="19" string="or" />
            <token id="20" string="art" />
            <token id="21" string="film" />
          </tokens>
        </chunking>
        <chunking id="8" string="a music" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="music" />
          </tokens>
        </chunking>
        <chunking id="9" string="Ono" type="NP">
          <tokens>
            <token id="7" string="Ono" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="2">'s</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">said</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">'s</governor>
          <dependent id="3">still</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">footage</governor>
          <dependent id="4">enough</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="2">'s</governor>
          <dependent id="5">footage</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">said</governor>
          <dependent id="7">Ono</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">_</governor>
          <dependent id="10">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">_</governor>
          <dependent id="11">another</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">_</governor>
          <dependent id="12">movie</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">said</governor>
          <dependent id="13">_</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">music</governor>
          <dependent id="14">perhaps</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">music</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">said</governor>
          <dependent id="16">music</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">music</governor>
          <dependent id="17">or</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">film</governor>
          <dependent id="18">political</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">political</governor>
          <dependent id="19">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">political</governor>
          <dependent id="20">art</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">music</governor>
          <dependent id="21">film</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="57" has_coreference="true">
      <content>And there&amp;apost;s another big John Lennon project on her horizon.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="big" lemma="big" stem="big" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="project" lemma="project" stem="project" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="11" string="horizon" lemma="horizon" stem="horizon" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (EX there)) (VP (VBZ 's) (NP (NP (DT another) (JJ big) (NNP John) (NNP Lennon) (NN project)) (PP (IN on) (NP (PRP$ her) (NN horizon))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="there" type="NP">
          <tokens>
            <token id="2" string="there" />
          </tokens>
        </chunking>
        <chunking id="2" string="her horizon" type="NP">
          <tokens>
            <token id="10" string="her" />
            <token id="11" string="horizon" />
          </tokens>
        </chunking>
        <chunking id="3" string="another big John Lennon project on her horizon" type="NP">
          <tokens>
            <token id="4" string="another" />
            <token id="5" string="big" />
            <token id="6" string="John" />
            <token id="7" string="Lennon" />
            <token id="8" string="project" />
            <token id="9" string="on" />
            <token id="10" string="her" />
            <token id="11" string="horizon" />
          </tokens>
        </chunking>
        <chunking id="4" string="'s another big John Lennon project on her horizon" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="another" />
            <token id="5" string="big" />
            <token id="6" string="John" />
            <token id="7" string="Lennon" />
            <token id="8" string="project" />
            <token id="9" string="on" />
            <token id="10" string="her" />
            <token id="11" string="horizon" />
          </tokens>
        </chunking>
        <chunking id="5" string="another big John Lennon project" type="NP">
          <tokens>
            <token id="4" string="another" />
            <token id="5" string="big" />
            <token id="6" string="John" />
            <token id="7" string="Lennon" />
            <token id="8" string="project" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">'s</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="3">'s</governor>
          <dependent id="2">there</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">project</governor>
          <dependent id="4">another</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">project</governor>
          <dependent id="5">big</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">project</governor>
          <dependent id="6">John</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">project</governor>
          <dependent id="7">Lennon</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">'s</governor>
          <dependent id="8">project</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">horizon</governor>
          <dependent id="9">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">horizon</governor>
          <dependent id="10">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">project</governor>
          <dependent id="11">horizon</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="John" />
            <token id="7" string="Lennon" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="58" has_coreference="true">
      <content>``It&amp;apost;s from unpublished songs which were written for a Broadway musical.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="unpublished" lemma="unpublished" stem="unpublish" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="songs" lemma="song" stem="song" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="written" lemma="write" stem="written" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="Broadway" lemma="Broadway" stem="broadwai" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="13" string="musical" lemma="musical" stem="music" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP It)) (VP (VBZ 's) (PP (IN from) (NP (NP (JJ unpublished) (NNS songs)) (SBAR (WHNP (WDT which)) (S (VP (VBD were) (VP (VBN written) (PP (IN for) (NP (DT a) (NNP Broadway) (NN musical)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="written for a Broadway musical" type="VP">
          <tokens>
            <token id="9" string="written" />
            <token id="10" string="for" />
            <token id="11" string="a" />
            <token id="12" string="Broadway" />
            <token id="13" string="musical" />
          </tokens>
        </chunking>
        <chunking id="2" string="were written for a Broadway musical" type="VP">
          <tokens>
            <token id="8" string="were" />
            <token id="9" string="written" />
            <token id="10" string="for" />
            <token id="11" string="a" />
            <token id="12" string="Broadway" />
            <token id="13" string="musical" />
          </tokens>
        </chunking>
        <chunking id="3" string="unpublished songs" type="NP">
          <tokens>
            <token id="5" string="unpublished" />
            <token id="6" string="songs" />
          </tokens>
        </chunking>
        <chunking id="4" string="which were written for a Broadway musical" type="SBAR">
          <tokens>
            <token id="7" string="which" />
            <token id="8" string="were" />
            <token id="9" string="written" />
            <token id="10" string="for" />
            <token id="11" string="a" />
            <token id="12" string="Broadway" />
            <token id="13" string="musical" />
          </tokens>
        </chunking>
        <chunking id="5" string="unpublished songs which were written for a Broadway musical" type="NP">
          <tokens>
            <token id="5" string="unpublished" />
            <token id="6" string="songs" />
            <token id="7" string="which" />
            <token id="8" string="were" />
            <token id="9" string="written" />
            <token id="10" string="for" />
            <token id="11" string="a" />
            <token id="12" string="Broadway" />
            <token id="13" string="musical" />
          </tokens>
        </chunking>
        <chunking id="6" string="a Broadway musical" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="Broadway" />
            <token id="13" string="musical" />
          </tokens>
        </chunking>
        <chunking id="7" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="8" string="'s from unpublished songs which were written for a Broadway musical" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="from" />
            <token id="5" string="unpublished" />
            <token id="6" string="songs" />
            <token id="7" string="which" />
            <token id="8" string="were" />
            <token id="9" string="written" />
            <token id="10" string="for" />
            <token id="11" string="a" />
            <token id="12" string="Broadway" />
            <token id="13" string="musical" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">songs</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">songs</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">songs</governor>
          <dependent id="4">from</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">songs</governor>
          <dependent id="5">unpublished</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">songs</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">written</governor>
          <dependent id="7">which</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">written</governor>
          <dependent id="8">were</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">songs</governor>
          <dependent id="9">written</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">musical</governor>
          <dependent id="10">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">musical</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">musical</governor>
          <dependent id="12">Broadway</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">written</governor>
          <dependent id="13">musical</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Broadway" type="MISC" score="0.0">
          <tokens>
            <token id="12" string="Broadway" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="59" has_coreference="true">
      <content>I don&amp;apost;t know if it would have gotten to Broadway.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="know" lemma="know" stem="know" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="gotten" lemma="get" stem="gotten" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Broadway" lemma="Broadway" stem="broadwai" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP do) (RB n't) (VP (VB know) (SBAR (IN if) (S (NP (PRP it)) (VP (MD would) (VP (VB have) (VP (VBN gotten) (PP (TO to) (NP (NNP Broadway)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="do n't know if it would have gotten to Broadway" type="VP">
          <tokens>
            <token id="2" string="do" />
            <token id="3" string="n't" />
            <token id="4" string="know" />
            <token id="5" string="if" />
            <token id="6" string="it" />
            <token id="7" string="would" />
            <token id="8" string="have" />
            <token id="9" string="gotten" />
            <token id="10" string="to" />
            <token id="11" string="Broadway" />
          </tokens>
        </chunking>
        <chunking id="2" string="know if it would have gotten to Broadway" type="VP">
          <tokens>
            <token id="4" string="know" />
            <token id="5" string="if" />
            <token id="6" string="it" />
            <token id="7" string="would" />
            <token id="8" string="have" />
            <token id="9" string="gotten" />
            <token id="10" string="to" />
            <token id="11" string="Broadway" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="if it would have gotten to Broadway" type="SBAR">
          <tokens>
            <token id="5" string="if" />
            <token id="6" string="it" />
            <token id="7" string="would" />
            <token id="8" string="have" />
            <token id="9" string="gotten" />
            <token id="10" string="to" />
            <token id="11" string="Broadway" />
          </tokens>
        </chunking>
        <chunking id="5" string="gotten to Broadway" type="VP">
          <tokens>
            <token id="9" string="gotten" />
            <token id="10" string="to" />
            <token id="11" string="Broadway" />
          </tokens>
        </chunking>
        <chunking id="6" string="Broadway" type="NP">
          <tokens>
            <token id="11" string="Broadway" />
          </tokens>
        </chunking>
        <chunking id="7" string="have gotten to Broadway" type="VP">
          <tokens>
            <token id="8" string="have" />
            <token id="9" string="gotten" />
            <token id="10" string="to" />
            <token id="11" string="Broadway" />
          </tokens>
        </chunking>
        <chunking id="8" string="it" type="NP">
          <tokens>
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="would have gotten to Broadway" type="VP">
          <tokens>
            <token id="7" string="would" />
            <token id="8" string="have" />
            <token id="9" string="gotten" />
            <token id="10" string="to" />
            <token id="11" string="Broadway" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">know</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">know</governor>
          <dependent id="2">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">know</governor>
          <dependent id="3">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">know</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">gotten</governor>
          <dependent id="5">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">gotten</governor>
          <dependent id="6">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">gotten</governor>
          <dependent id="7">would</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">gotten</governor>
          <dependent id="8">have</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">know</governor>
          <dependent id="9">gotten</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Broadway</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">gotten</governor>
          <dependent id="11">Broadway</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Broadway" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="Broadway" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="60" has_coreference="true">
      <content>You aim for the stars, you know.</content>
      <tokens>
        <token id="1" string="You" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="aim" lemma="aim" stem="aim" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="stars" lemma="star" stem="star" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="know" lemma="know" stem="know" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP You)) (VP (VBP aim) (PP (IN for) (NP (DT the) (NNS stars))))) (, ,) (NP (PRP you)) (VP (VBP know)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="aim for the stars" type="VP">
          <tokens>
            <token id="2" string="aim" />
            <token id="3" string="for" />
            <token id="4" string="the" />
            <token id="5" string="stars" />
          </tokens>
        </chunking>
        <chunking id="2" string="the stars" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="stars" />
          </tokens>
        </chunking>
        <chunking id="3" string="know" type="VP">
          <tokens>
            <token id="8" string="know" />
          </tokens>
        </chunking>
        <chunking id="4" string="You" type="NP">
          <tokens>
            <token id="1" string="You" />
          </tokens>
        </chunking>
        <chunking id="5" string="you" type="NP">
          <tokens>
            <token id="7" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">aim</governor>
          <dependent id="1">You</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">know</governor>
          <dependent id="2">aim</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">stars</governor>
          <dependent id="3">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">stars</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">aim</governor>
          <dependent id="5">stars</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">know</governor>
          <dependent id="7">you</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">know</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="61" has_coreference="true">
      <content>The songs might be strung together.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="songs" lemma="song" stem="song" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="strung" lemma="string" stem="strung" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="together" lemma="together" stem="togeth" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNS songs)) (VP (MD might) (VP (VB be) (VP (VBN strung) (ADVP (RB together))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="strung together" type="VP">
          <tokens>
            <token id="5" string="strung" />
            <token id="6" string="together" />
          </tokens>
        </chunking>
        <chunking id="2" string="might be strung together" type="VP">
          <tokens>
            <token id="3" string="might" />
            <token id="4" string="be" />
            <token id="5" string="strung" />
            <token id="6" string="together" />
          </tokens>
        </chunking>
        <chunking id="3" string="The songs" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="songs" />
          </tokens>
        </chunking>
        <chunking id="4" string="be strung together" type="VP">
          <tokens>
            <token id="4" string="be" />
            <token id="5" string="strung" />
            <token id="6" string="together" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">songs</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">strung</governor>
          <dependent id="2">songs</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">strung</governor>
          <dependent id="3">might</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">strung</governor>
          <dependent id="4">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">strung</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">strung</governor>
          <dependent id="6">together</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="62" has_coreference="true">
      <content>They might become a record, might eventually become a musical.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="become" lemma="become" stem="becom" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="record" lemma="record" stem="record" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="eventually" lemma="eventually" stem="eventu" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="become" lemma="become" stem="becom" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="musical" lemma="musical" stem="music" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (MD might) (VP (VB become) (NP (NP (DT a) (NN record)) (, ,) (SBAR (S (VP (MD might) (ADVP (RB eventually)) (VP (VB become) (NP (DT a) (NN musical))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="a record" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="record" />
          </tokens>
        </chunking>
        <chunking id="3" string="become a record , might eventually become a musical" type="VP">
          <tokens>
            <token id="3" string="become" />
            <token id="4" string="a" />
            <token id="5" string="record" />
            <token id="6" string="," />
            <token id="7" string="might" />
            <token id="8" string="eventually" />
            <token id="9" string="become" />
            <token id="10" string="a" />
            <token id="11" string="musical" />
          </tokens>
        </chunking>
        <chunking id="4" string="might eventually become a musical" type="SBAR">
          <tokens>
            <token id="7" string="might" />
            <token id="8" string="eventually" />
            <token id="9" string="become" />
            <token id="10" string="a" />
            <token id="11" string="musical" />
          </tokens>
        </chunking>
        <chunking id="5" string="become a musical" type="VP">
          <tokens>
            <token id="9" string="become" />
            <token id="10" string="a" />
            <token id="11" string="musical" />
          </tokens>
        </chunking>
        <chunking id="6" string="a musical" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="musical" />
          </tokens>
        </chunking>
        <chunking id="7" string="a record , might eventually become a musical" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="record" />
            <token id="6" string="," />
            <token id="7" string="might" />
            <token id="8" string="eventually" />
            <token id="9" string="become" />
            <token id="10" string="a" />
            <token id="11" string="musical" />
          </tokens>
        </chunking>
        <chunking id="8" string="might become a record , might eventually become a musical" type="VP">
          <tokens>
            <token id="2" string="might" />
            <token id="3" string="become" />
            <token id="4" string="a" />
            <token id="5" string="record" />
            <token id="6" string="," />
            <token id="7" string="might" />
            <token id="8" string="eventually" />
            <token id="9" string="become" />
            <token id="10" string="a" />
            <token id="11" string="musical" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">become</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">become</governor>
          <dependent id="2">might</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">become</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">record</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">become</governor>
          <dependent id="5">record</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">become</governor>
          <dependent id="7">might</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">become</governor>
          <dependent id="8">eventually</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">record</governor>
          <dependent id="9">become</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">musical</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">become</governor>
          <dependent id="11">musical</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="63" has_coreference="false">
      <content>There are enough finished songs.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="enough" lemma="enough" stem="enough" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="finished" lemma="finish" stem="finish" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="songs" lemma="song" stem="song" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (ADJP (RB enough) (VBN finished)) (NNS songs))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="are enough finished songs" type="VP">
          <tokens>
            <token id="2" string="are" />
            <token id="3" string="enough" />
            <token id="4" string="finished" />
            <token id="5" string="songs" />
          </tokens>
        </chunking>
        <chunking id="2" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="3" string="enough finished songs" type="NP">
          <tokens>
            <token id="3" string="enough" />
            <token id="4" string="finished" />
            <token id="5" string="songs" />
          </tokens>
        </chunking>
        <chunking id="4" string="enough finished" type="ADJP">
          <tokens>
            <token id="3" string="enough" />
            <token id="4" string="finished" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="2">are</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">finished</governor>
          <dependent id="3">enough</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">songs</governor>
          <dependent id="4">finished</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="2">are</governor>
          <dependent id="5">songs</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="64" has_coreference="false">
      <content>They were never recorded in the studio.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="recorded" lemma="record" stem="record" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="studio" lemma="studio" stem="studio" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBD were) (ADVP (RB never)) (VP (VBN recorded) (PP (IN in) (NP (DT the) (NN studio))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="recorded in the studio" type="VP">
          <tokens>
            <token id="4" string="recorded" />
            <token id="5" string="in" />
            <token id="6" string="the" />
            <token id="7" string="studio" />
          </tokens>
        </chunking>
        <chunking id="3" string="were never recorded in the studio" type="VP">
          <tokens>
            <token id="2" string="were" />
            <token id="3" string="never" />
            <token id="4" string="recorded" />
            <token id="5" string="in" />
            <token id="6" string="the" />
            <token id="7" string="studio" />
          </tokens>
        </chunking>
        <chunking id="4" string="the studio" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="studio" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="4">recorded</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">recorded</governor>
          <dependent id="2">were</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">recorded</governor>
          <dependent id="3">never</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">recorded</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">studio</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">studio</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">recorded</governor>
          <dependent id="7">studio</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="65" has_coreference="false">
      <content>They&amp;apost;re on cassettes.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="cassettes" lemma="cassette" stem="cassett" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBP 're) (PP (IN on) (NP (NNS cassettes)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="'re on cassettes" type="VP">
          <tokens>
            <token id="2" string="'re" />
            <token id="3" string="on" />
            <token id="4" string="cassettes" />
          </tokens>
        </chunking>
        <chunking id="3" string="cassettes" type="NP">
          <tokens>
            <token id="4" string="cassettes" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">cassettes</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">cassettes</governor>
          <dependent id="2">'re</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">cassettes</governor>
          <dependent id="3">on</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">cassettes</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="66" has_coreference="true">
      <content>Their son Sean, 13, like his older half-brother, Julian, has become interested in music and started playing guitar.</content>
      <tokens>
        <token id="1" string="Their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="son" lemma="son" stem="son" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Sean" lemma="Sean" stem="sean" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="13" lemma="13" stem="13" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="older" lemma="older" stem="older" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="half-brother" lemma="half-brother" stem="half-broth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Julian" lemma="Julian" stem="julian" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="become" lemma="become" stem="becom" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="interested" lemma="interested" stem="interest" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="music" lemma="music" stem="music" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="started" lemma="start" stem="start" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="playing" lemma="play" stem="plai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="guitar" lemma="guitar" stem="guitar" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (PRP$ Their) (NN son) (NNP Sean)) (, ,) (NP (CD 13)) (, ,)) (PP (IN like) (NP (NP (PRP$ his) (JJR older) (NN half-brother)) (, ,) (NP (NNP Julian)) (, ,)))) (VP (VP (VBZ has) (VP (VBN become) (ADJP (JJ interested)) (PP (IN in) (NP (NN music))))) (CC and) (VP (VBD started) (S (VP (VBG playing) (NP (NN guitar)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="13" type="NP">
          <tokens>
            <token id="5" string="13" />
          </tokens>
        </chunking>
        <chunking id="2" string="has become interested in music" type="VP">
          <tokens>
            <token id="14" string="has" />
            <token id="15" string="become" />
            <token id="16" string="interested" />
            <token id="17" string="in" />
            <token id="18" string="music" />
          </tokens>
        </chunking>
        <chunking id="3" string="started playing guitar" type="VP">
          <tokens>
            <token id="20" string="started" />
            <token id="21" string="playing" />
            <token id="22" string="guitar" />
          </tokens>
        </chunking>
        <chunking id="4" string="his older half-brother , Julian ," type="NP">
          <tokens>
            <token id="8" string="his" />
            <token id="9" string="older" />
            <token id="10" string="half-brother" />
            <token id="11" string="," />
            <token id="12" string="Julian" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="guitar" type="NP">
          <tokens>
            <token id="22" string="guitar" />
          </tokens>
        </chunking>
        <chunking id="6" string="Their son Sean , 13 ," type="NP">
          <tokens>
            <token id="1" string="Their" />
            <token id="2" string="son" />
            <token id="3" string="Sean" />
            <token id="4" string="," />
            <token id="5" string="13" />
            <token id="6" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="his older half-brother" type="NP">
          <tokens>
            <token id="8" string="his" />
            <token id="9" string="older" />
            <token id="10" string="half-brother" />
          </tokens>
        </chunking>
        <chunking id="8" string="Their son Sean , 13 , like his older half-brother , Julian ," type="NP">
          <tokens>
            <token id="1" string="Their" />
            <token id="2" string="son" />
            <token id="3" string="Sean" />
            <token id="4" string="," />
            <token id="5" string="13" />
            <token id="6" string="," />
            <token id="7" string="like" />
            <token id="8" string="his" />
            <token id="9" string="older" />
            <token id="10" string="half-brother" />
            <token id="11" string="," />
            <token id="12" string="Julian" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="9" string="Their son Sean" type="NP">
          <tokens>
            <token id="1" string="Their" />
            <token id="2" string="son" />
            <token id="3" string="Sean" />
          </tokens>
        </chunking>
        <chunking id="10" string="music" type="NP">
          <tokens>
            <token id="18" string="music" />
          </tokens>
        </chunking>
        <chunking id="11" string="interested" type="ADJP">
          <tokens>
            <token id="16" string="interested" />
          </tokens>
        </chunking>
        <chunking id="12" string="has become interested in music and started playing guitar" type="VP">
          <tokens>
            <token id="14" string="has" />
            <token id="15" string="become" />
            <token id="16" string="interested" />
            <token id="17" string="in" />
            <token id="18" string="music" />
            <token id="19" string="and" />
            <token id="20" string="started" />
            <token id="21" string="playing" />
            <token id="22" string="guitar" />
          </tokens>
        </chunking>
        <chunking id="13" string="become interested in music" type="VP">
          <tokens>
            <token id="15" string="become" />
            <token id="16" string="interested" />
            <token id="17" string="in" />
            <token id="18" string="music" />
          </tokens>
        </chunking>
        <chunking id="14" string="Julian" type="NP">
          <tokens>
            <token id="12" string="Julian" />
          </tokens>
        </chunking>
        <chunking id="15" string="playing guitar" type="VP">
          <tokens>
            <token id="21" string="playing" />
            <token id="22" string="guitar" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">Sean</governor>
          <dependent id="1">Their</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Sean</governor>
          <dependent id="2">son</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">become</governor>
          <dependent id="3">Sean</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">Sean</governor>
          <dependent id="5">13</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">half-brother</governor>
          <dependent id="7">like</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">half-brother</governor>
          <dependent id="8">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">half-brother</governor>
          <dependent id="9">older</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">Sean</governor>
          <dependent id="10">half-brother</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="10">half-brother</governor>
          <dependent id="12">Julian</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">become</governor>
          <dependent id="14">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">become</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">become</governor>
          <dependent id="16">interested</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">music</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">become</governor>
          <dependent id="18">music</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">become</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">become</governor>
          <dependent id="20">started</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="20">started</governor>
          <dependent id="21">playing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">playing</governor>
          <dependent id="22">guitar</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="13" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="13" />
          </tokens>
        </entity>
        <entity id="2" string="Sean" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Sean" />
          </tokens>
        </entity>
        <entity id="3" string="Julian" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Julian" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="67" has_coreference="true">
      <content>``I had reservations about Sean going into the music field.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="reservations" lemma="reservation" stem="reserv" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Sean" lemma="Sean" stem="sean" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="music" lemma="music" stem="music" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="field" lemma="field" stem="field" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBD had) (NP (NP (NNS reservations)) (PP (IN about) (NP (NP (NNP Sean)) (VP (VBG going) (PP (IN into) (NP (DT the) (NN music) (NN field)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="reservations about Sean going into the music field" type="NP">
          <tokens>
            <token id="4" string="reservations" />
            <token id="5" string="about" />
            <token id="6" string="Sean" />
            <token id="7" string="going" />
            <token id="8" string="into" />
            <token id="9" string="the" />
            <token id="10" string="music" />
            <token id="11" string="field" />
          </tokens>
        </chunking>
        <chunking id="2" string="reservations" type="NP">
          <tokens>
            <token id="4" string="reservations" />
          </tokens>
        </chunking>
        <chunking id="3" string="Sean going into the music field" type="NP">
          <tokens>
            <token id="6" string="Sean" />
            <token id="7" string="going" />
            <token id="8" string="into" />
            <token id="9" string="the" />
            <token id="10" string="music" />
            <token id="11" string="field" />
          </tokens>
        </chunking>
        <chunking id="4" string="the music field" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="music" />
            <token id="11" string="field" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="Sean" type="NP">
          <tokens>
            <token id="6" string="Sean" />
          </tokens>
        </chunking>
        <chunking id="7" string="going into the music field" type="VP">
          <tokens>
            <token id="7" string="going" />
            <token id="8" string="into" />
            <token id="9" string="the" />
            <token id="10" string="music" />
            <token id="11" string="field" />
          </tokens>
        </chunking>
        <chunking id="8" string="had reservations about Sean going into the music field" type="VP">
          <tokens>
            <token id="3" string="had" />
            <token id="4" string="reservations" />
            <token id="5" string="about" />
            <token id="6" string="Sean" />
            <token id="7" string="going" />
            <token id="8" string="into" />
            <token id="9" string="the" />
            <token id="10" string="music" />
            <token id="11" string="field" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">had</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">had</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">had</governor>
          <dependent id="4">reservations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Sean</governor>
          <dependent id="5">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">reservations</governor>
          <dependent id="6">Sean</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="6">Sean</governor>
          <dependent id="7">going</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">field</governor>
          <dependent id="8">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">field</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">field</governor>
          <dependent id="10">music</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">going</governor>
          <dependent id="11">field</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Sean" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Sean" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="68" has_coreference="true">
      <content>I still do.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (ADVP (RB still)) (VP (VBP do)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="2" string="do" type="VP">
          <tokens>
            <token id="3" string="do" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">do</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">do</governor>
          <dependent id="2">still</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">do</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="69" has_coreference="true">
      <content>But I kind of gave up on it,&amp;apost;&amp;apost; Ono said.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="kind" lemma="kind" stem="kind" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="gave" lemma="give" stem="gave" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (S (NP (PRP I)) (ADVP (NN kind) (IN of)) (VP (VBD gave) (PRT (RP up)) (PP (IN on) (NP (PRP it))))) (, ,) ('' '') (NP (NNP Ono)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="2" string="it" type="NP">
          <tokens>
            <token id="8" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="gave up on it" type="VP">
          <tokens>
            <token id="5" string="gave" />
            <token id="6" string="up" />
            <token id="7" string="on" />
            <token id="8" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="said" type="VP">
          <tokens>
            <token id="12" string="said" />
          </tokens>
        </chunking>
        <chunking id="5" string="Ono" type="NP">
          <tokens>
            <token id="11" string="Ono" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="12">said</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">gave</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">gave</governor>
          <dependent id="3">kind</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="3">kind</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">said</governor>
          <dependent id="5">gave</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="5">gave</governor>
          <dependent id="6">up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">it</governor>
          <dependent id="7">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">gave</governor>
          <dependent id="8">it</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">said</governor>
          <dependent id="11">Ono</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="70" has_coreference="true">
      <content>``He is into guitar now.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="guitar" lemma="guitar" stem="guitar" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP He)) (VP (VBZ is) (PP (IN into) (NP (NN guitar))) (ADVP (RB now))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="He" type="NP">
          <tokens>
            <token id="2" string="He" />
          </tokens>
        </chunking>
        <chunking id="2" string="is into guitar now" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="into" />
            <token id="5" string="guitar" />
            <token id="6" string="now" />
          </tokens>
        </chunking>
        <chunking id="3" string="guitar" type="NP">
          <tokens>
            <token id="5" string="guitar" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">guitar</governor>
          <dependent id="2">He</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">guitar</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">guitar</governor>
          <dependent id="4">into</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">guitar</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">guitar</governor>
          <dependent id="6">now</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="71" has_coreference="true">
      <content>A session musician, a very good one, was teaching him.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="session" lemma="session" stem="session" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="musician" lemma="musician" stem="musician" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="teaching" lemma="teach" stem="teach" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT A) (NN session) (NN musician)) (, ,) (NP (DT a) (ADJP (RB very) (JJ good)) (CD one)) (, ,)) (VP (VBD was) (VP (VBG teaching) (NP (PRP him)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="A session musician , a very good one ," type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="session" />
            <token id="3" string="musician" />
            <token id="4" string="," />
            <token id="5" string="a" />
            <token id="6" string="very" />
            <token id="7" string="good" />
            <token id="8" string="one" />
            <token id="9" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="very good" type="ADJP">
          <tokens>
            <token id="6" string="very" />
            <token id="7" string="good" />
          </tokens>
        </chunking>
        <chunking id="3" string="A session musician" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="session" />
            <token id="3" string="musician" />
          </tokens>
        </chunking>
        <chunking id="4" string="teaching him" type="VP">
          <tokens>
            <token id="11" string="teaching" />
            <token id="12" string="him" />
          </tokens>
        </chunking>
        <chunking id="5" string="a very good one" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="very" />
            <token id="7" string="good" />
            <token id="8" string="one" />
          </tokens>
        </chunking>
        <chunking id="6" string="him" type="NP">
          <tokens>
            <token id="12" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="was teaching him" type="VP">
          <tokens>
            <token id="10" string="was" />
            <token id="11" string="teaching" />
            <token id="12" string="him" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">musician</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">musician</governor>
          <dependent id="2">session</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">teaching</governor>
          <dependent id="3">musician</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">one</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">good</governor>
          <dependent id="6">very</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">one</governor>
          <dependent id="7">good</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">musician</governor>
          <dependent id="8">one</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">teaching</governor>
          <dependent id="10">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">teaching</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">teaching</governor>
          <dependent id="12">him</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="72" has_coreference="true">
      <content>According to this teacher, it seems like he is very good.</content>
      <tokens>
        <token id="1" string="According" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="teacher" lemma="teacher" stem="teacher" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="seems" lemma="seem" stem="seem" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (VBG According) (PP (TO to) (NP (DT this) (NN teacher)))) (, ,) (NP (PRP it)) (VP (VBZ seems) (SBAR (IN like) (S (NP (PRP he)) (VP (VBZ is) (ADJP (RB very) (JJ good)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="very good" type="ADJP">
          <tokens>
            <token id="11" string="very" />
            <token id="12" string="good" />
          </tokens>
        </chunking>
        <chunking id="2" string="seems like he is very good" type="VP">
          <tokens>
            <token id="7" string="seems" />
            <token id="8" string="like" />
            <token id="9" string="he" />
            <token id="10" string="is" />
            <token id="11" string="very" />
            <token id="12" string="good" />
          </tokens>
        </chunking>
        <chunking id="3" string="this teacher" type="NP">
          <tokens>
            <token id="3" string="this" />
            <token id="4" string="teacher" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="he" type="NP">
          <tokens>
            <token id="9" string="he" />
          </tokens>
        </chunking>
        <chunking id="6" string="is very good" type="VP">
          <tokens>
            <token id="10" string="is" />
            <token id="11" string="very" />
            <token id="12" string="good" />
          </tokens>
        </chunking>
        <chunking id="7" string="like he is very good" type="SBAR">
          <tokens>
            <token id="8" string="like" />
            <token id="9" string="he" />
            <token id="10" string="is" />
            <token id="11" string="very" />
            <token id="12" string="good" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">teacher</governor>
          <dependent id="1">According</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">According</governor>
          <dependent id="2">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">teacher</governor>
          <dependent id="3">this</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">seems</governor>
          <dependent id="4">teacher</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">seems</governor>
          <dependent id="6">it</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">seems</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">good</governor>
          <dependent id="8">like</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">good</governor>
          <dependent id="9">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">good</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">good</governor>
          <dependent id="11">very</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">seems</governor>
          <dependent id="12">good</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="73" has_coreference="true">
      <content>He is just totally involved in it, listening to Eric Clapton, Jimi Hendrix, his dad&amp;apost;s songs _ only for guitar playing, I think.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="totally" lemma="totally" stem="total" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="involved" lemma="involve" stem="involv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="listening" lemma="listen" stem="listen" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Eric" lemma="Eric" stem="eric" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string="Clapton" lemma="Clapton" stem="clapton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Jimi" lemma="Jimi" stem="jimi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="15" string="Hendrix" lemma="Hendrix" stem="hendrix" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="dad" lemma="dad" stem="dad" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="songs" lemma="song" stem="song" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="_" lemma="_" stem="_" pos="VBP" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="guitar" lemma="guitar" stem="guitar" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="playing" lemma="playing" stem="plai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP He)) (VP (VBZ is) (ADVP (RB just)) (ADJP (RB totally) (VBN involved) (PP (IN in) (S (S (NP (PRP it))) (, ,) (S (VP (VBG listening) (PP (TO to) (NP (NP (NNP Eric) (NNP Clapton)) (, ,) (NP (NNP Jimi) (NNP Hendrix)))))) (, ,) (S (NP (NP (PRP$ his) (NN dad) (POS 's)) (NNS songs)) (VP (VBP _) (ADVP (RB only)) (PP (IN for) (NP (NN guitar) (NN playing)))))))))) (, ,) (NP (PRP I)) (VP (VBP think)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is just totally involved in it , listening to Eric Clapton , Jimi Hendrix , his dad 's songs _ only for guitar playing" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="just" />
            <token id="4" string="totally" />
            <token id="5" string="involved" />
            <token id="6" string="in" />
            <token id="7" string="it" />
            <token id="8" string="," />
            <token id="9" string="listening" />
            <token id="10" string="to" />
            <token id="11" string="Eric" />
            <token id="12" string="Clapton" />
            <token id="13" string="," />
            <token id="14" string="Jimi" />
            <token id="15" string="Hendrix" />
            <token id="16" string="," />
            <token id="17" string="his" />
            <token id="18" string="dad" />
            <token id="19" string="'s" />
            <token id="20" string="songs" />
            <token id="21" string="_" />
            <token id="22" string="only" />
            <token id="23" string="for" />
            <token id="24" string="guitar" />
            <token id="25" string="playing" />
          </tokens>
        </chunking>
        <chunking id="2" string="listening to Eric Clapton , Jimi Hendrix" type="VP">
          <tokens>
            <token id="9" string="listening" />
            <token id="10" string="to" />
            <token id="11" string="Eric" />
            <token id="12" string="Clapton" />
            <token id="13" string="," />
            <token id="14" string="Jimi" />
            <token id="15" string="Hendrix" />
          </tokens>
        </chunking>
        <chunking id="3" string="Eric Clapton , Jimi Hendrix" type="NP">
          <tokens>
            <token id="11" string="Eric" />
            <token id="12" string="Clapton" />
            <token id="13" string="," />
            <token id="14" string="Jimi" />
            <token id="15" string="Hendrix" />
          </tokens>
        </chunking>
        <chunking id="4" string="think" type="VP">
          <tokens>
            <token id="28" string="think" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="27" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="Eric Clapton" type="NP">
          <tokens>
            <token id="11" string="Eric" />
            <token id="12" string="Clapton" />
          </tokens>
        </chunking>
        <chunking id="8" string="his dad 's" type="NP">
          <tokens>
            <token id="17" string="his" />
            <token id="18" string="dad" />
            <token id="19" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="totally involved in it , listening to Eric Clapton , Jimi Hendrix , his dad 's songs _ only for guitar playing" type="ADJP">
          <tokens>
            <token id="4" string="totally" />
            <token id="5" string="involved" />
            <token id="6" string="in" />
            <token id="7" string="it" />
            <token id="8" string="," />
            <token id="9" string="listening" />
            <token id="10" string="to" />
            <token id="11" string="Eric" />
            <token id="12" string="Clapton" />
            <token id="13" string="," />
            <token id="14" string="Jimi" />
            <token id="15" string="Hendrix" />
            <token id="16" string="," />
            <token id="17" string="his" />
            <token id="18" string="dad" />
            <token id="19" string="'s" />
            <token id="20" string="songs" />
            <token id="21" string="_" />
            <token id="22" string="only" />
            <token id="23" string="for" />
            <token id="24" string="guitar" />
            <token id="25" string="playing" />
          </tokens>
        </chunking>
        <chunking id="10" string="Jimi Hendrix" type="NP">
          <tokens>
            <token id="14" string="Jimi" />
            <token id="15" string="Hendrix" />
          </tokens>
        </chunking>
        <chunking id="11" string="_ only for guitar playing" type="VP">
          <tokens>
            <token id="21" string="_" />
            <token id="22" string="only" />
            <token id="23" string="for" />
            <token id="24" string="guitar" />
            <token id="25" string="playing" />
          </tokens>
        </chunking>
        <chunking id="12" string="guitar playing" type="NP">
          <tokens>
            <token id="24" string="guitar" />
            <token id="25" string="playing" />
          </tokens>
        </chunking>
        <chunking id="13" string="his dad 's songs" type="NP">
          <tokens>
            <token id="17" string="his" />
            <token id="18" string="dad" />
            <token id="19" string="'s" />
            <token id="20" string="songs" />
          </tokens>
        </chunking>
        <chunking id="14" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="5">involved</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">involved</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">involved</governor>
          <dependent id="3">just</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">involved</governor>
          <dependent id="4">totally</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="28">think</governor>
          <dependent id="5">involved</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">it</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">involved</governor>
          <dependent id="7">it</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="7">it</governor>
          <dependent id="9">listening</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Clapton</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Clapton</governor>
          <dependent id="11">Eric</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">listening</governor>
          <dependent id="12">Clapton</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Hendrix</governor>
          <dependent id="14">Jimi</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="12">Clapton</governor>
          <dependent id="15">Hendrix</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">dad</governor>
          <dependent id="17">his</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="20">songs</governor>
          <dependent id="18">dad</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">dad</governor>
          <dependent id="19">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">_</governor>
          <dependent id="20">songs</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="7">it</governor>
          <dependent id="21">_</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">_</governor>
          <dependent id="22">only</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">playing</governor>
          <dependent id="23">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">playing</governor>
          <dependent id="24">guitar</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">_</governor>
          <dependent id="25">playing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">think</governor>
          <dependent id="27">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="28">think</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jimi Hendrix" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Jimi" />
            <token id="15" string="Hendrix" />
          </tokens>
        </entity>
        <entity id="2" string="Eric Clapton" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Eric" />
            <token id="12" string="Clapton" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="74" has_coreference="true">
      <content>``He is into it so much, good luck to him.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="much" lemma="much" stem="much" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="luck" lemma="luck" stem="luck" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP He)) (VP (VBZ is) (PP (IN into) (NP (PRP it))) (NP (NP (RB so) (RB much)) (, ,) (NP (NP (JJ good) (NN luck)) (PP (TO to) (NP (PRP him)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="good luck to him" type="NP">
          <tokens>
            <token id="9" string="good" />
            <token id="10" string="luck" />
            <token id="11" string="to" />
            <token id="12" string="him" />
          </tokens>
        </chunking>
        <chunking id="2" string="is into it so much , good luck to him" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="into" />
            <token id="5" string="it" />
            <token id="6" string="so" />
            <token id="7" string="much" />
            <token id="8" string="," />
            <token id="9" string="good" />
            <token id="10" string="luck" />
            <token id="11" string="to" />
            <token id="12" string="him" />
          </tokens>
        </chunking>
        <chunking id="3" string="it" type="NP">
          <tokens>
            <token id="5" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="good luck" type="NP">
          <tokens>
            <token id="9" string="good" />
            <token id="10" string="luck" />
          </tokens>
        </chunking>
        <chunking id="5" string="him" type="NP">
          <tokens>
            <token id="12" string="him" />
          </tokens>
        </chunking>
        <chunking id="6" string="He" type="NP">
          <tokens>
            <token id="2" string="He" />
          </tokens>
        </chunking>
        <chunking id="7" string="so much" type="NP">
          <tokens>
            <token id="6" string="so" />
            <token id="7" string="much" />
          </tokens>
        </chunking>
        <chunking id="8" string="so much , good luck to him" type="NP">
          <tokens>
            <token id="6" string="so" />
            <token id="7" string="much" />
            <token id="8" string="," />
            <token id="9" string="good" />
            <token id="10" string="luck" />
            <token id="11" string="to" />
            <token id="12" string="him" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">much</governor>
          <dependent id="2">He</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">much</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">it</governor>
          <dependent id="4">into</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">much</governor>
          <dependent id="5">it</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">much</governor>
          <dependent id="6">so</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">much</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">luck</governor>
          <dependent id="9">good</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="7">much</governor>
          <dependent id="10">luck</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">him</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">luck</governor>
          <dependent id="12">him</dependent>
        </dependency>
      </dependencies>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PRONOMINAL">
      <referenced ids_tokens="2" string="I" id_sentence="1" />
      <mentions>
        <mention ids_tokens="11" string="you" id_sentence="26" />
      </mentions>
    </coreference>
    <coreference id="4" type="PROPER">
      <referenced ids_tokens="1-2-3-4" string="_ John Lennon ." id_sentence="5" />
      <mentions>
        <mention ids_tokens="9-10" string="John Lennon" id_sentence="6" />
        <mention ids_tokens="2" string="I" id_sentence="11" />
        <mention ids_tokens="11-13" string="John Lennon's" id_sentence="11" />
        <mention ids_tokens="3" string="John" id_sentence="12" />
        <mention ids_tokens="2" string="I" id_sentence="13" />
        <mention ids_tokens="1" string="I" id_sentence="14" />
        <mention ids_tokens="2" string="I" id_sentence="15" />
        <mention ids_tokens="1" string="I" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="5" type="NOMINAL">
      <referenced ids_tokens="2-3-4-5-6-7-8-9-10" string="the new movie , `` Imagine : John Lennon" id_sentence="6" />
      <mentions>
        <mention ids_tokens="6" string="I" id_sentence="7" />
        <mention ids_tokens="15" string="I" id_sentence="7" />
        <mention ids_tokens="26" string="it" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="2-3-4" string="the new movie" id_sentence="6" />
      <mentions>
        <mention ids_tokens="9" string="it" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="7" type="PROPER">
      <referenced ids_tokens="23-24" string="Yoko Ono" id_sentence="6" />
      <mentions>
        <mention ids_tokens="15" string="Ono" id_sentence="8" />
        <mention ids_tokens="1" string="She" id_sentence="9" />
        <mention ids_tokens="17" string="Ono" id_sentence="11" />
        <mention ids_tokens="7" string="Ono" id_sentence="23" />
        <mention ids_tokens="1" string="Ono" id_sentence="33" />
        <mention ids_tokens="1" string="Ono" id_sentence="40" />
        <mention ids_tokens="3-8" string="a painter when Lennon met her" id_sentence="40" />
        <mention ids_tokens="8" string="her" id_sentence="40" />
        <mention ids_tokens="1" string="She" id_sentence="41" />
        <mention ids_tokens="30" string="Ono" id_sentence="47" />
        <mention ids_tokens="8" string="Ono" id_sentence="52" />
        <mention ids_tokens="7" string="Ono" id_sentence="56" />
        <mention ids_tokens="10" string="her" id_sentence="57" />
        <mention ids_tokens="11" string="Ono" id_sentence="69" />
        <mention ids_tokens="2" string="He" id_sentence="70" />
      </mentions>
    </coreference>
    <coreference id="11" type="PROPER">
      <referenced ids_tokens="9-10" string="John Lennon" id_sentence="47" />
      <mentions>
        <mention ids_tokens="8-21" string="Lennon , which were edited in such a way that he narrates the picture" id_sentence="9" />
        <mention ids_tokens="8" string="Lennon" id_sentence="9" />
        <mention ids_tokens="18" string="he" id_sentence="9" />
        <mention ids_tokens="14-20" string="Lennon , tied in with the film" id_sentence="18" />
        <mention ids_tokens="14" string="Lennon" id_sentence="18" />
        <mention ids_tokens="10" string="Lennon" id_sentence="20" />
        <mention ids_tokens="13" string="Lennon" id_sentence="21" />
        <mention ids_tokens="41" string="Lennon" id_sentence="21" />
        <mention ids_tokens="3" string="Lennon" id_sentence="33" />
        <mention ids_tokens="1" string="Lennon" id_sentence="38" />
        <mention ids_tokens="1" string="He" id_sentence="39" />
        <mention ids_tokens="7" string="his" id_sentence="39" />
        <mention ids_tokens="6" string="Lennon" id_sentence="40" />
        <mention ids_tokens="4" string="him" id_sentence="41" />
        <mention ids_tokens="1-2" string="Lennon's" id_sentence="53" />
        <mention ids_tokens="12" string="Lennon" id_sentence="54" />
        <mention ids_tokens="1" string="I" id_sentence="59" />
      </mentions>
    </coreference>
    <coreference id="13" type="NOMINAL">
      <referenced ids_tokens="7-8-9-10-11-12-13-14" string="the definitive documentary of John Lennon 's life" id_sentence="11" />
      <mentions>
        <mention ids_tokens="5" string="This" id_sentence="10" />
        <mention ids_tokens="24" string="it" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="14" type="NOMINAL">
      <referenced ids_tokens="10-11" string="this film" id_sentence="12" />
      <mentions>
        <mention ids_tokens="5" string="it" id_sentence="13" />
        <mention ids_tokens="19-20" string="the film" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="15" type="PRONOMINAL">
      <referenced ids_tokens="5" string="them" id_sentence="14" />
      <mentions>
        <mention ids_tokens="3" string="they" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="16" type="NOMINAL">
      <referenced ids_tokens="8-9-10" string="a 40-year life" id_sentence="16" />
      <mentions>
        <mention ids_tokens="4-5" string="the life" id_sentence="55" />
      </mentions>
    </coreference>
    <coreference id="17" type="NOMINAL">
      <referenced ids_tokens="3-4-5" string="a soundtrack album" id_sentence="18" />
      <mentions>
        <mention ids_tokens="8" string="It" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="18" type="PRONOMINAL">
      <referenced ids_tokens="12" string="you" id_sentence="19" />
      <mentions>
        <mention ids_tokens="24" string="their" id_sentence="22" />
        <mention ids_tokens="28" string="they" id_sentence="22" />
        <mention ids_tokens="37" string="their" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="19" type="NOMINAL">
      <referenced ids_tokens="9-10-11" string="a Lennon elegy" id_sentence="20" />
      <mentions>
        <mention ids_tokens="2" string="it" id_sentence="21" />
        <mention ids_tokens="31" string="it" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="20" type="PROPER">
      <referenced ids_tokens="9-10-11-12-13-14-15-16-17" string="cartoonist Al Capp ( `` L'il Abner '' )" id_sentence="22" />
      <mentions>
        <mention ids_tokens="4-5" string="Al Capp" id_sentence="26" />
        <mention ids_tokens="8-9" string="a cartoonist" id_sentence="26" />
        <mention ids_tokens="14-15" string="a cartoonist" id_sentence="26" />
        <mention ids_tokens="2-3" string="Al Capp" id_sentence="28" />
      </mentions>
    </coreference>
    <coreference id="21" type="PRONOMINAL">
      <referenced ids_tokens="2" string="We" id_sentence="23" />
      <mentions>
        <mention ids_tokens="4" string="our" id_sentence="25" />
        <mention ids_tokens="2" string="us" id_sentence="26" />
        <mention ids_tokens="10" string="our" id_sentence="29" />
        <mention ids_tokens="7" string="us" id_sentence="31" />
        <mention ids_tokens="1" string="I" id_sentence="36" />
        <mention ids_tokens="41" string="i" id_sentence="37" />
        <mention ids_tokens="60" string="us" id_sentence="37" />
      </mentions>
    </coreference>
    <coreference id="22" type="NOMINAL">
      <referenced ids_tokens="2-3-4-5" string="A lot of things" id_sentence="24" />
      <mentions>
        <mention ids_tokens="2" string="that" id_sentence="25" />
        <mention ids_tokens="4-5" string="our strength" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="25" type="NOMINAL">
      <referenced ids_tokens="10-11-12-13" string="reporters in those days" id_sentence="31" />
      <mentions>
        <mention ids_tokens="2" string="We" id_sentence="34" />
        <mention ids_tokens="4" string="we" id_sentence="35" />
      </mentions>
    </coreference>
    <coreference id="26" type="NOMINAL">
      <referenced ids_tokens="1-2" string="Each time" id_sentence="32" />
      <mentions>
        <mention ids_tokens="18-19" string="this time" id_sentence="49" />
      </mentions>
    </coreference>
    <coreference id="27" type="NOMINAL">
      <referenced ids_tokens="4-5-6-7-8-9-10-11-12-13-14-15-16-17-18" string="the bed-in , the Toronto Peace Festival , the ` War 's Over ' billboard" id_sentence="34" />
      <mentions>
        <mention ids_tokens="1" string="He" id_sentence="35" />
      </mentions>
    </coreference>
    <coreference id="29" type="NOMINAL">
      <referenced ids_tokens="6-7-8-9-10-11-12-13-14" string="an anthem for this whole concept of world peace" id_sentence="35" />
      <mentions>
        <mention ids_tokens="3" string="it" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="30" type="NOMINAL">
      <referenced ids_tokens="16-17" string="people 's" id_sentence="36" />
      <mentions>
        <mention ids_tokens="9" string="people" id_sentence="49" />
      </mentions>
    </coreference>
    <coreference id="32" type="NOMINAL">
      <referenced ids_tokens="26-27-28-29-30-31" string="a very strange turn of events" id_sentence="42" />
      <mentions>
        <mention ids_tokens="7-14" string="his Manhattan apartment on Dec. 8 , 1980" id_sentence="39" />
        <mention ids_tokens="15" string="it" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="33" type="NOMINAL">
      <referenced ids_tokens="16-17" string="an artist" id_sentence="42" />
      <mentions>
        <mention ids_tokens="7" string="me" id_sentence="43" />
        <mention ids_tokens="9" string="I" id_sentence="43" />
        <mention ids_tokens="1" string="I" id_sentence="44" />
        <mention ids_tokens="6" string="my" id_sentence="44" />
        <mention ids_tokens="23" string="me" id_sentence="44" />
        <mention ids_tokens="2" string="I" id_sentence="45" />
        <mention ids_tokens="6" string="my" id_sentence="45" />
        <mention ids_tokens="3" string="me" id_sentence="46" />
      </mentions>
    </coreference>
    <coreference id="35" type="PROPER">
      <referenced ids_tokens="4" string="John" id_sentence="44" />
      <mentions>
        <mention ids_tokens="10" string="him" id_sentence="45" />
        <mention ids_tokens="1" string="He" id_sentence="46" />
      </mentions>
    </coreference>
    <coreference id="37" type="PROPER">
      <referenced ids_tokens="2-3-4" string="Albert Goldman 's" id_sentence="47" />
      <mentions>
        <mention ids_tokens="15" string="Goldman" id_sentence="51" />
      </mentions>
    </coreference>
    <coreference id="40" type="NOMINAL">
      <referenced ids_tokens="6-7-8-9-10" string="a tremendous amount of support" id_sentence="48" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="49" />
        <mention ids_tokens="13" string="me" id_sentence="49" />
        <mention ids_tokens="1" string="I" id_sentence="50" />
        <mention ids_tokens="1" string="I" id_sentence="51" />
        <mention ids_tokens="12-17" string="it ( the Goldman book )" id_sentence="51" />
        <mention ids_tokens="1" string="I" id_sentence="52" />
      </mentions>
    </coreference>
    <coreference id="41" type="NOMINAL">
      <referenced ids_tokens="6-7-8" string="so many people" id_sentence="51" />
      <mentions>
        <mention ids_tokens="5" string="that" id_sentence="52" />
        <mention ids_tokens="20" string="them" id_sentence="54" />
      </mentions>
    </coreference>
    <coreference id="42" type="PROPER">
      <referenced ids_tokens="6-7" string="Julia Baird" id_sentence="53" />
      <mentions>
        <mention ids_tokens="1" string="She" id_sentence="54" />
        <mention ids_tokens="14" string="she" id_sentence="54" />
      </mentions>
    </coreference>
    <coreference id="43" type="PROPER">
      <referenced ids_tokens="17-18-19-20-21" string="John Lennon , My Brother" id_sentence="53" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="55" />
        <mention ids_tokens="1" string="You" id_sentence="60" />
        <mention ids_tokens="7" string="you" id_sentence="60" />
      </mentions>
    </coreference>
    <coreference id="45" type="NOMINAL">
      <referenced ids_tokens="4-5-6-7-8-9-10-11" string="another big John Lennon project on her horizon" id_sentence="57" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="58" />
        <mention ids_tokens="6" string="it" id_sentence="59" />
      </mentions>
    </coreference>
    <coreference id="47" type="NOMINAL">
      <referenced ids_tokens="5-6-7-8-9-10-11-12-13" string="unpublished songs which were written for a Broadway musical" id_sentence="58" />
      <mentions>
        <mention ids_tokens="1-2" string="The songs" id_sentence="61" />
      </mentions>
    </coreference>
    <coreference id="48" type="PRONOMINAL">
      <referenced ids_tokens="1" string="They" id_sentence="62" />
      <mentions>
        <mention ids_tokens="1" string="Their" id_sentence="66" />
      </mentions>
    </coreference>
    <coreference id="50" type="PROPER">
      <referenced ids_tokens="5" string="13" id_sentence="66" />
      <mentions>
        <mention ids_tokens="8" string="it" id_sentence="69" />
      </mentions>
    </coreference>
    <coreference id="52" type="NOMINAL">
      <referenced ids_tokens="9-10-11" string="the music field" id_sentence="67" />
      <mentions>
        <mention ids_tokens="1" string="I" id_sentence="68" />
        <mention ids_tokens="2" string="I" id_sentence="69" />
        <mention ids_tokens="27" string="I" id_sentence="73" />
      </mentions>
    </coreference>
    <coreference id="54" type="NOMINAL">
      <referenced ids_tokens="5-6-7-8" string="a very good one" id_sentence="71" />
      <mentions>
        <mention ids_tokens="7" string="it" id_sentence="73" />
        <mention ids_tokens="5" string="it" id_sentence="74" />
      </mentions>
    </coreference>
    <coreference id="55" type="NOMINAL">
      <referenced ids_tokens="3-4" string="this teacher" id_sentence="72" />
      <mentions>
        <mention ids_tokens="1" string="He" id_sentence="73" />
        <mention ids_tokens="2" string="He" id_sentence="74" />
        <mention ids_tokens="12" string="him" id_sentence="74" />
      </mentions>
    </coreference>
  </coreferences>
</document>
