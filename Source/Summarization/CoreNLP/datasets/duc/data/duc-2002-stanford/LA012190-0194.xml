<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="LA012190-0194">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Geraldo Rivera was interviewing Peggy Ann Buckey on TV.</content>
      <tokens>
        <token id="1" string="Geraldo" lemma="Geraldo" stem="geraldo" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="Rivera" lemma="Rivera" stem="rivera" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="interviewing" lemma="interview" stem="interview" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="Peggy" lemma="Peggy" stem="peggi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="Ann" lemma="Ann" stem="ann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="TV" lemma="tv" stem="tv" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Geraldo) (NNP Rivera)) (VP (VBD was) (VP (VBG interviewing) (NP (NP (NNP Peggy) (NNP Ann) (NNP Buckey)) (PP (IN on) (NP (NN TV)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="TV" type="NP">
          <tokens>
            <token id="9" string="TV" />
          </tokens>
        </chunking>
        <chunking id="2" string="was interviewing Peggy Ann Buckey on TV" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="interviewing" />
            <token id="5" string="Peggy" />
            <token id="6" string="Ann" />
            <token id="7" string="Buckey" />
            <token id="8" string="on" />
            <token id="9" string="TV" />
          </tokens>
        </chunking>
        <chunking id="3" string="Peggy Ann Buckey" type="NP">
          <tokens>
            <token id="5" string="Peggy" />
            <token id="6" string="Ann" />
            <token id="7" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="4" string="interviewing Peggy Ann Buckey on TV" type="VP">
          <tokens>
            <token id="4" string="interviewing" />
            <token id="5" string="Peggy" />
            <token id="6" string="Ann" />
            <token id="7" string="Buckey" />
            <token id="8" string="on" />
            <token id="9" string="TV" />
          </tokens>
        </chunking>
        <chunking id="5" string="Peggy Ann Buckey on TV" type="NP">
          <tokens>
            <token id="5" string="Peggy" />
            <token id="6" string="Ann" />
            <token id="7" string="Buckey" />
            <token id="8" string="on" />
            <token id="9" string="TV" />
          </tokens>
        </chunking>
        <chunking id="6" string="Geraldo Rivera" type="NP">
          <tokens>
            <token id="1" string="Geraldo" />
            <token id="2" string="Rivera" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Rivera</governor>
          <dependent id="1">Geraldo</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">interviewing</governor>
          <dependent id="2">Rivera</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">interviewing</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">interviewing</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Buckey</governor>
          <dependent id="5">Peggy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Buckey</governor>
          <dependent id="6">Ann</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">interviewing</governor>
          <dependent id="7">Buckey</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">TV</governor>
          <dependent id="8">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">Buckey</governor>
          <dependent id="9">TV</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Peggy Ann Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Peggy" />
            <token id="6" string="Ann" />
            <token id="7" string="Buckey" />
          </tokens>
        </entity>
        <entity id="2" string="Geraldo Rivera" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Geraldo" />
            <token id="2" string="Rivera" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="false">
      <content>Abby Mann watched, listened -- and saw the makings of a movie.</content>
      <tokens>
        <token id="1" string="Abby" lemma="Abby" stem="abby" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="Mann" lemma="Mann" stem="mann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="watched" lemma="watch" stem="watch" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="listened" lemma="listen" stem="listen" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="saw" lemma="see" stem="saw" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="makings" lemma="makings" stem="make" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="movie" lemma="movie" stem="movi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Abby) (NNP Mann)) (VP (VBD watched))) (, ,) (VP (VP (VBD listened)) (: --) (CC and) (VP (VBD saw))) (NP (NP (DT the) (NNS makings)) (PP (IN of) (NP (DT a) (NN movie)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="watched" type="VP">
          <tokens>
            <token id="3" string="watched" />
          </tokens>
        </chunking>
        <chunking id="2" string="the makings of a movie" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="makings" />
            <token id="11" string="of" />
            <token id="12" string="a" />
            <token id="13" string="movie" />
          </tokens>
        </chunking>
        <chunking id="3" string="the makings" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="makings" />
          </tokens>
        </chunking>
        <chunking id="4" string="listened -- and saw" type="VP">
          <tokens>
            <token id="5" string="listened" />
            <token id="6" string="--" />
            <token id="7" string="and" />
            <token id="8" string="saw" />
          </tokens>
        </chunking>
        <chunking id="5" string="listened" type="VP">
          <tokens>
            <token id="5" string="listened" />
          </tokens>
        </chunking>
        <chunking id="6" string="saw" type="VP">
          <tokens>
            <token id="8" string="saw" />
          </tokens>
        </chunking>
        <chunking id="7" string="a movie" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="movie" />
          </tokens>
        </chunking>
        <chunking id="8" string="Abby Mann" type="NP">
          <tokens>
            <token id="1" string="Abby" />
            <token id="2" string="Mann" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Mann</governor>
          <dependent id="1">Abby</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">watched</governor>
          <dependent id="2">Mann</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">listened</governor>
          <dependent id="3">watched</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">listened</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">listened</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">listened</governor>
          <dependent id="8">saw</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">makings</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">listened</governor>
          <dependent id="10">makings</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">movie</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">movie</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">makings</governor>
          <dependent id="13">movie</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Abby Mann" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Abby" />
            <token id="2" string="Mann" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>Prosecutors had just dropped charges of child molestation against Buckey, one of the original seven defendants in the McMartin Pre-School case.</content>
      <tokens>
        <token id="1" string="Prosecutors" lemma="prosecutor" stem="prosecutor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="dropped" lemma="drop" stem="drop" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="child" lemma="child" stem="child" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="molestation" lemma="molestation" stem="molest" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="original" lemma="original" stem="origin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="seven" lemma="seven" stem="seven" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="17" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="Pre-School" lemma="Pre-School" stem="pre-school" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Prosecutors)) (VP (VBD had) (ADVP (RB just)) (VP (VBN dropped) (NP (NP (NNS charges)) (PP (IN of) (NP (NN child) (NN molestation)))) (PP (IN against) (NP (NNP Buckey))) (, ,) (NP (NP (CD one)) (PP (IN of) (NP (DT the) (JJ original) (CD seven) (NNS defendants)))) (PP (IN in) (NP (DT the) (NNP McMartin) (NNP Pre-School) (NN case))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="charges of child molestation" type="NP">
          <tokens>
            <token id="5" string="charges" />
            <token id="6" string="of" />
            <token id="7" string="child" />
            <token id="8" string="molestation" />
          </tokens>
        </chunking>
        <chunking id="2" string="Buckey" type="NP">
          <tokens>
            <token id="10" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="3" string="dropped charges of child molestation against Buckey , one of the original seven defendants in the McMartin Pre-School case" type="VP">
          <tokens>
            <token id="4" string="dropped" />
            <token id="5" string="charges" />
            <token id="6" string="of" />
            <token id="7" string="child" />
            <token id="8" string="molestation" />
            <token id="9" string="against" />
            <token id="10" string="Buckey" />
            <token id="11" string="," />
            <token id="12" string="one" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="original" />
            <token id="16" string="seven" />
            <token id="17" string="defendants" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="McMartin" />
            <token id="21" string="Pre-School" />
            <token id="22" string="case" />
          </tokens>
        </chunking>
        <chunking id="4" string="one of the original seven defendants" type="NP">
          <tokens>
            <token id="12" string="one" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="original" />
            <token id="16" string="seven" />
            <token id="17" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="5" string="the McMartin Pre-School case" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="McMartin" />
            <token id="21" string="Pre-School" />
            <token id="22" string="case" />
          </tokens>
        </chunking>
        <chunking id="6" string="charges" type="NP">
          <tokens>
            <token id="5" string="charges" />
          </tokens>
        </chunking>
        <chunking id="7" string="one" type="NP">
          <tokens>
            <token id="12" string="one" />
          </tokens>
        </chunking>
        <chunking id="8" string="Prosecutors" type="NP">
          <tokens>
            <token id="1" string="Prosecutors" />
          </tokens>
        </chunking>
        <chunking id="9" string="had just dropped charges of child molestation against Buckey , one of the original seven defendants in the McMartin Pre-School case" type="VP">
          <tokens>
            <token id="2" string="had" />
            <token id="3" string="just" />
            <token id="4" string="dropped" />
            <token id="5" string="charges" />
            <token id="6" string="of" />
            <token id="7" string="child" />
            <token id="8" string="molestation" />
            <token id="9" string="against" />
            <token id="10" string="Buckey" />
            <token id="11" string="," />
            <token id="12" string="one" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="original" />
            <token id="16" string="seven" />
            <token id="17" string="defendants" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="McMartin" />
            <token id="21" string="Pre-School" />
            <token id="22" string="case" />
          </tokens>
        </chunking>
        <chunking id="10" string="child molestation" type="NP">
          <tokens>
            <token id="7" string="child" />
            <token id="8" string="molestation" />
          </tokens>
        </chunking>
        <chunking id="11" string="the original seven defendants" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="original" />
            <token id="16" string="seven" />
            <token id="17" string="defendants" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">dropped</governor>
          <dependent id="1">Prosecutors</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">dropped</governor>
          <dependent id="2">had</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">dropped</governor>
          <dependent id="3">just</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">dropped</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">dropped</governor>
          <dependent id="5">charges</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">molestation</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">molestation</governor>
          <dependent id="7">child</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">charges</governor>
          <dependent id="8">molestation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Buckey</governor>
          <dependent id="9">against</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">dropped</governor>
          <dependent id="10">Buckey</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">dropped</governor>
          <dependent id="12">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">defendants</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">defendants</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">defendants</governor>
          <dependent id="15">original</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">defendants</governor>
          <dependent id="16">seven</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">one</governor>
          <dependent id="17">defendants</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">case</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">case</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">case</governor>
          <dependent id="20">McMartin</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">case</governor>
          <dependent id="21">Pre-School</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">dropped</governor>
          <dependent id="22">case</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Buckey" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="seven" type="NUMBER" score="0.0">
          <tokens>
            <token id="16" string="seven" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>In that 1986 interview, Peggy Buckey was &amp;quot;quite eloquent&amp;quot; in arguing that charges against her brother, Ray, and mother, Peggy McMartin Buckey, should be dropped as well, Mann recalled Friday.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="1986" lemma="1986" stem="1986" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="interview" lemma="interview" stem="interview" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Peggy" lemma="Peggy" stem="peggi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="quite" lemma="quite" stem="quit" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="eloquent" lemma="eloquent" stem="eloqu" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="arguing" lemma="argue" stem="argu" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="19" string="brother" lemma="brother" stem="brother" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="Ray" lemma="Ray" stem="rai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="mother" lemma="mother" stem="mother" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Peggy" lemma="Peggy" stem="peggi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="27" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="28" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="dropped" lemma="drop" stem="drop" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="Mann" lemma="Mann" stem="mann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="37" string="recalled" lemma="recall" stem="recal" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="Friday" lemma="Friday" stem="fridai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (DT that) (CD 1986) (NN interview))) (PRN (, ,) (S (NP (NNP Peggy) (NNP Buckey)) (VP (VBD was) (ADJP (`` ``) (RB quite) (JJ eloquent) ('' '') (PP (IN in) (S (VP (VBG arguing) (SBAR (IN that) (S (NP (NP (NP (NNS charges)) (PP (IN against) (NP (NP (PRP$ her) (NN brother)) (, ,) (NP (NNP Ray)) (, ,) (CC and) (NP (NN mother))))) (, ,) (NP (NNP Peggy) (NNP McMartin) (NNP Buckey)) (, ,)) (VP (MD should) (VP (VB be) (VP (VBN dropped) (ADVP (RB as) (RB well))))))))))))) (, ,)) (NP (NNP Mann)) (VP (VBD recalled) (NP-TMP (NNP Friday))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that 1986 interview" type="NP">
          <tokens>
            <token id="2" string="that" />
            <token id="3" string="1986" />
            <token id="4" string="interview" />
          </tokens>
        </chunking>
        <chunking id="2" string="arguing that charges against her brother , Ray , and mother , Peggy McMartin Buckey , should be dropped as well" type="VP">
          <tokens>
            <token id="14" string="arguing" />
            <token id="15" string="that" />
            <token id="16" string="charges" />
            <token id="17" string="against" />
            <token id="18" string="her" />
            <token id="19" string="brother" />
            <token id="20" string="," />
            <token id="21" string="Ray" />
            <token id="22" string="," />
            <token id="23" string="and" />
            <token id="24" string="mother" />
            <token id="25" string="," />
            <token id="26" string="Peggy" />
            <token id="27" string="McMartin" />
            <token id="28" string="Buckey" />
            <token id="29" string="," />
            <token id="30" string="should" />
            <token id="31" string="be" />
            <token id="32" string="dropped" />
            <token id="33" string="as" />
            <token id="34" string="well" />
          </tokens>
        </chunking>
        <chunking id="3" string="that charges against her brother , Ray , and mother , Peggy McMartin Buckey , should be dropped as well" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="charges" />
            <token id="17" string="against" />
            <token id="18" string="her" />
            <token id="19" string="brother" />
            <token id="20" string="," />
            <token id="21" string="Ray" />
            <token id="22" string="," />
            <token id="23" string="and" />
            <token id="24" string="mother" />
            <token id="25" string="," />
            <token id="26" string="Peggy" />
            <token id="27" string="McMartin" />
            <token id="28" string="Buckey" />
            <token id="29" string="," />
            <token id="30" string="should" />
            <token id="31" string="be" />
            <token id="32" string="dropped" />
            <token id="33" string="as" />
            <token id="34" string="well" />
          </tokens>
        </chunking>
        <chunking id="4" string="Peggy McMartin Buckey" type="NP">
          <tokens>
            <token id="26" string="Peggy" />
            <token id="27" string="McMartin" />
            <token id="28" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="5" string="recalled Friday" type="VP">
          <tokens>
            <token id="37" string="recalled" />
            <token id="38" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="6" string="Peggy Buckey" type="NP">
          <tokens>
            <token id="6" string="Peggy" />
            <token id="7" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="7" string="was `` quite eloquent '' in arguing that charges against her brother , Ray , and mother , Peggy McMartin Buckey , should be dropped as well" type="VP">
          <tokens>
            <token id="8" string="was" />
            <token id="9" string="&quot;" />
            <token id="10" string="quite" />
            <token id="11" string="eloquent" />
            <token id="12" string="&quot;" />
            <token id="13" string="in" />
            <token id="14" string="arguing" />
            <token id="15" string="that" />
            <token id="16" string="charges" />
            <token id="17" string="against" />
            <token id="18" string="her" />
            <token id="19" string="brother" />
            <token id="20" string="," />
            <token id="21" string="Ray" />
            <token id="22" string="," />
            <token id="23" string="and" />
            <token id="24" string="mother" />
            <token id="25" string="," />
            <token id="26" string="Peggy" />
            <token id="27" string="McMartin" />
            <token id="28" string="Buckey" />
            <token id="29" string="," />
            <token id="30" string="should" />
            <token id="31" string="be" />
            <token id="32" string="dropped" />
            <token id="33" string="as" />
            <token id="34" string="well" />
          </tokens>
        </chunking>
        <chunking id="8" string="charges against her brother , Ray , and mother , Peggy McMartin Buckey ," type="NP">
          <tokens>
            <token id="16" string="charges" />
            <token id="17" string="against" />
            <token id="18" string="her" />
            <token id="19" string="brother" />
            <token id="20" string="," />
            <token id="21" string="Ray" />
            <token id="22" string="," />
            <token id="23" string="and" />
            <token id="24" string="mother" />
            <token id="25" string="," />
            <token id="26" string="Peggy" />
            <token id="27" string="McMartin" />
            <token id="28" string="Buckey" />
            <token id="29" string="," />
          </tokens>
        </chunking>
        <chunking id="9" string="her brother , Ray , and mother" type="NP">
          <tokens>
            <token id="18" string="her" />
            <token id="19" string="brother" />
            <token id="20" string="," />
            <token id="21" string="Ray" />
            <token id="22" string="," />
            <token id="23" string="and" />
            <token id="24" string="mother" />
          </tokens>
        </chunking>
        <chunking id="10" string="dropped as well" type="VP">
          <tokens>
            <token id="32" string="dropped" />
            <token id="33" string="as" />
            <token id="34" string="well" />
          </tokens>
        </chunking>
        <chunking id="11" string="Ray" type="NP">
          <tokens>
            <token id="21" string="Ray" />
          </tokens>
        </chunking>
        <chunking id="12" string="be dropped as well" type="VP">
          <tokens>
            <token id="31" string="be" />
            <token id="32" string="dropped" />
            <token id="33" string="as" />
            <token id="34" string="well" />
          </tokens>
        </chunking>
        <chunking id="13" string="her brother" type="NP">
          <tokens>
            <token id="18" string="her" />
            <token id="19" string="brother" />
          </tokens>
        </chunking>
        <chunking id="14" string="`` quite eloquent '' in arguing that charges against her brother , Ray , and mother , Peggy McMartin Buckey , should be dropped as well" type="ADJP">
          <tokens>
            <token id="9" string="&quot;" />
            <token id="10" string="quite" />
            <token id="11" string="eloquent" />
            <token id="12" string="&quot;" />
            <token id="13" string="in" />
            <token id="14" string="arguing" />
            <token id="15" string="that" />
            <token id="16" string="charges" />
            <token id="17" string="against" />
            <token id="18" string="her" />
            <token id="19" string="brother" />
            <token id="20" string="," />
            <token id="21" string="Ray" />
            <token id="22" string="," />
            <token id="23" string="and" />
            <token id="24" string="mother" />
            <token id="25" string="," />
            <token id="26" string="Peggy" />
            <token id="27" string="McMartin" />
            <token id="28" string="Buckey" />
            <token id="29" string="," />
            <token id="30" string="should" />
            <token id="31" string="be" />
            <token id="32" string="dropped" />
            <token id="33" string="as" />
            <token id="34" string="well" />
          </tokens>
        </chunking>
        <chunking id="15" string="mother" type="NP">
          <tokens>
            <token id="24" string="mother" />
          </tokens>
        </chunking>
        <chunking id="16" string="charges" type="NP">
          <tokens>
            <token id="16" string="charges" />
          </tokens>
        </chunking>
        <chunking id="17" string="charges against her brother , Ray , and mother" type="NP">
          <tokens>
            <token id="16" string="charges" />
            <token id="17" string="against" />
            <token id="18" string="her" />
            <token id="19" string="brother" />
            <token id="20" string="," />
            <token id="21" string="Ray" />
            <token id="22" string="," />
            <token id="23" string="and" />
            <token id="24" string="mother" />
          </tokens>
        </chunking>
        <chunking id="18" string="Mann" type="NP">
          <tokens>
            <token id="36" string="Mann" />
          </tokens>
        </chunking>
        <chunking id="19" string="should be dropped as well" type="VP">
          <tokens>
            <token id="30" string="should" />
            <token id="31" string="be" />
            <token id="32" string="dropped" />
            <token id="33" string="as" />
            <token id="34" string="well" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">interview</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">interview</governor>
          <dependent id="2">that</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">interview</governor>
          <dependent id="3">1986</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="37">recalled</governor>
          <dependent id="4">interview</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Buckey</governor>
          <dependent id="6">Peggy</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">eloquent</governor>
          <dependent id="7">Buckey</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">eloquent</governor>
          <dependent id="8">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">eloquent</governor>
          <dependent id="10">quite</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="37">recalled</governor>
          <dependent id="11">eloquent</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">arguing</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">eloquent</governor>
          <dependent id="14">arguing</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="32">dropped</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="32">dropped</governor>
          <dependent id="16">charges</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">brother</governor>
          <dependent id="17">against</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">brother</governor>
          <dependent id="18">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">charges</governor>
          <dependent id="19">brother</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">brother</governor>
          <dependent id="21">Ray</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">brother</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">brother</governor>
          <dependent id="24">mother</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">Buckey</governor>
          <dependent id="26">Peggy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">Buckey</governor>
          <dependent id="27">McMartin</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="16">charges</governor>
          <dependent id="28">Buckey</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="32">dropped</governor>
          <dependent id="30">should</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="32">dropped</governor>
          <dependent id="31">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">arguing</governor>
          <dependent id="32">dropped</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="32">dropped</governor>
          <dependent id="33">as</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="33">as</governor>
          <dependent id="34">well</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="37">recalled</governor>
          <dependent id="36">Mann</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="37">recalled</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="37">recalled</governor>
          <dependent id="38">Friday</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Peggy McMartin Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="26" string="Peggy" />
            <token id="27" string="McMartin" />
            <token id="28" string="Buckey" />
          </tokens>
        </entity>
        <entity id="2" string="1986" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="1986" />
          </tokens>
        </entity>
        <entity id="3" string="Peggy Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Peggy" />
            <token id="7" string="Buckey" />
          </tokens>
        </entity>
        <entity id="4" string="Friday" type="DATE" score="0.0">
          <tokens>
            <token id="38" string="Friday" />
          </tokens>
        </entity>
        <entity id="5" string="Mann" type="PERSON" score="0.0">
          <tokens>
            <token id="36" string="Mann" />
          </tokens>
        </entity>
        <entity id="6" string="Ray" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Ray" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>Mann, an Oscar- and Emmy-winning screenwriter and producer, recognized a theme he had tapped before: the hysteria of a witch hunt.</content>
      <tokens>
        <token id="1" string="Mann" lemma="Mann" stem="mann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Oscar" lemma="Oscar" stem="oscar" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="5" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Emmy-winning" lemma="emmy-winning" stem="emmy-win" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="8" string="screenwriter" lemma="screenwriter" stem="screenwrit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="producer" lemma="producer" stem="produc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="recognized" lemma="recognize" stem="recogn" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="theme" lemma="theme" stem="theme" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="tapped" lemma="tap" stem="tap" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="hysteria" lemma="hysteria" stem="hysteria" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="witch" lemma="witch" stem="witch" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="hunt" lemma="hunt" stem="hunt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Mann)) (, ,) (NP (NP (DT an) (NNP Oscar)) (: -) (CC and) (NP (JJ Emmy-winning) (NN screenwriter) (CC and) (NN producer)) (, ,)) (VP (VBD recognized) (NP (NP (NP (DT a) (NN theme)) (SBAR (S (NP (PRP he)) (VP (VBD had) (VP (VBN tapped) (PP (IN before))))))) (: :) (NP (NP (DT the) (NN hysteria)) (PP (IN of) (NP (DT a) (NN witch) (NN hunt)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="an Oscar - and Emmy-winning screenwriter and producer ," type="NP">
          <tokens>
            <token id="3" string="an" />
            <token id="4" string="Oscar" />
            <token id="5" string="-" />
            <token id="6" string="and" />
            <token id="7" string="Emmy-winning" />
            <token id="8" string="screenwriter" />
            <token id="9" string="and" />
            <token id="10" string="producer" />
            <token id="11" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="recognized a theme he had tapped before : the hysteria of a witch hunt" type="VP">
          <tokens>
            <token id="12" string="recognized" />
            <token id="13" string="a" />
            <token id="14" string="theme" />
            <token id="15" string="he" />
            <token id="16" string="had" />
            <token id="17" string="tapped" />
            <token id="18" string="before" />
            <token id="19" string=":" />
            <token id="20" string="the" />
            <token id="21" string="hysteria" />
            <token id="22" string="of" />
            <token id="23" string="a" />
            <token id="24" string="witch" />
            <token id="25" string="hunt" />
          </tokens>
        </chunking>
        <chunking id="3" string="a theme" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="theme" />
          </tokens>
        </chunking>
        <chunking id="4" string="he had tapped before" type="SBAR">
          <tokens>
            <token id="15" string="he" />
            <token id="16" string="had" />
            <token id="17" string="tapped" />
            <token id="18" string="before" />
          </tokens>
        </chunking>
        <chunking id="5" string="tapped before" type="VP">
          <tokens>
            <token id="17" string="tapped" />
            <token id="18" string="before" />
          </tokens>
        </chunking>
        <chunking id="6" string="the hysteria" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="hysteria" />
          </tokens>
        </chunking>
        <chunking id="7" string="Emmy-winning screenwriter and producer" type="NP">
          <tokens>
            <token id="7" string="Emmy-winning" />
            <token id="8" string="screenwriter" />
            <token id="9" string="and" />
            <token id="10" string="producer" />
          </tokens>
        </chunking>
        <chunking id="8" string="a witch hunt" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="witch" />
            <token id="25" string="hunt" />
          </tokens>
        </chunking>
        <chunking id="9" string="a theme he had tapped before : the hysteria of a witch hunt" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="theme" />
            <token id="15" string="he" />
            <token id="16" string="had" />
            <token id="17" string="tapped" />
            <token id="18" string="before" />
            <token id="19" string=":" />
            <token id="20" string="the" />
            <token id="21" string="hysteria" />
            <token id="22" string="of" />
            <token id="23" string="a" />
            <token id="24" string="witch" />
            <token id="25" string="hunt" />
          </tokens>
        </chunking>
        <chunking id="10" string="an Oscar" type="NP">
          <tokens>
            <token id="3" string="an" />
            <token id="4" string="Oscar" />
          </tokens>
        </chunking>
        <chunking id="11" string="had tapped before" type="VP">
          <tokens>
            <token id="16" string="had" />
            <token id="17" string="tapped" />
            <token id="18" string="before" />
          </tokens>
        </chunking>
        <chunking id="12" string="Mann" type="NP">
          <tokens>
            <token id="1" string="Mann" />
          </tokens>
        </chunking>
        <chunking id="13" string="a theme he had tapped before" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="theme" />
            <token id="15" string="he" />
            <token id="16" string="had" />
            <token id="17" string="tapped" />
            <token id="18" string="before" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="15" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="the hysteria of a witch hunt" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="hysteria" />
            <token id="22" string="of" />
            <token id="23" string="a" />
            <token id="24" string="witch" />
            <token id="25" string="hunt" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="12">recognized</governor>
          <dependent id="1">Mann</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">Oscar</governor>
          <dependent id="3">an</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">recognized</governor>
          <dependent id="4">Oscar</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">Oscar</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">screenwriter</governor>
          <dependent id="7">Emmy-winning</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">Oscar</governor>
          <dependent id="8">screenwriter</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">screenwriter</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">screenwriter</governor>
          <dependent id="10">producer</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">recognized</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">theme</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">recognized</governor>
          <dependent id="14">theme</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">tapped</governor>
          <dependent id="15">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">tapped</governor>
          <dependent id="16">had</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="14">theme</governor>
          <dependent id="17">tapped</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">tapped</governor>
          <dependent id="18">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">hysteria</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">theme</governor>
          <dependent id="21">hysteria</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">hunt</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">hunt</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">hunt</governor>
          <dependent id="24">witch</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">hysteria</governor>
          <dependent id="25">hunt</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Oscar" type="MISC" score="0.0">
          <tokens>
            <token id="4" string="Oscar" />
          </tokens>
        </entity>
        <entity id="2" string="Mann" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Mann" />
          </tokens>
        </entity>
        <entity id="3" string="Emmy-winning" type="MISC" score="0.0">
          <tokens>
            <token id="7" string="Emmy-winning" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>Soon, Mann became a controversial figure in the case itself -- but he got the inside track on movie and book deals.</content>
      <tokens>
        <token id="1" string="Soon" lemma="soon" stem="soon" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Mann" lemma="Mann" stem="mann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="became" lemma="become" stem="becam" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="controversial" lemma="controversial" stem="controversi" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="figure" lemma="figure" stem="figur" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="itself" lemma="itself" stem="itself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="inside" lemma="inside" stem="insid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="track" lemma="track" stem="track" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="movie" lemma="movie" stem="movi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="deals" lemma="deal" stem="deal" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (ADVP (RB Soon)) (, ,) (NP (NNP Mann)) (VP (VBD became) (NP (DT a) (JJ controversial) (NN figure)) (PP (IN in) (NP (NP (DT the) (NN case)) (ADVP (PRP itself)))))) (: --) (CC but) (S (NP (PRP he)) (VP (VBD got) (NP (DT the) (JJ inside) (NN track)) (PP (IN on) (NP (NN movie) (CC and) (NN book) (NNS deals))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a controversial figure" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="controversial" />
            <token id="7" string="figure" />
          </tokens>
        </chunking>
        <chunking id="2" string="got the inside track on movie and book deals" type="VP">
          <tokens>
            <token id="15" string="got" />
            <token id="16" string="the" />
            <token id="17" string="inside" />
            <token id="18" string="track" />
            <token id="19" string="on" />
            <token id="20" string="movie" />
            <token id="21" string="and" />
            <token id="22" string="book" />
            <token id="23" string="deals" />
          </tokens>
        </chunking>
        <chunking id="3" string="the case itself" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="case" />
            <token id="11" string="itself" />
          </tokens>
        </chunking>
        <chunking id="4" string="the case" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="case" />
          </tokens>
        </chunking>
        <chunking id="5" string="Mann" type="NP">
          <tokens>
            <token id="3" string="Mann" />
          </tokens>
        </chunking>
        <chunking id="6" string="movie and book deals" type="NP">
          <tokens>
            <token id="20" string="movie" />
            <token id="21" string="and" />
            <token id="22" string="book" />
            <token id="23" string="deals" />
          </tokens>
        </chunking>
        <chunking id="7" string="he" type="NP">
          <tokens>
            <token id="14" string="he" />
          </tokens>
        </chunking>
        <chunking id="8" string="became a controversial figure in the case itself" type="VP">
          <tokens>
            <token id="4" string="became" />
            <token id="5" string="a" />
            <token id="6" string="controversial" />
            <token id="7" string="figure" />
            <token id="8" string="in" />
            <token id="9" string="the" />
            <token id="10" string="case" />
            <token id="11" string="itself" />
          </tokens>
        </chunking>
        <chunking id="9" string="the inside track" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="inside" />
            <token id="18" string="track" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">became</governor>
          <dependent id="1">Soon</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">became</governor>
          <dependent id="3">Mann</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">became</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">figure</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">figure</governor>
          <dependent id="6">controversial</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">became</governor>
          <dependent id="7">figure</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">case</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">case</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">became</governor>
          <dependent id="10">case</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">case</governor>
          <dependent id="11">itself</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">became</governor>
          <dependent id="13">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">got</governor>
          <dependent id="14">he</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">became</governor>
          <dependent id="15">got</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">track</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">track</governor>
          <dependent id="17">inside</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">got</governor>
          <dependent id="18">track</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">deals</governor>
          <dependent id="19">on</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">deals</governor>
          <dependent id="20">movie</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">movie</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">movie</governor>
          <dependent id="22">book</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">got</governor>
          <dependent id="23">deals</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mann" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Mann" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>And Thursday&amp;apost;s not-guilty verdicts in Ray and Peggy McMartin Buckey&amp;apost;s trial gave Mann the happy ending he was hoping for -- happy, at least, from his point of view.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Thursday" lemma="Thursday" stem="thursdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="not-guilty" lemma="not-guilty" stem="not-guilti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="verdicts" lemma="verdict" stem="verdict" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Ray" lemma="Ray" stem="rai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Peggy" lemma="Peggy" stem="peggi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="10" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="11" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="12" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="13" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="gave" lemma="give" stem="gave" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Mann" lemma="Mann" stem="mann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="happy" lemma="happy" stem="happi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="ending" lemma="end" stem="end" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="hoping" lemma="hope" stem="hope" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="happy" lemma="happy" stem="happi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="least" lemma="least" stem="least" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="point" lemma="point" stem="point" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="view" lemma="view" stem="view" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (NP (NP (NP (NNP Thursday) (POS 's)) (JJ not-guilty) (NNS verdicts)) (PP (IN in) (NP (NNP Ray)))) (CC and) (NP (NP (NNP Peggy) (NNP McMartin) (NNP Buckey) (POS 's)) (NN trial))) (VP (VBD gave) (NP (NNP Mann)) (NP (NP (NP (DT the) (JJ happy)) (VP (VBG ending) (SBAR (S (NP (PRP he)) (VP (VBD was) (VP (VBG hoping) (PP (IN for)))))))) (: --) (NP (NP (JJ happy)) (, ,) (ADVP (IN at) (JJS least))) (, ,) (PP (IN from) (NP (NP (PRP$ his) (NN point)) (PP (IN of) (NP (NN view))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Peggy McMartin Buckey 's" type="NP">
          <tokens>
            <token id="9" string="Peggy" />
            <token id="10" string="McMartin" />
            <token id="11" string="Buckey" />
            <token id="12" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="the happy" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="happy" />
          </tokens>
        </chunking>
        <chunking id="3" string="hoping for" type="VP">
          <tokens>
            <token id="21" string="hoping" />
            <token id="22" string="for" />
          </tokens>
        </chunking>
        <chunking id="4" string="Ray" type="NP">
          <tokens>
            <token id="7" string="Ray" />
          </tokens>
        </chunking>
        <chunking id="5" string="Thursday 's not-guilty verdicts in Ray" type="NP">
          <tokens>
            <token id="2" string="Thursday" />
            <token id="3" string="'s" />
            <token id="4" string="not-guilty" />
            <token id="5" string="verdicts" />
            <token id="6" string="in" />
            <token id="7" string="Ray" />
          </tokens>
        </chunking>
        <chunking id="6" string="his point" type="NP">
          <tokens>
            <token id="30" string="his" />
            <token id="31" string="point" />
          </tokens>
        </chunking>
        <chunking id="7" string="the happy ending he was hoping for" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="happy" />
            <token id="18" string="ending" />
            <token id="19" string="he" />
            <token id="20" string="was" />
            <token id="21" string="hoping" />
            <token id="22" string="for" />
          </tokens>
        </chunking>
        <chunking id="8" string="happy , at least" type="NP">
          <tokens>
            <token id="24" string="happy" />
            <token id="25" string="," />
            <token id="26" string="at" />
            <token id="27" string="least" />
          </tokens>
        </chunking>
        <chunking id="9" string="view" type="NP">
          <tokens>
            <token id="33" string="view" />
          </tokens>
        </chunking>
        <chunking id="10" string="his point of view" type="NP">
          <tokens>
            <token id="30" string="his" />
            <token id="31" string="point" />
            <token id="32" string="of" />
            <token id="33" string="view" />
          </tokens>
        </chunking>
        <chunking id="11" string="Mann" type="NP">
          <tokens>
            <token id="15" string="Mann" />
          </tokens>
        </chunking>
        <chunking id="12" string="happy" type="NP">
          <tokens>
            <token id="24" string="happy" />
          </tokens>
        </chunking>
        <chunking id="13" string="the happy ending he was hoping for -- happy , at least , from his point of view" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="happy" />
            <token id="18" string="ending" />
            <token id="19" string="he" />
            <token id="20" string="was" />
            <token id="21" string="hoping" />
            <token id="22" string="for" />
            <token id="23" string="--" />
            <token id="24" string="happy" />
            <token id="25" string="," />
            <token id="26" string="at" />
            <token id="27" string="least" />
            <token id="28" string="," />
            <token id="29" string="from" />
            <token id="30" string="his" />
            <token id="31" string="point" />
            <token id="32" string="of" />
            <token id="33" string="view" />
          </tokens>
        </chunking>
        <chunking id="14" string="he was hoping for" type="SBAR">
          <tokens>
            <token id="19" string="he" />
            <token id="20" string="was" />
            <token id="21" string="hoping" />
            <token id="22" string="for" />
          </tokens>
        </chunking>
        <chunking id="15" string="Peggy McMartin Buckey 's trial" type="NP">
          <tokens>
            <token id="9" string="Peggy" />
            <token id="10" string="McMartin" />
            <token id="11" string="Buckey" />
            <token id="12" string="'s" />
            <token id="13" string="trial" />
          </tokens>
        </chunking>
        <chunking id="16" string="gave Mann the happy ending he was hoping for -- happy , at least , from his point of view" type="VP">
          <tokens>
            <token id="14" string="gave" />
            <token id="15" string="Mann" />
            <token id="16" string="the" />
            <token id="17" string="happy" />
            <token id="18" string="ending" />
            <token id="19" string="he" />
            <token id="20" string="was" />
            <token id="21" string="hoping" />
            <token id="22" string="for" />
            <token id="23" string="--" />
            <token id="24" string="happy" />
            <token id="25" string="," />
            <token id="26" string="at" />
            <token id="27" string="least" />
            <token id="28" string="," />
            <token id="29" string="from" />
            <token id="30" string="his" />
            <token id="31" string="point" />
            <token id="32" string="of" />
            <token id="33" string="view" />
          </tokens>
        </chunking>
        <chunking id="17" string="he" type="NP">
          <tokens>
            <token id="19" string="he" />
          </tokens>
        </chunking>
        <chunking id="18" string="Thursday 's not-guilty verdicts in Ray and Peggy McMartin Buckey 's trial" type="NP">
          <tokens>
            <token id="2" string="Thursday" />
            <token id="3" string="'s" />
            <token id="4" string="not-guilty" />
            <token id="5" string="verdicts" />
            <token id="6" string="in" />
            <token id="7" string="Ray" />
            <token id="8" string="and" />
            <token id="9" string="Peggy" />
            <token id="10" string="McMartin" />
            <token id="11" string="Buckey" />
            <token id="12" string="'s" />
            <token id="13" string="trial" />
          </tokens>
        </chunking>
        <chunking id="19" string="Thursday 's" type="NP">
          <tokens>
            <token id="2" string="Thursday" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="20" string="ending he was hoping for" type="VP">
          <tokens>
            <token id="18" string="ending" />
            <token id="19" string="he" />
            <token id="20" string="was" />
            <token id="21" string="hoping" />
            <token id="22" string="for" />
          </tokens>
        </chunking>
        <chunking id="21" string="was hoping for" type="VP">
          <tokens>
            <token id="20" string="was" />
            <token id="21" string="hoping" />
            <token id="22" string="for" />
          </tokens>
        </chunking>
        <chunking id="22" string="Thursday 's not-guilty verdicts" type="NP">
          <tokens>
            <token id="2" string="Thursday" />
            <token id="3" string="'s" />
            <token id="4" string="not-guilty" />
            <token id="5" string="verdicts" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="14">gave</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">verdicts</governor>
          <dependent id="2">Thursday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Thursday</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">verdicts</governor>
          <dependent id="4">not-guilty</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">gave</governor>
          <dependent id="5">verdicts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Ray</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">verdicts</governor>
          <dependent id="7">Ray</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">verdicts</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Buckey</governor>
          <dependent id="9">Peggy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Buckey</governor>
          <dependent id="10">McMartin</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">trial</governor>
          <dependent id="11">Buckey</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Buckey</governor>
          <dependent id="12">'s</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">verdicts</governor>
          <dependent id="13">trial</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">gave</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="14">gave</governor>
          <dependent id="15">Mann</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">happy</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">gave</governor>
          <dependent id="17">happy</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="17">happy</governor>
          <dependent id="18">ending</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">hoping</governor>
          <dependent id="19">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">hoping</governor>
          <dependent id="20">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">ending</governor>
          <dependent id="21">hoping</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">hoping</governor>
          <dependent id="22">for</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">happy</governor>
          <dependent id="24">happy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">least</governor>
          <dependent id="26">at</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">happy</governor>
          <dependent id="27">least</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">point</governor>
          <dependent id="29">from</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="31">point</governor>
          <dependent id="30">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">happy</governor>
          <dependent id="31">point</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">view</governor>
          <dependent id="32">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">point</governor>
          <dependent id="33">view</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Peggy McMartin Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Peggy" />
            <token id="10" string="McMartin" />
            <token id="11" string="Buckey" />
          </tokens>
        </entity>
        <entity id="2" string="Thursday" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="Thursday" />
          </tokens>
        </entity>
        <entity id="3" string="Mann" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Mann" />
          </tokens>
        </entity>
        <entity id="4" string="Ray" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Ray" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>But Mann and his wife, Myra, who have an 800-page manuscript in the works for Random House and say they are close to finishing a screenplay, aren&amp;apost;t expected to monopolize the telling of the 6-year-old McMartin case -- or the perspective.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Mann" lemma="Mann" stem="mann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="5" string="wife" lemma="wife" stem="wife" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Myra" lemma="Myra" stem="myra" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="800-page" lemma="800-page" stem="800-page" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="manuscript" lemma="manuscript" stem="manuscript" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="works" lemma="work" stem="work" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Random" lemma="Random" stem="random" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="19" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="close" lemma="close" stem="close" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="finishing" lemma="finish" stem="finish" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="screenplay" lemma="screenplay" stem="screenplai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="expected" lemma="expect" stem="expect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="monopolize" lemma="monopolize" stem="monopol" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="telling" lemma="tell" stem="tell" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="39" string="6-year-old" lemma="6-year-old" stem="6-year-old" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="40" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="41" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="42" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="perspective" lemma="perspective" stem="perspect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NP (NP (NNP Mann)) (CC and) (NP (PRP$ his) (NN wife))) (, ,) (NP (NP (NNP Myra)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VP (VBP have) (NP (NP (DT an) (JJ 800-page) (NN manuscript)) (PP (IN in) (NP (NP (DT the) (NNS works)) (PP (IN for) (NP (NNP Random) (NNP House))))))) (CC and) (VP (VB say) (SBAR (S (NP (PRP they)) (VP (VBP are) (ADJP (JJ close) (PP (TO to) (S (VP (VBG finishing) (NP (DT a) (NN screenplay)))))))))))))) (, ,)) (VP (VBP are) (RB n't) (VP (VBN expected) (S (VP (TO to) (VP (VB monopolize) (NP (NP (NP (DT the) (VBG telling)) (PP (IN of) (NP (DT the) (JJ 6-year-old) (NNP McMartin) (NN case)))) (: --) (CC or) (NP (DT the) (NN perspective)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they are close to finishing a screenplay" type="SBAR">
          <tokens>
            <token id="22" string="they" />
            <token id="23" string="are" />
            <token id="24" string="close" />
            <token id="25" string="to" />
            <token id="26" string="finishing" />
            <token id="27" string="a" />
            <token id="28" string="screenplay" />
          </tokens>
        </chunking>
        <chunking id="2" string="are close to finishing a screenplay" type="VP">
          <tokens>
            <token id="23" string="are" />
            <token id="24" string="close" />
            <token id="25" string="to" />
            <token id="26" string="finishing" />
            <token id="27" string="a" />
            <token id="28" string="screenplay" />
          </tokens>
        </chunking>
        <chunking id="3" string="who have an 800-page manuscript in the works for Random House and say they are close to finishing a screenplay" type="SBAR">
          <tokens>
            <token id="9" string="who" />
            <token id="10" string="have" />
            <token id="11" string="an" />
            <token id="12" string="800-page" />
            <token id="13" string="manuscript" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="works" />
            <token id="17" string="for" />
            <token id="18" string="Random" />
            <token id="19" string="House" />
            <token id="20" string="and" />
            <token id="21" string="say" />
            <token id="22" string="they" />
            <token id="23" string="are" />
            <token id="24" string="close" />
            <token id="25" string="to" />
            <token id="26" string="finishing" />
            <token id="27" string="a" />
            <token id="28" string="screenplay" />
          </tokens>
        </chunking>
        <chunking id="4" string="a screenplay" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="screenplay" />
          </tokens>
        </chunking>
        <chunking id="5" string="are n't expected to monopolize the telling of the 6-year-old McMartin case -- or the perspective" type="VP">
          <tokens>
            <token id="30" string="are" />
            <token id="31" string="n't" />
            <token id="32" string="expected" />
            <token id="33" string="to" />
            <token id="34" string="monopolize" />
            <token id="35" string="the" />
            <token id="36" string="telling" />
            <token id="37" string="of" />
            <token id="38" string="the" />
            <token id="39" string="6-year-old" />
            <token id="40" string="McMartin" />
            <token id="41" string="case" />
            <token id="42" string="--" />
            <token id="43" string="or" />
            <token id="44" string="the" />
            <token id="45" string="perspective" />
          </tokens>
        </chunking>
        <chunking id="6" string="an 800-page manuscript" type="NP">
          <tokens>
            <token id="11" string="an" />
            <token id="12" string="800-page" />
            <token id="13" string="manuscript" />
          </tokens>
        </chunking>
        <chunking id="7" string="monopolize the telling of the 6-year-old McMartin case -- or the perspective" type="VP">
          <tokens>
            <token id="34" string="monopolize" />
            <token id="35" string="the" />
            <token id="36" string="telling" />
            <token id="37" string="of" />
            <token id="38" string="the" />
            <token id="39" string="6-year-old" />
            <token id="40" string="McMartin" />
            <token id="41" string="case" />
            <token id="42" string="--" />
            <token id="43" string="or" />
            <token id="44" string="the" />
            <token id="45" string="perspective" />
          </tokens>
        </chunking>
        <chunking id="8" string="close to finishing a screenplay" type="ADJP">
          <tokens>
            <token id="24" string="close" />
            <token id="25" string="to" />
            <token id="26" string="finishing" />
            <token id="27" string="a" />
            <token id="28" string="screenplay" />
          </tokens>
        </chunking>
        <chunking id="9" string="Mann and his wife" type="NP">
          <tokens>
            <token id="2" string="Mann" />
            <token id="3" string="and" />
            <token id="4" string="his" />
            <token id="5" string="wife" />
          </tokens>
        </chunking>
        <chunking id="10" string="Mann and his wife , Myra , who have an 800-page manuscript in the works for Random House and say they are close to finishing a screenplay ," type="NP">
          <tokens>
            <token id="2" string="Mann" />
            <token id="3" string="and" />
            <token id="4" string="his" />
            <token id="5" string="wife" />
            <token id="6" string="," />
            <token id="7" string="Myra" />
            <token id="8" string="," />
            <token id="9" string="who" />
            <token id="10" string="have" />
            <token id="11" string="an" />
            <token id="12" string="800-page" />
            <token id="13" string="manuscript" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="works" />
            <token id="17" string="for" />
            <token id="18" string="Random" />
            <token id="19" string="House" />
            <token id="20" string="and" />
            <token id="21" string="say" />
            <token id="22" string="they" />
            <token id="23" string="are" />
            <token id="24" string="close" />
            <token id="25" string="to" />
            <token id="26" string="finishing" />
            <token id="27" string="a" />
            <token id="28" string="screenplay" />
            <token id="29" string="," />
          </tokens>
        </chunking>
        <chunking id="11" string="the telling of the 6-year-old McMartin case -- or the perspective" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="telling" />
            <token id="37" string="of" />
            <token id="38" string="the" />
            <token id="39" string="6-year-old" />
            <token id="40" string="McMartin" />
            <token id="41" string="case" />
            <token id="42" string="--" />
            <token id="43" string="or" />
            <token id="44" string="the" />
            <token id="45" string="perspective" />
          </tokens>
        </chunking>
        <chunking id="12" string="the works" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="works" />
          </tokens>
        </chunking>
        <chunking id="13" string="have an 800-page manuscript in the works for Random House and say they are close to finishing a screenplay" type="VP">
          <tokens>
            <token id="10" string="have" />
            <token id="11" string="an" />
            <token id="12" string="800-page" />
            <token id="13" string="manuscript" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="works" />
            <token id="17" string="for" />
            <token id="18" string="Random" />
            <token id="19" string="House" />
            <token id="20" string="and" />
            <token id="21" string="say" />
            <token id="22" string="they" />
            <token id="23" string="are" />
            <token id="24" string="close" />
            <token id="25" string="to" />
            <token id="26" string="finishing" />
            <token id="27" string="a" />
            <token id="28" string="screenplay" />
          </tokens>
        </chunking>
        <chunking id="14" string="his wife" type="NP">
          <tokens>
            <token id="4" string="his" />
            <token id="5" string="wife" />
          </tokens>
        </chunking>
        <chunking id="15" string="expected to monopolize the telling of the 6-year-old McMartin case -- or the perspective" type="VP">
          <tokens>
            <token id="32" string="expected" />
            <token id="33" string="to" />
            <token id="34" string="monopolize" />
            <token id="35" string="the" />
            <token id="36" string="telling" />
            <token id="37" string="of" />
            <token id="38" string="the" />
            <token id="39" string="6-year-old" />
            <token id="40" string="McMartin" />
            <token id="41" string="case" />
            <token id="42" string="--" />
            <token id="43" string="or" />
            <token id="44" string="the" />
            <token id="45" string="perspective" />
          </tokens>
        </chunking>
        <chunking id="16" string="the works for Random House" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="works" />
            <token id="17" string="for" />
            <token id="18" string="Random" />
            <token id="19" string="House" />
          </tokens>
        </chunking>
        <chunking id="17" string="finishing a screenplay" type="VP">
          <tokens>
            <token id="26" string="finishing" />
            <token id="27" string="a" />
            <token id="28" string="screenplay" />
          </tokens>
        </chunking>
        <chunking id="18" string="Random House" type="NP">
          <tokens>
            <token id="18" string="Random" />
            <token id="19" string="House" />
          </tokens>
        </chunking>
        <chunking id="19" string="the telling" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="telling" />
          </tokens>
        </chunking>
        <chunking id="20" string="they" type="NP">
          <tokens>
            <token id="22" string="they" />
          </tokens>
        </chunking>
        <chunking id="21" string="Myra , who have an 800-page manuscript in the works for Random House and say they are close to finishing a screenplay" type="NP">
          <tokens>
            <token id="7" string="Myra" />
            <token id="8" string="," />
            <token id="9" string="who" />
            <token id="10" string="have" />
            <token id="11" string="an" />
            <token id="12" string="800-page" />
            <token id="13" string="manuscript" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="works" />
            <token id="17" string="for" />
            <token id="18" string="Random" />
            <token id="19" string="House" />
            <token id="20" string="and" />
            <token id="21" string="say" />
            <token id="22" string="they" />
            <token id="23" string="are" />
            <token id="24" string="close" />
            <token id="25" string="to" />
            <token id="26" string="finishing" />
            <token id="27" string="a" />
            <token id="28" string="screenplay" />
          </tokens>
        </chunking>
        <chunking id="22" string="the 6-year-old McMartin case" type="NP">
          <tokens>
            <token id="38" string="the" />
            <token id="39" string="6-year-old" />
            <token id="40" string="McMartin" />
            <token id="41" string="case" />
          </tokens>
        </chunking>
        <chunking id="23" string="Mann" type="NP">
          <tokens>
            <token id="2" string="Mann" />
          </tokens>
        </chunking>
        <chunking id="24" string="say they are close to finishing a screenplay" type="VP">
          <tokens>
            <token id="21" string="say" />
            <token id="22" string="they" />
            <token id="23" string="are" />
            <token id="24" string="close" />
            <token id="25" string="to" />
            <token id="26" string="finishing" />
            <token id="27" string="a" />
            <token id="28" string="screenplay" />
          </tokens>
        </chunking>
        <chunking id="25" string="to monopolize the telling of the 6-year-old McMartin case -- or the perspective" type="VP">
          <tokens>
            <token id="33" string="to" />
            <token id="34" string="monopolize" />
            <token id="35" string="the" />
            <token id="36" string="telling" />
            <token id="37" string="of" />
            <token id="38" string="the" />
            <token id="39" string="6-year-old" />
            <token id="40" string="McMartin" />
            <token id="41" string="case" />
            <token id="42" string="--" />
            <token id="43" string="or" />
            <token id="44" string="the" />
            <token id="45" string="perspective" />
          </tokens>
        </chunking>
        <chunking id="26" string="the telling of the 6-year-old McMartin case" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="telling" />
            <token id="37" string="of" />
            <token id="38" string="the" />
            <token id="39" string="6-year-old" />
            <token id="40" string="McMartin" />
            <token id="41" string="case" />
          </tokens>
        </chunking>
        <chunking id="27" string="the perspective" type="NP">
          <tokens>
            <token id="44" string="the" />
            <token id="45" string="perspective" />
          </tokens>
        </chunking>
        <chunking id="28" string="Myra" type="NP">
          <tokens>
            <token id="7" string="Myra" />
          </tokens>
        </chunking>
        <chunking id="29" string="have an 800-page manuscript in the works for Random House" type="VP">
          <tokens>
            <token id="10" string="have" />
            <token id="11" string="an" />
            <token id="12" string="800-page" />
            <token id="13" string="manuscript" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="works" />
            <token id="17" string="for" />
            <token id="18" string="Random" />
            <token id="19" string="House" />
          </tokens>
        </chunking>
        <chunking id="30" string="an 800-page manuscript in the works for Random House" type="NP">
          <tokens>
            <token id="11" string="an" />
            <token id="12" string="800-page" />
            <token id="13" string="manuscript" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="works" />
            <token id="17" string="for" />
            <token id="18" string="Random" />
            <token id="19" string="House" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="32">expected</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="32">expected</governor>
          <dependent id="2">Mann</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">Mann</governor>
          <dependent id="3">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">wife</governor>
          <dependent id="4">his</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">Mann</governor>
          <dependent id="5">wife</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Mann</governor>
          <dependent id="7">Myra</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">have</governor>
          <dependent id="9">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">Myra</governor>
          <dependent id="10">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">manuscript</governor>
          <dependent id="11">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">manuscript</governor>
          <dependent id="12">800-page</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">have</governor>
          <dependent id="13">manuscript</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">works</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">works</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">manuscript</governor>
          <dependent id="16">works</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">House</governor>
          <dependent id="17">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">House</governor>
          <dependent id="18">Random</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">works</governor>
          <dependent id="19">House</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">have</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">have</governor>
          <dependent id="21">say</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">close</governor>
          <dependent id="22">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="24">close</governor>
          <dependent id="23">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">say</governor>
          <dependent id="24">close</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">finishing</governor>
          <dependent id="25">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="24">close</governor>
          <dependent id="26">finishing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">screenplay</governor>
          <dependent id="27">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">finishing</governor>
          <dependent id="28">screenplay</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="32">expected</governor>
          <dependent id="30">are</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="32">expected</governor>
          <dependent id="31">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="32">expected</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="34">monopolize</governor>
          <dependent id="33">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="32">expected</governor>
          <dependent id="34">monopolize</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="34">monopolize</governor>
          <dependent id="35">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">the</governor>
          <dependent id="36">telling</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">case</governor>
          <dependent id="37">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="41">case</governor>
          <dependent id="38">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="41">case</governor>
          <dependent id="39">6-year-old</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="41">case</governor>
          <dependent id="40">McMartin</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">the</governor>
          <dependent id="41">case</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="35">the</governor>
          <dependent id="43">or</dependent>
        </dependency>
        <dependency type="det">
          <governor id="45">perspective</governor>
          <dependent id="44">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="35">the</governor>
          <dependent id="45">perspective</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="McMartin" type="PERSON" score="0.0">
          <tokens>
            <token id="40" string="McMartin" />
          </tokens>
        </entity>
        <entity id="2" string="6-year-old" type="DURATION" score="0.0">
          <tokens>
            <token id="39" string="6-year-old" />
          </tokens>
        </entity>
        <entity id="3" string="Mann" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Mann" />
          </tokens>
        </entity>
        <entity id="4" string="Random House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="18" string="Random" />
            <token id="19" string="House" />
          </tokens>
        </entity>
        <entity id="5" string="Myra" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Myra" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>At least two other books are planned, and at least one prominent television movie producer besides Mann says he is developing a McMartin project.</content>
      <tokens>
        <token id="1" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="least" lemma="least" stem="least" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="4" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="planned" lemma="plan" stem="plan" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="least" lemma="least" stem="least" pos="JJS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="13" string="prominent" lemma="prominent" stem="promin" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="movie" lemma="movie" stem="movi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="producer" lemma="producer" stem="produc" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="besides" lemma="besides" stem="besid" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="Mann" lemma="Mann" stem="mann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="19" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="developing" lemma="develop" stem="develop" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="project" lemma="project" stem="project" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (QP (IN At) (JJS least) (CD two)) (JJ other) (NNS books)) (VP (VBP are) (VP (VBN planned)))) (, ,) (CC and) (S (NP (NP (NP (QP (IN at) (JJS least) (CD one)) (JJ prominent) (NN television) (NN movie)) (NN producer)) (PP (IN besides) (NP (NNP Mann)))) (VP (VBZ says) (SBAR (S (NP (PRP he)) (VP (VBZ is) (VP (VBG developing) (NP (DT a) (NNP McMartin) (NN project)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is developing a McMartin project" type="VP">
          <tokens>
            <token id="21" string="is" />
            <token id="22" string="developing" />
            <token id="23" string="a" />
            <token id="24" string="McMartin" />
            <token id="25" string="project" />
          </tokens>
        </chunking>
        <chunking id="2" string="are planned" type="VP">
          <tokens>
            <token id="6" string="are" />
            <token id="7" string="planned" />
          </tokens>
        </chunking>
        <chunking id="3" string="at least one prominent television movie producer" type="NP">
          <tokens>
            <token id="10" string="at" />
            <token id="11" string="least" />
            <token id="12" string="one" />
            <token id="13" string="prominent" />
            <token id="14" string="television" />
            <token id="15" string="movie" />
            <token id="16" string="producer" />
          </tokens>
        </chunking>
        <chunking id="4" string="says he is developing a McMartin project" type="VP">
          <tokens>
            <token id="19" string="says" />
            <token id="20" string="he" />
            <token id="21" string="is" />
            <token id="22" string="developing" />
            <token id="23" string="a" />
            <token id="24" string="McMartin" />
            <token id="25" string="project" />
          </tokens>
        </chunking>
        <chunking id="5" string="he is developing a McMartin project" type="SBAR">
          <tokens>
            <token id="20" string="he" />
            <token id="21" string="is" />
            <token id="22" string="developing" />
            <token id="23" string="a" />
            <token id="24" string="McMartin" />
            <token id="25" string="project" />
          </tokens>
        </chunking>
        <chunking id="6" string="at least one prominent television movie" type="NP">
          <tokens>
            <token id="10" string="at" />
            <token id="11" string="least" />
            <token id="12" string="one" />
            <token id="13" string="prominent" />
            <token id="14" string="television" />
            <token id="15" string="movie" />
          </tokens>
        </chunking>
        <chunking id="7" string="planned" type="VP">
          <tokens>
            <token id="7" string="planned" />
          </tokens>
        </chunking>
        <chunking id="8" string="developing a McMartin project" type="VP">
          <tokens>
            <token id="22" string="developing" />
            <token id="23" string="a" />
            <token id="24" string="McMartin" />
            <token id="25" string="project" />
          </tokens>
        </chunking>
        <chunking id="9" string="at least one prominent television movie producer besides Mann" type="NP">
          <tokens>
            <token id="10" string="at" />
            <token id="11" string="least" />
            <token id="12" string="one" />
            <token id="13" string="prominent" />
            <token id="14" string="television" />
            <token id="15" string="movie" />
            <token id="16" string="producer" />
            <token id="17" string="besides" />
            <token id="18" string="Mann" />
          </tokens>
        </chunking>
        <chunking id="10" string="Mann" type="NP">
          <tokens>
            <token id="18" string="Mann" />
          </tokens>
        </chunking>
        <chunking id="11" string="a McMartin project" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="McMartin" />
            <token id="25" string="project" />
          </tokens>
        </chunking>
        <chunking id="12" string="At least two other books" type="NP">
          <tokens>
            <token id="1" string="At" />
            <token id="2" string="least" />
            <token id="3" string="two" />
            <token id="4" string="other" />
            <token id="5" string="books" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="20" string="he" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">least</governor>
          <dependent id="1">At</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="3">two</governor>
          <dependent id="2">least</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">books</governor>
          <dependent id="3">two</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">books</governor>
          <dependent id="4">other</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">planned</governor>
          <dependent id="5">books</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">planned</governor>
          <dependent id="6">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">planned</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">planned</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">least</governor>
          <dependent id="10">at</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="12">one</governor>
          <dependent id="11">least</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">movie</governor>
          <dependent id="12">one</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">movie</governor>
          <dependent id="13">prominent</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">movie</governor>
          <dependent id="14">television</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">producer</governor>
          <dependent id="15">movie</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">says</governor>
          <dependent id="16">producer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Mann</governor>
          <dependent id="17">besides</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">producer</governor>
          <dependent id="18">Mann</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">planned</governor>
          <dependent id="19">says</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">developing</governor>
          <dependent id="20">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">developing</governor>
          <dependent id="21">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">says</governor>
          <dependent id="22">developing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">project</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">project</governor>
          <dependent id="24">McMartin</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">developing</governor>
          <dependent id="25">project</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="Mann" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Mann" />
          </tokens>
        </entity>
        <entity id="3" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>That producer, who requested anonymity, said he is certain other producers are considering projects as well.</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="producer" lemma="producer" stem="produc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="requested" lemma="request" stem="request" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="anonymity" lemma="anonymity" stem="anonym" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="certain" lemma="certain" stem="certain" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="producers" lemma="producer" stem="produc" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="considering" lemma="consider" stem="consid" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="projects" lemma="project" stem="project" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT That) (NN producer)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD requested) (NP (NN anonymity))))) (, ,)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBZ is) (ADJP (JJ certain) (SBAR (S (NP (JJ other) (NNS producers)) (VP (VBP are) (VP (VBG considering) (NP (NNS projects)) (ADVP (RB as) (RB well))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="said he is certain other producers are considering projects as well" type="VP">
          <tokens>
            <token id="8" string="said" />
            <token id="9" string="he" />
            <token id="10" string="is" />
            <token id="11" string="certain" />
            <token id="12" string="other" />
            <token id="13" string="producers" />
            <token id="14" string="are" />
            <token id="15" string="considering" />
            <token id="16" string="projects" />
            <token id="17" string="as" />
            <token id="18" string="well" />
          </tokens>
        </chunking>
        <chunking id="2" string="projects" type="NP">
          <tokens>
            <token id="16" string="projects" />
          </tokens>
        </chunking>
        <chunking id="3" string="are considering projects as well" type="VP">
          <tokens>
            <token id="14" string="are" />
            <token id="15" string="considering" />
            <token id="16" string="projects" />
            <token id="17" string="as" />
            <token id="18" string="well" />
          </tokens>
        </chunking>
        <chunking id="4" string="requested anonymity" type="VP">
          <tokens>
            <token id="5" string="requested" />
            <token id="6" string="anonymity" />
          </tokens>
        </chunking>
        <chunking id="5" string="That producer , who requested anonymity ," type="NP">
          <tokens>
            <token id="1" string="That" />
            <token id="2" string="producer" />
            <token id="3" string="," />
            <token id="4" string="who" />
            <token id="5" string="requested" />
            <token id="6" string="anonymity" />
            <token id="7" string="," />
          </tokens>
        </chunking>
        <chunking id="6" string="certain other producers are considering projects as well" type="ADJP">
          <tokens>
            <token id="11" string="certain" />
            <token id="12" string="other" />
            <token id="13" string="producers" />
            <token id="14" string="are" />
            <token id="15" string="considering" />
            <token id="16" string="projects" />
            <token id="17" string="as" />
            <token id="18" string="well" />
          </tokens>
        </chunking>
        <chunking id="7" string="other producers" type="NP">
          <tokens>
            <token id="12" string="other" />
            <token id="13" string="producers" />
          </tokens>
        </chunking>
        <chunking id="8" string="anonymity" type="NP">
          <tokens>
            <token id="6" string="anonymity" />
          </tokens>
        </chunking>
        <chunking id="9" string="That producer" type="NP">
          <tokens>
            <token id="1" string="That" />
            <token id="2" string="producer" />
          </tokens>
        </chunking>
        <chunking id="10" string="who requested anonymity" type="SBAR">
          <tokens>
            <token id="4" string="who" />
            <token id="5" string="requested" />
            <token id="6" string="anonymity" />
          </tokens>
        </chunking>
        <chunking id="11" string="he is certain other producers are considering projects as well" type="SBAR">
          <tokens>
            <token id="9" string="he" />
            <token id="10" string="is" />
            <token id="11" string="certain" />
            <token id="12" string="other" />
            <token id="13" string="producers" />
            <token id="14" string="are" />
            <token id="15" string="considering" />
            <token id="16" string="projects" />
            <token id="17" string="as" />
            <token id="18" string="well" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="9" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="considering projects as well" type="VP">
          <tokens>
            <token id="15" string="considering" />
            <token id="16" string="projects" />
            <token id="17" string="as" />
            <token id="18" string="well" />
          </tokens>
        </chunking>
        <chunking id="14" string="is certain other producers are considering projects as well" type="VP">
          <tokens>
            <token id="10" string="is" />
            <token id="11" string="certain" />
            <token id="12" string="other" />
            <token id="13" string="producers" />
            <token id="14" string="are" />
            <token id="15" string="considering" />
            <token id="16" string="projects" />
            <token id="17" string="as" />
            <token id="18" string="well" />
          </tokens>
        </chunking>
        <chunking id="15" string="other producers are considering projects as well" type="SBAR">
          <tokens>
            <token id="12" string="other" />
            <token id="13" string="producers" />
            <token id="14" string="are" />
            <token id="15" string="considering" />
            <token id="16" string="projects" />
            <token id="17" string="as" />
            <token id="18" string="well" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">producer</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">said</governor>
          <dependent id="2">producer</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">requested</governor>
          <dependent id="4">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">producer</governor>
          <dependent id="5">requested</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">requested</governor>
          <dependent id="6">anonymity</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">certain</governor>
          <dependent id="9">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">certain</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">said</governor>
          <dependent id="11">certain</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">producers</governor>
          <dependent id="12">other</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">considering</governor>
          <dependent id="13">producers</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">considering</governor>
          <dependent id="14">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">certain</governor>
          <dependent id="15">considering</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">considering</governor>
          <dependent id="16">projects</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">considering</governor>
          <dependent id="17">as</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="17">as</governor>
          <dependent id="18">well</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>&amp;quot;It&amp;apost;s definitely a TV thing,&amp;quot; one agent said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="definitely" lemma="definitely" stem="definit" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="TV" lemma="tv" stem="tv" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="thing" lemma="thing" stem="thing" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="11" string="agent" lemma="agent" stem="agent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP It)) (VP (VBZ 's) (ADVP (RB definitely)) (NP (DT a) (NN TV) (NN thing)))) (, ,) ('' '') (NP (CD one) (NN agent)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a TV thing" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="TV" />
            <token id="7" string="thing" />
          </tokens>
        </chunking>
        <chunking id="2" string="'s definitely a TV thing" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="definitely" />
            <token id="5" string="a" />
            <token id="6" string="TV" />
            <token id="7" string="thing" />
          </tokens>
        </chunking>
        <chunking id="3" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="4" string="said" type="VP">
          <tokens>
            <token id="12" string="said" />
          </tokens>
        </chunking>
        <chunking id="5" string="one agent" type="NP">
          <tokens>
            <token id="10" string="one" />
            <token id="11" string="agent" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">thing</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">thing</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">thing</governor>
          <dependent id="4">definitely</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">thing</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">thing</governor>
          <dependent id="6">TV</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">said</governor>
          <dependent id="7">thing</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">agent</governor>
          <dependent id="10">one</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">said</governor>
          <dependent id="11">agent</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>&amp;quot;Just one of those perfect, high-concept, lurid television M-O-Ws&amp;quot; -- an acronym for movies-of-the-week.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="Just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="perfect" lemma="perfect" stem="perfect" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="high-concept" lemma="high-concept" stem="high-concept" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="lurid" lemma="lurid" stem="lurid" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="M-O-Ws" lemma="m-o-ws" stem="m-o-w" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="acronym" lemma="acronym" stem="acronym" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="movies-of-the-week" lemma="movies-of-the-week" stem="movies-of-the-week" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (`` ``) (NP (RB Just) (CD one)) (PP (IN of) (NP (DT those) (JJ perfect) (, ,) (JJ high-concept) (, ,) (JJ lurid) (NN television) (NN M-O-Ws))) ('' '')) (: --) (NP (NP (DT an) (NN acronym)) (PP (IN for) (NP (NN movies-of-the-week)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="`` Just one of those perfect , high-concept , lurid television M-O-Ws '' -- an acronym for movies-of-the-week ." type="NP">
          <tokens>
            <token id="1" string="&quot;" />
            <token id="2" string="Just" />
            <token id="3" string="one" />
            <token id="4" string="of" />
            <token id="5" string="those" />
            <token id="6" string="perfect" />
            <token id="7" string="," />
            <token id="8" string="high-concept" />
            <token id="9" string="," />
            <token id="10" string="lurid" />
            <token id="11" string="television" />
            <token id="12" string="M-O-Ws" />
            <token id="13" string="&quot;" />
            <token id="14" string="--" />
            <token id="15" string="an" />
            <token id="16" string="acronym" />
            <token id="17" string="for" />
            <token id="18" string="movies-of-the-week" />
            <token id="19" string="." />
          </tokens>
        </chunking>
        <chunking id="2" string="Just one" type="NP">
          <tokens>
            <token id="2" string="Just" />
            <token id="3" string="one" />
          </tokens>
        </chunking>
        <chunking id="3" string="an acronym for movies-of-the-week" type="NP">
          <tokens>
            <token id="15" string="an" />
            <token id="16" string="acronym" />
            <token id="17" string="for" />
            <token id="18" string="movies-of-the-week" />
          </tokens>
        </chunking>
        <chunking id="4" string="an acronym" type="NP">
          <tokens>
            <token id="15" string="an" />
            <token id="16" string="acronym" />
          </tokens>
        </chunking>
        <chunking id="5" string="those perfect , high-concept , lurid television M-O-Ws" type="NP">
          <tokens>
            <token id="5" string="those" />
            <token id="6" string="perfect" />
            <token id="7" string="," />
            <token id="8" string="high-concept" />
            <token id="9" string="," />
            <token id="10" string="lurid" />
            <token id="11" string="television" />
            <token id="12" string="M-O-Ws" />
          </tokens>
        </chunking>
        <chunking id="6" string="movies-of-the-week" type="NP">
          <tokens>
            <token id="18" string="movies-of-the-week" />
          </tokens>
        </chunking>
        <chunking id="7" string="`` Just one of those perfect , high-concept , lurid television M-O-Ws ''" type="NP">
          <tokens>
            <token id="1" string="&quot;" />
            <token id="2" string="Just" />
            <token id="3" string="one" />
            <token id="4" string="of" />
            <token id="5" string="those" />
            <token id="6" string="perfect" />
            <token id="7" string="," />
            <token id="8" string="high-concept" />
            <token id="9" string="," />
            <token id="10" string="lurid" />
            <token id="11" string="television" />
            <token id="12" string="M-O-Ws" />
            <token id="13" string="&quot;" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">one</governor>
          <dependent id="2">Just</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">M-O-Ws</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">M-O-Ws</governor>
          <dependent id="5">those</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">M-O-Ws</governor>
          <dependent id="6">perfect</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">M-O-Ws</governor>
          <dependent id="8">high-concept</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">M-O-Ws</governor>
          <dependent id="10">lurid</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">M-O-Ws</governor>
          <dependent id="11">television</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">one</governor>
          <dependent id="12">M-O-Ws</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">acronym</governor>
          <dependent id="15">an</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">one</governor>
          <dependent id="16">acronym</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">movies-of-the-week</governor>
          <dependent id="17">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">acronym</governor>
          <dependent id="18">movies-of-the-week</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>&amp;quot;The producer chases down participants, gets rights -- and then it&amp;apost;s an easy sale to networks.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="producer" lemma="producer" stem="produc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="chases" lemma="chase" stem="chase" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="down" lemma="down" stem="down" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="participants" lemma="participant" stem="particip" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="gets" lemma="get" stem="get" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="rights" lemma="rights" stem="right" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="easy" lemma="easy" stem="easi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="sale" lemma="sale" stem="sale" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="networks" lemma="network" stem="network" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (DT The) (NN producer)) (VP (VP (VBZ chases) (PRT (RP down)) (NP (NNS participants))) (, ,) (VP (VBZ gets) (NP (NNS rights))))) (: --) (CC and) (ADVP (RB then)) (S (NP (PRP it)) (VP (VBZ 's) (NP (NP (DT an) (JJ easy) (NN sale)) (PP (TO to) (NP (NNS networks)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="participants" type="NP">
          <tokens>
            <token id="6" string="participants" />
          </tokens>
        </chunking>
        <chunking id="2" string="chases down participants" type="VP">
          <tokens>
            <token id="4" string="chases" />
            <token id="5" string="down" />
            <token id="6" string="participants" />
          </tokens>
        </chunking>
        <chunking id="3" string="an easy sale" type="NP">
          <tokens>
            <token id="15" string="an" />
            <token id="16" string="easy" />
            <token id="17" string="sale" />
          </tokens>
        </chunking>
        <chunking id="4" string="The producer" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="producer" />
          </tokens>
        </chunking>
        <chunking id="5" string="rights" type="NP">
          <tokens>
            <token id="9" string="rights" />
          </tokens>
        </chunking>
        <chunking id="6" string="gets rights" type="VP">
          <tokens>
            <token id="8" string="gets" />
            <token id="9" string="rights" />
          </tokens>
        </chunking>
        <chunking id="7" string="'s an easy sale to networks" type="VP">
          <tokens>
            <token id="14" string="'s" />
            <token id="15" string="an" />
            <token id="16" string="easy" />
            <token id="17" string="sale" />
            <token id="18" string="to" />
            <token id="19" string="networks" />
          </tokens>
        </chunking>
        <chunking id="8" string="it" type="NP">
          <tokens>
            <token id="13" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="networks" type="NP">
          <tokens>
            <token id="19" string="networks" />
          </tokens>
        </chunking>
        <chunking id="10" string="an easy sale to networks" type="NP">
          <tokens>
            <token id="15" string="an" />
            <token id="16" string="easy" />
            <token id="17" string="sale" />
            <token id="18" string="to" />
            <token id="19" string="networks" />
          </tokens>
        </chunking>
        <chunking id="11" string="chases down participants , gets rights" type="VP">
          <tokens>
            <token id="4" string="chases" />
            <token id="5" string="down" />
            <token id="6" string="participants" />
            <token id="7" string="," />
            <token id="8" string="gets" />
            <token id="9" string="rights" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">producer</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">chases</governor>
          <dependent id="3">producer</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">chases</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="4">chases</governor>
          <dependent id="5">down</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">chases</governor>
          <dependent id="6">participants</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">chases</governor>
          <dependent id="8">gets</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">gets</governor>
          <dependent id="9">rights</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">chases</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">sale</governor>
          <dependent id="12">then</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">sale</governor>
          <dependent id="13">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">sale</governor>
          <dependent id="14">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">sale</governor>
          <dependent id="15">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">sale</governor>
          <dependent id="16">easy</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">chases</governor>
          <dependent id="17">sale</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">networks</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">sale</governor>
          <dependent id="19">networks</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="14" has_coreference="false">
      <content>Not that easy, network executives say.</content>
      <tokens>
        <token id="1" string="Not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="easy" lemma="easy" stem="easi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="network" lemma="network" stem="network" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="executives" lemma="executive" stem="execut" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (FRAG (RB Not) (ADJP (WHADVP (IN that)) (JJ easy))) (, ,) (NP (NN network) (NNS executives)) (VP (VBP say)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that" type="WHADVP">
          <tokens>
            <token id="2" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="network executives" type="NP">
          <tokens>
            <token id="5" string="network" />
            <token id="6" string="executives" />
          </tokens>
        </chunking>
        <chunking id="3" string="that easy" type="ADJP">
          <tokens>
            <token id="2" string="that" />
            <token id="3" string="easy" />
          </tokens>
        </chunking>
        <chunking id="4" string="say" type="VP">
          <tokens>
            <token id="7" string="say" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="7">say</governor>
          <dependent id="1">Not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">easy</governor>
          <dependent id="2">that</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">Not</governor>
          <dependent id="3">easy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">executives</governor>
          <dependent id="5">network</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">say</governor>
          <dependent id="6">executives</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">say</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>Unlike the hottest true-life property of the moment -- the Stuart murder case in Boston, which has CBS and The Fries Co. racing to produce the first docudrama -- McMartin creates some tricky legal and moral problems.</content>
      <tokens>
        <token id="1" string="Unlike" lemma="unlike" stem="unlike" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="hottest" lemma="hottest" stem="hottest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="true-life" lemma="true-life" stem="true-lif" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="property" lemma="property" stem="properti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="moment" lemma="moment" stem="moment" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Stuart" lemma="Stuart" stem="stuart" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="murder" lemma="murder" stem="murder" pos="NN" type="Word" isStopWord="false" ner="CRIMINAL_CHARGE" is_referenced="false" is_refers="false" />
        <token id="13" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Boston" lemma="Boston" stem="boston" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="CBS" lemma="CBS" stem="cbs" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="22" string="Fries" lemma="Fries" stem="fri" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="23" string="Co." lemma="Co." stem="co." pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="24" string="racing" lemma="race" stem="race" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="produce" lemma="produce" stem="produc" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="29" string="docudrama" lemma="docudrama" stem="docudrama" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="32" string="creates" lemma="create" stem="creat" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="tricky" lemma="tricky" stem="tricki" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="legal" lemma="legal" stem="legal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="moral" lemma="moral" stem="moral" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="problems" lemma="problem" stem="problem" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Unlike) (NP (NP (DT the) (JJS hottest) (JJ true-life) (NN property)) (PP (IN of) (NP (DT the) (NN moment))) (PRN (: --) (NP (NP (DT the) (NNP Stuart) (NN murder) (NN case)) (PP (IN in) (NP (NP (NNP Boston)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ has) (NP (NP (NNP CBS)) (CC and) (NP (NP (DT The) (NNP Fries) (NNP Co.)) (VP (VBG racing) (S (VP (TO to) (VP (VB produce) (NP (DT the) (JJ first) (NN docudrama)))))))))))))) (: --)))) (NP (NNP McMartin)) (VP (VBZ creates) (NP (DT some) (JJ tricky) (ADJP (JJ legal) (CC and) (JJ moral)) (NNS problems))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Boston , which has CBS and The Fries Co. racing to produce the first docudrama" type="NP">
          <tokens>
            <token id="15" string="Boston" />
            <token id="16" string="," />
            <token id="17" string="which" />
            <token id="18" string="has" />
            <token id="19" string="CBS" />
            <token id="20" string="and" />
            <token id="21" string="The" />
            <token id="22" string="Fries" />
            <token id="23" string="Co." />
            <token id="24" string="racing" />
            <token id="25" string="to" />
            <token id="26" string="produce" />
            <token id="27" string="the" />
            <token id="28" string="first" />
            <token id="29" string="docudrama" />
          </tokens>
        </chunking>
        <chunking id="2" string="the hottest true-life property of the moment -- the Stuart murder case in Boston , which has CBS and The Fries Co. racing to produce the first docudrama --" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="hottest" />
            <token id="4" string="true-life" />
            <token id="5" string="property" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="moment" />
            <token id="9" string="--" />
            <token id="10" string="the" />
            <token id="11" string="Stuart" />
            <token id="12" string="murder" />
            <token id="13" string="case" />
            <token id="14" string="in" />
            <token id="15" string="Boston" />
            <token id="16" string="," />
            <token id="17" string="which" />
            <token id="18" string="has" />
            <token id="19" string="CBS" />
            <token id="20" string="and" />
            <token id="21" string="The" />
            <token id="22" string="Fries" />
            <token id="23" string="Co." />
            <token id="24" string="racing" />
            <token id="25" string="to" />
            <token id="26" string="produce" />
            <token id="27" string="the" />
            <token id="28" string="first" />
            <token id="29" string="docudrama" />
            <token id="30" string="--" />
          </tokens>
        </chunking>
        <chunking id="3" string="The Fries Co. racing to produce the first docudrama" type="NP">
          <tokens>
            <token id="21" string="The" />
            <token id="22" string="Fries" />
            <token id="23" string="Co." />
            <token id="24" string="racing" />
            <token id="25" string="to" />
            <token id="26" string="produce" />
            <token id="27" string="the" />
            <token id="28" string="first" />
            <token id="29" string="docudrama" />
          </tokens>
        </chunking>
        <chunking id="4" string="McMartin" type="NP">
          <tokens>
            <token id="31" string="McMartin" />
          </tokens>
        </chunking>
        <chunking id="5" string="legal and moral" type="ADJP">
          <tokens>
            <token id="35" string="legal" />
            <token id="36" string="and" />
            <token id="37" string="moral" />
          </tokens>
        </chunking>
        <chunking id="6" string="has CBS and The Fries Co. racing to produce the first docudrama" type="VP">
          <tokens>
            <token id="18" string="has" />
            <token id="19" string="CBS" />
            <token id="20" string="and" />
            <token id="21" string="The" />
            <token id="22" string="Fries" />
            <token id="23" string="Co." />
            <token id="24" string="racing" />
            <token id="25" string="to" />
            <token id="26" string="produce" />
            <token id="27" string="the" />
            <token id="28" string="first" />
            <token id="29" string="docudrama" />
          </tokens>
        </chunking>
        <chunking id="7" string="The Fries Co." type="NP">
          <tokens>
            <token id="21" string="The" />
            <token id="22" string="Fries" />
            <token id="23" string="Co." />
          </tokens>
        </chunking>
        <chunking id="8" string="the Stuart murder case in Boston , which has CBS and The Fries Co. racing to produce the first docudrama" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="Stuart" />
            <token id="12" string="murder" />
            <token id="13" string="case" />
            <token id="14" string="in" />
            <token id="15" string="Boston" />
            <token id="16" string="," />
            <token id="17" string="which" />
            <token id="18" string="has" />
            <token id="19" string="CBS" />
            <token id="20" string="and" />
            <token id="21" string="The" />
            <token id="22" string="Fries" />
            <token id="23" string="Co." />
            <token id="24" string="racing" />
            <token id="25" string="to" />
            <token id="26" string="produce" />
            <token id="27" string="the" />
            <token id="28" string="first" />
            <token id="29" string="docudrama" />
          </tokens>
        </chunking>
        <chunking id="9" string="creates some tricky legal and moral problems" type="VP">
          <tokens>
            <token id="32" string="creates" />
            <token id="33" string="some" />
            <token id="34" string="tricky" />
            <token id="35" string="legal" />
            <token id="36" string="and" />
            <token id="37" string="moral" />
            <token id="38" string="problems" />
          </tokens>
        </chunking>
        <chunking id="10" string="which has CBS and The Fries Co. racing to produce the first docudrama" type="SBAR">
          <tokens>
            <token id="17" string="which" />
            <token id="18" string="has" />
            <token id="19" string="CBS" />
            <token id="20" string="and" />
            <token id="21" string="The" />
            <token id="22" string="Fries" />
            <token id="23" string="Co." />
            <token id="24" string="racing" />
            <token id="25" string="to" />
            <token id="26" string="produce" />
            <token id="27" string="the" />
            <token id="28" string="first" />
            <token id="29" string="docudrama" />
          </tokens>
        </chunking>
        <chunking id="11" string="some tricky legal and moral problems" type="NP">
          <tokens>
            <token id="33" string="some" />
            <token id="34" string="tricky" />
            <token id="35" string="legal" />
            <token id="36" string="and" />
            <token id="37" string="moral" />
            <token id="38" string="problems" />
          </tokens>
        </chunking>
        <chunking id="12" string="racing to produce the first docudrama" type="VP">
          <tokens>
            <token id="24" string="racing" />
            <token id="25" string="to" />
            <token id="26" string="produce" />
            <token id="27" string="the" />
            <token id="28" string="first" />
            <token id="29" string="docudrama" />
          </tokens>
        </chunking>
        <chunking id="13" string="the moment" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="moment" />
          </tokens>
        </chunking>
        <chunking id="14" string="CBS" type="NP">
          <tokens>
            <token id="19" string="CBS" />
          </tokens>
        </chunking>
        <chunking id="15" string="the hottest true-life property" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="hottest" />
            <token id="4" string="true-life" />
            <token id="5" string="property" />
          </tokens>
        </chunking>
        <chunking id="16" string="CBS and The Fries Co. racing to produce the first docudrama" type="NP">
          <tokens>
            <token id="19" string="CBS" />
            <token id="20" string="and" />
            <token id="21" string="The" />
            <token id="22" string="Fries" />
            <token id="23" string="Co." />
            <token id="24" string="racing" />
            <token id="25" string="to" />
            <token id="26" string="produce" />
            <token id="27" string="the" />
            <token id="28" string="first" />
            <token id="29" string="docudrama" />
          </tokens>
        </chunking>
        <chunking id="17" string="the first docudrama" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="first" />
            <token id="29" string="docudrama" />
          </tokens>
        </chunking>
        <chunking id="18" string="the Stuart murder case" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="Stuart" />
            <token id="12" string="murder" />
            <token id="13" string="case" />
          </tokens>
        </chunking>
        <chunking id="19" string="produce the first docudrama" type="VP">
          <tokens>
            <token id="26" string="produce" />
            <token id="27" string="the" />
            <token id="28" string="first" />
            <token id="29" string="docudrama" />
          </tokens>
        </chunking>
        <chunking id="20" string="Boston" type="NP">
          <tokens>
            <token id="15" string="Boston" />
          </tokens>
        </chunking>
        <chunking id="21" string="to produce the first docudrama" type="VP">
          <tokens>
            <token id="25" string="to" />
            <token id="26" string="produce" />
            <token id="27" string="the" />
            <token id="28" string="first" />
            <token id="29" string="docudrama" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">property</governor>
          <dependent id="1">Unlike</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">property</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">property</governor>
          <dependent id="3">hottest</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">property</governor>
          <dependent id="4">true-life</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">creates</governor>
          <dependent id="5">property</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">moment</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">moment</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">property</governor>
          <dependent id="8">moment</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">case</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">case</governor>
          <dependent id="11">Stuart</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">case</governor>
          <dependent id="12">murder</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">property</governor>
          <dependent id="13">case</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Boston</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">case</governor>
          <dependent id="15">Boston</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">has</governor>
          <dependent id="17">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">Boston</governor>
          <dependent id="18">has</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">has</governor>
          <dependent id="19">CBS</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">CBS</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">Co.</governor>
          <dependent id="21">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Co.</governor>
          <dependent id="22">Fries</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">CBS</governor>
          <dependent id="23">Co.</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="23">Co.</governor>
          <dependent id="24">racing</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">produce</governor>
          <dependent id="25">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="24">racing</governor>
          <dependent id="26">produce</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">docudrama</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">docudrama</governor>
          <dependent id="28">first</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">produce</governor>
          <dependent id="29">docudrama</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">creates</governor>
          <dependent id="31">McMartin</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="32">creates</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">problems</governor>
          <dependent id="33">some</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">problems</governor>
          <dependent id="34">tricky</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">problems</governor>
          <dependent id="35">legal</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="35">legal</governor>
          <dependent id="36">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="35">legal</governor>
          <dependent id="37">moral</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="32">creates</governor>
          <dependent id="38">problems</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="murder" type="CRIMINAL_CHARGE" score="0.0">
          <tokens>
            <token id="12" string="murder" />
          </tokens>
        </entity>
        <entity id="2" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="28" string="first" />
          </tokens>
        </entity>
        <entity id="3" string="CBS" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="19" string="CBS" />
          </tokens>
        </entity>
        <entity id="4" string="Stuart" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Stuart" />
          </tokens>
        </entity>
        <entity id="5" string="The Fries Co." type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="21" string="The" />
            <token id="22" string="Fries" />
            <token id="23" string="Co." />
          </tokens>
        </entity>
        <entity id="6" string="Boston" type="LOCATION" score="0.0">
          <tokens>
            <token id="15" string="Boston" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>The jury&amp;apost;s deadlock on 13 counts creates an ambiguity: Is Ray Buckey a villain or a victim?</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="jury" lemma="jury" stem="juri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="deadlock" lemma="deadlock" stem="deadlock" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="13" lemma="13" stem="13" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="7" string="counts" lemma="count" stem="count" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="creates" lemma="create" stem="creat" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="ambiguity" lemma="ambiguity" stem="ambigu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Ray" lemma="Ray" stem="rai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="villain" lemma="villain" stem="villain" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="victim" lemma="victim" stem="victim" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (DT The) (NN jury) (POS 's)) (NN deadlock)) (PP (IN on) (NP (CD 13) (NNS counts)))) (VP (VBZ creates) (NP (NP (DT an) (NN ambiguity)) (: :) (SQ (VBZ Is) (NP (NP (NNP Ray) (NNP Buckey)) (NP (NP (DT a) (NN villain)) (CC or) (NP (DT a) (NN victim))))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="creates an ambiguity : Is Ray Buckey a villain or a victim" type="VP">
          <tokens>
            <token id="8" string="creates" />
            <token id="9" string="an" />
            <token id="10" string="ambiguity" />
            <token id="11" string=":" />
            <token id="12" string="Is" />
            <token id="13" string="Ray" />
            <token id="14" string="Buckey" />
            <token id="15" string="a" />
            <token id="16" string="villain" />
            <token id="17" string="or" />
            <token id="18" string="a" />
            <token id="19" string="victim" />
          </tokens>
        </chunking>
        <chunking id="2" string="a villain or a victim" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="villain" />
            <token id="17" string="or" />
            <token id="18" string="a" />
            <token id="19" string="victim" />
          </tokens>
        </chunking>
        <chunking id="3" string="The jury 's deadlock" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="jury" />
            <token id="3" string="'s" />
            <token id="4" string="deadlock" />
          </tokens>
        </chunking>
        <chunking id="4" string="The jury 's deadlock on 13 counts" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="jury" />
            <token id="3" string="'s" />
            <token id="4" string="deadlock" />
            <token id="5" string="on" />
            <token id="6" string="13" />
            <token id="7" string="counts" />
          </tokens>
        </chunking>
        <chunking id="5" string="The jury 's" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="jury" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="Ray Buckey a villain or a victim" type="NP">
          <tokens>
            <token id="13" string="Ray" />
            <token id="14" string="Buckey" />
            <token id="15" string="a" />
            <token id="16" string="villain" />
            <token id="17" string="or" />
            <token id="18" string="a" />
            <token id="19" string="victim" />
          </tokens>
        </chunking>
        <chunking id="7" string="a villain" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="villain" />
          </tokens>
        </chunking>
        <chunking id="8" string="an ambiguity : Is Ray Buckey a villain or a victim" type="NP">
          <tokens>
            <token id="9" string="an" />
            <token id="10" string="ambiguity" />
            <token id="11" string=":" />
            <token id="12" string="Is" />
            <token id="13" string="Ray" />
            <token id="14" string="Buckey" />
            <token id="15" string="a" />
            <token id="16" string="villain" />
            <token id="17" string="or" />
            <token id="18" string="a" />
            <token id="19" string="victim" />
          </tokens>
        </chunking>
        <chunking id="9" string="an ambiguity" type="NP">
          <tokens>
            <token id="9" string="an" />
            <token id="10" string="ambiguity" />
          </tokens>
        </chunking>
        <chunking id="10" string="Ray Buckey" type="NP">
          <tokens>
            <token id="13" string="Ray" />
            <token id="14" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="11" string="a victim" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="victim" />
          </tokens>
        </chunking>
        <chunking id="12" string="13 counts" type="NP">
          <tokens>
            <token id="6" string="13" />
            <token id="7" string="counts" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">jury</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">deadlock</governor>
          <dependent id="2">jury</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">jury</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">creates</governor>
          <dependent id="4">deadlock</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">counts</governor>
          <dependent id="5">on</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">counts</governor>
          <dependent id="6">13</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">deadlock</governor>
          <dependent id="7">counts</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">creates</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">ambiguity</governor>
          <dependent id="9">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">creates</governor>
          <dependent id="10">ambiguity</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">ambiguity</governor>
          <dependent id="12">Is</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Buckey</governor>
          <dependent id="13">Ray</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">Is</governor>
          <dependent id="14">Buckey</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">villain</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">Buckey</governor>
          <dependent id="16">villain</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">villain</governor>
          <dependent id="17">or</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">victim</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">villain</governor>
          <dependent id="19">victim</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="13" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="13" />
          </tokens>
        </entity>
        <entity id="2" string="Ray Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Ray" />
            <token id="14" string="Buckey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>&amp;quot;None of the three networks would touch Ray Buckey&amp;apost;s story,&amp;quot; predicted Steven White, an independent producer who used to be a movie executive for both NBC and ABC.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="None" lemma="none" stem="none" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="6" string="networks" lemma="network" stem="network" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="touch" lemma="touch" stem="touch" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Ray" lemma="Ray" stem="rai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="predicted" lemma="predict" stem="predict" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="Steven" lemma="Steven" stem="steven" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="17" string="White" lemma="White" stem="white" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="independent" lemma="independent" stem="independ" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="21" string="producer" lemma="producer" stem="produc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="used" lemma="use" stem="us" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="movie" lemma="movie" stem="movi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="executive" lemma="executive" stem="execut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="both" lemma="both" stem="both" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="NBC" lemma="NBC" stem="nbc" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="32" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="ABC" lemma="ABC" stem="abc" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (NP (NN None)) (PP (IN of) (NP (DT the) (CD three) (NNS networks)))) (VP (MD would) (VP (VB touch) (NP (NP (NNP Ray) (NNP Buckey) (POS 's)) (NN story))))) (, ,) ('' '') (VP (VBD predicted)) (NP (NP (NNP Steven) (NNP White)) (, ,) (NP (NP (DT an) (JJ independent) (NN producer)) (SBAR (WHNP (WP who)) (S (VP (VBD used) (S (VP (TO to) (VP (VB be) (NP (NP (DT a) (NN movie) (NN executive)) (PP (IN for) (NP (DT both) (NNP NBC) (CC and) (NNP ABC)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Ray Buckey 's story" type="NP">
          <tokens>
            <token id="9" string="Ray" />
            <token id="10" string="Buckey" />
            <token id="11" string="'s" />
            <token id="12" string="story" />
          </tokens>
        </chunking>
        <chunking id="2" string="Ray Buckey 's" type="NP">
          <tokens>
            <token id="9" string="Ray" />
            <token id="10" string="Buckey" />
            <token id="11" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="an independent producer who used to be a movie executive for both NBC and ABC" type="NP">
          <tokens>
            <token id="19" string="an" />
            <token id="20" string="independent" />
            <token id="21" string="producer" />
            <token id="22" string="who" />
            <token id="23" string="used" />
            <token id="24" string="to" />
            <token id="25" string="be" />
            <token id="26" string="a" />
            <token id="27" string="movie" />
            <token id="28" string="executive" />
            <token id="29" string="for" />
            <token id="30" string="both" />
            <token id="31" string="NBC" />
            <token id="32" string="and" />
            <token id="33" string="ABC" />
          </tokens>
        </chunking>
        <chunking id="4" string="to be a movie executive for both NBC and ABC" type="VP">
          <tokens>
            <token id="24" string="to" />
            <token id="25" string="be" />
            <token id="26" string="a" />
            <token id="27" string="movie" />
            <token id="28" string="executive" />
            <token id="29" string="for" />
            <token id="30" string="both" />
            <token id="31" string="NBC" />
            <token id="32" string="and" />
            <token id="33" string="ABC" />
          </tokens>
        </chunking>
        <chunking id="5" string="would touch Ray Buckey 's story" type="VP">
          <tokens>
            <token id="7" string="would" />
            <token id="8" string="touch" />
            <token id="9" string="Ray" />
            <token id="10" string="Buckey" />
            <token id="11" string="'s" />
            <token id="12" string="story" />
          </tokens>
        </chunking>
        <chunking id="6" string="a movie executive" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="movie" />
            <token id="28" string="executive" />
          </tokens>
        </chunking>
        <chunking id="7" string="the three networks" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="three" />
            <token id="6" string="networks" />
          </tokens>
        </chunking>
        <chunking id="8" string="Steven White , an independent producer who used to be a movie executive for both NBC and ABC" type="NP">
          <tokens>
            <token id="16" string="Steven" />
            <token id="17" string="White" />
            <token id="18" string="," />
            <token id="19" string="an" />
            <token id="20" string="independent" />
            <token id="21" string="producer" />
            <token id="22" string="who" />
            <token id="23" string="used" />
            <token id="24" string="to" />
            <token id="25" string="be" />
            <token id="26" string="a" />
            <token id="27" string="movie" />
            <token id="28" string="executive" />
            <token id="29" string="for" />
            <token id="30" string="both" />
            <token id="31" string="NBC" />
            <token id="32" string="and" />
            <token id="33" string="ABC" />
          </tokens>
        </chunking>
        <chunking id="9" string="predicted" type="VP">
          <tokens>
            <token id="15" string="predicted" />
          </tokens>
        </chunking>
        <chunking id="10" string="None" type="NP">
          <tokens>
            <token id="2" string="None" />
          </tokens>
        </chunking>
        <chunking id="11" string="be a movie executive for both NBC and ABC" type="VP">
          <tokens>
            <token id="25" string="be" />
            <token id="26" string="a" />
            <token id="27" string="movie" />
            <token id="28" string="executive" />
            <token id="29" string="for" />
            <token id="30" string="both" />
            <token id="31" string="NBC" />
            <token id="32" string="and" />
            <token id="33" string="ABC" />
          </tokens>
        </chunking>
        <chunking id="12" string="touch Ray Buckey 's story" type="VP">
          <tokens>
            <token id="8" string="touch" />
            <token id="9" string="Ray" />
            <token id="10" string="Buckey" />
            <token id="11" string="'s" />
            <token id="12" string="story" />
          </tokens>
        </chunking>
        <chunking id="13" string="who used to be a movie executive for both NBC and ABC" type="SBAR">
          <tokens>
            <token id="22" string="who" />
            <token id="23" string="used" />
            <token id="24" string="to" />
            <token id="25" string="be" />
            <token id="26" string="a" />
            <token id="27" string="movie" />
            <token id="28" string="executive" />
            <token id="29" string="for" />
            <token id="30" string="both" />
            <token id="31" string="NBC" />
            <token id="32" string="and" />
            <token id="33" string="ABC" />
          </tokens>
        </chunking>
        <chunking id="14" string="a movie executive for both NBC and ABC" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="movie" />
            <token id="28" string="executive" />
            <token id="29" string="for" />
            <token id="30" string="both" />
            <token id="31" string="NBC" />
            <token id="32" string="and" />
            <token id="33" string="ABC" />
          </tokens>
        </chunking>
        <chunking id="15" string="None of the three networks" type="NP">
          <tokens>
            <token id="2" string="None" />
            <token id="3" string="of" />
            <token id="4" string="the" />
            <token id="5" string="three" />
            <token id="6" string="networks" />
          </tokens>
        </chunking>
        <chunking id="16" string="an independent producer" type="NP">
          <tokens>
            <token id="19" string="an" />
            <token id="20" string="independent" />
            <token id="21" string="producer" />
          </tokens>
        </chunking>
        <chunking id="17" string="Steven White" type="NP">
          <tokens>
            <token id="16" string="Steven" />
            <token id="17" string="White" />
          </tokens>
        </chunking>
        <chunking id="18" string="used to be a movie executive for both NBC and ABC" type="VP">
          <tokens>
            <token id="23" string="used" />
            <token id="24" string="to" />
            <token id="25" string="be" />
            <token id="26" string="a" />
            <token id="27" string="movie" />
            <token id="28" string="executive" />
            <token id="29" string="for" />
            <token id="30" string="both" />
            <token id="31" string="NBC" />
            <token id="32" string="and" />
            <token id="33" string="ABC" />
          </tokens>
        </chunking>
        <chunking id="19" string="both NBC and ABC" type="NP">
          <tokens>
            <token id="30" string="both" />
            <token id="31" string="NBC" />
            <token id="32" string="and" />
            <token id="33" string="ABC" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="8">touch</governor>
          <dependent id="2">None</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">networks</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">networks</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">networks</governor>
          <dependent id="5">three</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">None</governor>
          <dependent id="6">networks</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">touch</governor>
          <dependent id="7">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">predicted</governor>
          <dependent id="8">touch</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Buckey</governor>
          <dependent id="9">Ray</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">story</governor>
          <dependent id="10">Buckey</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Buckey</governor>
          <dependent id="11">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">touch</governor>
          <dependent id="12">story</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">predicted</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">White</governor>
          <dependent id="16">Steven</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">predicted</governor>
          <dependent id="17">White</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">producer</governor>
          <dependent id="19">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">producer</governor>
          <dependent id="20">independent</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="17">White</governor>
          <dependent id="21">producer</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">used</governor>
          <dependent id="22">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="21">producer</governor>
          <dependent id="23">used</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">executive</governor>
          <dependent id="24">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="28">executive</governor>
          <dependent id="25">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">executive</governor>
          <dependent id="26">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">executive</governor>
          <dependent id="27">movie</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="23">used</governor>
          <dependent id="28">executive</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">NBC</governor>
          <dependent id="29">for</dependent>
        </dependency>
        <dependency type="cc:preconj">
          <governor id="31">NBC</governor>
          <dependent id="30">both</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">executive</governor>
          <dependent id="31">NBC</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="31">NBC</governor>
          <dependent id="32">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="31">NBC</governor>
          <dependent id="33">ABC</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="ABC" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="33" string="ABC" />
          </tokens>
        </entity>
        <entity id="2" string="independent" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="20" string="independent" />
          </tokens>
        </entity>
        <entity id="3" string="Steven White" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Steven" />
            <token id="17" string="White" />
          </tokens>
        </entity>
        <entity id="4" string="Ray Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Ray" />
            <token id="10" string="Buckey" />
          </tokens>
        </entity>
        <entity id="5" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="three" />
          </tokens>
        </entity>
        <entity id="6" string="NBC" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="31" string="NBC" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="false">
      <content>&amp;quot;First, the man is still accused of 13 crimes. . . .</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="First" lemma="first" stem="first" pos="RB" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="accused" lemma="accuse" stem="accus" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="13" lemma="13" stem="13" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="11" string="crimes" lemma="crime" stem="crime" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (ADVP (RB First)) (, ,) (NP (DT the) (NN man)) (VP (VBZ is) (ADVP (RB still)) (VP (VBN accused) (PP (IN of) (NP (CD 13) (NNS crimes))))) (: ...) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the man" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="man" />
          </tokens>
        </chunking>
        <chunking id="2" string="accused of 13 crimes" type="VP">
          <tokens>
            <token id="8" string="accused" />
            <token id="9" string="of" />
            <token id="10" string="13" />
            <token id="11" string="crimes" />
          </tokens>
        </chunking>
        <chunking id="3" string="is still accused of 13 crimes" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="still" />
            <token id="8" string="accused" />
            <token id="9" string="of" />
            <token id="10" string="13" />
            <token id="11" string="crimes" />
          </tokens>
        </chunking>
        <chunking id="4" string="13 crimes" type="NP">
          <tokens>
            <token id="10" string="13" />
            <token id="11" string="crimes" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="8">accused</governor>
          <dependent id="2">First</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">man</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">accused</governor>
          <dependent id="5">man</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">accused</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">accused</governor>
          <dependent id="7">still</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">accused</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">crimes</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">crimes</governor>
          <dependent id="10">13</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">accused</governor>
          <dependent id="11">crimes</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="13" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="13" />
          </tokens>
        </entity>
        <entity id="2" string="First" type="ORDINAL" score="0.0">
          <tokens>
            <token id="2" string="First" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>If I were sitting in my old job, I wouldn&amp;apost;t touch this thing with a 10-foot pole.&amp;quot;</content>
      <tokens>
        <token id="1" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="sitting" lemma="sit" stem="sit" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="old" lemma="old" stem="old" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="job" lemma="job" stem="job" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="touch" lemma="touch" stem="touch" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="thing" lemma="thing" stem="thing" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="10-foot" lemma="10-foot" stem="10-foot" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="pole" lemma="pole" stem="pole" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN If) (S (NP (PRP I)) (VP (VBD were) (VP (VBG sitting) (PP (IN in) (NP (PRP$ my) (JJ old) (NN job))))))) (, ,) (NP (PRP I)) (VP (MD would) (RB n't) (VP (VB touch) (NP (DT this) (NN thing)) (PP (IN with) (NP (DT a) (JJ 10-foot) (NN pole))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="this thing" type="NP">
          <tokens>
            <token id="14" string="this" />
            <token id="15" string="thing" />
          </tokens>
        </chunking>
        <chunking id="2" string="If I were sitting in my old job" type="SBAR">
          <tokens>
            <token id="1" string="If" />
            <token id="2" string="I" />
            <token id="3" string="were" />
            <token id="4" string="sitting" />
            <token id="5" string="in" />
            <token id="6" string="my" />
            <token id="7" string="old" />
            <token id="8" string="job" />
          </tokens>
        </chunking>
        <chunking id="3" string="a 10-foot pole" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="10-foot" />
            <token id="19" string="pole" />
          </tokens>
        </chunking>
        <chunking id="4" string="would n't touch this thing with a 10-foot pole" type="VP">
          <tokens>
            <token id="11" string="would" />
            <token id="12" string="n't" />
            <token id="13" string="touch" />
            <token id="14" string="this" />
            <token id="15" string="thing" />
            <token id="16" string="with" />
            <token id="17" string="a" />
            <token id="18" string="10-foot" />
            <token id="19" string="pole" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="sitting in my old job" type="VP">
          <tokens>
            <token id="4" string="sitting" />
            <token id="5" string="in" />
            <token id="6" string="my" />
            <token id="7" string="old" />
            <token id="8" string="job" />
          </tokens>
        </chunking>
        <chunking id="7" string="were sitting in my old job" type="VP">
          <tokens>
            <token id="3" string="were" />
            <token id="4" string="sitting" />
            <token id="5" string="in" />
            <token id="6" string="my" />
            <token id="7" string="old" />
            <token id="8" string="job" />
          </tokens>
        </chunking>
        <chunking id="8" string="my old job" type="NP">
          <tokens>
            <token id="6" string="my" />
            <token id="7" string="old" />
            <token id="8" string="job" />
          </tokens>
        </chunking>
        <chunking id="9" string="touch this thing with a 10-foot pole" type="VP">
          <tokens>
            <token id="13" string="touch" />
            <token id="14" string="this" />
            <token id="15" string="thing" />
            <token id="16" string="with" />
            <token id="17" string="a" />
            <token id="18" string="10-foot" />
            <token id="19" string="pole" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="4">sitting</governor>
          <dependent id="1">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">sitting</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">sitting</governor>
          <dependent id="3">were</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">touch</governor>
          <dependent id="4">sitting</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">job</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">job</governor>
          <dependent id="6">my</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">job</governor>
          <dependent id="7">old</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">sitting</governor>
          <dependent id="8">job</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">touch</governor>
          <dependent id="10">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">touch</governor>
          <dependent id="11">would</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="13">touch</governor>
          <dependent id="12">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">touch</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">thing</governor>
          <dependent id="14">this</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">touch</governor>
          <dependent id="15">thing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">pole</governor>
          <dependent id="16">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">pole</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">pole</governor>
          <dependent id="18">10-foot</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">touch</governor>
          <dependent id="19">pole</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>&amp;quot;It raises so many legal and ethical questions at this point it would have to be looked at with a microscope,&amp;quot; said Larry Strichman, a senior executive in movie development at CBS.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="raises" lemma="raise" stem="rais" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="legal" lemma="legal" stem="legal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="ethical" lemma="ethical" stem="ethic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="questions" lemma="question" stem="question" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="point" lemma="point" stem="point" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="looked" lemma="look" stem="look" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="microscope" lemma="microscope" stem="microscop" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="Larry" lemma="Larry" stem="larri" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="27" string="Strichman" lemma="Strichman" stem="strichman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="senior" lemma="senior" stem="senior" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="executive" lemma="executive" stem="execut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="movie" lemma="movie" stem="movi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="development" lemma="development" stem="develop" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="CBS" lemma="CBS" stem="cbs" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP It)) (VP (VBZ raises) (NP (ADJP (RB so) (JJ many)) (JJ legal) (CC and) (JJ ethical) (NNS questions)) (PP (IN at) (NP (NP (DT this) (NN point)) (SBAR (S (NP (PRP it)) (VP (MD would) (VP (VB have) (S (VP (TO to) (VP (VB be) (VP (VBN looked) (PP (IN at) (PP (IN with) (NP (DT a) (NN microscope)))))))))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Larry) (NNP Strichman)) (, ,) (NP (NP (DT a) (JJ senior) (NN executive)) (PP (IN in) (NP (NP (NN movie) (NN development)) (PP (IN at) (NP (NNP CBS))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="movie development" type="NP">
          <tokens>
            <token id="33" string="movie" />
            <token id="34" string="development" />
          </tokens>
        </chunking>
        <chunking id="2" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="3" string="it" type="NP">
          <tokens>
            <token id="13" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="a microscope" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="microscope" />
          </tokens>
        </chunking>
        <chunking id="5" string="so many legal and ethical questions" type="NP">
          <tokens>
            <token id="4" string="so" />
            <token id="5" string="many" />
            <token id="6" string="legal" />
            <token id="7" string="and" />
            <token id="8" string="ethical" />
            <token id="9" string="questions" />
          </tokens>
        </chunking>
        <chunking id="6" string="be looked at with a microscope" type="VP">
          <tokens>
            <token id="17" string="be" />
            <token id="18" string="looked" />
            <token id="19" string="at" />
            <token id="20" string="with" />
            <token id="21" string="a" />
            <token id="22" string="microscope" />
          </tokens>
        </chunking>
        <chunking id="7" string="raises so many legal and ethical questions at this point it would have to be looked at with a microscope" type="VP">
          <tokens>
            <token id="3" string="raises" />
            <token id="4" string="so" />
            <token id="5" string="many" />
            <token id="6" string="legal" />
            <token id="7" string="and" />
            <token id="8" string="ethical" />
            <token id="9" string="questions" />
            <token id="10" string="at" />
            <token id="11" string="this" />
            <token id="12" string="point" />
            <token id="13" string="it" />
            <token id="14" string="would" />
            <token id="15" string="have" />
            <token id="16" string="to" />
            <token id="17" string="be" />
            <token id="18" string="looked" />
            <token id="19" string="at" />
            <token id="20" string="with" />
            <token id="21" string="a" />
            <token id="22" string="microscope" />
          </tokens>
        </chunking>
        <chunking id="8" string="Larry Strichman , a senior executive in movie development at CBS" type="NP">
          <tokens>
            <token id="26" string="Larry" />
            <token id="27" string="Strichman" />
            <token id="28" string="," />
            <token id="29" string="a" />
            <token id="30" string="senior" />
            <token id="31" string="executive" />
            <token id="32" string="in" />
            <token id="33" string="movie" />
            <token id="34" string="development" />
            <token id="35" string="at" />
            <token id="36" string="CBS" />
          </tokens>
        </chunking>
        <chunking id="9" string="so many" type="ADJP">
          <tokens>
            <token id="4" string="so" />
            <token id="5" string="many" />
          </tokens>
        </chunking>
        <chunking id="10" string="CBS" type="NP">
          <tokens>
            <token id="36" string="CBS" />
          </tokens>
        </chunking>
        <chunking id="11" string="it would have to be looked at with a microscope" type="SBAR">
          <tokens>
            <token id="13" string="it" />
            <token id="14" string="would" />
            <token id="15" string="have" />
            <token id="16" string="to" />
            <token id="17" string="be" />
            <token id="18" string="looked" />
            <token id="19" string="at" />
            <token id="20" string="with" />
            <token id="21" string="a" />
            <token id="22" string="microscope" />
          </tokens>
        </chunking>
        <chunking id="12" string="to be looked at with a microscope" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="be" />
            <token id="18" string="looked" />
            <token id="19" string="at" />
            <token id="20" string="with" />
            <token id="21" string="a" />
            <token id="22" string="microscope" />
          </tokens>
        </chunking>
        <chunking id="13" string="have to be looked at with a microscope" type="VP">
          <tokens>
            <token id="15" string="have" />
            <token id="16" string="to" />
            <token id="17" string="be" />
            <token id="18" string="looked" />
            <token id="19" string="at" />
            <token id="20" string="with" />
            <token id="21" string="a" />
            <token id="22" string="microscope" />
          </tokens>
        </chunking>
        <chunking id="14" string="looked at with a microscope" type="VP">
          <tokens>
            <token id="18" string="looked" />
            <token id="19" string="at" />
            <token id="20" string="with" />
            <token id="21" string="a" />
            <token id="22" string="microscope" />
          </tokens>
        </chunking>
        <chunking id="15" string="Larry Strichman" type="NP">
          <tokens>
            <token id="26" string="Larry" />
            <token id="27" string="Strichman" />
          </tokens>
        </chunking>
        <chunking id="16" string="this point" type="NP">
          <tokens>
            <token id="11" string="this" />
            <token id="12" string="point" />
          </tokens>
        </chunking>
        <chunking id="17" string="would have to be looked at with a microscope" type="VP">
          <tokens>
            <token id="14" string="would" />
            <token id="15" string="have" />
            <token id="16" string="to" />
            <token id="17" string="be" />
            <token id="18" string="looked" />
            <token id="19" string="at" />
            <token id="20" string="with" />
            <token id="21" string="a" />
            <token id="22" string="microscope" />
          </tokens>
        </chunking>
        <chunking id="18" string="a senior executive in movie development at CBS" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="senior" />
            <token id="31" string="executive" />
            <token id="32" string="in" />
            <token id="33" string="movie" />
            <token id="34" string="development" />
            <token id="35" string="at" />
            <token id="36" string="CBS" />
          </tokens>
        </chunking>
        <chunking id="19" string="movie development at CBS" type="NP">
          <tokens>
            <token id="33" string="movie" />
            <token id="34" string="development" />
            <token id="35" string="at" />
            <token id="36" string="CBS" />
          </tokens>
        </chunking>
        <chunking id="20" string="this point it would have to be looked at with a microscope" type="NP">
          <tokens>
            <token id="11" string="this" />
            <token id="12" string="point" />
            <token id="13" string="it" />
            <token id="14" string="would" />
            <token id="15" string="have" />
            <token id="16" string="to" />
            <token id="17" string="be" />
            <token id="18" string="looked" />
            <token id="19" string="at" />
            <token id="20" string="with" />
            <token id="21" string="a" />
            <token id="22" string="microscope" />
          </tokens>
        </chunking>
        <chunking id="21" string="said" type="VP">
          <tokens>
            <token id="25" string="said" />
          </tokens>
        </chunking>
        <chunking id="22" string="a senior executive" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="senior" />
            <token id="31" string="executive" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">raises</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="25">said</governor>
          <dependent id="3">raises</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">many</governor>
          <dependent id="4">so</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">legal</governor>
          <dependent id="5">many</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">raises</governor>
          <dependent id="6">legal</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">legal</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">questions</governor>
          <dependent id="8">ethical</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">legal</governor>
          <dependent id="9">questions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">point</governor>
          <dependent id="10">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">point</governor>
          <dependent id="11">this</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">raises</governor>
          <dependent id="12">point</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">have</governor>
          <dependent id="13">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">have</governor>
          <dependent id="14">would</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">point</governor>
          <dependent id="15">have</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">looked</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="18">looked</governor>
          <dependent id="17">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">have</governor>
          <dependent id="18">looked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">microscope</governor>
          <dependent id="19">at</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">microscope</governor>
          <dependent id="20">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">microscope</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">looked</governor>
          <dependent id="22">microscope</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="25">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Strichman</governor>
          <dependent id="26">Larry</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">said</governor>
          <dependent id="27">Strichman</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">executive</governor>
          <dependent id="29">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">executive</governor>
          <dependent id="30">senior</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="27">Strichman</governor>
          <dependent id="31">executive</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">development</governor>
          <dependent id="32">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">development</governor>
          <dependent id="33">movie</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">executive</governor>
          <dependent id="34">development</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">CBS</governor>
          <dependent id="35">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">development</governor>
          <dependent id="36">CBS</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="CBS" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="36" string="CBS" />
          </tokens>
        </entity>
        <entity id="2" string="Larry Strichman" type="PERSON" score="0.0">
          <tokens>
            <token id="26" string="Larry" />
            <token id="27" string="Strichman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>&amp;quot;What is the story you want to tell?</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="What" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="want" lemma="want" stem="want" pos="VBP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="tell" lemma="tell" stem="tell" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SBARQ (`` ``) (WHNP (WP What)) (SQ (VBZ is) (NP (NP (DT the) (NN story)) (SBAR (S (NP (PRP you)) (VP (VBP want) (S (VP (TO to) (VP (VB tell))))))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to tell" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="tell" />
          </tokens>
        </chunking>
        <chunking id="2" string="the story you want to tell" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="story" />
            <token id="6" string="you" />
            <token id="7" string="want" />
            <token id="8" string="to" />
            <token id="9" string="tell" />
          </tokens>
        </chunking>
        <chunking id="3" string="the story" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="story" />
          </tokens>
        </chunking>
        <chunking id="4" string="tell" type="VP">
          <tokens>
            <token id="9" string="tell" />
          </tokens>
        </chunking>
        <chunking id="5" string="you want to tell" type="SBAR">
          <tokens>
            <token id="6" string="you" />
            <token id="7" string="want" />
            <token id="8" string="to" />
            <token id="9" string="tell" />
          </tokens>
        </chunking>
        <chunking id="6" string="want to tell" type="VP">
          <tokens>
            <token id="7" string="want" />
            <token id="8" string="to" />
            <token id="9" string="tell" />
          </tokens>
        </chunking>
        <chunking id="7" string="you" type="NP">
          <tokens>
            <token id="6" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">What</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="2">What</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">story</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="2">What</governor>
          <dependent id="5">story</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">want</governor>
          <dependent id="6">you</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">story</governor>
          <dependent id="7">want</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">tell</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">want</governor>
          <dependent id="9">tell</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>Is it a story of justice done or justice denied?</content>
      <tokens>
        <token id="1" string="Is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="justice" lemma="justice" stem="justic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="done" lemma="do" stem="done" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="justice" lemma="justice" stem="justic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="denied" lemma="deny" stem="deni" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SQ (VBZ Is) (NP (PRP it)) (NP (NP (DT a) (NN story)) (PP (IN of) (NP (NP (NP (NN justice)) (VP (VBN done))) (CC or) (NP (NP (NN justice)) (VP (VBN denied)))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="justice done or justice denied" type="NP">
          <tokens>
            <token id="6" string="justice" />
            <token id="7" string="done" />
            <token id="8" string="or" />
            <token id="9" string="justice" />
            <token id="10" string="denied" />
          </tokens>
        </chunking>
        <chunking id="2" string="a story of justice done or justice denied" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="story" />
            <token id="5" string="of" />
            <token id="6" string="justice" />
            <token id="7" string="done" />
            <token id="8" string="or" />
            <token id="9" string="justice" />
            <token id="10" string="denied" />
          </tokens>
        </chunking>
        <chunking id="3" string="justice done" type="NP">
          <tokens>
            <token id="6" string="justice" />
            <token id="7" string="done" />
          </tokens>
        </chunking>
        <chunking id="4" string="a story" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="story" />
          </tokens>
        </chunking>
        <chunking id="5" string="justice" type="NP">
          <tokens>
            <token id="6" string="justice" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="2" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="justice denied" type="NP">
          <tokens>
            <token id="9" string="justice" />
            <token id="10" string="denied" />
          </tokens>
        </chunking>
        <chunking id="8" string="denied" type="VP">
          <tokens>
            <token id="10" string="denied" />
          </tokens>
        </chunking>
        <chunking id="9" string="done" type="VP">
          <tokens>
            <token id="7" string="done" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cop">
          <governor id="4">story</governor>
          <dependent id="1">Is</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">story</governor>
          <dependent id="2">it</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">story</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">story</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">justice</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">story</governor>
          <dependent id="6">justice</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="6">justice</governor>
          <dependent id="7">done</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">justice</governor>
          <dependent id="8">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">justice</governor>
          <dependent id="9">justice</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="9">justice</governor>
          <dependent id="10">denied</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>And it&amp;apost;s real unclear at the moment what the answer to that question is.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="real" lemma="real" stem="real" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="unclear" lemma="unclear" stem="unclear" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="moment" lemma="moment" stem="moment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="answer" lemma="answer" stem="answer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="question" lemma="question" stem="question" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (PRP it)) (VP (VBZ 's) (ADJP (ADJP (JJ real) (JJ unclear)) (PP (IN at) (NP (DT the) (NN moment)))) (SBAR (WHNP (WP what)) (S (NP (NP (DT the) (NN answer)) (PP (TO to) (NP (DT that) (NN question)))) (VP (VBZ is))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the answer" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="answer" />
          </tokens>
        </chunking>
        <chunking id="2" string="real unclear" type="ADJP">
          <tokens>
            <token id="4" string="real" />
            <token id="5" string="unclear" />
          </tokens>
        </chunking>
        <chunking id="3" string="'s real unclear at the moment what the answer to that question is" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="real" />
            <token id="5" string="unclear" />
            <token id="6" string="at" />
            <token id="7" string="the" />
            <token id="8" string="moment" />
            <token id="9" string="what" />
            <token id="10" string="the" />
            <token id="11" string="answer" />
            <token id="12" string="to" />
            <token id="13" string="that" />
            <token id="14" string="question" />
            <token id="15" string="is" />
          </tokens>
        </chunking>
        <chunking id="4" string="that question" type="NP">
          <tokens>
            <token id="13" string="that" />
            <token id="14" string="question" />
          </tokens>
        </chunking>
        <chunking id="5" string="is" type="VP">
          <tokens>
            <token id="15" string="is" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="2" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="what the answer to that question is" type="SBAR">
          <tokens>
            <token id="9" string="what" />
            <token id="10" string="the" />
            <token id="11" string="answer" />
            <token id="12" string="to" />
            <token id="13" string="that" />
            <token id="14" string="question" />
            <token id="15" string="is" />
          </tokens>
        </chunking>
        <chunking id="8" string="real unclear at the moment" type="ADJP">
          <tokens>
            <token id="4" string="real" />
            <token id="5" string="unclear" />
            <token id="6" string="at" />
            <token id="7" string="the" />
            <token id="8" string="moment" />
          </tokens>
        </chunking>
        <chunking id="9" string="the answer to that question" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="answer" />
            <token id="12" string="to" />
            <token id="13" string="that" />
            <token id="14" string="question" />
          </tokens>
        </chunking>
        <chunking id="10" string="the moment" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="moment" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="5">unclear</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">unclear</governor>
          <dependent id="2">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">unclear</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">unclear</governor>
          <dependent id="4">real</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">unclear</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">moment</governor>
          <dependent id="6">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">moment</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">unclear</governor>
          <dependent id="8">moment</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">is</governor>
          <dependent id="9">what</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">answer</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">is</governor>
          <dependent id="11">answer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">question</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">question</governor>
          <dependent id="13">that</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">answer</governor>
          <dependent id="14">question</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">unclear</governor>
          <dependent id="15">is</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="24" has_coreference="false">
      <content>Unlike a documentary, it&amp;apost;s hard to take an ambiguous position in a docudrama.&amp;quot;</content>
      <tokens>
        <token id="1" string="Unlike" lemma="unlike" stem="unlike" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="documentary" lemma="documentary" stem="documentari" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="hard" lemma="hard" stem="hard" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="ambiguous" lemma="ambiguous" stem="ambigu" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="position" lemma="position" stem="posit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="docudrama" lemma="docudrama" stem="docudrama" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Unlike) (NP (DT a) (NN documentary))) (, ,) (NP (PRP it)) (VP (VBZ 's) (ADJP (JJ hard) (S (VP (TO to) (VP (VB take) (NP (DT an) (JJ ambiguous) (NN position)) (PP (IN in) (NP (DT a) (NN docudrama)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="a documentary" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="documentary" />
          </tokens>
        </chunking>
        <chunking id="2" string="'s hard to take an ambiguous position in a docudrama" type="VP">
          <tokens>
            <token id="6" string="'s" />
            <token id="7" string="hard" />
            <token id="8" string="to" />
            <token id="9" string="take" />
            <token id="10" string="an" />
            <token id="11" string="ambiguous" />
            <token id="12" string="position" />
            <token id="13" string="in" />
            <token id="14" string="a" />
            <token id="15" string="docudrama" />
          </tokens>
        </chunking>
        <chunking id="3" string="a docudrama" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="docudrama" />
          </tokens>
        </chunking>
        <chunking id="4" string="to take an ambiguous position in a docudrama" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="take" />
            <token id="10" string="an" />
            <token id="11" string="ambiguous" />
            <token id="12" string="position" />
            <token id="13" string="in" />
            <token id="14" string="a" />
            <token id="15" string="docudrama" />
          </tokens>
        </chunking>
        <chunking id="5" string="take an ambiguous position in a docudrama" type="VP">
          <tokens>
            <token id="9" string="take" />
            <token id="10" string="an" />
            <token id="11" string="ambiguous" />
            <token id="12" string="position" />
            <token id="13" string="in" />
            <token id="14" string="a" />
            <token id="15" string="docudrama" />
          </tokens>
        </chunking>
        <chunking id="6" string="hard to take an ambiguous position in a docudrama" type="ADJP">
          <tokens>
            <token id="7" string="hard" />
            <token id="8" string="to" />
            <token id="9" string="take" />
            <token id="10" string="an" />
            <token id="11" string="ambiguous" />
            <token id="12" string="position" />
            <token id="13" string="in" />
            <token id="14" string="a" />
            <token id="15" string="docudrama" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="5" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="an ambiguous position" type="NP">
          <tokens>
            <token id="10" string="an" />
            <token id="11" string="ambiguous" />
            <token id="12" string="position" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">documentary</governor>
          <dependent id="1">Unlike</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">documentary</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">hard</governor>
          <dependent id="3">documentary</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">hard</governor>
          <dependent id="5">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">hard</governor>
          <dependent id="6">'s</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">hard</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">take</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">hard</governor>
          <dependent id="9">take</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">position</governor>
          <dependent id="10">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">position</governor>
          <dependent id="11">ambiguous</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">take</governor>
          <dependent id="12">position</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">docudrama</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">docudrama</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">take</governor>
          <dependent id="15">docudrama</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>Producers think network qualms can be overcome, however.</content>
      <tokens>
        <token id="1" string="Producers" lemma="producer" stem="produc" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="network" lemma="network" stem="network" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="qualms" lemma="qualm" stem="qualm" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="overcome" lemma="overcome" stem="overcom" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="however" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Producers)) (VP (VBP think) (SBAR (S (NP (NN network) (NNS qualms)) (VP (MD can) (VP (VB be) (VP (VBN overcome) (, ,) (ADVP (RB however)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Producers" type="NP">
          <tokens>
            <token id="1" string="Producers" />
          </tokens>
        </chunking>
        <chunking id="2" string="network qualms" type="NP">
          <tokens>
            <token id="3" string="network" />
            <token id="4" string="qualms" />
          </tokens>
        </chunking>
        <chunking id="3" string="be overcome , however" type="VP">
          <tokens>
            <token id="6" string="be" />
            <token id="7" string="overcome" />
            <token id="8" string="," />
            <token id="9" string="however" />
          </tokens>
        </chunking>
        <chunking id="4" string="overcome , however" type="VP">
          <tokens>
            <token id="7" string="overcome" />
            <token id="8" string="," />
            <token id="9" string="however" />
          </tokens>
        </chunking>
        <chunking id="5" string="network qualms can be overcome , however" type="SBAR">
          <tokens>
            <token id="3" string="network" />
            <token id="4" string="qualms" />
            <token id="5" string="can" />
            <token id="6" string="be" />
            <token id="7" string="overcome" />
            <token id="8" string="," />
            <token id="9" string="however" />
          </tokens>
        </chunking>
        <chunking id="6" string="can be overcome , however" type="VP">
          <tokens>
            <token id="5" string="can" />
            <token id="6" string="be" />
            <token id="7" string="overcome" />
            <token id="8" string="," />
            <token id="9" string="however" />
          </tokens>
        </chunking>
        <chunking id="7" string="think network qualms can be overcome , however" type="VP">
          <tokens>
            <token id="2" string="think" />
            <token id="3" string="network" />
            <token id="4" string="qualms" />
            <token id="5" string="can" />
            <token id="6" string="be" />
            <token id="7" string="overcome" />
            <token id="8" string="," />
            <token id="9" string="however" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">think</governor>
          <dependent id="1">Producers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">think</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">qualms</governor>
          <dependent id="3">network</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">overcome</governor>
          <dependent id="4">qualms</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">overcome</governor>
          <dependent id="5">can</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">overcome</governor>
          <dependent id="6">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">think</governor>
          <dependent id="7">overcome</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">overcome</governor>
          <dependent id="9">however</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="26" has_coreference="false">
      <content>One pointed out that the Billionaire Boys Club docudrama was broadcast before all the trials regarding the slayings were over.</content>
      <tokens>
        <token id="1" string="One" lemma="one" stem="one" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="2" string="pointed" lemma="point" stem="point" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Billionaire" lemma="billionaire" stem="billionair" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="7" string="Boys" lemma="boy" stem="boi" pos="NNS" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="8" string="Club" lemma="Club" stem="club" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="9" string="docudrama" lemma="docudrama" stem="docudrama" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="broadcast" lemma="broadcast" stem="broadcast" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="all" lemma="all" stem="all" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="trials" lemma="trial" stem="trial" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="regarding" lemma="regard" stem="regard" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="slayings" lemma="slaying" stem="slai" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="over" lemma="over" stem="over" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (CD One)) (VP (VBD pointed) (PRT (RP out)) (SBAR (IN that) (S (NP (NP (DT the) (NN Billionaire) (NNS Boys)) (SBAR (S (NP (NNP Club) (NN docudrama)) (VP (VBD was) (VP (VBN broadcast) (PP (IN before) (NP (NP (PDT all) (DT the) (NNS trials)) (PP (VBG regarding) (NP (DT the) (NNS slayings)))))))))) (VP (VBD were) (ADVP (RB over)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="broadcast before all the trials regarding the slayings" type="VP">
          <tokens>
            <token id="11" string="broadcast" />
            <token id="12" string="before" />
            <token id="13" string="all" />
            <token id="14" string="the" />
            <token id="15" string="trials" />
            <token id="16" string="regarding" />
            <token id="17" string="the" />
            <token id="18" string="slayings" />
          </tokens>
        </chunking>
        <chunking id="2" string="One" type="NP">
          <tokens>
            <token id="1" string="One" />
          </tokens>
        </chunking>
        <chunking id="3" string="pointed out that the Billionaire Boys Club docudrama was broadcast before all the trials regarding the slayings were over" type="VP">
          <tokens>
            <token id="2" string="pointed" />
            <token id="3" string="out" />
            <token id="4" string="that" />
            <token id="5" string="the" />
            <token id="6" string="Billionaire" />
            <token id="7" string="Boys" />
            <token id="8" string="Club" />
            <token id="9" string="docudrama" />
            <token id="10" string="was" />
            <token id="11" string="broadcast" />
            <token id="12" string="before" />
            <token id="13" string="all" />
            <token id="14" string="the" />
            <token id="15" string="trials" />
            <token id="16" string="regarding" />
            <token id="17" string="the" />
            <token id="18" string="slayings" />
            <token id="19" string="were" />
            <token id="20" string="over" />
          </tokens>
        </chunking>
        <chunking id="4" string="the slayings" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="slayings" />
          </tokens>
        </chunking>
        <chunking id="5" string="that the Billionaire Boys Club docudrama was broadcast before all the trials regarding the slayings were over" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="the" />
            <token id="6" string="Billionaire" />
            <token id="7" string="Boys" />
            <token id="8" string="Club" />
            <token id="9" string="docudrama" />
            <token id="10" string="was" />
            <token id="11" string="broadcast" />
            <token id="12" string="before" />
            <token id="13" string="all" />
            <token id="14" string="the" />
            <token id="15" string="trials" />
            <token id="16" string="regarding" />
            <token id="17" string="the" />
            <token id="18" string="slayings" />
            <token id="19" string="were" />
            <token id="20" string="over" />
          </tokens>
        </chunking>
        <chunking id="6" string="all the trials regarding the slayings" type="NP">
          <tokens>
            <token id="13" string="all" />
            <token id="14" string="the" />
            <token id="15" string="trials" />
            <token id="16" string="regarding" />
            <token id="17" string="the" />
            <token id="18" string="slayings" />
          </tokens>
        </chunking>
        <chunking id="7" string="were over" type="VP">
          <tokens>
            <token id="19" string="were" />
            <token id="20" string="over" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Billionaire Boys" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="Billionaire" />
            <token id="7" string="Boys" />
          </tokens>
        </chunking>
        <chunking id="9" string="Club docudrama was broadcast before all the trials regarding the slayings" type="SBAR">
          <tokens>
            <token id="8" string="Club" />
            <token id="9" string="docudrama" />
            <token id="10" string="was" />
            <token id="11" string="broadcast" />
            <token id="12" string="before" />
            <token id="13" string="all" />
            <token id="14" string="the" />
            <token id="15" string="trials" />
            <token id="16" string="regarding" />
            <token id="17" string="the" />
            <token id="18" string="slayings" />
          </tokens>
        </chunking>
        <chunking id="10" string="was broadcast before all the trials regarding the slayings" type="VP">
          <tokens>
            <token id="10" string="was" />
            <token id="11" string="broadcast" />
            <token id="12" string="before" />
            <token id="13" string="all" />
            <token id="14" string="the" />
            <token id="15" string="trials" />
            <token id="16" string="regarding" />
            <token id="17" string="the" />
            <token id="18" string="slayings" />
          </tokens>
        </chunking>
        <chunking id="11" string="the Billionaire Boys Club docudrama was broadcast before all the trials regarding the slayings" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="Billionaire" />
            <token id="7" string="Boys" />
            <token id="8" string="Club" />
            <token id="9" string="docudrama" />
            <token id="10" string="was" />
            <token id="11" string="broadcast" />
            <token id="12" string="before" />
            <token id="13" string="all" />
            <token id="14" string="the" />
            <token id="15" string="trials" />
            <token id="16" string="regarding" />
            <token id="17" string="the" />
            <token id="18" string="slayings" />
          </tokens>
        </chunking>
        <chunking id="12" string="Club docudrama" type="NP">
          <tokens>
            <token id="8" string="Club" />
            <token id="9" string="docudrama" />
          </tokens>
        </chunking>
        <chunking id="13" string="all the trials" type="NP">
          <tokens>
            <token id="13" string="all" />
            <token id="14" string="the" />
            <token id="15" string="trials" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">pointed</governor>
          <dependent id="1">One</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">pointed</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="2">pointed</governor>
          <dependent id="3">out</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">were</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">Boys</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Boys</governor>
          <dependent id="6">Billionaire</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">were</governor>
          <dependent id="7">Boys</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">docudrama</governor>
          <dependent id="8">Club</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="11">broadcast</governor>
          <dependent id="9">docudrama</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="11">broadcast</governor>
          <dependent id="10">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">Boys</governor>
          <dependent id="11">broadcast</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">trials</governor>
          <dependent id="12">before</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="15">trials</governor>
          <dependent id="13">all</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">trials</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">broadcast</governor>
          <dependent id="15">trials</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">slayings</governor>
          <dependent id="16">regarding</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">slayings</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">trials</governor>
          <dependent id="18">slayings</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">pointed</governor>
          <dependent id="19">were</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">were</governor>
          <dependent id="20">over</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="One" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="One" />
          </tokens>
        </entity>
        <entity id="2" string="Billionaire Boys Club" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="6" string="Billionaire" />
            <token id="7" string="Boys" />
            <token id="8" string="Club" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>&amp;quot;There are no rules,&amp;quot; the producer said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="rules" lemma="rule" stem="rule" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="producer" lemma="producer" stem="produc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (EX There)) (VP (VBP are) (NP (DT no) (NNS rules)))) (, ,) ('' '') (NP (DT the) (NN producer)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="There" type="NP">
          <tokens>
            <token id="2" string="There" />
          </tokens>
        </chunking>
        <chunking id="2" string="no rules" type="NP">
          <tokens>
            <token id="4" string="no" />
            <token id="5" string="rules" />
          </tokens>
        </chunking>
        <chunking id="3" string="the producer" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="producer" />
          </tokens>
        </chunking>
        <chunking id="4" string="said" type="VP">
          <tokens>
            <token id="10" string="said" />
          </tokens>
        </chunking>
        <chunking id="5" string="are no rules" type="VP">
          <tokens>
            <token id="3" string="are" />
            <token id="4" string="no" />
            <token id="5" string="rules" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="3">are</governor>
          <dependent id="2">There</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">said</governor>
          <dependent id="3">are</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">rules</governor>
          <dependent id="4">no</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">are</governor>
          <dependent id="5">rules</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">producer</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">said</governor>
          <dependent id="9">producer</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>Hollywood&amp;apost;s role in the McMartin case came to prominence early.</content>
      <tokens>
        <token id="1" string="Hollywood" lemma="Hollywood" stem="hollywood" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="role" lemma="role" stem="role" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="prominence" lemma="prominence" stem="promin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="early" lemma="early" stem="earli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NNP Hollywood) (POS 's)) (NN role)) (PP (IN in) (NP (DT the) (NNP McMartin) (NN case)))) (VP (VBD came) (PP (TO to) (NP (NN prominence) (RB early)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="came to prominence early" type="VP">
          <tokens>
            <token id="8" string="came" />
            <token id="9" string="to" />
            <token id="10" string="prominence" />
            <token id="11" string="early" />
          </tokens>
        </chunking>
        <chunking id="2" string="the McMartin case" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="McMartin" />
            <token id="7" string="case" />
          </tokens>
        </chunking>
        <chunking id="3" string="Hollywood 's role" type="NP">
          <tokens>
            <token id="1" string="Hollywood" />
            <token id="2" string="'s" />
            <token id="3" string="role" />
          </tokens>
        </chunking>
        <chunking id="4" string="Hollywood 's role in the McMartin case" type="NP">
          <tokens>
            <token id="1" string="Hollywood" />
            <token id="2" string="'s" />
            <token id="3" string="role" />
            <token id="4" string="in" />
            <token id="5" string="the" />
            <token id="6" string="McMartin" />
            <token id="7" string="case" />
          </tokens>
        </chunking>
        <chunking id="5" string="prominence early" type="NP">
          <tokens>
            <token id="10" string="prominence" />
            <token id="11" string="early" />
          </tokens>
        </chunking>
        <chunking id="6" string="Hollywood 's" type="NP">
          <tokens>
            <token id="1" string="Hollywood" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">role</governor>
          <dependent id="1">Hollywood</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Hollywood</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">came</governor>
          <dependent id="3">role</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">case</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">case</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">case</governor>
          <dependent id="6">McMartin</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">role</governor>
          <dependent id="7">case</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">came</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">prominence</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">came</governor>
          <dependent id="10">prominence</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">prominence</governor>
          <dependent id="11">early</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hollywood" type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="Hollywood" />
          </tokens>
        </entity>
        <entity id="2" string="McMartin" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="McMartin" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="false">
      <content>Not long after the first allegations of child molestation six years ago, several producers pitched projects to networks.</content>
      <tokens>
        <token id="1" string="Not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="long" lemma="long" stem="long" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="6" string="allegations" lemma="allegation" stem="alleg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="child" lemma="child" stem="child" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="molestation" lemma="molestation" stem="molest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="ago" lemma="ago" stem="ago" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="several" lemma="several" stem="sever" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="producers" lemma="producer" stem="produc" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="pitched" lemma="pitch" stem="pitch" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="projects" lemma="project" stem="project" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="networks" lemma="network" stem="network" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (ADVP (RB Not) (RB long)) (PP (IN after) (NP (NP (DT the) (JJ first) (NNS allegations)) (PP (IN of) (NP (NN child) (NN molestation)))) (ADVP (NP (CD six) (NNS years)) (RB ago)))) (, ,) (NP (JJ several) (NNS producers)) (VP (VBD pitched) (NP (NNS projects)) (PP (TO to) (NP (NNS networks)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="projects" type="NP">
          <tokens>
            <token id="17" string="projects" />
          </tokens>
        </chunking>
        <chunking id="2" string="pitched projects to networks" type="VP">
          <tokens>
            <token id="16" string="pitched" />
            <token id="17" string="projects" />
            <token id="18" string="to" />
            <token id="19" string="networks" />
          </tokens>
        </chunking>
        <chunking id="3" string="several producers" type="NP">
          <tokens>
            <token id="14" string="several" />
            <token id="15" string="producers" />
          </tokens>
        </chunking>
        <chunking id="4" string="the first allegations" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="first" />
            <token id="6" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="5" string="the first allegations of child molestation" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="first" />
            <token id="6" string="allegations" />
            <token id="7" string="of" />
            <token id="8" string="child" />
            <token id="9" string="molestation" />
          </tokens>
        </chunking>
        <chunking id="6" string="child molestation" type="NP">
          <tokens>
            <token id="8" string="child" />
            <token id="9" string="molestation" />
          </tokens>
        </chunking>
        <chunking id="7" string="networks" type="NP">
          <tokens>
            <token id="19" string="networks" />
          </tokens>
        </chunking>
        <chunking id="8" string="six years" type="NP">
          <tokens>
            <token id="10" string="six" />
            <token id="11" string="years" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="2">long</governor>
          <dependent id="1">Not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">pitched</governor>
          <dependent id="2">long</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">allegations</governor>
          <dependent id="3">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">allegations</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">allegations</governor>
          <dependent id="5">first</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">long</governor>
          <dependent id="6">allegations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">molestation</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">molestation</governor>
          <dependent id="8">child</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">allegations</governor>
          <dependent id="9">molestation</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">years</governor>
          <dependent id="10">six</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="12">ago</governor>
          <dependent id="11">years</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">allegations</governor>
          <dependent id="12">ago</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">producers</governor>
          <dependent id="14">several</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">pitched</governor>
          <dependent id="15">producers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">pitched</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">pitched</governor>
          <dependent id="17">projects</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">networks</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">pitched</governor>
          <dependent id="19">networks</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="5" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="six years ago" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="six" />
            <token id="11" string="years" />
            <token id="12" string="ago" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="false">
      <content>Though no explicit McMartin story was produced, child abuse and molestation was a recurring subject.</content>
      <tokens>
        <token id="1" string="Though" lemma="though" stem="though" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="explicit" lemma="explicit" stem="explicit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="produced" lemma="produce" stem="produc" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="child" lemma="child" stem="child" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="abuse" lemma="abuse" stem="abus" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="molestation" lemma="molestation" stem="molest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="recurring" lemma="recur" stem="recur" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="subject" lemma="subject" stem="subject" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Though) (S (NP (DT no) (JJ explicit) (NNP McMartin) (NN story)) (VP (VBD was) (VP (VBN produced))))) (, ,) (NP (NP (NN child) (NN abuse)) (CC and) (NP (NN molestation))) (VP (VBD was) (NP (DT a) (VBG recurring) (NN subject))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="no explicit McMartin story" type="NP">
          <tokens>
            <token id="2" string="no" />
            <token id="3" string="explicit" />
            <token id="4" string="McMartin" />
            <token id="5" string="story" />
          </tokens>
        </chunking>
        <chunking id="2" string="molestation" type="NP">
          <tokens>
            <token id="12" string="molestation" />
          </tokens>
        </chunking>
        <chunking id="3" string="a recurring subject" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="recurring" />
            <token id="16" string="subject" />
          </tokens>
        </chunking>
        <chunking id="4" string="Though no explicit McMartin story was produced" type="SBAR">
          <tokens>
            <token id="1" string="Though" />
            <token id="2" string="no" />
            <token id="3" string="explicit" />
            <token id="4" string="McMartin" />
            <token id="5" string="story" />
            <token id="6" string="was" />
            <token id="7" string="produced" />
          </tokens>
        </chunking>
        <chunking id="5" string="child abuse" type="NP">
          <tokens>
            <token id="9" string="child" />
            <token id="10" string="abuse" />
          </tokens>
        </chunking>
        <chunking id="6" string="produced" type="VP">
          <tokens>
            <token id="7" string="produced" />
          </tokens>
        </chunking>
        <chunking id="7" string="was produced" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="produced" />
          </tokens>
        </chunking>
        <chunking id="8" string="was a recurring subject" type="VP">
          <tokens>
            <token id="13" string="was" />
            <token id="14" string="a" />
            <token id="15" string="recurring" />
            <token id="16" string="subject" />
          </tokens>
        </chunking>
        <chunking id="9" string="child abuse and molestation" type="NP">
          <tokens>
            <token id="9" string="child" />
            <token id="10" string="abuse" />
            <token id="11" string="and" />
            <token id="12" string="molestation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="7">produced</governor>
          <dependent id="1">Though</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">story</governor>
          <dependent id="2">no</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">story</governor>
          <dependent id="3">explicit</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">story</governor>
          <dependent id="4">McMartin</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">produced</governor>
          <dependent id="5">story</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">produced</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">subject</governor>
          <dependent id="7">produced</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">abuse</governor>
          <dependent id="9">child</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">subject</governor>
          <dependent id="10">abuse</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">abuse</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">abuse</governor>
          <dependent id="12">molestation</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">subject</governor>
          <dependent id="13">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">subject</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">subject</governor>
          <dependent id="15">recurring</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">subject</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="31" has_coreference="false">
      <content>One CBS fictional movie last year -- &amp;quot;Did You Know the Muffin Man?&amp;quot;</content>
      <tokens>
        <token id="1" string="One" lemma="one" stem="one" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="2" string="CBS" lemma="CBS" stem="cbs" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="3" string="fictional" lemma="fictional" stem="fiction" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="movie" lemma="movie" stem="movi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="You" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Know" lemma="Know" stem="know" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Muffin" lemma="Muffin" stem="muffin" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="14" string="Man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="15" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (CD One) (NNP CBS)) (VP (JJ fictional) (NP (NP (NN movie) (JJ last) (NN year)) (: --) (`` ``) (SQ (VBD Did) (NP (PRP You)) (NP (NNP Know) (NP (DT the) (NNP Muffin) (NN Man)))) (. ?) ('' '')))))</syntactictree>
      <chunkings>
        <chunking id="1" string="Know the Muffin Man" type="NP">
          <tokens>
            <token id="11" string="Know" />
            <token id="12" string="the" />
            <token id="13" string="Muffin" />
            <token id="14" string="Man" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Muffin Man" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="Muffin" />
            <token id="14" string="Man" />
          </tokens>
        </chunking>
        <chunking id="3" string="One CBS" type="NP">
          <tokens>
            <token id="1" string="One" />
            <token id="2" string="CBS" />
          </tokens>
        </chunking>
        <chunking id="4" string="movie last year -- `` Did You Know the Muffin Man ? ''" type="NP">
          <tokens>
            <token id="4" string="movie" />
            <token id="5" string="last" />
            <token id="6" string="year" />
            <token id="7" string="--" />
            <token id="8" string="&quot;" />
            <token id="9" string="Did" />
            <token id="10" string="You" />
            <token id="11" string="Know" />
            <token id="12" string="the" />
            <token id="13" string="Muffin" />
            <token id="14" string="Man" />
            <token id="15" string="?" />
            <token id="16" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="5" string="movie last year" type="NP">
          <tokens>
            <token id="4" string="movie" />
            <token id="5" string="last" />
            <token id="6" string="year" />
          </tokens>
        </chunking>
        <chunking id="6" string="fictional movie last year -- `` Did You Know the Muffin Man ? ''" type="VP">
          <tokens>
            <token id="3" string="fictional" />
            <token id="4" string="movie" />
            <token id="5" string="last" />
            <token id="6" string="year" />
            <token id="7" string="--" />
            <token id="8" string="&quot;" />
            <token id="9" string="Did" />
            <token id="10" string="You" />
            <token id="11" string="Know" />
            <token id="12" string="the" />
            <token id="13" string="Muffin" />
            <token id="14" string="Man" />
            <token id="15" string="?" />
            <token id="16" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="7" string="You" type="NP">
          <tokens>
            <token id="10" string="You" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nummod">
          <governor id="2">CBS</governor>
          <dependent id="1">One</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">fictional</governor>
          <dependent id="2">CBS</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">fictional</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">year</governor>
          <dependent id="4">movie</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">year</governor>
          <dependent id="5">last</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">fictional</governor>
          <dependent id="6">year</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">year</governor>
          <dependent id="9">Did</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">Did</governor>
          <dependent id="10">You</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">Did</governor>
          <dependent id="11">Know</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">Man</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Man</governor>
          <dependent id="13">Muffin</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">Know</governor>
          <dependent id="14">Man</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="CBS" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="CBS" />
          </tokens>
        </entity>
        <entity id="2" string="One" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="One" />
          </tokens>
        </entity>
        <entity id="3" string="last year" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="last" />
            <token id="6" string="year" />
          </tokens>
        </entity>
        <entity id="4" string="Muffin Man" type="MISC" score="0.0">
          <tokens>
            <token id="13" string="Muffin" />
            <token id="14" string="Man" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="false">
      <content>-- featured a preschool and satanic child molesters.</content>
      <tokens>
        <token id="1" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="featured" lemma="feature" stem="featur" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="preschool" lemma="preschool" stem="preschool" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="satanic" lemma="satanic" stem="satan" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="child" lemma="child" stem="child" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="molesters" lemma="molester" stem="molest" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (: --) (VP (VBD featured) (NP (DT a) (JJ preschool) (CC and) (JJ satanic) (NN child) (NNS molesters))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="featured a preschool and satanic child molesters" type="VP">
          <tokens>
            <token id="2" string="featured" />
            <token id="3" string="a" />
            <token id="4" string="preschool" />
            <token id="5" string="and" />
            <token id="6" string="satanic" />
            <token id="7" string="child" />
            <token id="8" string="molesters" />
          </tokens>
        </chunking>
        <chunking id="2" string="a preschool and satanic child molesters" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="preschool" />
            <token id="5" string="and" />
            <token id="6" string="satanic" />
            <token id="7" string="child" />
            <token id="8" string="molesters" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">featured</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">preschool</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">featured</governor>
          <dependent id="4">preschool</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">preschool</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">molesters</governor>
          <dependent id="6">satanic</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">molesters</governor>
          <dependent id="7">child</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">preschool</governor>
          <dependent id="8">molesters</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>Mann, whose writing credits include the Academy Award-winning &amp;quot;Judgment at Nuremberg&amp;quot; in 1961, won an Emmy for &amp;quot;The Marcus-Nelson Murders,&amp;quot; a three-hour &amp;quot;Kojak&amp;quot; drama based on a true case in which a black youth was wrongly convicted of the killings of two white women.</content>
      <tokens>
        <token id="1" string="Mann" lemma="Mann" stem="mann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="whose" lemma="whose" stem="whose" pos="WP$" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="writing" lemma="write" stem="write" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="credits" lemma="credit" stem="credit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="include" lemma="include" stem="includ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="8" string="Academy" lemma="Academy" stem="academi" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="true" />
        <token id="9" string="Award-winning" lemma="award-winning" stem="award-win" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="10" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="Judgment" lemma="judgment" stem="judgment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="Nuremberg" lemma="Nuremberg" stem="nuremberg" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="14" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="1961" lemma="1961" stem="1961" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Emmy" lemma="Emmy" stem="emmy" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="Marcus-Nelson" lemma="Marcus-Nelson" stem="marcus-nelson" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="Murders" lemma="Murders" stem="murder" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="three-hour" lemma="three-hour" stem="three-hour" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="30" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="Kojak" lemma="Kojak" stem="kojak" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="drama" lemma="drama" stem="drama" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="based" lemma="base" stem="base" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="true" lemma="true" stem="true" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="youth" lemma="youth" stem="youth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="wrongly" lemma="wrongly" stem="wrongli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="convicted" lemma="convict" stem="convict" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="killings" lemma="killing" stem="kill" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="50" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="51" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="52" string="white" lemma="white" stem="white" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="53" string="women" lemma="woman" stem="women" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="54" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Mann)) (, ,) (SBAR (WP$ whose) (S (VP (VBG writing) (SBAR (S (NP (NNS credits)) (VP (VBP include) (S (NP (DT the) (NNP Academy)) (ADJP (JJ Award-winning))))))) (NP-TMP (NP (`` ``) (NP (NN Judgment)) (PP (IN at) (NP (NNP Nuremberg))) ('' '')) (PP (IN in) (NP (CD 1961)))))) (, ,)) (VP (VBD won) (NP (NP (DT an) (NNP Emmy)) (PP (IN for) (NP (`` ``) (NP (DT The) (NNP Marcus-Nelson) (NNP Murders)) (, ,) ('' '') (NP (NP (DT a) (JJ three-hour) (`` ``) (NNP Kojak) ('' '') (NN drama)) (VP (VBN based) (PP (IN on) (NP (NP (DT a) (JJ true) (NN case)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (DT a) (JJ black) (NN youth)) (VP (VBD was) (ADVP (RB wrongly)) (VP (VBN convicted) (PP (IN of) (NP (NP (DT the) (NNS killings)) (PP (IN of) (NP (CD two) (JJ white) (NNS women))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a true case" type="NP">
          <tokens>
            <token id="36" string="a" />
            <token id="37" string="true" />
            <token id="38" string="case" />
          </tokens>
        </chunking>
        <chunking id="2" string="`` Judgment at Nuremberg ''" type="NP">
          <tokens>
            <token id="10" string="&quot;" />
            <token id="11" string="Judgment" />
            <token id="12" string="at" />
            <token id="13" string="Nuremberg" />
            <token id="14" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="3" string="a black youth" type="NP">
          <tokens>
            <token id="41" string="a" />
            <token id="42" string="black" />
            <token id="43" string="youth" />
          </tokens>
        </chunking>
        <chunking id="4" string="whose writing credits include the Academy Award-winning `` Judgment at Nuremberg '' in 1961" type="SBAR">
          <tokens>
            <token id="3" string="whose" />
            <token id="4" string="writing" />
            <token id="5" string="credits" />
            <token id="6" string="include" />
            <token id="7" string="the" />
            <token id="8" string="Academy" />
            <token id="9" string="Award-winning" />
            <token id="10" string="&quot;" />
            <token id="11" string="Judgment" />
            <token id="12" string="at" />
            <token id="13" string="Nuremberg" />
            <token id="14" string="&quot;" />
            <token id="15" string="in" />
            <token id="16" string="1961" />
          </tokens>
        </chunking>
        <chunking id="5" string="a three-hour `` Kojak '' drama" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="three-hour" />
            <token id="30" string="&quot;" />
            <token id="31" string="Kojak" />
            <token id="32" string="&quot;" />
            <token id="33" string="drama" />
          </tokens>
        </chunking>
        <chunking id="6" string="Mann , whose writing credits include the Academy Award-winning `` Judgment at Nuremberg '' in 1961 ," type="NP">
          <tokens>
            <token id="1" string="Mann" />
            <token id="2" string="," />
            <token id="3" string="whose" />
            <token id="4" string="writing" />
            <token id="5" string="credits" />
            <token id="6" string="include" />
            <token id="7" string="the" />
            <token id="8" string="Academy" />
            <token id="9" string="Award-winning" />
            <token id="10" string="&quot;" />
            <token id="11" string="Judgment" />
            <token id="12" string="at" />
            <token id="13" string="Nuremberg" />
            <token id="14" string="&quot;" />
            <token id="15" string="in" />
            <token id="16" string="1961" />
            <token id="17" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="1961" type="NP">
          <tokens>
            <token id="16" string="1961" />
          </tokens>
        </chunking>
        <chunking id="8" string="include the Academy Award-winning" type="VP">
          <tokens>
            <token id="6" string="include" />
            <token id="7" string="the" />
            <token id="8" string="Academy" />
            <token id="9" string="Award-winning" />
          </tokens>
        </chunking>
        <chunking id="9" string="an Emmy for `` The Marcus-Nelson Murders , '' a three-hour `` Kojak '' drama based on a true case in which a black youth was wrongly convicted of the killings of two white women" type="NP">
          <tokens>
            <token id="19" string="an" />
            <token id="20" string="Emmy" />
            <token id="21" string="for" />
            <token id="22" string="&quot;" />
            <token id="23" string="The" />
            <token id="24" string="Marcus-Nelson" />
            <token id="25" string="Murders" />
            <token id="26" string="," />
            <token id="27" string="&quot;" />
            <token id="28" string="a" />
            <token id="29" string="three-hour" />
            <token id="30" string="&quot;" />
            <token id="31" string="Kojak" />
            <token id="32" string="&quot;" />
            <token id="33" string="drama" />
            <token id="34" string="based" />
            <token id="35" string="on" />
            <token id="36" string="a" />
            <token id="37" string="true" />
            <token id="38" string="case" />
            <token id="39" string="in" />
            <token id="40" string="which" />
            <token id="41" string="a" />
            <token id="42" string="black" />
            <token id="43" string="youth" />
            <token id="44" string="was" />
            <token id="45" string="wrongly" />
            <token id="46" string="convicted" />
            <token id="47" string="of" />
            <token id="48" string="the" />
            <token id="49" string="killings" />
            <token id="50" string="of" />
            <token id="51" string="two" />
            <token id="52" string="white" />
            <token id="53" string="women" />
          </tokens>
        </chunking>
        <chunking id="10" string="convicted of the killings of two white women" type="VP">
          <tokens>
            <token id="46" string="convicted" />
            <token id="47" string="of" />
            <token id="48" string="the" />
            <token id="49" string="killings" />
            <token id="50" string="of" />
            <token id="51" string="two" />
            <token id="52" string="white" />
            <token id="53" string="women" />
          </tokens>
        </chunking>
        <chunking id="11" string="won an Emmy for `` The Marcus-Nelson Murders , '' a three-hour `` Kojak '' drama based on a true case in which a black youth was wrongly convicted of the killings of two white women" type="VP">
          <tokens>
            <token id="18" string="won" />
            <token id="19" string="an" />
            <token id="20" string="Emmy" />
            <token id="21" string="for" />
            <token id="22" string="&quot;" />
            <token id="23" string="The" />
            <token id="24" string="Marcus-Nelson" />
            <token id="25" string="Murders" />
            <token id="26" string="," />
            <token id="27" string="&quot;" />
            <token id="28" string="a" />
            <token id="29" string="three-hour" />
            <token id="30" string="&quot;" />
            <token id="31" string="Kojak" />
            <token id="32" string="&quot;" />
            <token id="33" string="drama" />
            <token id="34" string="based" />
            <token id="35" string="on" />
            <token id="36" string="a" />
            <token id="37" string="true" />
            <token id="38" string="case" />
            <token id="39" string="in" />
            <token id="40" string="which" />
            <token id="41" string="a" />
            <token id="42" string="black" />
            <token id="43" string="youth" />
            <token id="44" string="was" />
            <token id="45" string="wrongly" />
            <token id="46" string="convicted" />
            <token id="47" string="of" />
            <token id="48" string="the" />
            <token id="49" string="killings" />
            <token id="50" string="of" />
            <token id="51" string="two" />
            <token id="52" string="white" />
            <token id="53" string="women" />
          </tokens>
        </chunking>
        <chunking id="12" string="in which a black youth was wrongly convicted of the killings of two white women" type="SBAR">
          <tokens>
            <token id="39" string="in" />
            <token id="40" string="which" />
            <token id="41" string="a" />
            <token id="42" string="black" />
            <token id="43" string="youth" />
            <token id="44" string="was" />
            <token id="45" string="wrongly" />
            <token id="46" string="convicted" />
            <token id="47" string="of" />
            <token id="48" string="the" />
            <token id="49" string="killings" />
            <token id="50" string="of" />
            <token id="51" string="two" />
            <token id="52" string="white" />
            <token id="53" string="women" />
          </tokens>
        </chunking>
        <chunking id="13" string="a true case in which a black youth was wrongly convicted of the killings of two white women" type="NP">
          <tokens>
            <token id="36" string="a" />
            <token id="37" string="true" />
            <token id="38" string="case" />
            <token id="39" string="in" />
            <token id="40" string="which" />
            <token id="41" string="a" />
            <token id="42" string="black" />
            <token id="43" string="youth" />
            <token id="44" string="was" />
            <token id="45" string="wrongly" />
            <token id="46" string="convicted" />
            <token id="47" string="of" />
            <token id="48" string="the" />
            <token id="49" string="killings" />
            <token id="50" string="of" />
            <token id="51" string="two" />
            <token id="52" string="white" />
            <token id="53" string="women" />
          </tokens>
        </chunking>
        <chunking id="14" string="Award-winning" type="ADJP">
          <tokens>
            <token id="9" string="Award-winning" />
          </tokens>
        </chunking>
        <chunking id="15" string="a three-hour `` Kojak '' drama based on a true case in which a black youth was wrongly convicted of the killings of two white women" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="three-hour" />
            <token id="30" string="&quot;" />
            <token id="31" string="Kojak" />
            <token id="32" string="&quot;" />
            <token id="33" string="drama" />
            <token id="34" string="based" />
            <token id="35" string="on" />
            <token id="36" string="a" />
            <token id="37" string="true" />
            <token id="38" string="case" />
            <token id="39" string="in" />
            <token id="40" string="which" />
            <token id="41" string="a" />
            <token id="42" string="black" />
            <token id="43" string="youth" />
            <token id="44" string="was" />
            <token id="45" string="wrongly" />
            <token id="46" string="convicted" />
            <token id="47" string="of" />
            <token id="48" string="the" />
            <token id="49" string="killings" />
            <token id="50" string="of" />
            <token id="51" string="two" />
            <token id="52" string="white" />
            <token id="53" string="women" />
          </tokens>
        </chunking>
        <chunking id="16" string="two white women" type="NP">
          <tokens>
            <token id="51" string="two" />
            <token id="52" string="white" />
            <token id="53" string="women" />
          </tokens>
        </chunking>
        <chunking id="17" string="credits include the Academy Award-winning" type="SBAR">
          <tokens>
            <token id="5" string="credits" />
            <token id="6" string="include" />
            <token id="7" string="the" />
            <token id="8" string="Academy" />
            <token id="9" string="Award-winning" />
          </tokens>
        </chunking>
        <chunking id="18" string="based on a true case in which a black youth was wrongly convicted of the killings of two white women" type="VP">
          <tokens>
            <token id="34" string="based" />
            <token id="35" string="on" />
            <token id="36" string="a" />
            <token id="37" string="true" />
            <token id="38" string="case" />
            <token id="39" string="in" />
            <token id="40" string="which" />
            <token id="41" string="a" />
            <token id="42" string="black" />
            <token id="43" string="youth" />
            <token id="44" string="was" />
            <token id="45" string="wrongly" />
            <token id="46" string="convicted" />
            <token id="47" string="of" />
            <token id="48" string="the" />
            <token id="49" string="killings" />
            <token id="50" string="of" />
            <token id="51" string="two" />
            <token id="52" string="white" />
            <token id="53" string="women" />
          </tokens>
        </chunking>
        <chunking id="19" string="`` The Marcus-Nelson Murders , '' a three-hour `` Kojak '' drama based on a true case in which a black youth was wrongly convicted of the killings of two white women" type="NP">
          <tokens>
            <token id="22" string="&quot;" />
            <token id="23" string="The" />
            <token id="24" string="Marcus-Nelson" />
            <token id="25" string="Murders" />
            <token id="26" string="," />
            <token id="27" string="&quot;" />
            <token id="28" string="a" />
            <token id="29" string="three-hour" />
            <token id="30" string="&quot;" />
            <token id="31" string="Kojak" />
            <token id="32" string="&quot;" />
            <token id="33" string="drama" />
            <token id="34" string="based" />
            <token id="35" string="on" />
            <token id="36" string="a" />
            <token id="37" string="true" />
            <token id="38" string="case" />
            <token id="39" string="in" />
            <token id="40" string="which" />
            <token id="41" string="a" />
            <token id="42" string="black" />
            <token id="43" string="youth" />
            <token id="44" string="was" />
            <token id="45" string="wrongly" />
            <token id="46" string="convicted" />
            <token id="47" string="of" />
            <token id="48" string="the" />
            <token id="49" string="killings" />
            <token id="50" string="of" />
            <token id="51" string="two" />
            <token id="52" string="white" />
            <token id="53" string="women" />
          </tokens>
        </chunking>
        <chunking id="20" string="writing credits include the Academy Award-winning" type="VP">
          <tokens>
            <token id="4" string="writing" />
            <token id="5" string="credits" />
            <token id="6" string="include" />
            <token id="7" string="the" />
            <token id="8" string="Academy" />
            <token id="9" string="Award-winning" />
          </tokens>
        </chunking>
        <chunking id="21" string="The Marcus-Nelson Murders" type="NP">
          <tokens>
            <token id="23" string="The" />
            <token id="24" string="Marcus-Nelson" />
            <token id="25" string="Murders" />
          </tokens>
        </chunking>
        <chunking id="22" string="was wrongly convicted of the killings of two white women" type="VP">
          <tokens>
            <token id="44" string="was" />
            <token id="45" string="wrongly" />
            <token id="46" string="convicted" />
            <token id="47" string="of" />
            <token id="48" string="the" />
            <token id="49" string="killings" />
            <token id="50" string="of" />
            <token id="51" string="two" />
            <token id="52" string="white" />
            <token id="53" string="women" />
          </tokens>
        </chunking>
        <chunking id="23" string="an Emmy" type="NP">
          <tokens>
            <token id="19" string="an" />
            <token id="20" string="Emmy" />
          </tokens>
        </chunking>
        <chunking id="24" string="the killings" type="NP">
          <tokens>
            <token id="48" string="the" />
            <token id="49" string="killings" />
          </tokens>
        </chunking>
        <chunking id="25" string="credits" type="NP">
          <tokens>
            <token id="5" string="credits" />
          </tokens>
        </chunking>
        <chunking id="26" string="Mann" type="NP">
          <tokens>
            <token id="1" string="Mann" />
          </tokens>
        </chunking>
        <chunking id="27" string="Judgment" type="NP">
          <tokens>
            <token id="11" string="Judgment" />
          </tokens>
        </chunking>
        <chunking id="28" string="the killings of two white women" type="NP">
          <tokens>
            <token id="48" string="the" />
            <token id="49" string="killings" />
            <token id="50" string="of" />
            <token id="51" string="two" />
            <token id="52" string="white" />
            <token id="53" string="women" />
          </tokens>
        </chunking>
        <chunking id="29" string="the Academy" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Academy" />
          </tokens>
        </chunking>
        <chunking id="30" string="Nuremberg" type="NP">
          <tokens>
            <token id="13" string="Nuremberg" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="18">won</governor>
          <dependent id="1">Mann</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">writing</governor>
          <dependent id="3">whose</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">Mann</governor>
          <dependent id="4">writing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">include</governor>
          <dependent id="5">credits</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">writing</governor>
          <dependent id="6">include</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">Academy</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">Award-winning</governor>
          <dependent id="8">Academy</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">include</governor>
          <dependent id="9">Award-winning</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">writing</governor>
          <dependent id="11">Judgment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Nuremberg</governor>
          <dependent id="12">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">Judgment</governor>
          <dependent id="13">Nuremberg</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">1961</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">Judgment</governor>
          <dependent id="16">1961</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">won</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">Emmy</governor>
          <dependent id="19">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">won</governor>
          <dependent id="20">Emmy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Murders</governor>
          <dependent id="21">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">Murders</governor>
          <dependent id="23">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Murders</governor>
          <dependent id="24">Marcus-Nelson</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">Emmy</governor>
          <dependent id="25">Murders</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">drama</governor>
          <dependent id="28">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">drama</governor>
          <dependent id="29">three-hour</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">drama</governor>
          <dependent id="31">Kojak</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="25">Murders</governor>
          <dependent id="33">drama</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="33">drama</governor>
          <dependent id="34">based</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">case</governor>
          <dependent id="35">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">case</governor>
          <dependent id="36">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">case</governor>
          <dependent id="37">true</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">based</governor>
          <dependent id="38">case</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">which</governor>
          <dependent id="39">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="46">convicted</governor>
          <dependent id="40">which</dependent>
        </dependency>
        <dependency type="det">
          <governor id="43">youth</governor>
          <dependent id="41">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="43">youth</governor>
          <dependent id="42">black</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="46">convicted</governor>
          <dependent id="43">youth</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="46">convicted</governor>
          <dependent id="44">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="46">convicted</governor>
          <dependent id="45">wrongly</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="38">case</governor>
          <dependent id="46">convicted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="49">killings</governor>
          <dependent id="47">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="49">killings</governor>
          <dependent id="48">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="46">convicted</governor>
          <dependent id="49">killings</dependent>
        </dependency>
        <dependency type="case">
          <governor id="53">women</governor>
          <dependent id="50">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="53">women</governor>
          <dependent id="51">two</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="53">women</governor>
          <dependent id="52">white</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="49">killings</governor>
          <dependent id="53">women</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Academy Award-winning" type="MISC" score="0.0">
          <tokens>
            <token id="8" string="Academy" />
            <token id="9" string="Award-winning" />
          </tokens>
        </entity>
        <entity id="2" string="1961" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="1961" />
          </tokens>
        </entity>
        <entity id="3" string="three-hour" type="DURATION" score="0.0">
          <tokens>
            <token id="29" string="three-hour" />
          </tokens>
        </entity>
        <entity id="4" string="Mann" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Mann" />
          </tokens>
        </entity>
        <entity id="5" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="51" string="two" />
          </tokens>
        </entity>
        <entity id="6" string="Nuremberg" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Nuremberg" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>The prosecutors, the media and the community seemed blinded by hysteria, Mann said.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="prosecutors" lemma="prosecutor" stem="prosecutor" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="media" lemma="media" stem="media" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="community" lemma="community" stem="commun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="seemed" lemma="seem" stem="seem" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="blinded" lemma="blind" stem="blind" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="hysteria" lemma="hysteria" stem="hysteria" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Mann" lemma="Mann" stem="mann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="15" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (DT The) (NNS prosecutors)) (, ,) (NP (DT the) (NNS media)) (CC and) (NP (DT the) (NN community))) (VP (VBD seemed) (VP (VBN blinded) (PP (IN by) (NP (NN hysteria)))))) (, ,) (NP (NNP Mann)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The prosecutors , the media and the community" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="prosecutors" />
            <token id="3" string="," />
            <token id="4" string="the" />
            <token id="5" string="media" />
            <token id="6" string="and" />
            <token id="7" string="the" />
            <token id="8" string="community" />
          </tokens>
        </chunking>
        <chunking id="2" string="seemed blinded by hysteria" type="VP">
          <tokens>
            <token id="9" string="seemed" />
            <token id="10" string="blinded" />
            <token id="11" string="by" />
            <token id="12" string="hysteria" />
          </tokens>
        </chunking>
        <chunking id="3" string="blinded by hysteria" type="VP">
          <tokens>
            <token id="10" string="blinded" />
            <token id="11" string="by" />
            <token id="12" string="hysteria" />
          </tokens>
        </chunking>
        <chunking id="4" string="Mann" type="NP">
          <tokens>
            <token id="14" string="Mann" />
          </tokens>
        </chunking>
        <chunking id="5" string="the media" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="media" />
          </tokens>
        </chunking>
        <chunking id="6" string="The prosecutors" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="prosecutors" />
          </tokens>
        </chunking>
        <chunking id="7" string="hysteria" type="NP">
          <tokens>
            <token id="12" string="hysteria" />
          </tokens>
        </chunking>
        <chunking id="8" string="said" type="VP">
          <tokens>
            <token id="15" string="said" />
          </tokens>
        </chunking>
        <chunking id="9" string="the community" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="community" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">prosecutors</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">seemed</governor>
          <dependent id="2">prosecutors</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">media</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">prosecutors</governor>
          <dependent id="5">media</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">prosecutors</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">community</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">prosecutors</governor>
          <dependent id="8">community</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">said</governor>
          <dependent id="9">seemed</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">seemed</governor>
          <dependent id="10">blinded</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">hysteria</governor>
          <dependent id="11">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">blinded</governor>
          <dependent id="12">hysteria</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">said</governor>
          <dependent id="14">Mann</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mann" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Mann" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>Gaining the confidence of the McMartin defendants, the Manns were ultimately hired as &amp;quot;investigators&amp;quot; by the defense.</content>
      <tokens>
        <token id="1" string="Gaining" lemma="Gaining" stem="gain" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="confidence" lemma="confidence" stem="confid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="Manns" lemma="Manns" stem="mann" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="11" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="ultimately" lemma="ultimately" stem="ultim" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="hired" lemma="hire" stem="hire" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="investigators" lemma="investigator" stem="investig" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="defense" lemma="defense" stem="defens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (NNP Gaining) (NP (DT the) (NN confidence)) (PP (IN of) (NP (DT the) (NNP McMartin) (NNS defendants))))) (, ,) (NP (DT the) (NNP Manns)) (VP (VBD were) (ADVP (RB ultimately)) (VP (VBN hired) (PP (IN as) (`` ``) (NP (NNS investigators)) ('' '')) (PP (IN by) (NP (DT the) (NN defense))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="were ultimately hired as `` investigators '' by the defense" type="VP">
          <tokens>
            <token id="11" string="were" />
            <token id="12" string="ultimately" />
            <token id="13" string="hired" />
            <token id="14" string="as" />
            <token id="15" string="&quot;" />
            <token id="16" string="investigators" />
            <token id="17" string="&quot;" />
            <token id="18" string="by" />
            <token id="19" string="the" />
            <token id="20" string="defense" />
          </tokens>
        </chunking>
        <chunking id="2" string="the defense" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="defense" />
          </tokens>
        </chunking>
        <chunking id="3" string="investigators" type="NP">
          <tokens>
            <token id="16" string="investigators" />
          </tokens>
        </chunking>
        <chunking id="4" string="Gaining the confidence of the McMartin defendants" type="VP">
          <tokens>
            <token id="1" string="Gaining" />
            <token id="2" string="the" />
            <token id="3" string="confidence" />
            <token id="4" string="of" />
            <token id="5" string="the" />
            <token id="6" string="McMartin" />
            <token id="7" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="5" string="the McMartin defendants" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="McMartin" />
            <token id="7" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="6" string="hired as `` investigators '' by the defense" type="VP">
          <tokens>
            <token id="13" string="hired" />
            <token id="14" string="as" />
            <token id="15" string="&quot;" />
            <token id="16" string="investigators" />
            <token id="17" string="&quot;" />
            <token id="18" string="by" />
            <token id="19" string="the" />
            <token id="20" string="defense" />
          </tokens>
        </chunking>
        <chunking id="7" string="the Manns" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="Manns" />
          </tokens>
        </chunking>
        <chunking id="8" string="the confidence" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="confidence" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="3">confidence</governor>
          <dependent id="1">Gaining</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">confidence</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">hired</governor>
          <dependent id="3">confidence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">defendants</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">defendants</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">defendants</governor>
          <dependent id="6">McMartin</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">confidence</governor>
          <dependent id="7">defendants</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">Manns</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">hired</governor>
          <dependent id="10">Manns</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">hired</governor>
          <dependent id="11">were</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">hired</governor>
          <dependent id="12">ultimately</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">hired</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">investigators</governor>
          <dependent id="14">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">hired</governor>
          <dependent id="16">investigators</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">defense</governor>
          <dependent id="18">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">defense</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">hired</governor>
          <dependent id="20">defense</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Manns" type="MISC" score="0.0">
          <tokens>
            <token id="10" string="Manns" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>That and their earlier alliance with former prosecutor Glenn Stevens sparked charges from parents of alleged child molestation victims of a conspiracy to obstruct justice for monetary gain.</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="earlier" lemma="earlier" stem="earlier" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="alliance" lemma="alliance" stem="allianc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="prosecutor" lemma="prosecutor" stem="prosecutor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Glenn" lemma="Glenn" stem="glenn" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="10" string="Stevens" lemma="Stevens" stem="steven" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="sparked" lemma="spark" stem="spark" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="parents" lemma="parent" stem="parent" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="alleged" lemma="alleged" stem="alleg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="child" lemma="child" stem="child" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="molestation" lemma="molestation" stem="molest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="victims" lemma="victim" stem="victim" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="conspiracy" lemma="conspiracy" stem="conspiraci" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="obstruct" lemma="obstruct" stem="obstruct" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="justice" lemma="justice" stem="justic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="monetary" lemma="monetary" stem="monetari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="gain" lemma="gain" stem="gain" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT That)) (CC and) (NP (NP (PRP$ their) (JJR earlier) (NN alliance)) (PP (IN with) (NP (JJ former) (NN prosecutor) (NNP Glenn) (NNP Stevens))))) (VP (VBD sparked) (NP (NNS charges)) (PP (IN from) (NP (NP (NNS parents)) (PP (IN of) (NP (NP (JJ alleged) (NN child) (NN molestation) (NNS victims)) (PP (IN of) (NP (DT a) (NN conspiracy))))))) (S (VP (TO to) (VP (VB obstruct) (NP (NN justice)) (PP (IN for) (NP (JJ monetary) (NN gain))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="That" type="NP">
          <tokens>
            <token id="1" string="That" />
          </tokens>
        </chunking>
        <chunking id="2" string="That and their earlier alliance with former prosecutor Glenn Stevens" type="NP">
          <tokens>
            <token id="1" string="That" />
            <token id="2" string="and" />
            <token id="3" string="their" />
            <token id="4" string="earlier" />
            <token id="5" string="alliance" />
            <token id="6" string="with" />
            <token id="7" string="former" />
            <token id="8" string="prosecutor" />
            <token id="9" string="Glenn" />
            <token id="10" string="Stevens" />
          </tokens>
        </chunking>
        <chunking id="3" string="to obstruct justice for monetary gain" type="VP">
          <tokens>
            <token id="23" string="to" />
            <token id="24" string="obstruct" />
            <token id="25" string="justice" />
            <token id="26" string="for" />
            <token id="27" string="monetary" />
            <token id="28" string="gain" />
          </tokens>
        </chunking>
        <chunking id="4" string="monetary gain" type="NP">
          <tokens>
            <token id="27" string="monetary" />
            <token id="28" string="gain" />
          </tokens>
        </chunking>
        <chunking id="5" string="alleged child molestation victims" type="NP">
          <tokens>
            <token id="16" string="alleged" />
            <token id="17" string="child" />
            <token id="18" string="molestation" />
            <token id="19" string="victims" />
          </tokens>
        </chunking>
        <chunking id="6" string="sparked charges from parents of alleged child molestation victims of a conspiracy to obstruct justice for monetary gain" type="VP">
          <tokens>
            <token id="11" string="sparked" />
            <token id="12" string="charges" />
            <token id="13" string="from" />
            <token id="14" string="parents" />
            <token id="15" string="of" />
            <token id="16" string="alleged" />
            <token id="17" string="child" />
            <token id="18" string="molestation" />
            <token id="19" string="victims" />
            <token id="20" string="of" />
            <token id="21" string="a" />
            <token id="22" string="conspiracy" />
            <token id="23" string="to" />
            <token id="24" string="obstruct" />
            <token id="25" string="justice" />
            <token id="26" string="for" />
            <token id="27" string="monetary" />
            <token id="28" string="gain" />
          </tokens>
        </chunking>
        <chunking id="7" string="their earlier alliance with former prosecutor Glenn Stevens" type="NP">
          <tokens>
            <token id="3" string="their" />
            <token id="4" string="earlier" />
            <token id="5" string="alliance" />
            <token id="6" string="with" />
            <token id="7" string="former" />
            <token id="8" string="prosecutor" />
            <token id="9" string="Glenn" />
            <token id="10" string="Stevens" />
          </tokens>
        </chunking>
        <chunking id="8" string="their earlier alliance" type="NP">
          <tokens>
            <token id="3" string="their" />
            <token id="4" string="earlier" />
            <token id="5" string="alliance" />
          </tokens>
        </chunking>
        <chunking id="9" string="former prosecutor Glenn Stevens" type="NP">
          <tokens>
            <token id="7" string="former" />
            <token id="8" string="prosecutor" />
            <token id="9" string="Glenn" />
            <token id="10" string="Stevens" />
          </tokens>
        </chunking>
        <chunking id="10" string="a conspiracy" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="conspiracy" />
          </tokens>
        </chunking>
        <chunking id="11" string="parents of alleged child molestation victims of a conspiracy" type="NP">
          <tokens>
            <token id="14" string="parents" />
            <token id="15" string="of" />
            <token id="16" string="alleged" />
            <token id="17" string="child" />
            <token id="18" string="molestation" />
            <token id="19" string="victims" />
            <token id="20" string="of" />
            <token id="21" string="a" />
            <token id="22" string="conspiracy" />
          </tokens>
        </chunking>
        <chunking id="12" string="charges" type="NP">
          <tokens>
            <token id="12" string="charges" />
          </tokens>
        </chunking>
        <chunking id="13" string="justice" type="NP">
          <tokens>
            <token id="25" string="justice" />
          </tokens>
        </chunking>
        <chunking id="14" string="obstruct justice for monetary gain" type="VP">
          <tokens>
            <token id="24" string="obstruct" />
            <token id="25" string="justice" />
            <token id="26" string="for" />
            <token id="27" string="monetary" />
            <token id="28" string="gain" />
          </tokens>
        </chunking>
        <chunking id="15" string="alleged child molestation victims of a conspiracy" type="NP">
          <tokens>
            <token id="16" string="alleged" />
            <token id="17" string="child" />
            <token id="18" string="molestation" />
            <token id="19" string="victims" />
            <token id="20" string="of" />
            <token id="21" string="a" />
            <token id="22" string="conspiracy" />
          </tokens>
        </chunking>
        <chunking id="16" string="parents" type="NP">
          <tokens>
            <token id="14" string="parents" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="11">sparked</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">That</governor>
          <dependent id="2">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">alliance</governor>
          <dependent id="3">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">alliance</governor>
          <dependent id="4">earlier</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">That</governor>
          <dependent id="5">alliance</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Stevens</governor>
          <dependent id="6">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">Stevens</governor>
          <dependent id="7">former</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Stevens</governor>
          <dependent id="8">prosecutor</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Stevens</governor>
          <dependent id="9">Glenn</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">alliance</governor>
          <dependent id="10">Stevens</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">sparked</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">sparked</governor>
          <dependent id="12">charges</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">parents</governor>
          <dependent id="13">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">sparked</governor>
          <dependent id="14">parents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">victims</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">victims</governor>
          <dependent id="16">alleged</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">victims</governor>
          <dependent id="17">child</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">victims</governor>
          <dependent id="18">molestation</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">parents</governor>
          <dependent id="19">victims</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">conspiracy</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">conspiracy</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">victims</governor>
          <dependent id="22">conspiracy</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">obstruct</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">sparked</governor>
          <dependent id="24">obstruct</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">obstruct</governor>
          <dependent id="25">justice</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">gain</governor>
          <dependent id="26">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">gain</governor>
          <dependent id="27">monetary</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">obstruct</governor>
          <dependent id="28">gain</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Glenn Stevens" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Glenn" />
            <token id="10" string="Stevens" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>Stevens, who said he had asked to be removed from the McMartin trial team in October, 1985, said he and Mann agreed in March, 1986, to produce a book and movie about the case with the understanding that their discussions would become public after the trial and appeals were over.</content>
      <tokens>
        <token id="1" string="Stevens" lemma="Stevens" stem="steven" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="asked" lemma="ask" stem="ask" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="removed" lemma="remove" stem="remov" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="14" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="team" lemma="team" stem="team" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="October" lemma="October" stem="october" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="19" string="1985" lemma="1985" stem="1985" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="Mann" lemma="Mann" stem="mann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="25" string="agreed" lemma="agree" stem="agre" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="March" lemma="March" stem="march" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="29" string="1986" lemma="1986" stem="1986" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="produce" lemma="produce" stem="produc" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="movie" lemma="movie" stem="movi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="39" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="40" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="41" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="42" string="understanding" lemma="understanding" stem="understand" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="43" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="discussions" lemma="discussion" stem="discuss" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="become" lemma="become" stem="becom" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="51" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="52" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="53" string="appeals" lemma="appeal" stem="appeal" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="54" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="55" string="over" lemma="over" stem="over" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="56" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Stevens)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBD had) (VP (VBN asked) (S (VP (TO to) (VP (VB be) (VP (VBN removed) (PP (IN from) (NP (NP (DT the) (NNP McMartin) (NN trial) (NN team)) (PP (IN in) (NP (NP (NNP October)) (, ,) (NP (CD 1985))))))))))))))))) (, ,)) (VP (VBD said) (SBAR (S (NP (PRP he) (CC and) (NNP Mann)) (VP (VBD agreed) (PP (IN in) (NP (NP (NNP March)) (, ,) (NP (CD 1986)))) (, ,) (S (VP (TO to) (VP (VB produce) (NP (DT a) (NN book) (CC and) (NN movie)) (PP (IN about) (NP (NP (DT the) (NN case)) (PP (IN with) (NP (DT the) (NN understanding))))) (SBAR (IN that) (S (NP (PRP$ their) (NNS discussions)) (VP (MD would) (VP (VB become) (ADJP (JJ public)) (SBAR (IN after) (S (NP (NP (DT the) (NN trial)) (CC and) (NP (NNS appeals))) (VP (VBD were) (ADVP (RB over)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="become public after the trial and appeals were over" type="VP">
          <tokens>
            <token id="47" string="become" />
            <token id="48" string="public" />
            <token id="49" string="after" />
            <token id="50" string="the" />
            <token id="51" string="trial" />
            <token id="52" string="and" />
            <token id="53" string="appeals" />
            <token id="54" string="were" />
            <token id="55" string="over" />
          </tokens>
        </chunking>
        <chunking id="2" string="the trial" type="NP">
          <tokens>
            <token id="50" string="the" />
            <token id="51" string="trial" />
          </tokens>
        </chunking>
        <chunking id="3" string="he and Mann" type="NP">
          <tokens>
            <token id="22" string="he" />
            <token id="23" string="and" />
            <token id="24" string="Mann" />
          </tokens>
        </chunking>
        <chunking id="4" string="the McMartin trial team in October , 1985" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="McMartin" />
            <token id="14" string="trial" />
            <token id="15" string="team" />
            <token id="16" string="in" />
            <token id="17" string="October" />
            <token id="18" string="," />
            <token id="19" string="1985" />
          </tokens>
        </chunking>
        <chunking id="5" string="the case" type="NP">
          <tokens>
            <token id="38" string="the" />
            <token id="39" string="case" />
          </tokens>
        </chunking>
        <chunking id="6" string="October , 1985" type="NP">
          <tokens>
            <token id="17" string="October" />
            <token id="18" string="," />
            <token id="19" string="1985" />
          </tokens>
        </chunking>
        <chunking id="7" string="said he had asked to be removed from the McMartin trial team in October , 1985" type="VP">
          <tokens>
            <token id="4" string="said" />
            <token id="5" string="he" />
            <token id="6" string="had" />
            <token id="7" string="asked" />
            <token id="8" string="to" />
            <token id="9" string="be" />
            <token id="10" string="removed" />
            <token id="11" string="from" />
            <token id="12" string="the" />
            <token id="13" string="McMartin" />
            <token id="14" string="trial" />
            <token id="15" string="team" />
            <token id="16" string="in" />
            <token id="17" string="October" />
            <token id="18" string="," />
            <token id="19" string="1985" />
          </tokens>
        </chunking>
        <chunking id="8" string="that their discussions would become public after the trial and appeals were over" type="SBAR">
          <tokens>
            <token id="43" string="that" />
            <token id="44" string="their" />
            <token id="45" string="discussions" />
            <token id="46" string="would" />
            <token id="47" string="become" />
            <token id="48" string="public" />
            <token id="49" string="after" />
            <token id="50" string="the" />
            <token id="51" string="trial" />
            <token id="52" string="and" />
            <token id="53" string="appeals" />
            <token id="54" string="were" />
            <token id="55" string="over" />
          </tokens>
        </chunking>
        <chunking id="9" string="Stevens" type="NP">
          <tokens>
            <token id="1" string="Stevens" />
          </tokens>
        </chunking>
        <chunking id="10" string="a book and movie" type="NP">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="book" />
            <token id="35" string="and" />
            <token id="36" string="movie" />
          </tokens>
        </chunking>
        <chunking id="11" string="October" type="NP">
          <tokens>
            <token id="17" string="October" />
          </tokens>
        </chunking>
        <chunking id="12" string="were over" type="VP">
          <tokens>
            <token id="54" string="were" />
            <token id="55" string="over" />
          </tokens>
        </chunking>
        <chunking id="13" string="asked to be removed from the McMartin trial team in October , 1985" type="VP">
          <tokens>
            <token id="7" string="asked" />
            <token id="8" string="to" />
            <token id="9" string="be" />
            <token id="10" string="removed" />
            <token id="11" string="from" />
            <token id="12" string="the" />
            <token id="13" string="McMartin" />
            <token id="14" string="trial" />
            <token id="15" string="team" />
            <token id="16" string="in" />
            <token id="17" string="October" />
            <token id="18" string="," />
            <token id="19" string="1985" />
          </tokens>
        </chunking>
        <chunking id="14" string="who said he had asked to be removed from the McMartin trial team in October , 1985" type="SBAR">
          <tokens>
            <token id="3" string="who" />
            <token id="4" string="said" />
            <token id="5" string="he" />
            <token id="6" string="had" />
            <token id="7" string="asked" />
            <token id="8" string="to" />
            <token id="9" string="be" />
            <token id="10" string="removed" />
            <token id="11" string="from" />
            <token id="12" string="the" />
            <token id="13" string="McMartin" />
            <token id="14" string="trial" />
            <token id="15" string="team" />
            <token id="16" string="in" />
            <token id="17" string="October" />
            <token id="18" string="," />
            <token id="19" string="1985" />
          </tokens>
        </chunking>
        <chunking id="15" string="would become public after the trial and appeals were over" type="VP">
          <tokens>
            <token id="46" string="would" />
            <token id="47" string="become" />
            <token id="48" string="public" />
            <token id="49" string="after" />
            <token id="50" string="the" />
            <token id="51" string="trial" />
            <token id="52" string="and" />
            <token id="53" string="appeals" />
            <token id="54" string="were" />
            <token id="55" string="over" />
          </tokens>
        </chunking>
        <chunking id="16" string="1986" type="NP">
          <tokens>
            <token id="29" string="1986" />
          </tokens>
        </chunking>
        <chunking id="17" string="removed from the McMartin trial team in October , 1985" type="VP">
          <tokens>
            <token id="10" string="removed" />
            <token id="11" string="from" />
            <token id="12" string="the" />
            <token id="13" string="McMartin" />
            <token id="14" string="trial" />
            <token id="15" string="team" />
            <token id="16" string="in" />
            <token id="17" string="October" />
            <token id="18" string="," />
            <token id="19" string="1985" />
          </tokens>
        </chunking>
        <chunking id="18" string="1985" type="NP">
          <tokens>
            <token id="19" string="1985" />
          </tokens>
        </chunking>
        <chunking id="19" string="the case with the understanding" type="NP">
          <tokens>
            <token id="38" string="the" />
            <token id="39" string="case" />
            <token id="40" string="with" />
            <token id="41" string="the" />
            <token id="42" string="understanding" />
          </tokens>
        </chunking>
        <chunking id="20" string="the understanding" type="NP">
          <tokens>
            <token id="41" string="the" />
            <token id="42" string="understanding" />
          </tokens>
        </chunking>
        <chunking id="21" string="appeals" type="NP">
          <tokens>
            <token id="53" string="appeals" />
          </tokens>
        </chunking>
        <chunking id="22" string="he" type="NP">
          <tokens>
            <token id="5" string="he" />
          </tokens>
        </chunking>
        <chunking id="23" string="said he and Mann agreed in March , 1986 , to produce a book and movie about the case with the understanding that their discussions would become public after the trial and appeals were over" type="VP">
          <tokens>
            <token id="21" string="said" />
            <token id="22" string="he" />
            <token id="23" string="and" />
            <token id="24" string="Mann" />
            <token id="25" string="agreed" />
            <token id="26" string="in" />
            <token id="27" string="March" />
            <token id="28" string="," />
            <token id="29" string="1986" />
            <token id="30" string="," />
            <token id="31" string="to" />
            <token id="32" string="produce" />
            <token id="33" string="a" />
            <token id="34" string="book" />
            <token id="35" string="and" />
            <token id="36" string="movie" />
            <token id="37" string="about" />
            <token id="38" string="the" />
            <token id="39" string="case" />
            <token id="40" string="with" />
            <token id="41" string="the" />
            <token id="42" string="understanding" />
            <token id="43" string="that" />
            <token id="44" string="their" />
            <token id="45" string="discussions" />
            <token id="46" string="would" />
            <token id="47" string="become" />
            <token id="48" string="public" />
            <token id="49" string="after" />
            <token id="50" string="the" />
            <token id="51" string="trial" />
            <token id="52" string="and" />
            <token id="53" string="appeals" />
            <token id="54" string="were" />
            <token id="55" string="over" />
          </tokens>
        </chunking>
        <chunking id="24" string="the trial and appeals" type="NP">
          <tokens>
            <token id="50" string="the" />
            <token id="51" string="trial" />
            <token id="52" string="and" />
            <token id="53" string="appeals" />
          </tokens>
        </chunking>
        <chunking id="25" string="Stevens , who said he had asked to be removed from the McMartin trial team in October , 1985 ," type="NP">
          <tokens>
            <token id="1" string="Stevens" />
            <token id="2" string="," />
            <token id="3" string="who" />
            <token id="4" string="said" />
            <token id="5" string="he" />
            <token id="6" string="had" />
            <token id="7" string="asked" />
            <token id="8" string="to" />
            <token id="9" string="be" />
            <token id="10" string="removed" />
            <token id="11" string="from" />
            <token id="12" string="the" />
            <token id="13" string="McMartin" />
            <token id="14" string="trial" />
            <token id="15" string="team" />
            <token id="16" string="in" />
            <token id="17" string="October" />
            <token id="18" string="," />
            <token id="19" string="1985" />
            <token id="20" string="," />
          </tokens>
        </chunking>
        <chunking id="26" string="the McMartin trial team" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="McMartin" />
            <token id="14" string="trial" />
            <token id="15" string="team" />
          </tokens>
        </chunking>
        <chunking id="27" string="March , 1986" type="NP">
          <tokens>
            <token id="27" string="March" />
            <token id="28" string="," />
            <token id="29" string="1986" />
          </tokens>
        </chunking>
        <chunking id="28" string="agreed in March , 1986 , to produce a book and movie about the case with the understanding that their discussions would become public after the trial and appeals were over" type="VP">
          <tokens>
            <token id="25" string="agreed" />
            <token id="26" string="in" />
            <token id="27" string="March" />
            <token id="28" string="," />
            <token id="29" string="1986" />
            <token id="30" string="," />
            <token id="31" string="to" />
            <token id="32" string="produce" />
            <token id="33" string="a" />
            <token id="34" string="book" />
            <token id="35" string="and" />
            <token id="36" string="movie" />
            <token id="37" string="about" />
            <token id="38" string="the" />
            <token id="39" string="case" />
            <token id="40" string="with" />
            <token id="41" string="the" />
            <token id="42" string="understanding" />
            <token id="43" string="that" />
            <token id="44" string="their" />
            <token id="45" string="discussions" />
            <token id="46" string="would" />
            <token id="47" string="become" />
            <token id="48" string="public" />
            <token id="49" string="after" />
            <token id="50" string="the" />
            <token id="51" string="trial" />
            <token id="52" string="and" />
            <token id="53" string="appeals" />
            <token id="54" string="were" />
            <token id="55" string="over" />
          </tokens>
        </chunking>
        <chunking id="29" string="March" type="NP">
          <tokens>
            <token id="27" string="March" />
          </tokens>
        </chunking>
        <chunking id="30" string="their discussions" type="NP">
          <tokens>
            <token id="44" string="their" />
            <token id="45" string="discussions" />
          </tokens>
        </chunking>
        <chunking id="31" string="had asked to be removed from the McMartin trial team in October , 1985" type="VP">
          <tokens>
            <token id="6" string="had" />
            <token id="7" string="asked" />
            <token id="8" string="to" />
            <token id="9" string="be" />
            <token id="10" string="removed" />
            <token id="11" string="from" />
            <token id="12" string="the" />
            <token id="13" string="McMartin" />
            <token id="14" string="trial" />
            <token id="15" string="team" />
            <token id="16" string="in" />
            <token id="17" string="October" />
            <token id="18" string="," />
            <token id="19" string="1985" />
          </tokens>
        </chunking>
        <chunking id="32" string="he had asked to be removed from the McMartin trial team in October , 1985" type="SBAR">
          <tokens>
            <token id="5" string="he" />
            <token id="6" string="had" />
            <token id="7" string="asked" />
            <token id="8" string="to" />
            <token id="9" string="be" />
            <token id="10" string="removed" />
            <token id="11" string="from" />
            <token id="12" string="the" />
            <token id="13" string="McMartin" />
            <token id="14" string="trial" />
            <token id="15" string="team" />
            <token id="16" string="in" />
            <token id="17" string="October" />
            <token id="18" string="," />
            <token id="19" string="1985" />
          </tokens>
        </chunking>
        <chunking id="33" string="public" type="ADJP">
          <tokens>
            <token id="48" string="public" />
          </tokens>
        </chunking>
        <chunking id="34" string="to be removed from the McMartin trial team in October , 1985" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="be" />
            <token id="10" string="removed" />
            <token id="11" string="from" />
            <token id="12" string="the" />
            <token id="13" string="McMartin" />
            <token id="14" string="trial" />
            <token id="15" string="team" />
            <token id="16" string="in" />
            <token id="17" string="October" />
            <token id="18" string="," />
            <token id="19" string="1985" />
          </tokens>
        </chunking>
        <chunking id="35" string="he and Mann agreed in March , 1986 , to produce a book and movie about the case with the understanding that their discussions would become public after the trial and appeals were over" type="SBAR">
          <tokens>
            <token id="22" string="he" />
            <token id="23" string="and" />
            <token id="24" string="Mann" />
            <token id="25" string="agreed" />
            <token id="26" string="in" />
            <token id="27" string="March" />
            <token id="28" string="," />
            <token id="29" string="1986" />
            <token id="30" string="," />
            <token id="31" string="to" />
            <token id="32" string="produce" />
            <token id="33" string="a" />
            <token id="34" string="book" />
            <token id="35" string="and" />
            <token id="36" string="movie" />
            <token id="37" string="about" />
            <token id="38" string="the" />
            <token id="39" string="case" />
            <token id="40" string="with" />
            <token id="41" string="the" />
            <token id="42" string="understanding" />
            <token id="43" string="that" />
            <token id="44" string="their" />
            <token id="45" string="discussions" />
            <token id="46" string="would" />
            <token id="47" string="become" />
            <token id="48" string="public" />
            <token id="49" string="after" />
            <token id="50" string="the" />
            <token id="51" string="trial" />
            <token id="52" string="and" />
            <token id="53" string="appeals" />
            <token id="54" string="were" />
            <token id="55" string="over" />
          </tokens>
        </chunking>
        <chunking id="36" string="produce a book and movie about the case with the understanding that their discussions would become public after the trial and appeals were over" type="VP">
          <tokens>
            <token id="32" string="produce" />
            <token id="33" string="a" />
            <token id="34" string="book" />
            <token id="35" string="and" />
            <token id="36" string="movie" />
            <token id="37" string="about" />
            <token id="38" string="the" />
            <token id="39" string="case" />
            <token id="40" string="with" />
            <token id="41" string="the" />
            <token id="42" string="understanding" />
            <token id="43" string="that" />
            <token id="44" string="their" />
            <token id="45" string="discussions" />
            <token id="46" string="would" />
            <token id="47" string="become" />
            <token id="48" string="public" />
            <token id="49" string="after" />
            <token id="50" string="the" />
            <token id="51" string="trial" />
            <token id="52" string="and" />
            <token id="53" string="appeals" />
            <token id="54" string="were" />
            <token id="55" string="over" />
          </tokens>
        </chunking>
        <chunking id="37" string="after the trial and appeals were over" type="SBAR">
          <tokens>
            <token id="49" string="after" />
            <token id="50" string="the" />
            <token id="51" string="trial" />
            <token id="52" string="and" />
            <token id="53" string="appeals" />
            <token id="54" string="were" />
            <token id="55" string="over" />
          </tokens>
        </chunking>
        <chunking id="38" string="be removed from the McMartin trial team in October , 1985" type="VP">
          <tokens>
            <token id="9" string="be" />
            <token id="10" string="removed" />
            <token id="11" string="from" />
            <token id="12" string="the" />
            <token id="13" string="McMartin" />
            <token id="14" string="trial" />
            <token id="15" string="team" />
            <token id="16" string="in" />
            <token id="17" string="October" />
            <token id="18" string="," />
            <token id="19" string="1985" />
          </tokens>
        </chunking>
        <chunking id="39" string="to produce a book and movie about the case with the understanding that their discussions would become public after the trial and appeals were over" type="VP">
          <tokens>
            <token id="31" string="to" />
            <token id="32" string="produce" />
            <token id="33" string="a" />
            <token id="34" string="book" />
            <token id="35" string="and" />
            <token id="36" string="movie" />
            <token id="37" string="about" />
            <token id="38" string="the" />
            <token id="39" string="case" />
            <token id="40" string="with" />
            <token id="41" string="the" />
            <token id="42" string="understanding" />
            <token id="43" string="that" />
            <token id="44" string="their" />
            <token id="45" string="discussions" />
            <token id="46" string="would" />
            <token id="47" string="become" />
            <token id="48" string="public" />
            <token id="49" string="after" />
            <token id="50" string="the" />
            <token id="51" string="trial" />
            <token id="52" string="and" />
            <token id="53" string="appeals" />
            <token id="54" string="were" />
            <token id="55" string="over" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="21">said</governor>
          <dependent id="1">Stevens</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">said</governor>
          <dependent id="3">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="1">Stevens</governor>
          <dependent id="4">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">asked</governor>
          <dependent id="5">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">asked</governor>
          <dependent id="6">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">said</governor>
          <dependent id="7">asked</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">removed</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">removed</governor>
          <dependent id="9">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">asked</governor>
          <dependent id="10">removed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">team</governor>
          <dependent id="11">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">team</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">team</governor>
          <dependent id="13">McMartin</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">team</governor>
          <dependent id="14">trial</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">removed</governor>
          <dependent id="15">team</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">October</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">team</governor>
          <dependent id="17">October</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">October</governor>
          <dependent id="19">1985</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">agreed</governor>
          <dependent id="22">he</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">he</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">he</governor>
          <dependent id="24">Mann</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">said</governor>
          <dependent id="25">agreed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">March</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">agreed</governor>
          <dependent id="27">March</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">March</governor>
          <dependent id="29">1986</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="32">produce</governor>
          <dependent id="31">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="25">agreed</governor>
          <dependent id="32">produce</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">book</governor>
          <dependent id="33">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="32">produce</governor>
          <dependent id="34">book</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="34">book</governor>
          <dependent id="35">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="34">book</governor>
          <dependent id="36">movie</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">case</governor>
          <dependent id="37">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">case</governor>
          <dependent id="38">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">produce</governor>
          <dependent id="39">case</dependent>
        </dependency>
        <dependency type="case">
          <governor id="42">understanding</governor>
          <dependent id="40">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="42">understanding</governor>
          <dependent id="41">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="39">case</governor>
          <dependent id="42">understanding</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="47">become</governor>
          <dependent id="43">that</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="45">discussions</governor>
          <dependent id="44">their</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="47">become</governor>
          <dependent id="45">discussions</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="47">become</governor>
          <dependent id="46">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="32">produce</governor>
          <dependent id="47">become</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="47">become</governor>
          <dependent id="48">public</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="54">were</governor>
          <dependent id="49">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="51">trial</governor>
          <dependent id="50">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="54">were</governor>
          <dependent id="51">trial</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="51">trial</governor>
          <dependent id="52">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="51">trial</governor>
          <dependent id="53">appeals</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="47">become</governor>
          <dependent id="54">were</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="54">were</governor>
          <dependent id="55">over</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="March , 1986" type="DATE" score="0.0">
          <tokens>
            <token id="27" string="March" />
            <token id="28" string="," />
            <token id="29" string="1986" />
          </tokens>
        </entity>
        <entity id="2" string="McMartin" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="McMartin" />
          </tokens>
        </entity>
        <entity id="3" string="October , 1985" type="DATE" score="0.0">
          <tokens>
            <token id="17" string="October" />
            <token id="18" string="," />
            <token id="19" string="1985" />
          </tokens>
        </entity>
        <entity id="4" string="Mann" type="PERSON" score="0.0">
          <tokens>
            <token id="24" string="Mann" />
          </tokens>
        </entity>
        <entity id="5" string="Stevens" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Stevens" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>But in late 1986, Mann released interviews with Stevens in which Stevens said he doubted the defendants&amp;apost; guilt.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="late" lemma="late" stem="late" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="1986" lemma="1986" stem="1986" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Mann" lemma="Mann" stem="mann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="released" lemma="release" stem="releas" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="interviews" lemma="interview" stem="interview" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Stevens" lemma="Stevens" stem="steven" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Stevens" lemma="Stevens" stem="steven" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="doubted" lemma="doubt" stem="doubt" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="guilt" lemma="guilt" stem="guilt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (PP (IN in) (NP (JJ late) (CD 1986))) (, ,) (NP (NNP Mann)) (VP (VBD released) (NP (NNS interviews)) (PP (IN with) (NP (NP (NNP Stevens)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (NNP Stevens)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBD doubted) (NP (NP (DT the) (NNS defendants) (POS ')) (NN guilt))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="he doubted the defendants ' guilt" type="SBAR">
          <tokens>
            <token id="15" string="he" />
            <token id="16" string="doubted" />
            <token id="17" string="the" />
            <token id="18" string="defendants" />
            <token id="19" string="'" />
            <token id="20" string="guilt" />
          </tokens>
        </chunking>
        <chunking id="2" string="released interviews with Stevens in which Stevens said he doubted the defendants ' guilt" type="VP">
          <tokens>
            <token id="7" string="released" />
            <token id="8" string="interviews" />
            <token id="9" string="with" />
            <token id="10" string="Stevens" />
            <token id="11" string="in" />
            <token id="12" string="which" />
            <token id="13" string="Stevens" />
            <token id="14" string="said" />
            <token id="15" string="he" />
            <token id="16" string="doubted" />
            <token id="17" string="the" />
            <token id="18" string="defendants" />
            <token id="19" string="'" />
            <token id="20" string="guilt" />
          </tokens>
        </chunking>
        <chunking id="3" string="doubted the defendants ' guilt" type="VP">
          <tokens>
            <token id="16" string="doubted" />
            <token id="17" string="the" />
            <token id="18" string="defendants" />
            <token id="19" string="'" />
            <token id="20" string="guilt" />
          </tokens>
        </chunking>
        <chunking id="4" string="in which Stevens said he doubted the defendants ' guilt" type="SBAR">
          <tokens>
            <token id="11" string="in" />
            <token id="12" string="which" />
            <token id="13" string="Stevens" />
            <token id="14" string="said" />
            <token id="15" string="he" />
            <token id="16" string="doubted" />
            <token id="17" string="the" />
            <token id="18" string="defendants" />
            <token id="19" string="'" />
            <token id="20" string="guilt" />
          </tokens>
        </chunking>
        <chunking id="5" string="the defendants ' guilt" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="defendants" />
            <token id="19" string="'" />
            <token id="20" string="guilt" />
          </tokens>
        </chunking>
        <chunking id="6" string="late 1986" type="NP">
          <tokens>
            <token id="3" string="late" />
            <token id="4" string="1986" />
          </tokens>
        </chunking>
        <chunking id="7" string="Stevens" type="NP">
          <tokens>
            <token id="10" string="Stevens" />
          </tokens>
        </chunking>
        <chunking id="8" string="interviews" type="NP">
          <tokens>
            <token id="8" string="interviews" />
          </tokens>
        </chunking>
        <chunking id="9" string="said he doubted the defendants ' guilt" type="VP">
          <tokens>
            <token id="14" string="said" />
            <token id="15" string="he" />
            <token id="16" string="doubted" />
            <token id="17" string="the" />
            <token id="18" string="defendants" />
            <token id="19" string="'" />
            <token id="20" string="guilt" />
          </tokens>
        </chunking>
        <chunking id="10" string="the defendants '" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="defendants" />
            <token id="19" string="'" />
          </tokens>
        </chunking>
        <chunking id="11" string="Mann" type="NP">
          <tokens>
            <token id="6" string="Mann" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="15" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="Stevens in which Stevens said he doubted the defendants ' guilt" type="NP">
          <tokens>
            <token id="10" string="Stevens" />
            <token id="11" string="in" />
            <token id="12" string="which" />
            <token id="13" string="Stevens" />
            <token id="14" string="said" />
            <token id="15" string="he" />
            <token id="16" string="doubted" />
            <token id="17" string="the" />
            <token id="18" string="defendants" />
            <token id="19" string="'" />
            <token id="20" string="guilt" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="7">released</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">1986</governor>
          <dependent id="2">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">1986</governor>
          <dependent id="3">late</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">released</governor>
          <dependent id="4">1986</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">released</governor>
          <dependent id="6">Mann</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">released</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">released</governor>
          <dependent id="8">interviews</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Stevens</governor>
          <dependent id="9">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">released</governor>
          <dependent id="10">Stevens</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">which</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">said</governor>
          <dependent id="12">which</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">said</governor>
          <dependent id="13">Stevens</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">Stevens</governor>
          <dependent id="14">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">doubted</governor>
          <dependent id="15">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">said</governor>
          <dependent id="16">doubted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">defendants</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="20">guilt</governor>
          <dependent id="18">defendants</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">defendants</governor>
          <dependent id="19">'</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">doubted</governor>
          <dependent id="20">guilt</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mann" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Mann" />
          </tokens>
        </entity>
        <entity id="2" string="late 1986" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="late" />
            <token id="4" string="1986" />
          </tokens>
        </entity>
        <entity id="3" string="Stevens" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Stevens" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>Mann said his attorneys had advised him that to withhold them would be an obstruction of justice.</content>
      <tokens>
        <token id="1" string="Mann" lemma="Mann" stem="mann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="attorneys" lemma="attorney" stem="attornei" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="advised" lemma="advise" stem="advis" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="withhold" lemma="withhold" stem="withhold" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="obstruction" lemma="obstruction" stem="obstruct" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="justice" lemma="justice" stem="justic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Mann)) (VP (VBD said) (SBAR (S (NP (PRP$ his) (NNS attorneys)) (VP (VBD had) (VP (VBN advised) (NP (PRP him)) (SBAR (IN that) (S (VP (TO to) (VP (VB withhold) (SBAR (S (NP (PRP them)) (VP (MD would) (VP (VB be) (NP (NP (DT an) (NN obstruction)) (PP (IN of) (NP (NN justice))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="an obstruction" type="NP">
          <tokens>
            <token id="14" string="an" />
            <token id="15" string="obstruction" />
          </tokens>
        </chunking>
        <chunking id="2" string="to withhold them would be an obstruction of justice" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="withhold" />
            <token id="11" string="them" />
            <token id="12" string="would" />
            <token id="13" string="be" />
            <token id="14" string="an" />
            <token id="15" string="obstruction" />
            <token id="16" string="of" />
            <token id="17" string="justice" />
          </tokens>
        </chunking>
        <chunking id="3" string="withhold them would be an obstruction of justice" type="VP">
          <tokens>
            <token id="10" string="withhold" />
            <token id="11" string="them" />
            <token id="12" string="would" />
            <token id="13" string="be" />
            <token id="14" string="an" />
            <token id="15" string="obstruction" />
            <token id="16" string="of" />
            <token id="17" string="justice" />
          </tokens>
        </chunking>
        <chunking id="4" string="his attorneys had advised him that to withhold them would be an obstruction of justice" type="SBAR">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="attorneys" />
            <token id="5" string="had" />
            <token id="6" string="advised" />
            <token id="7" string="him" />
            <token id="8" string="that" />
            <token id="9" string="to" />
            <token id="10" string="withhold" />
            <token id="11" string="them" />
            <token id="12" string="would" />
            <token id="13" string="be" />
            <token id="14" string="an" />
            <token id="15" string="obstruction" />
            <token id="16" string="of" />
            <token id="17" string="justice" />
          </tokens>
        </chunking>
        <chunking id="5" string="would be an obstruction of justice" type="VP">
          <tokens>
            <token id="12" string="would" />
            <token id="13" string="be" />
            <token id="14" string="an" />
            <token id="15" string="obstruction" />
            <token id="16" string="of" />
            <token id="17" string="justice" />
          </tokens>
        </chunking>
        <chunking id="6" string="advised him that to withhold them would be an obstruction of justice" type="VP">
          <tokens>
            <token id="6" string="advised" />
            <token id="7" string="him" />
            <token id="8" string="that" />
            <token id="9" string="to" />
            <token id="10" string="withhold" />
            <token id="11" string="them" />
            <token id="12" string="would" />
            <token id="13" string="be" />
            <token id="14" string="an" />
            <token id="15" string="obstruction" />
            <token id="16" string="of" />
            <token id="17" string="justice" />
          </tokens>
        </chunking>
        <chunking id="7" string="his attorneys" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="attorneys" />
          </tokens>
        </chunking>
        <chunking id="8" string="him" type="NP">
          <tokens>
            <token id="7" string="him" />
          </tokens>
        </chunking>
        <chunking id="9" string="them" type="NP">
          <tokens>
            <token id="11" string="them" />
          </tokens>
        </chunking>
        <chunking id="10" string="an obstruction of justice" type="NP">
          <tokens>
            <token id="14" string="an" />
            <token id="15" string="obstruction" />
            <token id="16" string="of" />
            <token id="17" string="justice" />
          </tokens>
        </chunking>
        <chunking id="11" string="them would be an obstruction of justice" type="SBAR">
          <tokens>
            <token id="11" string="them" />
            <token id="12" string="would" />
            <token id="13" string="be" />
            <token id="14" string="an" />
            <token id="15" string="obstruction" />
            <token id="16" string="of" />
            <token id="17" string="justice" />
          </tokens>
        </chunking>
        <chunking id="12" string="had advised him that to withhold them would be an obstruction of justice" type="VP">
          <tokens>
            <token id="5" string="had" />
            <token id="6" string="advised" />
            <token id="7" string="him" />
            <token id="8" string="that" />
            <token id="9" string="to" />
            <token id="10" string="withhold" />
            <token id="11" string="them" />
            <token id="12" string="would" />
            <token id="13" string="be" />
            <token id="14" string="an" />
            <token id="15" string="obstruction" />
            <token id="16" string="of" />
            <token id="17" string="justice" />
          </tokens>
        </chunking>
        <chunking id="13" string="said his attorneys had advised him that to withhold them would be an obstruction of justice" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="his" />
            <token id="4" string="attorneys" />
            <token id="5" string="had" />
            <token id="6" string="advised" />
            <token id="7" string="him" />
            <token id="8" string="that" />
            <token id="9" string="to" />
            <token id="10" string="withhold" />
            <token id="11" string="them" />
            <token id="12" string="would" />
            <token id="13" string="be" />
            <token id="14" string="an" />
            <token id="15" string="obstruction" />
            <token id="16" string="of" />
            <token id="17" string="justice" />
          </tokens>
        </chunking>
        <chunking id="14" string="that to withhold them would be an obstruction of justice" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="to" />
            <token id="10" string="withhold" />
            <token id="11" string="them" />
            <token id="12" string="would" />
            <token id="13" string="be" />
            <token id="14" string="an" />
            <token id="15" string="obstruction" />
            <token id="16" string="of" />
            <token id="17" string="justice" />
          </tokens>
        </chunking>
        <chunking id="15" string="Mann" type="NP">
          <tokens>
            <token id="1" string="Mann" />
          </tokens>
        </chunking>
        <chunking id="16" string="justice" type="NP">
          <tokens>
            <token id="17" string="justice" />
          </tokens>
        </chunking>
        <chunking id="17" string="be an obstruction of justice" type="VP">
          <tokens>
            <token id="13" string="be" />
            <token id="14" string="an" />
            <token id="15" string="obstruction" />
            <token id="16" string="of" />
            <token id="17" string="justice" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Mann</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">attorneys</governor>
          <dependent id="3">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">advised</governor>
          <dependent id="4">attorneys</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">advised</governor>
          <dependent id="5">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="6">advised</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">advised</governor>
          <dependent id="7">him</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">withhold</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">withhold</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">advised</governor>
          <dependent id="10">withhold</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">obstruction</governor>
          <dependent id="11">them</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">obstruction</governor>
          <dependent id="12">would</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">obstruction</governor>
          <dependent id="13">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">obstruction</governor>
          <dependent id="14">an</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">withhold</governor>
          <dependent id="15">obstruction</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">justice</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">obstruction</governor>
          <dependent id="17">justice</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mann" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Mann" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>Outraged parents suggested the real aim was a not-guilty verdict, which would improve the value of Mann&amp;apost;s movie deal.</content>
      <tokens>
        <token id="1" string="Outraged" lemma="outraged" stem="outrag" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="parents" lemma="parent" stem="parent" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="suggested" lemma="suggest" stem="suggest" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="real" lemma="real" stem="real" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="aim" lemma="aim" stem="aim" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="not-guilty" lemma="not-guilty" stem="not-guilti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="verdict" lemma="verdict" stem="verdict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="improve" lemma="improve" stem="improv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="value" lemma="value" stem="valu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Mann" lemma="Mann" stem="mann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="movie" lemma="movie" stem="movi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="deal" lemma="deal" stem="deal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (JJ Outraged) (NNS parents)) (VP (VBD suggested) (SBAR (S (NP (DT the) (JJ real) (NN aim)) (VP (VBD was) (NP (NP (DT a) (JJ not-guilty) (NN verdict)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (MD would) (VP (VB improve) (NP (NP (DT the) (NN value)) (PP (IN of) (NP (NP (NNP Mann) (POS 's)) (NN movie) (NN deal))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="suggested the real aim was a not-guilty verdict , which would improve the value of Mann 's movie deal" type="VP">
          <tokens>
            <token id="3" string="suggested" />
            <token id="4" string="the" />
            <token id="5" string="real" />
            <token id="6" string="aim" />
            <token id="7" string="was" />
            <token id="8" string="a" />
            <token id="9" string="not-guilty" />
            <token id="10" string="verdict" />
            <token id="11" string="," />
            <token id="12" string="which" />
            <token id="13" string="would" />
            <token id="14" string="improve" />
            <token id="15" string="the" />
            <token id="16" string="value" />
            <token id="17" string="of" />
            <token id="18" string="Mann" />
            <token id="19" string="'s" />
            <token id="20" string="movie" />
            <token id="21" string="deal" />
          </tokens>
        </chunking>
        <chunking id="2" string="the real aim" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="real" />
            <token id="6" string="aim" />
          </tokens>
        </chunking>
        <chunking id="3" string="a not-guilty verdict , which would improve the value of Mann 's movie deal" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="not-guilty" />
            <token id="10" string="verdict" />
            <token id="11" string="," />
            <token id="12" string="which" />
            <token id="13" string="would" />
            <token id="14" string="improve" />
            <token id="15" string="the" />
            <token id="16" string="value" />
            <token id="17" string="of" />
            <token id="18" string="Mann" />
            <token id="19" string="'s" />
            <token id="20" string="movie" />
            <token id="21" string="deal" />
          </tokens>
        </chunking>
        <chunking id="4" string="the real aim was a not-guilty verdict , which would improve the value of Mann 's movie deal" type="SBAR">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="real" />
            <token id="6" string="aim" />
            <token id="7" string="was" />
            <token id="8" string="a" />
            <token id="9" string="not-guilty" />
            <token id="10" string="verdict" />
            <token id="11" string="," />
            <token id="12" string="which" />
            <token id="13" string="would" />
            <token id="14" string="improve" />
            <token id="15" string="the" />
            <token id="16" string="value" />
            <token id="17" string="of" />
            <token id="18" string="Mann" />
            <token id="19" string="'s" />
            <token id="20" string="movie" />
            <token id="21" string="deal" />
          </tokens>
        </chunking>
        <chunking id="5" string="which would improve the value of Mann 's movie deal" type="SBAR">
          <tokens>
            <token id="12" string="which" />
            <token id="13" string="would" />
            <token id="14" string="improve" />
            <token id="15" string="the" />
            <token id="16" string="value" />
            <token id="17" string="of" />
            <token id="18" string="Mann" />
            <token id="19" string="'s" />
            <token id="20" string="movie" />
            <token id="21" string="deal" />
          </tokens>
        </chunking>
        <chunking id="6" string="a not-guilty verdict" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="not-guilty" />
            <token id="10" string="verdict" />
          </tokens>
        </chunking>
        <chunking id="7" string="Mann 's" type="NP">
          <tokens>
            <token id="18" string="Mann" />
            <token id="19" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="Outraged parents" type="NP">
          <tokens>
            <token id="1" string="Outraged" />
            <token id="2" string="parents" />
          </tokens>
        </chunking>
        <chunking id="9" string="the value" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="value" />
          </tokens>
        </chunking>
        <chunking id="10" string="Mann 's movie deal" type="NP">
          <tokens>
            <token id="18" string="Mann" />
            <token id="19" string="'s" />
            <token id="20" string="movie" />
            <token id="21" string="deal" />
          </tokens>
        </chunking>
        <chunking id="11" string="was a not-guilty verdict , which would improve the value of Mann 's movie deal" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="a" />
            <token id="9" string="not-guilty" />
            <token id="10" string="verdict" />
            <token id="11" string="," />
            <token id="12" string="which" />
            <token id="13" string="would" />
            <token id="14" string="improve" />
            <token id="15" string="the" />
            <token id="16" string="value" />
            <token id="17" string="of" />
            <token id="18" string="Mann" />
            <token id="19" string="'s" />
            <token id="20" string="movie" />
            <token id="21" string="deal" />
          </tokens>
        </chunking>
        <chunking id="12" string="would improve the value of Mann 's movie deal" type="VP">
          <tokens>
            <token id="13" string="would" />
            <token id="14" string="improve" />
            <token id="15" string="the" />
            <token id="16" string="value" />
            <token id="17" string="of" />
            <token id="18" string="Mann" />
            <token id="19" string="'s" />
            <token id="20" string="movie" />
            <token id="21" string="deal" />
          </tokens>
        </chunking>
        <chunking id="13" string="improve the value of Mann 's movie deal" type="VP">
          <tokens>
            <token id="14" string="improve" />
            <token id="15" string="the" />
            <token id="16" string="value" />
            <token id="17" string="of" />
            <token id="18" string="Mann" />
            <token id="19" string="'s" />
            <token id="20" string="movie" />
            <token id="21" string="deal" />
          </tokens>
        </chunking>
        <chunking id="14" string="the value of Mann 's movie deal" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="value" />
            <token id="17" string="of" />
            <token id="18" string="Mann" />
            <token id="19" string="'s" />
            <token id="20" string="movie" />
            <token id="21" string="deal" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">parents</governor>
          <dependent id="1">Outraged</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">suggested</governor>
          <dependent id="2">parents</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">suggested</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">aim</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">aim</governor>
          <dependent id="5">real</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">verdict</governor>
          <dependent id="6">aim</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">verdict</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">verdict</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">verdict</governor>
          <dependent id="9">not-guilty</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">suggested</governor>
          <dependent id="10">verdict</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">improve</governor>
          <dependent id="12">which</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">improve</governor>
          <dependent id="13">would</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">verdict</governor>
          <dependent id="14">improve</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">value</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">improve</governor>
          <dependent id="16">value</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">deal</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">deal</governor>
          <dependent id="18">Mann</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Mann</governor>
          <dependent id="19">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">deal</governor>
          <dependent id="20">movie</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">value</governor>
          <dependent id="21">deal</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mann" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Mann" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>But Stevens and the Manns have said their ambition from the start has been to get the truth out.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Stevens" lemma="Stevens" stem="steven" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="3" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="Manns" lemma="Manns" stem="mann" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="6" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="ambition" lemma="ambition" stem="ambit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="start" lemma="start" stem="start" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="get" lemma="get" stem="get" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="truth" lemma="truth" stem="truth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NP (NNP Stevens)) (CC and) (NP (DT the) (NNPS Manns))) (VP (VBP have) (VP (VBD said) (SBAR (S (NP (NP (PRP$ their) (NN ambition)) (PP (IN from) (NP (DT the) (NN start)))) (VP (VBZ has) (VP (VBN been) (S (VP (TO to) (VP (VB get) (NP (DT the) (NN truth)) (PRT (RP out))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="have said their ambition from the start has been to get the truth out" type="VP">
          <tokens>
            <token id="6" string="have" />
            <token id="7" string="said" />
            <token id="8" string="their" />
            <token id="9" string="ambition" />
            <token id="10" string="from" />
            <token id="11" string="the" />
            <token id="12" string="start" />
            <token id="13" string="has" />
            <token id="14" string="been" />
            <token id="15" string="to" />
            <token id="16" string="get" />
            <token id="17" string="the" />
            <token id="18" string="truth" />
            <token id="19" string="out" />
          </tokens>
        </chunking>
        <chunking id="2" string="has been to get the truth out" type="VP">
          <tokens>
            <token id="13" string="has" />
            <token id="14" string="been" />
            <token id="15" string="to" />
            <token id="16" string="get" />
            <token id="17" string="the" />
            <token id="18" string="truth" />
            <token id="19" string="out" />
          </tokens>
        </chunking>
        <chunking id="3" string="been to get the truth out" type="VP">
          <tokens>
            <token id="14" string="been" />
            <token id="15" string="to" />
            <token id="16" string="get" />
            <token id="17" string="the" />
            <token id="18" string="truth" />
            <token id="19" string="out" />
          </tokens>
        </chunking>
        <chunking id="4" string="their ambition from the start" type="NP">
          <tokens>
            <token id="8" string="their" />
            <token id="9" string="ambition" />
            <token id="10" string="from" />
            <token id="11" string="the" />
            <token id="12" string="start" />
          </tokens>
        </chunking>
        <chunking id="5" string="the start" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="start" />
          </tokens>
        </chunking>
        <chunking id="6" string="get the truth out" type="VP">
          <tokens>
            <token id="16" string="get" />
            <token id="17" string="the" />
            <token id="18" string="truth" />
            <token id="19" string="out" />
          </tokens>
        </chunking>
        <chunking id="7" string="Stevens" type="NP">
          <tokens>
            <token id="2" string="Stevens" />
          </tokens>
        </chunking>
        <chunking id="8" string="Stevens and the Manns" type="NP">
          <tokens>
            <token id="2" string="Stevens" />
            <token id="3" string="and" />
            <token id="4" string="the" />
            <token id="5" string="Manns" />
          </tokens>
        </chunking>
        <chunking id="9" string="said their ambition from the start has been to get the truth out" type="VP">
          <tokens>
            <token id="7" string="said" />
            <token id="8" string="their" />
            <token id="9" string="ambition" />
            <token id="10" string="from" />
            <token id="11" string="the" />
            <token id="12" string="start" />
            <token id="13" string="has" />
            <token id="14" string="been" />
            <token id="15" string="to" />
            <token id="16" string="get" />
            <token id="17" string="the" />
            <token id="18" string="truth" />
            <token id="19" string="out" />
          </tokens>
        </chunking>
        <chunking id="10" string="their ambition from the start has been to get the truth out" type="SBAR">
          <tokens>
            <token id="8" string="their" />
            <token id="9" string="ambition" />
            <token id="10" string="from" />
            <token id="11" string="the" />
            <token id="12" string="start" />
            <token id="13" string="has" />
            <token id="14" string="been" />
            <token id="15" string="to" />
            <token id="16" string="get" />
            <token id="17" string="the" />
            <token id="18" string="truth" />
            <token id="19" string="out" />
          </tokens>
        </chunking>
        <chunking id="11" string="to get the truth out" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="get" />
            <token id="17" string="the" />
            <token id="18" string="truth" />
            <token id="19" string="out" />
          </tokens>
        </chunking>
        <chunking id="12" string="the Manns" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Manns" />
          </tokens>
        </chunking>
        <chunking id="13" string="their ambition" type="NP">
          <tokens>
            <token id="8" string="their" />
            <token id="9" string="ambition" />
          </tokens>
        </chunking>
        <chunking id="14" string="the truth" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="truth" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="7">said</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">said</governor>
          <dependent id="2">Stevens</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">Stevens</governor>
          <dependent id="3">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">Manns</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">Stevens</governor>
          <dependent id="5">Manns</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">said</governor>
          <dependent id="6">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">said</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">ambition</governor>
          <dependent id="8">their</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">been</governor>
          <dependent id="9">ambition</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">start</governor>
          <dependent id="10">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">start</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">ambition</governor>
          <dependent id="12">start</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">been</governor>
          <dependent id="13">has</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">said</governor>
          <dependent id="14">been</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">get</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">been</governor>
          <dependent id="16">get</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">truth</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">get</governor>
          <dependent id="18">truth</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="16">get</governor>
          <dependent id="19">out</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Manns" type="MISC" score="0.0">
          <tokens>
            <token id="5" string="Manns" />
          </tokens>
        </entity>
        <entity id="2" string="Stevens" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Stevens" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="false">
      <content>At least two other perspectives may reach the bookstores.</content>
      <tokens>
        <token id="1" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="least" lemma="least" stem="least" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="perspectives" lemma="perspective" stem="perspect" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="reach" lemma="reach" stem="reach" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="bookstores" lemma="bookstore" stem="bookstor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (QP (IN At) (JJS least) (CD two)) (JJ other) (NNS perspectives)) (VP (MD may) (VP (VB reach) (NP (DT the) (NNS bookstores)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="reach the bookstores" type="VP">
          <tokens>
            <token id="7" string="reach" />
            <token id="8" string="the" />
            <token id="9" string="bookstores" />
          </tokens>
        </chunking>
        <chunking id="2" string="the bookstores" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="bookstores" />
          </tokens>
        </chunking>
        <chunking id="3" string="may reach the bookstores" type="VP">
          <tokens>
            <token id="6" string="may" />
            <token id="7" string="reach" />
            <token id="8" string="the" />
            <token id="9" string="bookstores" />
          </tokens>
        </chunking>
        <chunking id="4" string="At least two other perspectives" type="NP">
          <tokens>
            <token id="1" string="At" />
            <token id="2" string="least" />
            <token id="3" string="two" />
            <token id="4" string="other" />
            <token id="5" string="perspectives" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">least</governor>
          <dependent id="1">At</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="3">two</governor>
          <dependent id="2">least</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">perspectives</governor>
          <dependent id="3">two</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">perspectives</governor>
          <dependent id="4">other</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">reach</governor>
          <dependent id="5">perspectives</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">reach</governor>
          <dependent id="6">may</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">reach</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">bookstores</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">reach</governor>
          <dependent id="9">bookstores</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="43" has_coreference="false">
      <content>Ray Buckey&amp;apost;s lawyer, Danny Davis, and writer Gordon Dillow, former columnist for the defunct Los Angeles Herald Examiner, have a book proposal that is being pitched to a variety of publishers.</content>
      <tokens>
        <token id="1" string="Ray" lemma="Ray" stem="rai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="lawyer" lemma="lawyer" stem="lawyer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Danny" lemma="Danny" stem="danni" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="Davis" lemma="Davis" stem="davi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="writer" lemma="writer" stem="writer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Gordon" lemma="Gordon" stem="gordon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="Dillow" lemma="Dillow" stem="dillow" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="columnist" lemma="columnist" stem="columnist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="defunct" lemma="defunct" stem="defunct" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="20" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="21" string="Herald" lemma="Herald" stem="herald" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="22" string="Examiner" lemma="Examiner" stem="examin" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="proposal" lemma="proposal" stem="propos" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="pitched" lemma="pitch" stem="pitch" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="variety" lemma="variety" stem="varieti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="publishers" lemma="publisher" stem="publish" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NP (NNP Ray) (NNP Buckey) (POS 's)) (NN lawyer)) (, ,) (NP (NNP Danny) (NNP Davis)) (, ,)) (CC and) (NP (NP (NN writer) (NNP Gordon) (NNP Dillow)) (, ,) (NP (NP (JJ former) (NN columnist)) (PP (IN for) (NP (DT the) (JJ defunct) (NNP Los) (NNP Angeles) (NNP Herald) (NNP Examiner)))) (, ,))) (VP (VBP have) (NP (NP (DT a) (NN book) (NN proposal)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (VP (VBG being) (VP (VBN pitched) (PP (TO to) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (NNS publishers)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="have a book proposal that is being pitched to a variety of publishers" type="VP">
          <tokens>
            <token id="24" string="have" />
            <token id="25" string="a" />
            <token id="26" string="book" />
            <token id="27" string="proposal" />
            <token id="28" string="that" />
            <token id="29" string="is" />
            <token id="30" string="being" />
            <token id="31" string="pitched" />
            <token id="32" string="to" />
            <token id="33" string="a" />
            <token id="34" string="variety" />
            <token id="35" string="of" />
            <token id="36" string="publishers" />
          </tokens>
        </chunking>
        <chunking id="2" string="is being pitched to a variety of publishers" type="VP">
          <tokens>
            <token id="29" string="is" />
            <token id="30" string="being" />
            <token id="31" string="pitched" />
            <token id="32" string="to" />
            <token id="33" string="a" />
            <token id="34" string="variety" />
            <token id="35" string="of" />
            <token id="36" string="publishers" />
          </tokens>
        </chunking>
        <chunking id="3" string="being pitched to a variety of publishers" type="VP">
          <tokens>
            <token id="30" string="being" />
            <token id="31" string="pitched" />
            <token id="32" string="to" />
            <token id="33" string="a" />
            <token id="34" string="variety" />
            <token id="35" string="of" />
            <token id="36" string="publishers" />
          </tokens>
        </chunking>
        <chunking id="4" string="Ray Buckey 's" type="NP">
          <tokens>
            <token id="1" string="Ray" />
            <token id="2" string="Buckey" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="former columnist" type="NP">
          <tokens>
            <token id="14" string="former" />
            <token id="15" string="columnist" />
          </tokens>
        </chunking>
        <chunking id="6" string="writer Gordon Dillow" type="NP">
          <tokens>
            <token id="10" string="writer" />
            <token id="11" string="Gordon" />
            <token id="12" string="Dillow" />
          </tokens>
        </chunking>
        <chunking id="7" string="Danny Davis" type="NP">
          <tokens>
            <token id="6" string="Danny" />
            <token id="7" string="Davis" />
          </tokens>
        </chunking>
        <chunking id="8" string="pitched to a variety of publishers" type="VP">
          <tokens>
            <token id="31" string="pitched" />
            <token id="32" string="to" />
            <token id="33" string="a" />
            <token id="34" string="variety" />
            <token id="35" string="of" />
            <token id="36" string="publishers" />
          </tokens>
        </chunking>
        <chunking id="9" string="former columnist for the defunct Los Angeles Herald Examiner" type="NP">
          <tokens>
            <token id="14" string="former" />
            <token id="15" string="columnist" />
            <token id="16" string="for" />
            <token id="17" string="the" />
            <token id="18" string="defunct" />
            <token id="19" string="Los" />
            <token id="20" string="Angeles" />
            <token id="21" string="Herald" />
            <token id="22" string="Examiner" />
          </tokens>
        </chunking>
        <chunking id="10" string="Ray Buckey 's lawyer , Danny Davis ," type="NP">
          <tokens>
            <token id="1" string="Ray" />
            <token id="2" string="Buckey" />
            <token id="3" string="'s" />
            <token id="4" string="lawyer" />
            <token id="5" string="," />
            <token id="6" string="Danny" />
            <token id="7" string="Davis" />
            <token id="8" string="," />
          </tokens>
        </chunking>
        <chunking id="11" string="a book proposal" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="book" />
            <token id="27" string="proposal" />
          </tokens>
        </chunking>
        <chunking id="12" string="Ray Buckey 's lawyer , Danny Davis , and writer Gordon Dillow , former columnist for the defunct Los Angeles Herald Examiner ," type="NP">
          <tokens>
            <token id="1" string="Ray" />
            <token id="2" string="Buckey" />
            <token id="3" string="'s" />
            <token id="4" string="lawyer" />
            <token id="5" string="," />
            <token id="6" string="Danny" />
            <token id="7" string="Davis" />
            <token id="8" string="," />
            <token id="9" string="and" />
            <token id="10" string="writer" />
            <token id="11" string="Gordon" />
            <token id="12" string="Dillow" />
            <token id="13" string="," />
            <token id="14" string="former" />
            <token id="15" string="columnist" />
            <token id="16" string="for" />
            <token id="17" string="the" />
            <token id="18" string="defunct" />
            <token id="19" string="Los" />
            <token id="20" string="Angeles" />
            <token id="21" string="Herald" />
            <token id="22" string="Examiner" />
            <token id="23" string="," />
          </tokens>
        </chunking>
        <chunking id="13" string="Ray Buckey 's lawyer" type="NP">
          <tokens>
            <token id="1" string="Ray" />
            <token id="2" string="Buckey" />
            <token id="3" string="'s" />
            <token id="4" string="lawyer" />
          </tokens>
        </chunking>
        <chunking id="14" string="the defunct Los Angeles Herald Examiner" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="defunct" />
            <token id="19" string="Los" />
            <token id="20" string="Angeles" />
            <token id="21" string="Herald" />
            <token id="22" string="Examiner" />
          </tokens>
        </chunking>
        <chunking id="15" string="a variety" type="NP">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="variety" />
          </tokens>
        </chunking>
        <chunking id="16" string="publishers" type="NP">
          <tokens>
            <token id="36" string="publishers" />
          </tokens>
        </chunking>
        <chunking id="17" string="a variety of publishers" type="NP">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="variety" />
            <token id="35" string="of" />
            <token id="36" string="publishers" />
          </tokens>
        </chunking>
        <chunking id="18" string="a book proposal that is being pitched to a variety of publishers" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="book" />
            <token id="27" string="proposal" />
            <token id="28" string="that" />
            <token id="29" string="is" />
            <token id="30" string="being" />
            <token id="31" string="pitched" />
            <token id="32" string="to" />
            <token id="33" string="a" />
            <token id="34" string="variety" />
            <token id="35" string="of" />
            <token id="36" string="publishers" />
          </tokens>
        </chunking>
        <chunking id="19" string="that is being pitched to a variety of publishers" type="SBAR">
          <tokens>
            <token id="28" string="that" />
            <token id="29" string="is" />
            <token id="30" string="being" />
            <token id="31" string="pitched" />
            <token id="32" string="to" />
            <token id="33" string="a" />
            <token id="34" string="variety" />
            <token id="35" string="of" />
            <token id="36" string="publishers" />
          </tokens>
        </chunking>
        <chunking id="20" string="writer Gordon Dillow , former columnist for the defunct Los Angeles Herald Examiner ," type="NP">
          <tokens>
            <token id="10" string="writer" />
            <token id="11" string="Gordon" />
            <token id="12" string="Dillow" />
            <token id="13" string="," />
            <token id="14" string="former" />
            <token id="15" string="columnist" />
            <token id="16" string="for" />
            <token id="17" string="the" />
            <token id="18" string="defunct" />
            <token id="19" string="Los" />
            <token id="20" string="Angeles" />
            <token id="21" string="Herald" />
            <token id="22" string="Examiner" />
            <token id="23" string="," />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Buckey</governor>
          <dependent id="1">Ray</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">lawyer</governor>
          <dependent id="2">Buckey</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Buckey</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">have</governor>
          <dependent id="4">lawyer</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Davis</governor>
          <dependent id="6">Danny</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="4">lawyer</governor>
          <dependent id="7">Davis</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">lawyer</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Dillow</governor>
          <dependent id="10">writer</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Dillow</governor>
          <dependent id="11">Gordon</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">lawyer</governor>
          <dependent id="12">Dillow</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">columnist</governor>
          <dependent id="14">former</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="12">Dillow</governor>
          <dependent id="15">columnist</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">Examiner</governor>
          <dependent id="16">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">Examiner</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">Examiner</governor>
          <dependent id="18">defunct</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Examiner</governor>
          <dependent id="19">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Examiner</governor>
          <dependent id="20">Angeles</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Examiner</governor>
          <dependent id="21">Herald</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">columnist</governor>
          <dependent id="22">Examiner</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="24">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">proposal</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">proposal</governor>
          <dependent id="26">book</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">have</governor>
          <dependent id="27">proposal</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="31">pitched</governor>
          <dependent id="28">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="31">pitched</governor>
          <dependent id="29">is</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="31">pitched</governor>
          <dependent id="30">being</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="27">proposal</governor>
          <dependent id="31">pitched</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">variety</governor>
          <dependent id="32">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">variety</governor>
          <dependent id="33">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">pitched</governor>
          <dependent id="34">variety</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">publishers</governor>
          <dependent id="35">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">variety</governor>
          <dependent id="36">publishers</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Los Angeles Herald Examiner" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="19" string="Los" />
            <token id="20" string="Angeles" />
            <token id="21" string="Herald" />
            <token id="22" string="Examiner" />
          </tokens>
        </entity>
        <entity id="2" string="Danny Davis" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Danny" />
            <token id="7" string="Davis" />
          </tokens>
        </entity>
        <entity id="3" string="Ray Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Ray" />
            <token id="2" string="Buckey" />
          </tokens>
        </entity>
        <entity id="4" string="Gordon Dillow" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Gordon" />
            <token id="12" string="Dillow" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>Times staff writer Lois Timnick, who covered the case from its early stages through the trial, also is planning a book.</content>
      <tokens>
        <token id="1" string="Times" lemma="Times" stem="time" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="staff" lemma="staff" stem="staff" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="writer" lemma="writer" stem="writer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Lois" lemma="Lois" stem="loi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="5" string="Timnick" lemma="Timnick" stem="timnick" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="covered" lemma="cover" stem="cover" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="early" lemma="early" stem="earli" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="stages" lemma="stage" stem="stage" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="planning" lemma="plan" stem="plan" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Times) (NN staff) (NN writer) (NNP Lois) (NNP Timnick)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD covered) (NP (DT the) (NN case)) (PP (IN from) (NP (PRP$ its) (JJ early) (NNS stages))) (PP (IN through) (NP (DT the) (NN trial)))))) (, ,)) (ADVP (RB also)) (VP (VBZ is) (VP (VBG planning) (NP (DT a) (NN book)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a book" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="book" />
          </tokens>
        </chunking>
        <chunking id="2" string="Times staff writer Lois Timnick , who covered the case from its early stages through the trial ," type="NP">
          <tokens>
            <token id="1" string="Times" />
            <token id="2" string="staff" />
            <token id="3" string="writer" />
            <token id="4" string="Lois" />
            <token id="5" string="Timnick" />
            <token id="6" string="," />
            <token id="7" string="who" />
            <token id="8" string="covered" />
            <token id="9" string="the" />
            <token id="10" string="case" />
            <token id="11" string="from" />
            <token id="12" string="its" />
            <token id="13" string="early" />
            <token id="14" string="stages" />
            <token id="15" string="through" />
            <token id="16" string="the" />
            <token id="17" string="trial" />
            <token id="18" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="the trial" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="trial" />
          </tokens>
        </chunking>
        <chunking id="4" string="the case" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="case" />
          </tokens>
        </chunking>
        <chunking id="5" string="planning a book" type="VP">
          <tokens>
            <token id="21" string="planning" />
            <token id="22" string="a" />
            <token id="23" string="book" />
          </tokens>
        </chunking>
        <chunking id="6" string="is planning a book" type="VP">
          <tokens>
            <token id="20" string="is" />
            <token id="21" string="planning" />
            <token id="22" string="a" />
            <token id="23" string="book" />
          </tokens>
        </chunking>
        <chunking id="7" string="who covered the case from its early stages through the trial" type="SBAR">
          <tokens>
            <token id="7" string="who" />
            <token id="8" string="covered" />
            <token id="9" string="the" />
            <token id="10" string="case" />
            <token id="11" string="from" />
            <token id="12" string="its" />
            <token id="13" string="early" />
            <token id="14" string="stages" />
            <token id="15" string="through" />
            <token id="16" string="the" />
            <token id="17" string="trial" />
          </tokens>
        </chunking>
        <chunking id="8" string="covered the case from its early stages through the trial" type="VP">
          <tokens>
            <token id="8" string="covered" />
            <token id="9" string="the" />
            <token id="10" string="case" />
            <token id="11" string="from" />
            <token id="12" string="its" />
            <token id="13" string="early" />
            <token id="14" string="stages" />
            <token id="15" string="through" />
            <token id="16" string="the" />
            <token id="17" string="trial" />
          </tokens>
        </chunking>
        <chunking id="9" string="Times staff writer Lois Timnick" type="NP">
          <tokens>
            <token id="1" string="Times" />
            <token id="2" string="staff" />
            <token id="3" string="writer" />
            <token id="4" string="Lois" />
            <token id="5" string="Timnick" />
          </tokens>
        </chunking>
        <chunking id="10" string="its early stages" type="NP">
          <tokens>
            <token id="12" string="its" />
            <token id="13" string="early" />
            <token id="14" string="stages" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="5">Timnick</governor>
          <dependent id="1">Times</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Timnick</governor>
          <dependent id="2">staff</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Timnick</governor>
          <dependent id="3">writer</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Timnick</governor>
          <dependent id="4">Lois</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">planning</governor>
          <dependent id="5">Timnick</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">covered</governor>
          <dependent id="7">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">Timnick</governor>
          <dependent id="8">covered</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">case</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">covered</governor>
          <dependent id="10">case</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">stages</governor>
          <dependent id="11">from</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">stages</governor>
          <dependent id="12">its</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">stages</governor>
          <dependent id="13">early</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">covered</governor>
          <dependent id="14">stages</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">trial</governor>
          <dependent id="15">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">trial</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">covered</governor>
          <dependent id="17">trial</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">planning</governor>
          <dependent id="19">also</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">planning</governor>
          <dependent id="20">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">planning</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">book</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">planning</governor>
          <dependent id="23">book</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lois Timnick" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Lois" />
            <token id="5" string="Timnick" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="45" has_coreference="true">
      <content>Mann said his script isn&amp;apost;t a courtroom drama.</content>
      <tokens>
        <token id="1" string="Mann" lemma="Mann" stem="mann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="script" lemma="script" stem="script" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="courtroom" lemma="courtroom" stem="courtroom" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="drama" lemma="drama" stem="drama" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Mann)) (VP (VBD said) (SBAR (S (NP (PRP$ his) (NN script)) (VP (VBZ is) (RB n't) (NP (DT a) (NN courtroom) (NN drama)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his script" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="script" />
          </tokens>
        </chunking>
        <chunking id="2" string="Mann" type="NP">
          <tokens>
            <token id="1" string="Mann" />
          </tokens>
        </chunking>
        <chunking id="3" string="a courtroom drama" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="courtroom" />
            <token id="9" string="drama" />
          </tokens>
        </chunking>
        <chunking id="4" string="said his script is n't a courtroom drama" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="his" />
            <token id="4" string="script" />
            <token id="5" string="is" />
            <token id="6" string="n't" />
            <token id="7" string="a" />
            <token id="8" string="courtroom" />
            <token id="9" string="drama" />
          </tokens>
        </chunking>
        <chunking id="5" string="his script is n't a courtroom drama" type="SBAR">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="script" />
            <token id="5" string="is" />
            <token id="6" string="n't" />
            <token id="7" string="a" />
            <token id="8" string="courtroom" />
            <token id="9" string="drama" />
          </tokens>
        </chunking>
        <chunking id="6" string="is n't a courtroom drama" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="n't" />
            <token id="7" string="a" />
            <token id="8" string="courtroom" />
            <token id="9" string="drama" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Mann</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">script</governor>
          <dependent id="3">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">drama</governor>
          <dependent id="4">script</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">drama</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="9">drama</governor>
          <dependent id="6">n't</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">drama</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">drama</governor>
          <dependent id="8">courtroom</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="9">drama</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mann" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Mann" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="46" has_coreference="true">
      <content>&amp;quot;It&amp;apost;s not a trial movie.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="movie" lemma="movie" stem="movi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP It)) (VP (VBZ 's) (RB not) (NP (DT a) (NN trial) (NN movie))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a trial movie" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="trial" />
            <token id="7" string="movie" />
          </tokens>
        </chunking>
        <chunking id="2" string="'s not a trial movie" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="not" />
            <token id="5" string="a" />
            <token id="6" string="trial" />
            <token id="7" string="movie" />
          </tokens>
        </chunking>
        <chunking id="3" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">movie</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">movie</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">movie</governor>
          <dependent id="4">not</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">movie</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">movie</governor>
          <dependent id="6">trial</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">movie</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="47" has_coreference="true">
      <content>It&amp;apost;s what happens to human beings.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="happens" lemma="happen" stem="happen" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="human" lemma="human" stem="human" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="beings" lemma="being" stem="be" pos="NNS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ 's) (SBAR (WHNP (WP what)) (S (VP (VBZ happens) (PP (TO to) (NP (JJ human) (NNS beings))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="happens to human beings" type="VP">
          <tokens>
            <token id="4" string="happens" />
            <token id="5" string="to" />
            <token id="6" string="human" />
            <token id="7" string="beings" />
          </tokens>
        </chunking>
        <chunking id="2" string="'s what happens to human beings" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="what" />
            <token id="4" string="happens" />
            <token id="5" string="to" />
            <token id="6" string="human" />
            <token id="7" string="beings" />
          </tokens>
        </chunking>
        <chunking id="3" string="what happens to human beings" type="SBAR">
          <tokens>
            <token id="3" string="what" />
            <token id="4" string="happens" />
            <token id="5" string="to" />
            <token id="6" string="human" />
            <token id="7" string="beings" />
          </tokens>
        </chunking>
        <chunking id="4" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="5" string="human beings" type="NP">
          <tokens>
            <token id="6" string="human" />
            <token id="7" string="beings" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">'s</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">happens</governor>
          <dependent id="3">what</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">'s</governor>
          <dependent id="4">happens</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">beings</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">beings</governor>
          <dependent id="6">human</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">happens</governor>
          <dependent id="7">beings</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="48" has_coreference="true">
      <content>I intend to be fair to the parents.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="intend" lemma="intend" stem="intend" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="fair" lemma="fair" stem="fair" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="parents" lemma="parent" stem="parent" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP intend) (S (VP (TO to) (VP (VB be) (ADJP (JJ fair) (PP (TO to) (NP (DT the) (NNS parents)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="be fair to the parents" type="VP">
          <tokens>
            <token id="4" string="be" />
            <token id="5" string="fair" />
            <token id="6" string="to" />
            <token id="7" string="the" />
            <token id="8" string="parents" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="intend to be fair to the parents" type="VP">
          <tokens>
            <token id="2" string="intend" />
            <token id="3" string="to" />
            <token id="4" string="be" />
            <token id="5" string="fair" />
            <token id="6" string="to" />
            <token id="7" string="the" />
            <token id="8" string="parents" />
          </tokens>
        </chunking>
        <chunking id="4" string="the parents" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="parents" />
          </tokens>
        </chunking>
        <chunking id="5" string="to be fair to the parents" type="VP">
          <tokens>
            <token id="3" string="to" />
            <token id="4" string="be" />
            <token id="5" string="fair" />
            <token id="6" string="to" />
            <token id="7" string="the" />
            <token id="8" string="parents" />
          </tokens>
        </chunking>
        <chunking id="6" string="fair to the parents" type="ADJP">
          <tokens>
            <token id="5" string="fair" />
            <token id="6" string="to" />
            <token id="7" string="the" />
            <token id="8" string="parents" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">intend</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">intend</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">fair</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">fair</governor>
          <dependent id="4">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">intend</governor>
          <dependent id="5">fair</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">parents</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">parents</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">fair</governor>
          <dependent id="8">parents</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="49" has_coreference="true">
      <content>I don&amp;apost;t mean to be vindicative. . . .</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="mean" lemma="mean" stem="mean" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="vindicative" lemma="vindicative" stem="vindic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP do) (RB n't) (VP (VB mean) (S (VP (TO to) (VP (VB be) (ADJP (JJ vindicative))))))) (: ...) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="vindicative" type="ADJP">
          <tokens>
            <token id="7" string="vindicative" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="do n't mean to be vindicative" type="VP">
          <tokens>
            <token id="2" string="do" />
            <token id="3" string="n't" />
            <token id="4" string="mean" />
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="vindicative" />
          </tokens>
        </chunking>
        <chunking id="4" string="be vindicative" type="VP">
          <tokens>
            <token id="6" string="be" />
            <token id="7" string="vindicative" />
          </tokens>
        </chunking>
        <chunking id="5" string="mean to be vindicative" type="VP">
          <tokens>
            <token id="4" string="mean" />
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="vindicative" />
          </tokens>
        </chunking>
        <chunking id="6" string="to be vindicative" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="vindicative" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">mean</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">mean</governor>
          <dependent id="2">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">mean</governor>
          <dependent id="3">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">mean</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">vindicative</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">vindicative</governor>
          <dependent id="6">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">mean</governor>
          <dependent id="7">vindicative</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="50" has_coreference="true">
      <content>For the most part, I have great sympathy for the parents.&amp;quot;</content>
      <tokens>
        <token id="1" string="For" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="most" lemma="most" stem="most" pos="JJS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="part" lemma="part" stem="part" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="great" lemma="great" stem="great" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="sympathy" lemma="sympathy" stem="sympathi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="parents" lemma="parent" stem="parent" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN For) (NP (DT the) (JJS most) (NN part))) (, ,) (NP (PRP I)) (VP (VBP have) (NP (NP (JJ great) (NN sympathy)) (PP (IN for) (NP (DT the) (NNS parents))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="great sympathy for the parents" type="NP">
          <tokens>
            <token id="8" string="great" />
            <token id="9" string="sympathy" />
            <token id="10" string="for" />
            <token id="11" string="the" />
            <token id="12" string="parents" />
          </tokens>
        </chunking>
        <chunking id="2" string="great sympathy" type="NP">
          <tokens>
            <token id="8" string="great" />
            <token id="9" string="sympathy" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="6" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="have great sympathy for the parents" type="VP">
          <tokens>
            <token id="7" string="have" />
            <token id="8" string="great" />
            <token id="9" string="sympathy" />
            <token id="10" string="for" />
            <token id="11" string="the" />
            <token id="12" string="parents" />
          </tokens>
        </chunking>
        <chunking id="5" string="the parents" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="parents" />
          </tokens>
        </chunking>
        <chunking id="6" string="the most part" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="most" />
            <token id="4" string="part" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">part</governor>
          <dependent id="1">For</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">part</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">part</governor>
          <dependent id="3">most</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">have</governor>
          <dependent id="4">part</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">have</governor>
          <dependent id="6">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">have</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">sympathy</governor>
          <dependent id="8">great</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">have</governor>
          <dependent id="9">sympathy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">parents</governor>
          <dependent id="10">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">parents</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">sympathy</governor>
          <dependent id="12">parents</dependent>
        </dependency>
      </dependencies>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="5-6-7-8-9" string="Peggy Ann Buckey on TV" id_sentence="1" />
      <mentions>
        <mention ids_tokens="10" string="Buckey" id_sentence="3" />
        <mention ids_tokens="6-7" string="Peggy Buckey" id_sentence="4" />
        <mention ids_tokens="18" string="her" id_sentence="4" />
      </mentions>
    </coreference>
    <coreference id="2" type="NOMINAL">
      <referenced ids_tokens="1-2" string="The prosecutors" id_sentence="34" />
      <mentions>
        <mention ids_tokens="1" string="Prosecutors" id_sentence="3" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="19-20-21-22" string="the McMartin Pre-School case" id_sentence="3" />
      <mentions>
        <mention ids_tokens="9-11" string="the case itself" id_sentence="6" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="21" string="Ray" id_sentence="4" />
      <mentions>
        <mention ids_tokens="19" string="he" id_sentence="7" />
        <mention ids_tokens="30" string="his" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="6" type="PROPER">
      <referenced ids_tokens="26-27-28" string="Peggy McMartin Buckey" id_sentence="4" />
      <mentions>
        <mention ids_tokens="9-12" string="Peggy McMartin Buckey's" id_sentence="7" />
        <mention ids_tokens="40" string="McMartin" id_sentence="8" />
        <mention ids_tokens="31" string="McMartin" id_sentence="15" />
        <mention ids_tokens="6" string="McMartin" id_sentence="28" />
        <mention ids_tokens="13" string="McMartin" id_sentence="37" />
      </mentions>
    </coreference>
    <coreference id="7" type="PROPER">
      <referenced ids_tokens="36" string="Mann" id_sentence="4" />
      <mentions>
        <mention ids_tokens="15" string="he" id_sentence="5" />
        <mention ids_tokens="14" string="he" id_sentence="6" />
        <mention ids_tokens="4" string="his" id_sentence="8" />
        <mention ids_tokens="1-16" string="Mann , whose writing credits include the Academy Award-winning &quot; Judgment at Nuremberg &quot; in 1961" id_sentence="33" />
        <mention ids_tokens="3" string="his" id_sentence="39" />
        <mention ids_tokens="7" string="him" id_sentence="39" />
        <mention ids_tokens="18-19" string="Mann's" id_sentence="40" />
        <mention ids_tokens="3" string="his" id_sentence="45" />
      </mentions>
    </coreference>
    <coreference id="8" type="NOMINAL">
      <referenced ids_tokens="16-17-18-19-20-21-22-23-24" string="charges against her brother , Ray , and mother" id_sentence="4" />
      <mentions>
        <mention ids_tokens="12" string="charges" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="10" type="NOMINAL">
      <referenced ids_tokens="9-10-11-12-13" string="Peggy McMartin Buckey 's trial" id_sentence="7" />
      <mentions>
        <mention ids_tokens="50-51" string="the trial" id_sentence="37" />
        <mention ids_tokens="16-17" string="the trial" id_sentence="44" />
        <mention ids_tokens="1" string="I" id_sentence="48" />
        <mention ids_tokens="1" string="I" id_sentence="49" />
        <mention ids_tokens="6" string="I" id_sentence="50" />
      </mentions>
    </coreference>
    <coreference id="12" type="NOMINAL">
      <referenced ids_tokens="38-39-40-41" string="the 6-year-old McMartin case" id_sentence="8" />
      <mentions>
        <mention ids_tokens="5-7" string="the McMartin case" id_sentence="28" />
      </mentions>
    </coreference>
    <coreference id="13" type="PROPER">
      <referenced ids_tokens="3" string="two" id_sentence="9" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="11" />
        <mention ids_tokens="5-7" string="a TV thing" id_sentence="11" />
        <mention ids_tokens="14-15" string="this thing" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="14" type="NOMINAL">
      <referenced ids_tokens="10-11-12-13-14-15-16-17-18" string="at least one prominent television movie producer besides Mann" id_sentence="9" />
      <mentions>
        <mention ids_tokens="1-2" string="That producer" id_sentence="10" />
        <mention ids_tokens="9" string="he" id_sentence="10" />
        <mention ids_tokens="2-3" string="The producer" id_sentence="13" />
        <mention ids_tokens="8-9" string="the producer" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="15" type="NOMINAL">
      <referenced ids_tokens="12-13" string="other producers" id_sentence="10" />
      <mentions>
        <mention ids_tokens="1" string="Producers" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="17" type="PROPER">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19" string="&quot; Just one of those perfect , high-concept , lurid television M-O-Ws &quot; -- an acronym for movies-of-the-week ." id_sentence="12" />
      <mentions>
        <mention ids_tokens="13" string="it" id_sentence="13" />
        <mention ids_tokens="15-19" string="an easy sale to networks" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="23" type="PROPER">
      <referenced ids_tokens="9-10-11" string="Ray Buckey 's" id_sentence="17" />
      <mentions>
        <mention ids_tokens="13-19" string="Ray Buckey a villain or a victim" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="25" type="NOMINAL">
      <referenced ids_tokens="9-10-11-12" string="Ray Buckey 's story" id_sentence="17" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="19" />
        <mention ids_tokens="6" string="my" id_sentence="19" />
        <mention ids_tokens="10" string="I" id_sentence="19" />
        <mention ids_tokens="2" string="It" id_sentence="20" />
        <mention ids_tokens="13" string="it" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="27" type="NOMINAL">
      <referenced ids_tokens="4-5-6-7-8-9" string="the story you want to tell" id_sentence="21" />
      <mentions>
        <mention ids_tokens="2" string="it" id_sentence="22" />
        <mention ids_tokens="2" string="it" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="32" type="NOMINAL">
      <referenced ids_tokens="2-3" string="the confidence" id_sentence="35" />
      <mentions>
        <mention ids_tokens="1" string="That" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="33" type="NOMINAL">
      <referenced ids_tokens="5-6-7" string="the McMartin defendants" id_sentence="35" />
      <mentions>
        <mention ids_tokens="3" string="their" id_sentence="36" />
        <mention ids_tokens="17-19" string="the defendants'" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="35" type="PROPER">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19" string="Stevens , who said he had asked to be removed from the McMartin trial team in October , 1985" id_sentence="37" />
      <mentions>
        <mention ids_tokens="13" string="Stevens" id_sentence="38" />
        <mention ids_tokens="15" string="he" id_sentence="38" />
        <mention ids_tokens="2" string="Stevens" id_sentence="41" />
      </mentions>
    </coreference>
    <coreference id="37" type="NOMINAL">
      <referenced ids_tokens="38-39-40-41-42" string="the case with the understanding" id_sentence="37" />
      <mentions>
        <mention ids_tokens="9-10" string="the case" id_sentence="44" />
        <mention ids_tokens="12" string="its" id_sentence="44" />
      </mentions>
    </coreference>
    <coreference id="39" type="NOMINAL">
      <referenced ids_tokens="1-2" string="Outraged parents" id_sentence="40" />
      <mentions>
        <mention ids_tokens="7-8" string="the parents" id_sentence="48" />
        <mention ids_tokens="11-12" string="the parents" id_sentence="50" />
      </mentions>
    </coreference>
    <coreference id="42" type="NOMINAL">
      <referenced ids_tokens="7-8-9" string="a courtroom drama" id_sentence="45" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="46" />
        <mention ids_tokens="5-7" string="a trial movie" id_sentence="46" />
        <mention ids_tokens="1" string="It" id_sentence="47" />
      </mentions>
    </coreference>
  </coreferences>
</document>
