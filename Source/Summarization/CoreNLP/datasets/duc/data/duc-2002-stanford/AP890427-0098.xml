<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP890427-0098">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>An outpouring of sympathy from presidents to childhood neighbors followed the death of Lucille Ball, but many said the queen mother of comedy will live on through television reruns and her influence on comedy.</content>
      <tokens>
        <token id="1" string="An" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="outpouring" lemma="outpouring" stem="outpour" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="sympathy" lemma="sympathy" stem="sympathi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="presidents" lemma="president" stem="presid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="childhood" lemma="childhood" stem="childhood" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="neighbors" lemma="neighbor" stem="neighbor" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="followed" lemma="follow" stem="follow" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="death" lemma="death" stem="death" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="Lucille" lemma="Lucille" stem="lucil" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="15" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="queen" lemma="queen" stem="queen" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="mother" lemma="mother" stem="mother" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="comedy" lemma="comedy" stem="comedi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="live" lemma="live" stem="live" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="reruns" lemma="rerun" stem="rerun" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="influence" lemma="influence" stem="influenc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="comedy" lemma="comedy" stem="comedi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (DT An) (NN outpouring)) (PP (IN of) (NP (NP (NN sympathy)) (PP (IN from) (NP (NP (NNS presidents)) (PP (TO to) (NP (NN childhood) (NNS neighbors)))))))) (VP (VBD followed) (NP (NP (DT the) (NN death)) (PP (IN of) (NP (NNP Lucille) (NNP Ball)))))) (, ,) (CC but) (S (NP (JJ many)) (VP (VBD said) (SBAR (S (NP (NP (DT the) (NN queen) (NN mother)) (PP (IN of) (NP (NN comedy)))) (VP (MD will) (VP (VB live) (PP (IN on) (IN through) (NP (NP (NN television) (NNS reruns)) (CC and) (NP (PRP$ her) (NN influence)))) (PP (IN on) (NP (NN comedy))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="childhood neighbors" type="NP">
          <tokens>
            <token id="8" string="childhood" />
            <token id="9" string="neighbors" />
          </tokens>
        </chunking>
        <chunking id="2" string="the queen mother" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="queen" />
            <token id="22" string="mother" />
          </tokens>
        </chunking>
        <chunking id="3" string="comedy" type="NP">
          <tokens>
            <token id="24" string="comedy" />
          </tokens>
        </chunking>
        <chunking id="4" string="television reruns and her influence" type="NP">
          <tokens>
            <token id="29" string="television" />
            <token id="30" string="reruns" />
            <token id="31" string="and" />
            <token id="32" string="her" />
            <token id="33" string="influence" />
          </tokens>
        </chunking>
        <chunking id="5" string="presidents" type="NP">
          <tokens>
            <token id="6" string="presidents" />
          </tokens>
        </chunking>
        <chunking id="6" string="will live on through television reruns and her influence on comedy" type="VP">
          <tokens>
            <token id="25" string="will" />
            <token id="26" string="live" />
            <token id="27" string="on" />
            <token id="28" string="through" />
            <token id="29" string="television" />
            <token id="30" string="reruns" />
            <token id="31" string="and" />
            <token id="32" string="her" />
            <token id="33" string="influence" />
            <token id="34" string="on" />
            <token id="35" string="comedy" />
          </tokens>
        </chunking>
        <chunking id="7" string="An outpouring" type="NP">
          <tokens>
            <token id="1" string="An" />
            <token id="2" string="outpouring" />
          </tokens>
        </chunking>
        <chunking id="8" string="sympathy from presidents to childhood neighbors" type="NP">
          <tokens>
            <token id="4" string="sympathy" />
            <token id="5" string="from" />
            <token id="6" string="presidents" />
            <token id="7" string="to" />
            <token id="8" string="childhood" />
            <token id="9" string="neighbors" />
          </tokens>
        </chunking>
        <chunking id="9" string="many" type="NP">
          <tokens>
            <token id="18" string="many" />
          </tokens>
        </chunking>
        <chunking id="10" string="the death of Lucille Ball" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="death" />
            <token id="13" string="of" />
            <token id="14" string="Lucille" />
            <token id="15" string="Ball" />
          </tokens>
        </chunking>
        <chunking id="11" string="said the queen mother of comedy will live on through television reruns and her influence on comedy" type="VP">
          <tokens>
            <token id="19" string="said" />
            <token id="20" string="the" />
            <token id="21" string="queen" />
            <token id="22" string="mother" />
            <token id="23" string="of" />
            <token id="24" string="comedy" />
            <token id="25" string="will" />
            <token id="26" string="live" />
            <token id="27" string="on" />
            <token id="28" string="through" />
            <token id="29" string="television" />
            <token id="30" string="reruns" />
            <token id="31" string="and" />
            <token id="32" string="her" />
            <token id="33" string="influence" />
            <token id="34" string="on" />
            <token id="35" string="comedy" />
          </tokens>
        </chunking>
        <chunking id="12" string="the death" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="death" />
          </tokens>
        </chunking>
        <chunking id="13" string="her influence" type="NP">
          <tokens>
            <token id="32" string="her" />
            <token id="33" string="influence" />
          </tokens>
        </chunking>
        <chunking id="14" string="An outpouring of sympathy from presidents to childhood neighbors" type="NP">
          <tokens>
            <token id="1" string="An" />
            <token id="2" string="outpouring" />
            <token id="3" string="of" />
            <token id="4" string="sympathy" />
            <token id="5" string="from" />
            <token id="6" string="presidents" />
            <token id="7" string="to" />
            <token id="8" string="childhood" />
            <token id="9" string="neighbors" />
          </tokens>
        </chunking>
        <chunking id="15" string="live on through television reruns and her influence on comedy" type="VP">
          <tokens>
            <token id="26" string="live" />
            <token id="27" string="on" />
            <token id="28" string="through" />
            <token id="29" string="television" />
            <token id="30" string="reruns" />
            <token id="31" string="and" />
            <token id="32" string="her" />
            <token id="33" string="influence" />
            <token id="34" string="on" />
            <token id="35" string="comedy" />
          </tokens>
        </chunking>
        <chunking id="16" string="the queen mother of comedy" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="queen" />
            <token id="22" string="mother" />
            <token id="23" string="of" />
            <token id="24" string="comedy" />
          </tokens>
        </chunking>
        <chunking id="17" string="sympathy" type="NP">
          <tokens>
            <token id="4" string="sympathy" />
          </tokens>
        </chunking>
        <chunking id="18" string="presidents to childhood neighbors" type="NP">
          <tokens>
            <token id="6" string="presidents" />
            <token id="7" string="to" />
            <token id="8" string="childhood" />
            <token id="9" string="neighbors" />
          </tokens>
        </chunking>
        <chunking id="19" string="followed the death of Lucille Ball" type="VP">
          <tokens>
            <token id="10" string="followed" />
            <token id="11" string="the" />
            <token id="12" string="death" />
            <token id="13" string="of" />
            <token id="14" string="Lucille" />
            <token id="15" string="Ball" />
          </tokens>
        </chunking>
        <chunking id="20" string="Lucille Ball" type="NP">
          <tokens>
            <token id="14" string="Lucille" />
            <token id="15" string="Ball" />
          </tokens>
        </chunking>
        <chunking id="21" string="television reruns" type="NP">
          <tokens>
            <token id="29" string="television" />
            <token id="30" string="reruns" />
          </tokens>
        </chunking>
        <chunking id="22" string="the queen mother of comedy will live on through television reruns and her influence on comedy" type="SBAR">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="queen" />
            <token id="22" string="mother" />
            <token id="23" string="of" />
            <token id="24" string="comedy" />
            <token id="25" string="will" />
            <token id="26" string="live" />
            <token id="27" string="on" />
            <token id="28" string="through" />
            <token id="29" string="television" />
            <token id="30" string="reruns" />
            <token id="31" string="and" />
            <token id="32" string="her" />
            <token id="33" string="influence" />
            <token id="34" string="on" />
            <token id="35" string="comedy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">outpouring</governor>
          <dependent id="1">An</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">followed</governor>
          <dependent id="2">outpouring</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">sympathy</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">outpouring</governor>
          <dependent id="4">sympathy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">presidents</governor>
          <dependent id="5">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">sympathy</governor>
          <dependent id="6">presidents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">neighbors</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">neighbors</governor>
          <dependent id="8">childhood</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">presidents</governor>
          <dependent id="9">neighbors</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">followed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">death</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">followed</governor>
          <dependent id="12">death</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Ball</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Ball</governor>
          <dependent id="14">Lucille</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">death</governor>
          <dependent id="15">Ball</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">followed</governor>
          <dependent id="17">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">said</governor>
          <dependent id="18">many</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">followed</governor>
          <dependent id="19">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">mother</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">mother</governor>
          <dependent id="21">queen</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">live</governor>
          <dependent id="22">mother</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">comedy</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">mother</governor>
          <dependent id="24">comedy</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">live</governor>
          <dependent id="25">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">said</governor>
          <dependent id="26">live</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">reruns</governor>
          <dependent id="27">on</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">reruns</governor>
          <dependent id="28">through</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">reruns</governor>
          <dependent id="29">television</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">live</governor>
          <dependent id="30">reruns</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="30">reruns</governor>
          <dependent id="31">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="33">influence</governor>
          <dependent id="32">her</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="30">reruns</governor>
          <dependent id="33">influence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">comedy</governor>
          <dependent id="34">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">live</governor>
          <dependent id="35">comedy</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lucille Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Lucille" />
            <token id="15" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>The daffy, redheaded comedian whose harebrained schemes drove her television family crazy and delighted viewers for four decades died Wednesday of a ruptured abdominal artery at Cedars-Sinai Medical Center.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="daffy" lemma="daffy" stem="daffi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="redheaded" lemma="redheaded" stem="redhead" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="comedian" lemma="comedian" stem="comedian" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="whose" lemma="whose" stem="whose" pos="WP$" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="harebrained" lemma="harebrained" stem="harebrain" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="schemes" lemma="scheme" stem="scheme" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="drove" lemma="drive" stem="drove" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="11" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="crazy" lemma="crazy" stem="crazi" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="delighted" lemma="delighted" stem="delight" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="viewers" lemma="viewer" stem="viewer" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="four" lemma="four" stem="four" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="19" string="decades" lemma="decade" stem="decad" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="20" string="died" lemma="die" stem="di" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="Wednesday" lemma="Wednesday" stem="wednesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="ruptured" lemma="rupture" stem="ruptur" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="abdominal" lemma="abdominal" stem="abdomin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="artery" lemma="artery" stem="arteri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Cedars-Sinai" lemma="Cedars-Sinai" stem="cedars-sinai" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="29" string="Medical" lemma="Medical" stem="medic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="30" string="Center" lemma="Center" stem="center" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (JJ daffy) (, ,) (JJ redheaded) (NN comedian)) (SBAR (WP$ whose) (S (NP (JJ harebrained) (NNS schemes)) (VP (VBD drove) (NP (PRP$ her) (NN television) (NN family)) (PP (NP (ADJP (JJ crazy) (CC and) (JJ delighted)) (NNS viewers)) (IN for) (NP (CD four) (NNS decades))))))) (VP (VBD died) (NP (NP (NNP Wednesday)) (PP (IN of) (NP (NP (DT a) (VBN ruptured) (JJ abdominal) (NN artery)) (PP (IN at) (NP (NNP Cedars-Sinai) (NNP Medical) (NNP Center))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="whose harebrained schemes drove her television family crazy and delighted viewers for four decades" type="SBAR">
          <tokens>
            <token id="6" string="whose" />
            <token id="7" string="harebrained" />
            <token id="8" string="schemes" />
            <token id="9" string="drove" />
            <token id="10" string="her" />
            <token id="11" string="television" />
            <token id="12" string="family" />
            <token id="13" string="crazy" />
            <token id="14" string="and" />
            <token id="15" string="delighted" />
            <token id="16" string="viewers" />
            <token id="17" string="for" />
            <token id="18" string="four" />
            <token id="19" string="decades" />
          </tokens>
        </chunking>
        <chunking id="2" string="drove her television family crazy and delighted viewers for four decades" type="VP">
          <tokens>
            <token id="9" string="drove" />
            <token id="10" string="her" />
            <token id="11" string="television" />
            <token id="12" string="family" />
            <token id="13" string="crazy" />
            <token id="14" string="and" />
            <token id="15" string="delighted" />
            <token id="16" string="viewers" />
            <token id="17" string="for" />
            <token id="18" string="four" />
            <token id="19" string="decades" />
          </tokens>
        </chunking>
        <chunking id="3" string="died Wednesday of a ruptured abdominal artery at Cedars-Sinai Medical Center" type="VP">
          <tokens>
            <token id="20" string="died" />
            <token id="21" string="Wednesday" />
            <token id="22" string="of" />
            <token id="23" string="a" />
            <token id="24" string="ruptured" />
            <token id="25" string="abdominal" />
            <token id="26" string="artery" />
            <token id="27" string="at" />
            <token id="28" string="Cedars-Sinai" />
            <token id="29" string="Medical" />
            <token id="30" string="Center" />
          </tokens>
        </chunking>
        <chunking id="4" string="crazy and delighted viewers" type="NP">
          <tokens>
            <token id="13" string="crazy" />
            <token id="14" string="and" />
            <token id="15" string="delighted" />
            <token id="16" string="viewers" />
          </tokens>
        </chunking>
        <chunking id="5" string="a ruptured abdominal artery at Cedars-Sinai Medical Center" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="ruptured" />
            <token id="25" string="abdominal" />
            <token id="26" string="artery" />
            <token id="27" string="at" />
            <token id="28" string="Cedars-Sinai" />
            <token id="29" string="Medical" />
            <token id="30" string="Center" />
          </tokens>
        </chunking>
        <chunking id="6" string="a ruptured abdominal artery" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="ruptured" />
            <token id="25" string="abdominal" />
            <token id="26" string="artery" />
          </tokens>
        </chunking>
        <chunking id="7" string="Wednesday of a ruptured abdominal artery at Cedars-Sinai Medical Center" type="NP">
          <tokens>
            <token id="21" string="Wednesday" />
            <token id="22" string="of" />
            <token id="23" string="a" />
            <token id="24" string="ruptured" />
            <token id="25" string="abdominal" />
            <token id="26" string="artery" />
            <token id="27" string="at" />
            <token id="28" string="Cedars-Sinai" />
            <token id="29" string="Medical" />
            <token id="30" string="Center" />
          </tokens>
        </chunking>
        <chunking id="8" string="The daffy , redheaded comedian whose harebrained schemes drove her television family crazy and delighted viewers for four decades" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="daffy" />
            <token id="3" string="," />
            <token id="4" string="redheaded" />
            <token id="5" string="comedian" />
            <token id="6" string="whose" />
            <token id="7" string="harebrained" />
            <token id="8" string="schemes" />
            <token id="9" string="drove" />
            <token id="10" string="her" />
            <token id="11" string="television" />
            <token id="12" string="family" />
            <token id="13" string="crazy" />
            <token id="14" string="and" />
            <token id="15" string="delighted" />
            <token id="16" string="viewers" />
            <token id="17" string="for" />
            <token id="18" string="four" />
            <token id="19" string="decades" />
          </tokens>
        </chunking>
        <chunking id="9" string="harebrained schemes" type="NP">
          <tokens>
            <token id="7" string="harebrained" />
            <token id="8" string="schemes" />
          </tokens>
        </chunking>
        <chunking id="10" string="The daffy , redheaded comedian" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="daffy" />
            <token id="3" string="," />
            <token id="4" string="redheaded" />
            <token id="5" string="comedian" />
          </tokens>
        </chunking>
        <chunking id="11" string="four decades" type="NP">
          <tokens>
            <token id="18" string="four" />
            <token id="19" string="decades" />
          </tokens>
        </chunking>
        <chunking id="12" string="Wednesday" type="NP">
          <tokens>
            <token id="21" string="Wednesday" />
          </tokens>
        </chunking>
        <chunking id="13" string="Cedars-Sinai Medical Center" type="NP">
          <tokens>
            <token id="28" string="Cedars-Sinai" />
            <token id="29" string="Medical" />
            <token id="30" string="Center" />
          </tokens>
        </chunking>
        <chunking id="14" string="her television family" type="NP">
          <tokens>
            <token id="10" string="her" />
            <token id="11" string="television" />
            <token id="12" string="family" />
          </tokens>
        </chunking>
        <chunking id="15" string="crazy and delighted" type="ADJP">
          <tokens>
            <token id="13" string="crazy" />
            <token id="14" string="and" />
            <token id="15" string="delighted" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="5">comedian</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">comedian</governor>
          <dependent id="2">daffy</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">comedian</governor>
          <dependent id="4">redheaded</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">died</governor>
          <dependent id="5">comedian</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">drove</governor>
          <dependent id="6">whose</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">schemes</governor>
          <dependent id="7">harebrained</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">drove</governor>
          <dependent id="8">schemes</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">comedian</governor>
          <dependent id="9">drove</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">family</governor>
          <dependent id="10">her</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">family</governor>
          <dependent id="11">television</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">drove</governor>
          <dependent id="12">family</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">viewers</governor>
          <dependent id="13">crazy</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">crazy</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">crazy</governor>
          <dependent id="15">delighted</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">drove</governor>
          <dependent id="16">viewers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">viewers</governor>
          <dependent id="17">for</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">decades</governor>
          <dependent id="18">four</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">viewers</governor>
          <dependent id="19">decades</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">died</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">died</governor>
          <dependent id="21">Wednesday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">artery</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">artery</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">artery</governor>
          <dependent id="24">ruptured</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">artery</governor>
          <dependent id="25">abdominal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">Wednesday</governor>
          <dependent id="26">artery</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">Center</governor>
          <dependent id="27">at</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">Center</governor>
          <dependent id="28">Cedars-Sinai</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">Center</governor>
          <dependent id="29">Medical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">artery</governor>
          <dependent id="30">Center</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="four decades" type="DURATION" score="0.0">
          <tokens>
            <token id="18" string="four" />
            <token id="19" string="decades" />
          </tokens>
        </entity>
        <entity id="2" string="Wednesday" type="DATE" score="0.0">
          <tokens>
            <token id="21" string="Wednesday" />
          </tokens>
        </entity>
        <entity id="3" string="Cedars-Sinai Medical Center" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="28" string="Cedars-Sinai" />
            <token id="29" string="Medical" />
            <token id="30" string="Center" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>She was 77 and died eight days after emergency heart surgery.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="77" lemma="77" stem="77" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="died" lemma="die" stem="di" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="eight" lemma="eight" stem="eight" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="7" string="days" lemma="day" stem="dai" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="8" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="emergency" lemma="emergency" stem="emerg" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="heart" lemma="heart" stem="heart" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="surgery" lemma="surgery" stem="surgeri" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VP (VBD was) (NP (CD 77))) (CC and) (VP (VBD died) (NP (CD eight) (NNS days)) (PP (IN after) (NP (NN emergency) (NN heart) (NN surgery))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="emergency heart surgery" type="NP">
          <tokens>
            <token id="9" string="emergency" />
            <token id="10" string="heart" />
            <token id="11" string="surgery" />
          </tokens>
        </chunking>
        <chunking id="2" string="eight days" type="NP">
          <tokens>
            <token id="6" string="eight" />
            <token id="7" string="days" />
          </tokens>
        </chunking>
        <chunking id="3" string="was 77" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="77" />
          </tokens>
        </chunking>
        <chunking id="4" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="5" string="was 77 and died eight days after emergency heart surgery" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="77" />
            <token id="4" string="and" />
            <token id="5" string="died" />
            <token id="6" string="eight" />
            <token id="7" string="days" />
            <token id="8" string="after" />
            <token id="9" string="emergency" />
            <token id="10" string="heart" />
            <token id="11" string="surgery" />
          </tokens>
        </chunking>
        <chunking id="6" string="77" type="NP">
          <tokens>
            <token id="3" string="77" />
          </tokens>
        </chunking>
        <chunking id="7" string="died eight days after emergency heart surgery" type="VP">
          <tokens>
            <token id="5" string="died" />
            <token id="6" string="eight" />
            <token id="7" string="days" />
            <token id="8" string="after" />
            <token id="9" string="emergency" />
            <token id="10" string="heart" />
            <token id="11" string="surgery" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">77</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="3">77</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">77</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">77</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">77</governor>
          <dependent id="5">died</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">days</governor>
          <dependent id="6">eight</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="5">died</governor>
          <dependent id="7">days</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">surgery</governor>
          <dependent id="8">after</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">surgery</governor>
          <dependent id="9">emergency</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">surgery</governor>
          <dependent id="10">heart</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">died</governor>
          <dependent id="11">surgery</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="eight days" type="DURATION" score="0.0">
          <tokens>
            <token id="6" string="eight" />
            <token id="7" string="days" />
          </tokens>
        </entity>
        <entity id="2" string="77" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="77" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>A private burial was planned, reportedly with no funeral services in accordance with Miss Ball&amp;apost;s wishes.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="private" lemma="private" stem="privat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="burial" lemma="burial" stem="burial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="planned" lemma="plan" stem="plan" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="reportedly" lemma="reportedly" stem="reportedli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="funeral" lemma="funeral" stem="funer" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="services" lemma="service" stem="servic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="accordance" lemma="accordance" stem="accord" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="17" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="wishes" lemma="wish" stem="wish" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT A) (JJ private) (NN burial)) (VP (VBD was) (VP (VBN planned) (, ,) (PP (ADVP (RB reportedly)) (IN with) (NP (NP (DT no) (JJ funeral) (NNS services)) (PP (IN in) (NP (NP (NN accordance)) (PP (IN with) (NP (NP (NNP Miss) (NNP Ball) (POS 's)) (NNS wishes))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="planned , reportedly with no funeral services in accordance with Miss Ball 's wishes" type="VP">
          <tokens>
            <token id="5" string="planned" />
            <token id="6" string="," />
            <token id="7" string="reportedly" />
            <token id="8" string="with" />
            <token id="9" string="no" />
            <token id="10" string="funeral" />
            <token id="11" string="services" />
            <token id="12" string="in" />
            <token id="13" string="accordance" />
            <token id="14" string="with" />
            <token id="15" string="Miss" />
            <token id="16" string="Ball" />
            <token id="17" string="'s" />
            <token id="18" string="wishes" />
          </tokens>
        </chunking>
        <chunking id="2" string="A private burial" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="private" />
            <token id="3" string="burial" />
          </tokens>
        </chunking>
        <chunking id="3" string="accordance" type="NP">
          <tokens>
            <token id="13" string="accordance" />
          </tokens>
        </chunking>
        <chunking id="4" string="Miss Ball 's" type="NP">
          <tokens>
            <token id="15" string="Miss" />
            <token id="16" string="Ball" />
            <token id="17" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="no funeral services in accordance with Miss Ball 's wishes" type="NP">
          <tokens>
            <token id="9" string="no" />
            <token id="10" string="funeral" />
            <token id="11" string="services" />
            <token id="12" string="in" />
            <token id="13" string="accordance" />
            <token id="14" string="with" />
            <token id="15" string="Miss" />
            <token id="16" string="Ball" />
            <token id="17" string="'s" />
            <token id="18" string="wishes" />
          </tokens>
        </chunking>
        <chunking id="6" string="Miss Ball 's wishes" type="NP">
          <tokens>
            <token id="15" string="Miss" />
            <token id="16" string="Ball" />
            <token id="17" string="'s" />
            <token id="18" string="wishes" />
          </tokens>
        </chunking>
        <chunking id="7" string="no funeral services" type="NP">
          <tokens>
            <token id="9" string="no" />
            <token id="10" string="funeral" />
            <token id="11" string="services" />
          </tokens>
        </chunking>
        <chunking id="8" string="accordance with Miss Ball 's wishes" type="NP">
          <tokens>
            <token id="13" string="accordance" />
            <token id="14" string="with" />
            <token id="15" string="Miss" />
            <token id="16" string="Ball" />
            <token id="17" string="'s" />
            <token id="18" string="wishes" />
          </tokens>
        </chunking>
        <chunking id="9" string="was planned , reportedly with no funeral services in accordance with Miss Ball 's wishes" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="planned" />
            <token id="6" string="," />
            <token id="7" string="reportedly" />
            <token id="8" string="with" />
            <token id="9" string="no" />
            <token id="10" string="funeral" />
            <token id="11" string="services" />
            <token id="12" string="in" />
            <token id="13" string="accordance" />
            <token id="14" string="with" />
            <token id="15" string="Miss" />
            <token id="16" string="Ball" />
            <token id="17" string="'s" />
            <token id="18" string="wishes" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">burial</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">burial</governor>
          <dependent id="2">private</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">planned</governor>
          <dependent id="3">burial</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">planned</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">planned</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">services</governor>
          <dependent id="7">reportedly</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">services</governor>
          <dependent id="8">with</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">services</governor>
          <dependent id="9">no</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">services</governor>
          <dependent id="10">funeral</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">planned</governor>
          <dependent id="11">services</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">wishes</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="12">in</governor>
          <dependent id="13">accordance</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="12">in</governor>
          <dependent id="14">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Ball</governor>
          <dependent id="15">Miss</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">wishes</governor>
          <dependent id="16">Ball</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Ball</governor>
          <dependent id="17">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">services</governor>
          <dependent id="18">wishes</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>``God has her now, and, thanks to television, we&amp;apost;ll have her forever,&amp;apost;&amp;apost; said comedian and longtime friend Bob Hope.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="God" lemma="God" stem="god" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="thanks" lemma="thanks" stem="thank" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="'ll" lemma="will" stem="'ll" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="forever" lemma="forever" stem="forev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="comedian" lemma="comedian" stem="comedian" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="longtime" lemma="longtime" stem="longtim" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="friend" lemma="friend" stem="friend" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="Bob" lemma="Bob" stem="bob" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="26" string="Hope" lemma="Hope" stem="hope" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (S (NP (NNP God)) (VP (VBZ has) (NP (PRP$ her)) (ADVP (RB now)))) (, ,) (CC and) (S (FRAG (, ,) (PP (NP (NNS thanks)) (PP (TO to) (NP (NN television)))) (, ,)) (NP (PRP we)) (VP (MD 'll) (VP (VB have) (NP (PRP$ her)) (ADVP (RB forever)))))) (, ,) ('' '') (VP (VBD said) (NP (NP (NN comedian)) (CC and) (NP (JJ longtime) (NN friend)))) (NP (NNP Bob) (NNP Hope)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="have her forever" type="VP">
          <tokens>
            <token id="15" string="have" />
            <token id="16" string="her" />
            <token id="17" string="forever" />
          </tokens>
        </chunking>
        <chunking id="2" string="television" type="NP">
          <tokens>
            <token id="11" string="television" />
          </tokens>
        </chunking>
        <chunking id="3" string="comedian and longtime friend" type="NP">
          <tokens>
            <token id="21" string="comedian" />
            <token id="22" string="and" />
            <token id="23" string="longtime" />
            <token id="24" string="friend" />
          </tokens>
        </chunking>
        <chunking id="4" string="said comedian and longtime friend" type="VP">
          <tokens>
            <token id="20" string="said" />
            <token id="21" string="comedian" />
            <token id="22" string="and" />
            <token id="23" string="longtime" />
            <token id="24" string="friend" />
          </tokens>
        </chunking>
        <chunking id="5" string="Bob Hope" type="NP">
          <tokens>
            <token id="25" string="Bob" />
            <token id="26" string="Hope" />
          </tokens>
        </chunking>
        <chunking id="6" string="we" type="NP">
          <tokens>
            <token id="13" string="we" />
          </tokens>
        </chunking>
        <chunking id="7" string="'ll have her forever" type="VP">
          <tokens>
            <token id="14" string="'ll" />
            <token id="15" string="have" />
            <token id="16" string="her" />
            <token id="17" string="forever" />
          </tokens>
        </chunking>
        <chunking id="8" string="thanks" type="NP">
          <tokens>
            <token id="9" string="thanks" />
          </tokens>
        </chunking>
        <chunking id="9" string="comedian" type="NP">
          <tokens>
            <token id="21" string="comedian" />
          </tokens>
        </chunking>
        <chunking id="10" string="her" type="NP">
          <tokens>
            <token id="4" string="her" />
          </tokens>
        </chunking>
        <chunking id="11" string="God" type="NP">
          <tokens>
            <token id="2" string="God" />
          </tokens>
        </chunking>
        <chunking id="12" string="has her now" type="VP">
          <tokens>
            <token id="3" string="has" />
            <token id="4" string="her" />
            <token id="5" string="now" />
          </tokens>
        </chunking>
        <chunking id="13" string="longtime friend" type="NP">
          <tokens>
            <token id="23" string="longtime" />
            <token id="24" string="friend" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">has</governor>
          <dependent id="2">God</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">said</governor>
          <dependent id="3">has</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">has</governor>
          <dependent id="4">her</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">has</governor>
          <dependent id="5">now</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">has</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="15">have</governor>
          <dependent id="9">thanks</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">television</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">thanks</governor>
          <dependent id="11">television</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">have</governor>
          <dependent id="13">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">have</governor>
          <dependent id="14">'ll</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">has</governor>
          <dependent id="15">have</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">have</governor>
          <dependent id="16">her</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">have</governor>
          <dependent id="17">forever</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">said</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">said</governor>
          <dependent id="21">comedian</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">comedian</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">friend</governor>
          <dependent id="23">longtime</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">comedian</governor>
          <dependent id="24">friend</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Hope</governor>
          <dependent id="25">Bob</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">said</governor>
          <dependent id="26">Hope</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="now" />
          </tokens>
        </entity>
        <entity id="2" string="Bob Hope" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Bob" />
            <token id="26" string="Hope" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>Hospital switchboards were swamped with condolence calls and thousands of cards after Miss Ball&amp;apost;s death, spokesman Ron Wise said.</content>
      <tokens>
        <token id="1" string="Hospital" lemma="Hospital" stem="hospit" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="switchboards" lemma="switchboard" stem="switchboard" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="swamped" lemma="swamp" stem="swamp" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="condolence" lemma="condolence" stem="condol" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="calls" lemma="call" stem="call" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="thousands" lemma="thousand" stem="thousand" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="cards" lemma="card" stem="card" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="14" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="15" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="16" string="death" lemma="death" stem="death" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="spokesman" lemma="spokesman" stem="spokesman" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="Ron" lemma="Ron" stem="ron" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="20" string="Wise" lemma="Wise" stem="wise" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="21" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Hospital) (NNS switchboards)) (VP (VBD were) (VP (VBN swamped) (PP (IN with) (NP (NP (NN condolence) (NNS calls) (CC and) (NNS thousands)) (PP (IN of) (NP (NNS cards))))) (PP (IN after) (NP (NP (NNP Miss) (NNP Ball) (POS 's)) (NN death)))))) (, ,) (NP (NN spokesman) (NNP Ron) (NNP Wise)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Hospital switchboards" type="NP">
          <tokens>
            <token id="1" string="Hospital" />
            <token id="2" string="switchboards" />
          </tokens>
        </chunking>
        <chunking id="2" string="cards" type="NP">
          <tokens>
            <token id="11" string="cards" />
          </tokens>
        </chunking>
        <chunking id="3" string="swamped with condolence calls and thousands of cards after Miss Ball 's death" type="VP">
          <tokens>
            <token id="4" string="swamped" />
            <token id="5" string="with" />
            <token id="6" string="condolence" />
            <token id="7" string="calls" />
            <token id="8" string="and" />
            <token id="9" string="thousands" />
            <token id="10" string="of" />
            <token id="11" string="cards" />
            <token id="12" string="after" />
            <token id="13" string="Miss" />
            <token id="14" string="Ball" />
            <token id="15" string="'s" />
            <token id="16" string="death" />
          </tokens>
        </chunking>
        <chunking id="4" string="condolence calls and thousands" type="NP">
          <tokens>
            <token id="6" string="condolence" />
            <token id="7" string="calls" />
            <token id="8" string="and" />
            <token id="9" string="thousands" />
          </tokens>
        </chunking>
        <chunking id="5" string="were swamped with condolence calls and thousands of cards after Miss Ball 's death" type="VP">
          <tokens>
            <token id="3" string="were" />
            <token id="4" string="swamped" />
            <token id="5" string="with" />
            <token id="6" string="condolence" />
            <token id="7" string="calls" />
            <token id="8" string="and" />
            <token id="9" string="thousands" />
            <token id="10" string="of" />
            <token id="11" string="cards" />
            <token id="12" string="after" />
            <token id="13" string="Miss" />
            <token id="14" string="Ball" />
            <token id="15" string="'s" />
            <token id="16" string="death" />
          </tokens>
        </chunking>
        <chunking id="6" string="spokesman Ron Wise" type="NP">
          <tokens>
            <token id="18" string="spokesman" />
            <token id="19" string="Ron" />
            <token id="20" string="Wise" />
          </tokens>
        </chunking>
        <chunking id="7" string="Miss Ball 's" type="NP">
          <tokens>
            <token id="13" string="Miss" />
            <token id="14" string="Ball" />
            <token id="15" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="Miss Ball 's death" type="NP">
          <tokens>
            <token id="13" string="Miss" />
            <token id="14" string="Ball" />
            <token id="15" string="'s" />
            <token id="16" string="death" />
          </tokens>
        </chunking>
        <chunking id="9" string="condolence calls and thousands of cards" type="NP">
          <tokens>
            <token id="6" string="condolence" />
            <token id="7" string="calls" />
            <token id="8" string="and" />
            <token id="9" string="thousands" />
            <token id="10" string="of" />
            <token id="11" string="cards" />
          </tokens>
        </chunking>
        <chunking id="10" string="said" type="VP">
          <tokens>
            <token id="21" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">switchboards</governor>
          <dependent id="1">Hospital</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="4">swamped</governor>
          <dependent id="2">switchboards</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">swamped</governor>
          <dependent id="3">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">said</governor>
          <dependent id="4">swamped</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">calls</governor>
          <dependent id="5">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">calls</governor>
          <dependent id="6">condolence</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">swamped</governor>
          <dependent id="7">calls</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">calls</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">calls</governor>
          <dependent id="9">thousands</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">cards</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">calls</governor>
          <dependent id="11">cards</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">death</governor>
          <dependent id="12">after</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Ball</governor>
          <dependent id="13">Miss</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">death</governor>
          <dependent id="14">Ball</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Ball</governor>
          <dependent id="15">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">swamped</governor>
          <dependent id="16">death</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Wise</governor>
          <dependent id="18">spokesman</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Wise</governor>
          <dependent id="19">Ron</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">said</governor>
          <dependent id="20">Wise</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ron Wise" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Ron" />
            <token id="20" string="Wise" />
          </tokens>
        </entity>
        <entity id="2" string="Miss Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Miss" />
            <token id="14" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>Miss Ball&amp;apost;s family requested that any flowers sent to the Medical Center in her memory be distributed to other patients.</content>
      <tokens>
        <token id="1" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="2" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="requested" lemma="request" stem="request" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="flowers" lemma="flower" stem="flower" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="sent" lemma="send" stem="sent" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Medical" lemma="Medical" stem="medic" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="13" string="Center" lemma="Center" stem="center" pos="NNP" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="memory" lemma="memory" stem="memori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="distributed" lemma="distribute" stem="distribut" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="patients" lemma="patient" stem="patient" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Miss) (NNP Ball) (POS 's)) (NN family)) (VP (VBD requested) (SBAR (IN that) (S (NP (NP (DT any) (NNS flowers)) (VP (VBN sent) (PP (TO to) (NP (NP (DT the) (NNP Medical) (NNP Center)) (PP (IN in) (NP (PRP$ her) (NN memory))))))) (VP (VB be) (VP (VBN distributed) (PP (TO to) (NP (JJ other) (NNS patients)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Miss Ball 's family" type="NP">
          <tokens>
            <token id="1" string="Miss" />
            <token id="2" string="Ball" />
            <token id="3" string="'s" />
            <token id="4" string="family" />
          </tokens>
        </chunking>
        <chunking id="2" string="that any flowers sent to the Medical Center in her memory be distributed to other patients" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="any" />
            <token id="8" string="flowers" />
            <token id="9" string="sent" />
            <token id="10" string="to" />
            <token id="11" string="the" />
            <token id="12" string="Medical" />
            <token id="13" string="Center" />
            <token id="14" string="in" />
            <token id="15" string="her" />
            <token id="16" string="memory" />
            <token id="17" string="be" />
            <token id="18" string="distributed" />
            <token id="19" string="to" />
            <token id="20" string="other" />
            <token id="21" string="patients" />
          </tokens>
        </chunking>
        <chunking id="3" string="be distributed to other patients" type="VP">
          <tokens>
            <token id="17" string="be" />
            <token id="18" string="distributed" />
            <token id="19" string="to" />
            <token id="20" string="other" />
            <token id="21" string="patients" />
          </tokens>
        </chunking>
        <chunking id="4" string="other patients" type="NP">
          <tokens>
            <token id="20" string="other" />
            <token id="21" string="patients" />
          </tokens>
        </chunking>
        <chunking id="5" string="Miss Ball 's" type="NP">
          <tokens>
            <token id="1" string="Miss" />
            <token id="2" string="Ball" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="any flowers" type="NP">
          <tokens>
            <token id="7" string="any" />
            <token id="8" string="flowers" />
          </tokens>
        </chunking>
        <chunking id="7" string="distributed to other patients" type="VP">
          <tokens>
            <token id="18" string="distributed" />
            <token id="19" string="to" />
            <token id="20" string="other" />
            <token id="21" string="patients" />
          </tokens>
        </chunking>
        <chunking id="8" string="any flowers sent to the Medical Center in her memory" type="NP">
          <tokens>
            <token id="7" string="any" />
            <token id="8" string="flowers" />
            <token id="9" string="sent" />
            <token id="10" string="to" />
            <token id="11" string="the" />
            <token id="12" string="Medical" />
            <token id="13" string="Center" />
            <token id="14" string="in" />
            <token id="15" string="her" />
            <token id="16" string="memory" />
          </tokens>
        </chunking>
        <chunking id="9" string="her memory" type="NP">
          <tokens>
            <token id="15" string="her" />
            <token id="16" string="memory" />
          </tokens>
        </chunking>
        <chunking id="10" string="the Medical Center" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="Medical" />
            <token id="13" string="Center" />
          </tokens>
        </chunking>
        <chunking id="11" string="the Medical Center in her memory" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="Medical" />
            <token id="13" string="Center" />
            <token id="14" string="in" />
            <token id="15" string="her" />
            <token id="16" string="memory" />
          </tokens>
        </chunking>
        <chunking id="12" string="requested that any flowers sent to the Medical Center in her memory be distributed to other patients" type="VP">
          <tokens>
            <token id="5" string="requested" />
            <token id="6" string="that" />
            <token id="7" string="any" />
            <token id="8" string="flowers" />
            <token id="9" string="sent" />
            <token id="10" string="to" />
            <token id="11" string="the" />
            <token id="12" string="Medical" />
            <token id="13" string="Center" />
            <token id="14" string="in" />
            <token id="15" string="her" />
            <token id="16" string="memory" />
            <token id="17" string="be" />
            <token id="18" string="distributed" />
            <token id="19" string="to" />
            <token id="20" string="other" />
            <token id="21" string="patients" />
          </tokens>
        </chunking>
        <chunking id="13" string="sent to the Medical Center in her memory" type="VP">
          <tokens>
            <token id="9" string="sent" />
            <token id="10" string="to" />
            <token id="11" string="the" />
            <token id="12" string="Medical" />
            <token id="13" string="Center" />
            <token id="14" string="in" />
            <token id="15" string="her" />
            <token id="16" string="memory" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Ball</governor>
          <dependent id="1">Miss</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">family</governor>
          <dependent id="2">Ball</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Ball</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">requested</governor>
          <dependent id="4">family</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">requested</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">distributed</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">flowers</governor>
          <dependent id="7">any</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="18">distributed</governor>
          <dependent id="8">flowers</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="8">flowers</governor>
          <dependent id="9">sent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Center</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">Center</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Center</governor>
          <dependent id="12">Medical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">sent</governor>
          <dependent id="13">Center</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">memory</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">memory</governor>
          <dependent id="15">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">Center</governor>
          <dependent id="16">memory</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="18">distributed</governor>
          <dependent id="17">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">requested</governor>
          <dependent id="18">distributed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">patients</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">patients</governor>
          <dependent id="20">other</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">distributed</governor>
          <dependent id="21">patients</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Ball" />
          </tokens>
        </entity>
        <entity id="2" string="Center" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="13" string="Center" />
          </tokens>
        </entity>
        <entity id="3" string="Medical" type="MISC" score="0.0">
          <tokens>
            <token id="12" string="Medical" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>Miss Ball maintained her sense of humor even when she was critically ill.</content>
      <tokens>
        <token id="1" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="2" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="3" string="maintained" lemma="maintain" stem="maintain" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="sense" lemma="sense" stem="sens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="humor" lemma="humor" stem="humor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="critically" lemma="critically" stem="critic" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="ill" lemma="ill" stem="ill" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Miss) (NNP Ball)) (VP (VBD maintained) (NP (NP (PRP$ her) (NN sense)) (PP (IN of) (NP (NN humor)))) (SBAR (RB even) (WHADVP (WRB when)) (S (NP (PRP she)) (VP (VBD was) (ADJP (RB critically) (RB ill)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was critically ill" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="critically" />
            <token id="13" string="ill" />
          </tokens>
        </chunking>
        <chunking id="2" string="humor" type="NP">
          <tokens>
            <token id="7" string="humor" />
          </tokens>
        </chunking>
        <chunking id="3" string="maintained her sense of humor even when she was critically ill" type="VP">
          <tokens>
            <token id="3" string="maintained" />
            <token id="4" string="her" />
            <token id="5" string="sense" />
            <token id="6" string="of" />
            <token id="7" string="humor" />
            <token id="8" string="even" />
            <token id="9" string="when" />
            <token id="10" string="she" />
            <token id="11" string="was" />
            <token id="12" string="critically" />
            <token id="13" string="ill" />
          </tokens>
        </chunking>
        <chunking id="4" string="her sense of humor" type="NP">
          <tokens>
            <token id="4" string="her" />
            <token id="5" string="sense" />
            <token id="6" string="of" />
            <token id="7" string="humor" />
          </tokens>
        </chunking>
        <chunking id="5" string="her sense" type="NP">
          <tokens>
            <token id="4" string="her" />
            <token id="5" string="sense" />
          </tokens>
        </chunking>
        <chunking id="6" string="even when she was critically ill" type="SBAR">
          <tokens>
            <token id="8" string="even" />
            <token id="9" string="when" />
            <token id="10" string="she" />
            <token id="11" string="was" />
            <token id="12" string="critically" />
            <token id="13" string="ill" />
          </tokens>
        </chunking>
        <chunking id="7" string="critically ill" type="ADJP">
          <tokens>
            <token id="12" string="critically" />
            <token id="13" string="ill" />
          </tokens>
        </chunking>
        <chunking id="8" string="when" type="WHADVP">
          <tokens>
            <token id="9" string="when" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="10" string="she" />
          </tokens>
        </chunking>
        <chunking id="10" string="Miss Ball" type="NP">
          <tokens>
            <token id="1" string="Miss" />
            <token id="2" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Ball</governor>
          <dependent id="1">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">maintained</governor>
          <dependent id="2">Ball</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">maintained</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">sense</governor>
          <dependent id="4">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">maintained</governor>
          <dependent id="5">sense</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">humor</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">sense</governor>
          <dependent id="7">humor</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">ill</governor>
          <dependent id="8">even</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">ill</governor>
          <dependent id="9">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">ill</governor>
          <dependent id="10">she</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">ill</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">ill</governor>
          <dependent id="12">critically</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">maintained</governor>
          <dependent id="13">ill</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Miss Ball" type="MISC" score="0.0">
          <tokens>
            <token id="1" string="Miss" />
            <token id="2" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>Following her operation last week, her first words to her daughter, Lucie, were: ``Wouldn&amp;apost;t you know _ this is the day I was going to get my hair done.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="Following" lemma="follow" stem="follow" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="operation" lemma="operation" stem="oper" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="9" string="words" lemma="word" stem="word" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="12" string="daughter" lemma="daughter" stem="daughter" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Lucie" lemma="Lucie" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="know" lemma="know" stem="know" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="_" lemma="_" stem="_" pos="RB" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="27" string="day" lemma="day" stem="dai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="28" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="29" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="32" string="get" lemma="get" stem="get" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="34" string="hair" lemma="hair" stem="hair" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="done" lemma="do" stem="done" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (VBG Following) (NP (PRP$ her) (NN operation))) (NP-TMP (JJ last) (NN week)) (PRN (, ,) (S (NP (NP (PRP$ her) (JJ first) (NNS words)) (PP (TO to) (NP (NP (PRP$ her) (NN daughter)) (, ,) (NP (NNP Lucie)) (, ,)))) (VP (VP (VBD were)) (: :) (`` ``) (VP (MD Would) (RB n't))))) (NP (PRP you)) (VP (VBP know) (S (ADVP (RB _)) (NP (DT this)) (VP (VBZ is) (NP (NP (DT the) (NN day)) (SBAR (S (NP (PRP I)) (VP (VBD was) (VP (VBG going) (S (VP (TO to) (VP (VB get) (NP (NP (PRP$ my) (NN hair)) (VP (VBN done)))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="my hair" type="NP">
          <tokens>
            <token id="33" string="my" />
            <token id="34" string="hair" />
          </tokens>
        </chunking>
        <chunking id="2" string="was going to get my hair done" type="VP">
          <tokens>
            <token id="29" string="was" />
            <token id="30" string="going" />
            <token id="31" string="to" />
            <token id="32" string="get" />
            <token id="33" string="my" />
            <token id="34" string="hair" />
            <token id="35" string="done" />
          </tokens>
        </chunking>
        <chunking id="3" string="is the day I was going to get my hair done" type="VP">
          <tokens>
            <token id="25" string="is" />
            <token id="26" string="the" />
            <token id="27" string="day" />
            <token id="28" string="I" />
            <token id="29" string="was" />
            <token id="30" string="going" />
            <token id="31" string="to" />
            <token id="32" string="get" />
            <token id="33" string="my" />
            <token id="34" string="hair" />
            <token id="35" string="done" />
          </tokens>
        </chunking>
        <chunking id="4" string="the day" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="day" />
          </tokens>
        </chunking>
        <chunking id="5" string="get my hair done" type="VP">
          <tokens>
            <token id="32" string="get" />
            <token id="33" string="my" />
            <token id="34" string="hair" />
            <token id="35" string="done" />
          </tokens>
        </chunking>
        <chunking id="6" string="going to get my hair done" type="VP">
          <tokens>
            <token id="30" string="going" />
            <token id="31" string="to" />
            <token id="32" string="get" />
            <token id="33" string="my" />
            <token id="34" string="hair" />
            <token id="35" string="done" />
          </tokens>
        </chunking>
        <chunking id="7" string="I" type="NP">
          <tokens>
            <token id="28" string="I" />
          </tokens>
        </chunking>
        <chunking id="8" string="her operation" type="NP">
          <tokens>
            <token id="2" string="her" />
            <token id="3" string="operation" />
          </tokens>
        </chunking>
        <chunking id="9" string="this" type="NP">
          <tokens>
            <token id="24" string="this" />
          </tokens>
        </chunking>
        <chunking id="10" string="done" type="VP">
          <tokens>
            <token id="35" string="done" />
          </tokens>
        </chunking>
        <chunking id="11" string="her daughter" type="NP">
          <tokens>
            <token id="11" string="her" />
            <token id="12" string="daughter" />
          </tokens>
        </chunking>
        <chunking id="12" string="Lucie" type="NP">
          <tokens>
            <token id="14" string="Lucie" />
          </tokens>
        </chunking>
        <chunking id="13" string="I was going to get my hair done" type="SBAR">
          <tokens>
            <token id="28" string="I" />
            <token id="29" string="was" />
            <token id="30" string="going" />
            <token id="31" string="to" />
            <token id="32" string="get" />
            <token id="33" string="my" />
            <token id="34" string="hair" />
            <token id="35" string="done" />
          </tokens>
        </chunking>
        <chunking id="14" string="her first words to her daughter , Lucie ," type="NP">
          <tokens>
            <token id="7" string="her" />
            <token id="8" string="first" />
            <token id="9" string="words" />
            <token id="10" string="to" />
            <token id="11" string="her" />
            <token id="12" string="daughter" />
            <token id="13" string="," />
            <token id="14" string="Lucie" />
            <token id="15" string="," />
          </tokens>
        </chunking>
        <chunking id="15" string="her first words" type="NP">
          <tokens>
            <token id="7" string="her" />
            <token id="8" string="first" />
            <token id="9" string="words" />
          </tokens>
        </chunking>
        <chunking id="16" string="the day I was going to get my hair done" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="day" />
            <token id="28" string="I" />
            <token id="29" string="was" />
            <token id="30" string="going" />
            <token id="31" string="to" />
            <token id="32" string="get" />
            <token id="33" string="my" />
            <token id="34" string="hair" />
            <token id="35" string="done" />
          </tokens>
        </chunking>
        <chunking id="17" string="Would n't" type="VP">
          <tokens>
            <token id="19" string="Would" />
            <token id="20" string="n't" />
          </tokens>
        </chunking>
        <chunking id="18" string="know _ this is the day I was going to get my hair done" type="VP">
          <tokens>
            <token id="22" string="know" />
            <token id="23" string="_" />
            <token id="24" string="this" />
            <token id="25" string="is" />
            <token id="26" string="the" />
            <token id="27" string="day" />
            <token id="28" string="I" />
            <token id="29" string="was" />
            <token id="30" string="going" />
            <token id="31" string="to" />
            <token id="32" string="get" />
            <token id="33" string="my" />
            <token id="34" string="hair" />
            <token id="35" string="done" />
          </tokens>
        </chunking>
        <chunking id="19" string="were" type="VP">
          <tokens>
            <token id="16" string="were" />
          </tokens>
        </chunking>
        <chunking id="20" string="her daughter , Lucie ," type="NP">
          <tokens>
            <token id="11" string="her" />
            <token id="12" string="daughter" />
            <token id="13" string="," />
            <token id="14" string="Lucie" />
            <token id="15" string="," />
          </tokens>
        </chunking>
        <chunking id="21" string="my hair done" type="NP">
          <tokens>
            <token id="33" string="my" />
            <token id="34" string="hair" />
            <token id="35" string="done" />
          </tokens>
        </chunking>
        <chunking id="22" string="were : `` Would n't" type="VP">
          <tokens>
            <token id="16" string="were" />
            <token id="17" string=":" />
            <token id="18" string="``" />
            <token id="19" string="Would" />
            <token id="20" string="n't" />
          </tokens>
        </chunking>
        <chunking id="23" string="to get my hair done" type="VP">
          <tokens>
            <token id="31" string="to" />
            <token id="32" string="get" />
            <token id="33" string="my" />
            <token id="34" string="hair" />
            <token id="35" string="done" />
          </tokens>
        </chunking>
        <chunking id="24" string="you" type="NP">
          <tokens>
            <token id="21" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">operation</governor>
          <dependent id="1">Following</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="3">operation</governor>
          <dependent id="2">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">know</governor>
          <dependent id="3">operation</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">week</governor>
          <dependent id="4">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="22">know</governor>
          <dependent id="5">week</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">words</governor>
          <dependent id="7">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">words</governor>
          <dependent id="8">first</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">were</governor>
          <dependent id="9">words</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">daughter</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">daughter</governor>
          <dependent id="11">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">words</governor>
          <dependent id="12">daughter</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="12">daughter</governor>
          <dependent id="14">Lucie</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="22">know</governor>
          <dependent id="16">were</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">were</governor>
          <dependent id="19">Would</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="19">Would</governor>
          <dependent id="20">n't</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">know</governor>
          <dependent id="21">you</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="22">know</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="27">day</governor>
          <dependent id="23">_</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">day</governor>
          <dependent id="24">this</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="27">day</governor>
          <dependent id="25">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">day</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">know</governor>
          <dependent id="27">day</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">going</governor>
          <dependent id="28">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="30">going</governor>
          <dependent id="29">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="27">day</governor>
          <dependent id="30">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="32">get</governor>
          <dependent id="31">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="30">going</governor>
          <dependent id="32">get</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="34">hair</governor>
          <dependent id="33">my</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="32">get</governor>
          <dependent id="34">hair</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="34">hair</governor>
          <dependent id="35">done</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lucie" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Lucie" />
          </tokens>
        </entity>
        <entity id="2" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="8" string="first" />
          </tokens>
        </entity>
        <entity id="3" string="the day" type="DATE" score="0.0">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="day" />
          </tokens>
        </entity>
        <entity id="4" string="last week" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="last" />
            <token id="5" string="week" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Miss Ball had been improving steadily from the heart surgery, so her death came as a shock.</content>
      <tokens>
        <token id="1" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="improving" lemma="improve" stem="improv" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="steadily" lemma="steadily" stem="steadili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="heart" lemma="heart" stem="heart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="surgery" lemma="surgery" stem="surgeri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="death" lemma="death" stem="death" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="shock" lemma="shock" stem="shock" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Miss) (NNP Ball)) (VP (VBD had) (VP (VBN been) (VP (VBG improving) (ADVP (RB steadily)) (PP (IN from) (NP (DT the) (NN heart) (NN surgery))))))) (, ,) (RB so) (S (NP (PRP$ her) (NN death)) (VP (VBD came) (PP (IN as) (NP (DT a) (NN shock))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="came as a shock" type="VP">
          <tokens>
            <token id="15" string="came" />
            <token id="16" string="as" />
            <token id="17" string="a" />
            <token id="18" string="shock" />
          </tokens>
        </chunking>
        <chunking id="2" string="had been improving steadily from the heart surgery" type="VP">
          <tokens>
            <token id="3" string="had" />
            <token id="4" string="been" />
            <token id="5" string="improving" />
            <token id="6" string="steadily" />
            <token id="7" string="from" />
            <token id="8" string="the" />
            <token id="9" string="heart" />
            <token id="10" string="surgery" />
          </tokens>
        </chunking>
        <chunking id="3" string="been improving steadily from the heart surgery" type="VP">
          <tokens>
            <token id="4" string="been" />
            <token id="5" string="improving" />
            <token id="6" string="steadily" />
            <token id="7" string="from" />
            <token id="8" string="the" />
            <token id="9" string="heart" />
            <token id="10" string="surgery" />
          </tokens>
        </chunking>
        <chunking id="4" string="her death" type="NP">
          <tokens>
            <token id="13" string="her" />
            <token id="14" string="death" />
          </tokens>
        </chunking>
        <chunking id="5" string="improving steadily from the heart surgery" type="VP">
          <tokens>
            <token id="5" string="improving" />
            <token id="6" string="steadily" />
            <token id="7" string="from" />
            <token id="8" string="the" />
            <token id="9" string="heart" />
            <token id="10" string="surgery" />
          </tokens>
        </chunking>
        <chunking id="6" string="Miss Ball" type="NP">
          <tokens>
            <token id="1" string="Miss" />
            <token id="2" string="Ball" />
          </tokens>
        </chunking>
        <chunking id="7" string="the heart surgery" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="heart" />
            <token id="10" string="surgery" />
          </tokens>
        </chunking>
        <chunking id="8" string="a shock" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="shock" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Ball</governor>
          <dependent id="1">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">improving</governor>
          <dependent id="2">Ball</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">improving</governor>
          <dependent id="3">had</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">improving</governor>
          <dependent id="4">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">improving</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">improving</governor>
          <dependent id="6">steadily</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">surgery</governor>
          <dependent id="7">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">surgery</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">surgery</governor>
          <dependent id="9">heart</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">improving</governor>
          <dependent id="10">surgery</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">improving</governor>
          <dependent id="12">so</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">death</governor>
          <dependent id="13">her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">came</governor>
          <dependent id="14">death</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="5">improving</governor>
          <dependent id="15">came</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">shock</governor>
          <dependent id="16">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">shock</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">came</governor>
          <dependent id="18">shock</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>``She had been walking, her spirits were up.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="walking" lemma="walk" stem="walk" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="spirits" lemma="spirit" stem="spirit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="up" lemma="up" stem="up" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP She)) (VP (VBD had) (VP (VBN been) (VP (VBG walking))))) (, ,) (NP (PRP$ her) (NNS spirits)) (VP (VBD were) (ADVP (RB up))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="had been walking" type="VP">
          <tokens>
            <token id="3" string="had" />
            <token id="4" string="been" />
            <token id="5" string="walking" />
          </tokens>
        </chunking>
        <chunking id="2" string="been walking" type="VP">
          <tokens>
            <token id="4" string="been" />
            <token id="5" string="walking" />
          </tokens>
        </chunking>
        <chunking id="3" string="walking" type="VP">
          <tokens>
            <token id="5" string="walking" />
          </tokens>
        </chunking>
        <chunking id="4" string="were up" type="VP">
          <tokens>
            <token id="9" string="were" />
            <token id="10" string="up" />
          </tokens>
        </chunking>
        <chunking id="5" string="She" type="NP">
          <tokens>
            <token id="2" string="She" />
          </tokens>
        </chunking>
        <chunking id="6" string="her spirits" type="NP">
          <tokens>
            <token id="7" string="her" />
            <token id="8" string="spirits" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">walking</governor>
          <dependent id="2">She</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">walking</governor>
          <dependent id="3">had</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">walking</governor>
          <dependent id="4">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">were</governor>
          <dependent id="5">walking</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">spirits</governor>
          <dependent id="7">her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">were</governor>
          <dependent id="8">spirits</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">were</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">were</governor>
          <dependent id="10">up</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>Her family was with her,&amp;apost;&amp;apost; Wise said.</content>
      <tokens>
        <token id="1" string="Her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="her" lemma="she" stem="her" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Wise" lemma="Wise" stem="wise" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP$ Her) (NN family)) (VP (VBD was) (PP (IN with) (NP (PRP her))))) (, ,) ('' '') (NP (NNP Wise)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Her family" type="NP">
          <tokens>
            <token id="1" string="Her" />
            <token id="2" string="family" />
          </tokens>
        </chunking>
        <chunking id="2" string="her" type="NP">
          <tokens>
            <token id="5" string="her" />
          </tokens>
        </chunking>
        <chunking id="3" string="Wise" type="NP">
          <tokens>
            <token id="8" string="Wise" />
          </tokens>
        </chunking>
        <chunking id="4" string="was with her" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="with" />
            <token id="5" string="her" />
          </tokens>
        </chunking>
        <chunking id="5" string="said" type="VP">
          <tokens>
            <token id="9" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">family</governor>
          <dependent id="1">Her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">her</governor>
          <dependent id="2">family</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">her</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">her</governor>
          <dependent id="4">with</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">said</governor>
          <dependent id="5">her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">said</governor>
          <dependent id="8">Wise</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Wise" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Wise" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>``She responded as well as anyone could respond to that kind of surgery.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="responded" lemma="respond" stem="respond" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="anyone" lemma="anyone" stem="anyon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="respond" lemma="respond" stem="respond" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="kind" lemma="kind" stem="kind" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="surgery" lemma="surgery" stem="surgeri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP She)) (VP (VBD responded) (ADVP (RB as) (RB well)) (SBAR (IN as) (S (NP (NN anyone)) (VP (MD could) (VP (VB respond) (PP (TO to) (NP (NP (DT that) (NN kind)) (PP (IN of) (NP (NN surgery)))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="could respond to that kind of surgery" type="VP">
          <tokens>
            <token id="8" string="could" />
            <token id="9" string="respond" />
            <token id="10" string="to" />
            <token id="11" string="that" />
            <token id="12" string="kind" />
            <token id="13" string="of" />
            <token id="14" string="surgery" />
          </tokens>
        </chunking>
        <chunking id="2" string="anyone" type="NP">
          <tokens>
            <token id="7" string="anyone" />
          </tokens>
        </chunking>
        <chunking id="3" string="responded as well as anyone could respond to that kind of surgery" type="VP">
          <tokens>
            <token id="3" string="responded" />
            <token id="4" string="as" />
            <token id="5" string="well" />
            <token id="6" string="as" />
            <token id="7" string="anyone" />
            <token id="8" string="could" />
            <token id="9" string="respond" />
            <token id="10" string="to" />
            <token id="11" string="that" />
            <token id="12" string="kind" />
            <token id="13" string="of" />
            <token id="14" string="surgery" />
          </tokens>
        </chunking>
        <chunking id="4" string="that kind of surgery" type="NP">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="kind" />
            <token id="13" string="of" />
            <token id="14" string="surgery" />
          </tokens>
        </chunking>
        <chunking id="5" string="as anyone could respond to that kind of surgery" type="SBAR">
          <tokens>
            <token id="6" string="as" />
            <token id="7" string="anyone" />
            <token id="8" string="could" />
            <token id="9" string="respond" />
            <token id="10" string="to" />
            <token id="11" string="that" />
            <token id="12" string="kind" />
            <token id="13" string="of" />
            <token id="14" string="surgery" />
          </tokens>
        </chunking>
        <chunking id="6" string="respond to that kind of surgery" type="VP">
          <tokens>
            <token id="9" string="respond" />
            <token id="10" string="to" />
            <token id="11" string="that" />
            <token id="12" string="kind" />
            <token id="13" string="of" />
            <token id="14" string="surgery" />
          </tokens>
        </chunking>
        <chunking id="7" string="that kind" type="NP">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="kind" />
          </tokens>
        </chunking>
        <chunking id="8" string="She" type="NP">
          <tokens>
            <token id="2" string="She" />
          </tokens>
        </chunking>
        <chunking id="9" string="surgery" type="NP">
          <tokens>
            <token id="14" string="surgery" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">responded</governor>
          <dependent id="2">She</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">responded</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">responded</governor>
          <dependent id="4">as</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="4">as</governor>
          <dependent id="5">well</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">respond</governor>
          <dependent id="6">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">respond</governor>
          <dependent id="7">anyone</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">respond</governor>
          <dependent id="8">could</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">responded</governor>
          <dependent id="9">respond</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">kind</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">kind</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">respond</governor>
          <dependent id="12">kind</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">surgery</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">kind</governor>
          <dependent id="14">surgery</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>He said she woke up early Wednesday complaining about a sudden pain in her back, and in a matter of seconds went into a full cardiac arrest that was caused by a ruptured aorta.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="woke" lemma="wake" stem="woke" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="up" lemma="up" stem="up" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="early" lemma="early" stem="earli" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="7" string="Wednesday" lemma="Wednesday" stem="wednesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="8" string="complaining" lemma="complain" stem="complain" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="sudden" lemma="sudden" stem="sudden" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="pain" lemma="pain" stem="pain" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="back" lemma="back" stem="back" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="matter" lemma="matter" stem="matter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="seconds" lemma="seconds" stem="second" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="23" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="full" lemma="full" stem="full" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="cardiac" lemma="cardiac" stem="cardiac" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="arrest" lemma="arrest" stem="arrest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="caused" lemma="cause" stem="caus" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="ruptured" lemma="rupture" stem="ruptur" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="aorta" lemma="aorta" stem="aorta" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD said) (SBAR (SBAR (S (NP (PRP she)) (VP (VBD woke) (ADVP (RB up)) (NP-TMP (JJ early) (NNP Wednesday)) (S (VP (VBG complaining) (PP (IN about) (NP (NP (DT a) (JJ sudden) (NN pain)) (PP (IN in) (NP (PRP$ her) (NN back)))))))))) (, ,) (CC and) (SBAR (IN in) (S (NP (NP (DT a) (NN matter)) (PP (IN of) (NP (NNS seconds)))) (VP (VBD went) (PP (IN into) (NP (NP (DT a) (JJ full) (JJ cardiac) (NN arrest)) (SBAR (WHNP (WDT that)) (S (VP (VBD was) (VP (VBN caused) (PP (IN by) (NP (DT a) (VBN ruptured) (NN aorta)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="woke up early Wednesday complaining about a sudden pain in her back" type="VP">
          <tokens>
            <token id="4" string="woke" />
            <token id="5" string="up" />
            <token id="6" string="early" />
            <token id="7" string="Wednesday" />
            <token id="8" string="complaining" />
            <token id="9" string="about" />
            <token id="10" string="a" />
            <token id="11" string="sudden" />
            <token id="12" string="pain" />
            <token id="13" string="in" />
            <token id="14" string="her" />
            <token id="15" string="back" />
          </tokens>
        </chunking>
        <chunking id="2" string="in a matter of seconds went into a full cardiac arrest that was caused by a ruptured aorta" type="SBAR">
          <tokens>
            <token id="18" string="in" />
            <token id="19" string="a" />
            <token id="20" string="matter" />
            <token id="21" string="of" />
            <token id="22" string="seconds" />
            <token id="23" string="went" />
            <token id="24" string="into" />
            <token id="25" string="a" />
            <token id="26" string="full" />
            <token id="27" string="cardiac" />
            <token id="28" string="arrest" />
            <token id="29" string="that" />
            <token id="30" string="was" />
            <token id="31" string="caused" />
            <token id="32" string="by" />
            <token id="33" string="a" />
            <token id="34" string="ruptured" />
            <token id="35" string="aorta" />
          </tokens>
        </chunking>
        <chunking id="3" string="a full cardiac arrest that was caused by a ruptured aorta" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="full" />
            <token id="27" string="cardiac" />
            <token id="28" string="arrest" />
            <token id="29" string="that" />
            <token id="30" string="was" />
            <token id="31" string="caused" />
            <token id="32" string="by" />
            <token id="33" string="a" />
            <token id="34" string="ruptured" />
            <token id="35" string="aorta" />
          </tokens>
        </chunking>
        <chunking id="4" string="complaining about a sudden pain in her back" type="VP">
          <tokens>
            <token id="8" string="complaining" />
            <token id="9" string="about" />
            <token id="10" string="a" />
            <token id="11" string="sudden" />
            <token id="12" string="pain" />
            <token id="13" string="in" />
            <token id="14" string="her" />
            <token id="15" string="back" />
          </tokens>
        </chunking>
        <chunking id="5" string="she" type="NP">
          <tokens>
            <token id="3" string="she" />
          </tokens>
        </chunking>
        <chunking id="6" string="that was caused by a ruptured aorta" type="SBAR">
          <tokens>
            <token id="29" string="that" />
            <token id="30" string="was" />
            <token id="31" string="caused" />
            <token id="32" string="by" />
            <token id="33" string="a" />
            <token id="34" string="ruptured" />
            <token id="35" string="aorta" />
          </tokens>
        </chunking>
        <chunking id="7" string="went into a full cardiac arrest that was caused by a ruptured aorta" type="VP">
          <tokens>
            <token id="23" string="went" />
            <token id="24" string="into" />
            <token id="25" string="a" />
            <token id="26" string="full" />
            <token id="27" string="cardiac" />
            <token id="28" string="arrest" />
            <token id="29" string="that" />
            <token id="30" string="was" />
            <token id="31" string="caused" />
            <token id="32" string="by" />
            <token id="33" string="a" />
            <token id="34" string="ruptured" />
            <token id="35" string="aorta" />
          </tokens>
        </chunking>
        <chunking id="8" string="she woke up early Wednesday complaining about a sudden pain in her back" type="SBAR">
          <tokens>
            <token id="3" string="she" />
            <token id="4" string="woke" />
            <token id="5" string="up" />
            <token id="6" string="early" />
            <token id="7" string="Wednesday" />
            <token id="8" string="complaining" />
            <token id="9" string="about" />
            <token id="10" string="a" />
            <token id="11" string="sudden" />
            <token id="12" string="pain" />
            <token id="13" string="in" />
            <token id="14" string="her" />
            <token id="15" string="back" />
          </tokens>
        </chunking>
        <chunking id="9" string="she woke up early Wednesday complaining about a sudden pain in her back , and in a matter of seconds went into a full cardiac arrest that was caused by a ruptured aorta" type="SBAR">
          <tokens>
            <token id="3" string="she" />
            <token id="4" string="woke" />
            <token id="5" string="up" />
            <token id="6" string="early" />
            <token id="7" string="Wednesday" />
            <token id="8" string="complaining" />
            <token id="9" string="about" />
            <token id="10" string="a" />
            <token id="11" string="sudden" />
            <token id="12" string="pain" />
            <token id="13" string="in" />
            <token id="14" string="her" />
            <token id="15" string="back" />
            <token id="16" string="," />
            <token id="17" string="and" />
            <token id="18" string="in" />
            <token id="19" string="a" />
            <token id="20" string="matter" />
            <token id="21" string="of" />
            <token id="22" string="seconds" />
            <token id="23" string="went" />
            <token id="24" string="into" />
            <token id="25" string="a" />
            <token id="26" string="full" />
            <token id="27" string="cardiac" />
            <token id="28" string="arrest" />
            <token id="29" string="that" />
            <token id="30" string="was" />
            <token id="31" string="caused" />
            <token id="32" string="by" />
            <token id="33" string="a" />
            <token id="34" string="ruptured" />
            <token id="35" string="aorta" />
          </tokens>
        </chunking>
        <chunking id="10" string="a sudden pain" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="sudden" />
            <token id="12" string="pain" />
          </tokens>
        </chunking>
        <chunking id="11" string="caused by a ruptured aorta" type="VP">
          <tokens>
            <token id="31" string="caused" />
            <token id="32" string="by" />
            <token id="33" string="a" />
            <token id="34" string="ruptured" />
            <token id="35" string="aorta" />
          </tokens>
        </chunking>
        <chunking id="12" string="seconds" type="NP">
          <tokens>
            <token id="22" string="seconds" />
          </tokens>
        </chunking>
        <chunking id="13" string="a ruptured aorta" type="NP">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="ruptured" />
            <token id="35" string="aorta" />
          </tokens>
        </chunking>
        <chunking id="14" string="said she woke up early Wednesday complaining about a sudden pain in her back , and in a matter of seconds went into a full cardiac arrest that was caused by a ruptured aorta" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="she" />
            <token id="4" string="woke" />
            <token id="5" string="up" />
            <token id="6" string="early" />
            <token id="7" string="Wednesday" />
            <token id="8" string="complaining" />
            <token id="9" string="about" />
            <token id="10" string="a" />
            <token id="11" string="sudden" />
            <token id="12" string="pain" />
            <token id="13" string="in" />
            <token id="14" string="her" />
            <token id="15" string="back" />
            <token id="16" string="," />
            <token id="17" string="and" />
            <token id="18" string="in" />
            <token id="19" string="a" />
            <token id="20" string="matter" />
            <token id="21" string="of" />
            <token id="22" string="seconds" />
            <token id="23" string="went" />
            <token id="24" string="into" />
            <token id="25" string="a" />
            <token id="26" string="full" />
            <token id="27" string="cardiac" />
            <token id="28" string="arrest" />
            <token id="29" string="that" />
            <token id="30" string="was" />
            <token id="31" string="caused" />
            <token id="32" string="by" />
            <token id="33" string="a" />
            <token id="34" string="ruptured" />
            <token id="35" string="aorta" />
          </tokens>
        </chunking>
        <chunking id="15" string="a matter of seconds" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="matter" />
            <token id="21" string="of" />
            <token id="22" string="seconds" />
          </tokens>
        </chunking>
        <chunking id="16" string="a sudden pain in her back" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="sudden" />
            <token id="12" string="pain" />
            <token id="13" string="in" />
            <token id="14" string="her" />
            <token id="15" string="back" />
          </tokens>
        </chunking>
        <chunking id="17" string="her back" type="NP">
          <tokens>
            <token id="14" string="her" />
            <token id="15" string="back" />
          </tokens>
        </chunking>
        <chunking id="18" string="a matter" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="matter" />
          </tokens>
        </chunking>
        <chunking id="19" string="was caused by a ruptured aorta" type="VP">
          <tokens>
            <token id="30" string="was" />
            <token id="31" string="caused" />
            <token id="32" string="by" />
            <token id="33" string="a" />
            <token id="34" string="ruptured" />
            <token id="35" string="aorta" />
          </tokens>
        </chunking>
        <chunking id="20" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="21" string="a full cardiac arrest" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="full" />
            <token id="27" string="cardiac" />
            <token id="28" string="arrest" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">woke</governor>
          <dependent id="3">she</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">said</governor>
          <dependent id="4">woke</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">woke</governor>
          <dependent id="5">up</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">Wednesday</governor>
          <dependent id="6">early</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="4">woke</governor>
          <dependent id="7">Wednesday</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">woke</governor>
          <dependent id="8">complaining</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">pain</governor>
          <dependent id="9">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">pain</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">pain</governor>
          <dependent id="11">sudden</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">complaining</governor>
          <dependent id="12">pain</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">back</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">back</governor>
          <dependent id="14">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">pain</governor>
          <dependent id="15">back</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">woke</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">went</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">matter</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">went</governor>
          <dependent id="20">matter</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">seconds</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">matter</governor>
          <dependent id="22">seconds</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">woke</governor>
          <dependent id="23">went</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">arrest</governor>
          <dependent id="24">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">arrest</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">arrest</governor>
          <dependent id="26">full</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">arrest</governor>
          <dependent id="27">cardiac</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">went</governor>
          <dependent id="28">arrest</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="31">caused</governor>
          <dependent id="29">that</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="31">caused</governor>
          <dependent id="30">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="28">arrest</governor>
          <dependent id="31">caused</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">aorta</governor>
          <dependent id="32">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">aorta</governor>
          <dependent id="33">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">aorta</governor>
          <dependent id="34">ruptured</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">caused</governor>
          <dependent id="35">aorta</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="seconds" type="DURATION" score="0.0">
          <tokens>
            <token id="22" string="seconds" />
          </tokens>
        </entity>
        <entity id="2" string="early Wednesday" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="early" />
            <token id="7" string="Wednesday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>Miss Ball and her late former husband, Desi Arnaz, starred in ``I Love Lucy&amp;apost;&amp;apost; from 1951 to 1957.</content>
      <tokens>
        <token id="1" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="5" string="late" lemma="late" stem="late" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="husband" lemma="husband" stem="husband" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Desi" lemma="Desi" stem="desi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="10" string="Arnaz" lemma="Arnaz" stem="arnaz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="starred" lemma="star" stem="star" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="Love" lemma="Love" stem="love" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="1951" lemma="1951" stem="1951" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="22" string="1957" lemma="1957" stem="1957" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NNP Miss) (NNP Ball)) (CC and) (NP (PRP$ her) (JJ late) (JJ former) (NN husband))) (, ,) (NP (NNP Desi) (NNP Arnaz)) (, ,)) (VP (VBD starred) (PP (IN in) (`` ``) (NP (NP (PRP I)) (NP (NNP Love) (NNP Lucy))) ('' '')) (PP (IN from) (NP (CD 1951) (TO to) (CD 1957)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="1951 to 1957" type="NP">
          <tokens>
            <token id="20" string="1951" />
            <token id="21" string="to" />
            <token id="22" string="1957" />
          </tokens>
        </chunking>
        <chunking id="2" string="her late former husband" type="NP">
          <tokens>
            <token id="4" string="her" />
            <token id="5" string="late" />
            <token id="6" string="former" />
            <token id="7" string="husband" />
          </tokens>
        </chunking>
        <chunking id="3" string="starred in `` I Love Lucy '' from 1951 to 1957" type="VP">
          <tokens>
            <token id="12" string="starred" />
            <token id="13" string="in" />
            <token id="14" string="``" />
            <token id="15" string="I" />
            <token id="16" string="Love" />
            <token id="17" string="Lucy" />
            <token id="18" string="''" />
            <token id="19" string="from" />
            <token id="20" string="1951" />
            <token id="21" string="to" />
            <token id="22" string="1957" />
          </tokens>
        </chunking>
        <chunking id="4" string="Miss Ball and her late former husband , Desi Arnaz ," type="NP">
          <tokens>
            <token id="1" string="Miss" />
            <token id="2" string="Ball" />
            <token id="3" string="and" />
            <token id="4" string="her" />
            <token id="5" string="late" />
            <token id="6" string="former" />
            <token id="7" string="husband" />
            <token id="8" string="," />
            <token id="9" string="Desi" />
            <token id="10" string="Arnaz" />
            <token id="11" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="Desi Arnaz" type="NP">
          <tokens>
            <token id="9" string="Desi" />
            <token id="10" string="Arnaz" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="15" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="Miss Ball and her late former husband" type="NP">
          <tokens>
            <token id="1" string="Miss" />
            <token id="2" string="Ball" />
            <token id="3" string="and" />
            <token id="4" string="her" />
            <token id="5" string="late" />
            <token id="6" string="former" />
            <token id="7" string="husband" />
          </tokens>
        </chunking>
        <chunking id="8" string="I Love Lucy" type="NP">
          <tokens>
            <token id="15" string="I" />
            <token id="16" string="Love" />
            <token id="17" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="9" string="Miss Ball" type="NP">
          <tokens>
            <token id="1" string="Miss" />
            <token id="2" string="Ball" />
          </tokens>
        </chunking>
        <chunking id="10" string="Love Lucy" type="NP">
          <tokens>
            <token id="16" string="Love" />
            <token id="17" string="Lucy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Ball</governor>
          <dependent id="1">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">starred</governor>
          <dependent id="2">Ball</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">Ball</governor>
          <dependent id="3">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">husband</governor>
          <dependent id="4">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">husband</governor>
          <dependent id="5">late</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">husband</governor>
          <dependent id="6">former</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">Ball</governor>
          <dependent id="7">husband</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Arnaz</governor>
          <dependent id="9">Desi</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Ball</governor>
          <dependent id="10">Arnaz</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">starred</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">I</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">starred</governor>
          <dependent id="15">I</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Lucy</governor>
          <dependent id="16">Love</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="15">I</governor>
          <dependent id="17">Lucy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">1957</governor>
          <dependent id="19">from</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="22">1957</governor>
          <dependent id="20">1951</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="22">1957</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">starred</governor>
          <dependent id="22">1957</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Ball" />
          </tokens>
        </entity>
        <entity id="2" string="1951 to 1957" type="DATE" score="0.0">
          <tokens>
            <token id="20" string="1951" />
            <token id="21" string="to" />
            <token id="22" string="1957" />
          </tokens>
        </entity>
        <entity id="3" string="Desi Arnaz" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Desi" />
            <token id="10" string="Arnaz" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>In the ground-breaking show, still seen in syndication worldwide, the late Vivian Vance and William Frawley played their neighbors, Fred and Ethel Mertz.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="ground-breaking" lemma="ground-breaking" stem="ground-break" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="show" lemma="show" stem="show" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="seen" lemma="see" stem="seen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="syndication" lemma="syndication" stem="syndic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="worldwide" lemma="worldwide" stem="worldwid" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="late" lemma="late" stem="late" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="Vivian" lemma="Vivian" stem="vivian" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="15" string="Vance" lemma="Vance" stem="vanc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="William" lemma="William" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="18" string="Frawley" lemma="Frawley" stem="frawlei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="19" string="played" lemma="play" stem="plai" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="neighbors" lemma="neighbor" stem="neighbor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Fred" lemma="Fred" stem="fred" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Ethel" lemma="Ethel" stem="ethel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="26" string="Mertz" lemma="Mertz" stem="mertz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NP (DT the) (JJ ground-breaking) (NN show)) (, ,) (VP (ADVP (RB still)) (VBN seen) (PP (IN in) (NP (NN syndication)) (ADVP (RB worldwide)))))) (, ,) (NP (DT the) (JJ late) (NNP Vivian) (NNP Vance) (CC and) (NNP William) (NNP Frawley)) (VP (VBD played) (NP (NP (PRP$ their) (NNS neighbors)) (, ,) (NP (NNP Fred)) (CC and) (NP (NNP Ethel) (NNP Mertz)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="syndication" type="NP">
          <tokens>
            <token id="9" string="syndication" />
          </tokens>
        </chunking>
        <chunking id="2" string="still seen in syndication worldwide" type="VP">
          <tokens>
            <token id="6" string="still" />
            <token id="7" string="seen" />
            <token id="8" string="in" />
            <token id="9" string="syndication" />
            <token id="10" string="worldwide" />
          </tokens>
        </chunking>
        <chunking id="3" string="played their neighbors , Fred and Ethel Mertz" type="VP">
          <tokens>
            <token id="19" string="played" />
            <token id="20" string="their" />
            <token id="21" string="neighbors" />
            <token id="22" string="," />
            <token id="23" string="Fred" />
            <token id="24" string="and" />
            <token id="25" string="Ethel" />
            <token id="26" string="Mertz" />
          </tokens>
        </chunking>
        <chunking id="4" string="their neighbors , Fred and Ethel Mertz" type="NP">
          <tokens>
            <token id="20" string="their" />
            <token id="21" string="neighbors" />
            <token id="22" string="," />
            <token id="23" string="Fred" />
            <token id="24" string="and" />
            <token id="25" string="Ethel" />
            <token id="26" string="Mertz" />
          </tokens>
        </chunking>
        <chunking id="5" string="Ethel Mertz" type="NP">
          <tokens>
            <token id="25" string="Ethel" />
            <token id="26" string="Mertz" />
          </tokens>
        </chunking>
        <chunking id="6" string="the late Vivian Vance and William Frawley" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="late" />
            <token id="14" string="Vivian" />
            <token id="15" string="Vance" />
            <token id="16" string="and" />
            <token id="17" string="William" />
            <token id="18" string="Frawley" />
          </tokens>
        </chunking>
        <chunking id="7" string="their neighbors" type="NP">
          <tokens>
            <token id="20" string="their" />
            <token id="21" string="neighbors" />
          </tokens>
        </chunking>
        <chunking id="8" string="Fred" type="NP">
          <tokens>
            <token id="23" string="Fred" />
          </tokens>
        </chunking>
        <chunking id="9" string="the ground-breaking show , still seen in syndication worldwide" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="ground-breaking" />
            <token id="4" string="show" />
            <token id="5" string="," />
            <token id="6" string="still" />
            <token id="7" string="seen" />
            <token id="8" string="in" />
            <token id="9" string="syndication" />
            <token id="10" string="worldwide" />
          </tokens>
        </chunking>
        <chunking id="10" string="the ground-breaking show" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="ground-breaking" />
            <token id="4" string="show" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">show</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">show</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">show</governor>
          <dependent id="3">ground-breaking</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">played</governor>
          <dependent id="4">show</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">seen</governor>
          <dependent id="6">still</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="4">show</governor>
          <dependent id="7">seen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">syndication</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">seen</governor>
          <dependent id="9">syndication</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">syndication</governor>
          <dependent id="10">worldwide</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">Vance</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">Vance</governor>
          <dependent id="13">late</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Vance</governor>
          <dependent id="14">Vivian</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">played</governor>
          <dependent id="15">Vance</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">Vance</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Frawley</governor>
          <dependent id="17">William</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">Vance</governor>
          <dependent id="18">Frawley</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">played</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">neighbors</governor>
          <dependent id="20">their</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">played</governor>
          <dependent id="21">neighbors</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">neighbors</governor>
          <dependent id="23">Fred</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">neighbors</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Mertz</governor>
          <dependent id="25">Ethel</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">neighbors</governor>
          <dependent id="26">Mertz</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="William Frawley" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="William" />
            <token id="18" string="Frawley" />
          </tokens>
        </entity>
        <entity id="2" string="Ethel Mertz" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Ethel" />
            <token id="26" string="Mertz" />
          </tokens>
        </entity>
        <entity id="3" string="Fred" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Fred" />
          </tokens>
        </entity>
        <entity id="4" string="Vivian Vance" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Vivian" />
            <token id="15" string="Vance" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>``Probably a lot of what she did rubbed off on what I do,&amp;apost;&amp;apost; said actress-comedian Jane Curtin, star of the sitcom ``Kate and Allie.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Probably" lemma="probably" stem="probabl" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="rubbed" lemma="rub" stem="rub" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="off" lemma="off" stem="off" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="actress-comedian" lemma="actress-comedian" stem="actress-comedian" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="Jane" lemma="Jane" stem="jane" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="20" string="Curtin" lemma="Curtin" stem="curtin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="star" lemma="star" stem="star" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="sitcom" lemma="sitcom" stem="sitcom" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="Kate" lemma="Kate" stem="kate" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="28" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="Allie" lemma="Allie" stem="allie" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (FRAG (ADVP (RB Probably)) (NP (NP (DT a) (NN lot)) (PP (IN of) (SBAR (WHNP (WP what)) (S (NP (PRP she)) (VP (VBD did) (VP (VBN rubbed) (PRT (RP off)) (PP (IN on) (SBAR (WHNP (WP what)) (S (NP (PRP I)) (VP (VBP do)))))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (JJ actress-comedian) (NNP Jane) (NNP Curtin)) (, ,) (NP (NP (NN star)) (PP (IN of) (NP (NP (DT the) (NN sitcom)) (`` ``) (NP (NNP Kate) (CC and) (NNP Allie)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="what I do" type="SBAR">
          <tokens>
            <token id="12" string="what" />
            <token id="13" string="I" />
            <token id="14" string="do" />
          </tokens>
        </chunking>
        <chunking id="2" string="rubbed off on what I do" type="VP">
          <tokens>
            <token id="9" string="rubbed" />
            <token id="10" string="off" />
            <token id="11" string="on" />
            <token id="12" string="what" />
            <token id="13" string="I" />
            <token id="14" string="do" />
          </tokens>
        </chunking>
        <chunking id="3" string="a lot of what she did rubbed off on what I do" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="lot" />
            <token id="5" string="of" />
            <token id="6" string="what" />
            <token id="7" string="she" />
            <token id="8" string="did" />
            <token id="9" string="rubbed" />
            <token id="10" string="off" />
            <token id="11" string="on" />
            <token id="12" string="what" />
            <token id="13" string="I" />
            <token id="14" string="do" />
          </tokens>
        </chunking>
        <chunking id="4" string="star" type="NP">
          <tokens>
            <token id="22" string="star" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="13" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="do" type="VP">
          <tokens>
            <token id="14" string="do" />
          </tokens>
        </chunking>
        <chunking id="7" string="the sitcom `` Kate and Allie" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="sitcom" />
            <token id="26" string="``" />
            <token id="27" string="Kate" />
            <token id="28" string="and" />
            <token id="29" string="Allie" />
          </tokens>
        </chunking>
        <chunking id="8" string="did rubbed off on what I do" type="VP">
          <tokens>
            <token id="8" string="did" />
            <token id="9" string="rubbed" />
            <token id="10" string="off" />
            <token id="11" string="on" />
            <token id="12" string="what" />
            <token id="13" string="I" />
            <token id="14" string="do" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="7" string="she" />
          </tokens>
        </chunking>
        <chunking id="10" string="a lot" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="lot" />
          </tokens>
        </chunking>
        <chunking id="11" string="star of the sitcom `` Kate and Allie" type="NP">
          <tokens>
            <token id="22" string="star" />
            <token id="23" string="of" />
            <token id="24" string="the" />
            <token id="25" string="sitcom" />
            <token id="26" string="``" />
            <token id="27" string="Kate" />
            <token id="28" string="and" />
            <token id="29" string="Allie" />
          </tokens>
        </chunking>
        <chunking id="12" string="what she did rubbed off on what I do" type="SBAR">
          <tokens>
            <token id="6" string="what" />
            <token id="7" string="she" />
            <token id="8" string="did" />
            <token id="9" string="rubbed" />
            <token id="10" string="off" />
            <token id="11" string="on" />
            <token id="12" string="what" />
            <token id="13" string="I" />
            <token id="14" string="do" />
          </tokens>
        </chunking>
        <chunking id="13" string="actress-comedian Jane Curtin" type="NP">
          <tokens>
            <token id="18" string="actress-comedian" />
            <token id="19" string="Jane" />
            <token id="20" string="Curtin" />
          </tokens>
        </chunking>
        <chunking id="14" string="the sitcom" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="sitcom" />
          </tokens>
        </chunking>
        <chunking id="15" string="said" type="VP">
          <tokens>
            <token id="17" string="said" />
          </tokens>
        </chunking>
        <chunking id="16" string="Kate and Allie" type="NP">
          <tokens>
            <token id="27" string="Kate" />
            <token id="28" string="and" />
            <token id="29" string="Allie" />
          </tokens>
        </chunking>
        <chunking id="17" string="actress-comedian Jane Curtin , star of the sitcom `` Kate and Allie" type="NP">
          <tokens>
            <token id="18" string="actress-comedian" />
            <token id="19" string="Jane" />
            <token id="20" string="Curtin" />
            <token id="21" string="," />
            <token id="22" string="star" />
            <token id="23" string="of" />
            <token id="24" string="the" />
            <token id="25" string="sitcom" />
            <token id="26" string="``" />
            <token id="27" string="Kate" />
            <token id="28" string="and" />
            <token id="29" string="Allie" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="4">lot</governor>
          <dependent id="2">Probably</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">lot</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">said</governor>
          <dependent id="4">lot</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">rubbed</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">rubbed</governor>
          <dependent id="6">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">rubbed</governor>
          <dependent id="7">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">rubbed</governor>
          <dependent id="8">did</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="4">lot</governor>
          <dependent id="9">rubbed</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="9">rubbed</governor>
          <dependent id="10">off</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">do</governor>
          <dependent id="11">on</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">do</governor>
          <dependent id="12">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">do</governor>
          <dependent id="13">I</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">rubbed</governor>
          <dependent id="14">do</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">said</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">Curtin</governor>
          <dependent id="18">actress-comedian</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Curtin</governor>
          <dependent id="19">Jane</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">said</governor>
          <dependent id="20">Curtin</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="20">Curtin</governor>
          <dependent id="22">star</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">sitcom</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">sitcom</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">star</governor>
          <dependent id="25">sitcom</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="25">sitcom</governor>
          <dependent id="27">Kate</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="27">Kate</governor>
          <dependent id="28">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="27">Kate</governor>
          <dependent id="29">Allie</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Kate" type="PERSON" score="0.0">
          <tokens>
            <token id="27" string="Kate" />
          </tokens>
        </entity>
        <entity id="2" string="Jane Curtin" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Jane" />
            <token id="20" string="Curtin" />
          </tokens>
        </entity>
        <entity id="3" string="Allie" type="PERSON" score="0.0">
          <tokens>
            <token id="29" string="Allie" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>``But it couldn&amp;apost;t be helped, because I memorized her shows.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="helped" lemma="help" stem="help" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="memorized" lemma="memorize" stem="memor" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="13" string="shows" lemma="show" stem="show" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (CC But) (NP (PRP it)) (VP (MD could) (RB n't) (VP (VB be) (VP (VBN helped) (, ,) (SBAR (IN because) (S (NP (PRP I)) (VP (VBD memorized) (NP (PRP$ her) (NNS shows)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="her shows" type="NP">
          <tokens>
            <token id="12" string="her" />
            <token id="13" string="shows" />
          </tokens>
        </chunking>
        <chunking id="2" string="be helped , because I memorized her shows" type="VP">
          <tokens>
            <token id="6" string="be" />
            <token id="7" string="helped" />
            <token id="8" string="," />
            <token id="9" string="because" />
            <token id="10" string="I" />
            <token id="11" string="memorized" />
            <token id="12" string="her" />
            <token id="13" string="shows" />
          </tokens>
        </chunking>
        <chunking id="3" string="could n't be helped , because I memorized her shows" type="VP">
          <tokens>
            <token id="4" string="could" />
            <token id="5" string="n't" />
            <token id="6" string="be" />
            <token id="7" string="helped" />
            <token id="8" string="," />
            <token id="9" string="because" />
            <token id="10" string="I" />
            <token id="11" string="memorized" />
            <token id="12" string="her" />
            <token id="13" string="shows" />
          </tokens>
        </chunking>
        <chunking id="4" string="helped , because I memorized her shows" type="VP">
          <tokens>
            <token id="7" string="helped" />
            <token id="8" string="," />
            <token id="9" string="because" />
            <token id="10" string="I" />
            <token id="11" string="memorized" />
            <token id="12" string="her" />
            <token id="13" string="shows" />
          </tokens>
        </chunking>
        <chunking id="5" string="because I memorized her shows" type="SBAR">
          <tokens>
            <token id="9" string="because" />
            <token id="10" string="I" />
            <token id="11" string="memorized" />
            <token id="12" string="her" />
            <token id="13" string="shows" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="10" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="3" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="memorized her shows" type="VP">
          <tokens>
            <token id="11" string="memorized" />
            <token id="12" string="her" />
            <token id="13" string="shows" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="7">helped</governor>
          <dependent id="2">But</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">helped</governor>
          <dependent id="3">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">helped</governor>
          <dependent id="4">could</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">helped</governor>
          <dependent id="5">n't</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">helped</governor>
          <dependent id="6">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">helped</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">memorized</governor>
          <dependent id="9">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">memorized</governor>
          <dependent id="10">I</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">helped</governor>
          <dependent id="11">memorized</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">shows</governor>
          <dependent id="12">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">memorized</governor>
          <dependent id="13">shows</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>The show, one of the most popular in television history, was distinguished by Miss Ball&amp;apost;s faultless timing, rubber-faced expressions, wide-mouthed wails and extravagant pratfalls.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="show" lemma="show" stem="show" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="popular" lemma="popular" stem="popular" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="history" lemma="history" stem="histori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="distinguished" lemma="distinguish" stem="distinguish" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="17" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="18" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="19" string="faultless" lemma="faultless" stem="faultless" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="timing" lemma="timing" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="rubber-faced" lemma="rubber-faced" stem="rubber-fac" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="expressions" lemma="expression" stem="express" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="wide-mouthed" lemma="wide-mouthed" stem="wide-mouth" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="wails" lemma="wail" stem="wail" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="extravagant" lemma="extravagant" stem="extravag" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="pratfalls" lemma="pratfall" stem="pratfal" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN show)) (, ,) (NP (NP (CD one)) (PP (IN of) (NP (DT the) (ADJP (RBS most) (JJ popular) (PP (IN in) (NP (NN television)))) (NN history)))) (, ,)) (VP (VBD was) (VP (VBN distinguished) (PP (IN by) (NP (NP (NP (NNP Miss) (NNP Ball) (POS 's)) (JJ faultless) (NN timing)) (, ,) (NP (NP (JJ rubber-faced) (NNS expressions)) (, ,) (NP (JJ wide-mouthed) (NNS wails)) (CC and) (NP (JJ extravagant) (NNS pratfalls))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="one" type="NP">
          <tokens>
            <token id="4" string="one" />
          </tokens>
        </chunking>
        <chunking id="2" string="one of the most popular in television history" type="NP">
          <tokens>
            <token id="4" string="one" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="most" />
            <token id="8" string="popular" />
            <token id="9" string="in" />
            <token id="10" string="television" />
            <token id="11" string="history" />
          </tokens>
        </chunking>
        <chunking id="3" string="television" type="NP">
          <tokens>
            <token id="10" string="television" />
          </tokens>
        </chunking>
        <chunking id="4" string="Miss Ball 's faultless timing" type="NP">
          <tokens>
            <token id="16" string="Miss" />
            <token id="17" string="Ball" />
            <token id="18" string="'s" />
            <token id="19" string="faultless" />
            <token id="20" string="timing" />
          </tokens>
        </chunking>
        <chunking id="5" string="rubber-faced expressions" type="NP">
          <tokens>
            <token id="22" string="rubber-faced" />
            <token id="23" string="expressions" />
          </tokens>
        </chunking>
        <chunking id="6" string="Miss Ball 's" type="NP">
          <tokens>
            <token id="16" string="Miss" />
            <token id="17" string="Ball" />
            <token id="18" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="extravagant pratfalls" type="NP">
          <tokens>
            <token id="28" string="extravagant" />
            <token id="29" string="pratfalls" />
          </tokens>
        </chunking>
        <chunking id="8" string="most popular in television" type="ADJP">
          <tokens>
            <token id="7" string="most" />
            <token id="8" string="popular" />
            <token id="9" string="in" />
            <token id="10" string="television" />
          </tokens>
        </chunking>
        <chunking id="9" string="distinguished by Miss Ball 's faultless timing , rubber-faced expressions , wide-mouthed wails and extravagant pratfalls" type="VP">
          <tokens>
            <token id="14" string="distinguished" />
            <token id="15" string="by" />
            <token id="16" string="Miss" />
            <token id="17" string="Ball" />
            <token id="18" string="'s" />
            <token id="19" string="faultless" />
            <token id="20" string="timing" />
            <token id="21" string="," />
            <token id="22" string="rubber-faced" />
            <token id="23" string="expressions" />
            <token id="24" string="," />
            <token id="25" string="wide-mouthed" />
            <token id="26" string="wails" />
            <token id="27" string="and" />
            <token id="28" string="extravagant" />
            <token id="29" string="pratfalls" />
          </tokens>
        </chunking>
        <chunking id="10" string="rubber-faced expressions , wide-mouthed wails and extravagant pratfalls" type="NP">
          <tokens>
            <token id="22" string="rubber-faced" />
            <token id="23" string="expressions" />
            <token id="24" string="," />
            <token id="25" string="wide-mouthed" />
            <token id="26" string="wails" />
            <token id="27" string="and" />
            <token id="28" string="extravagant" />
            <token id="29" string="pratfalls" />
          </tokens>
        </chunking>
        <chunking id="11" string="The show , one of the most popular in television history ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="show" />
            <token id="3" string="," />
            <token id="4" string="one" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="most" />
            <token id="8" string="popular" />
            <token id="9" string="in" />
            <token id="10" string="television" />
            <token id="11" string="history" />
            <token id="12" string="," />
          </tokens>
        </chunking>
        <chunking id="12" string="the most popular in television history" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="most" />
            <token id="8" string="popular" />
            <token id="9" string="in" />
            <token id="10" string="television" />
            <token id="11" string="history" />
          </tokens>
        </chunking>
        <chunking id="13" string="The show" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="show" />
          </tokens>
        </chunking>
        <chunking id="14" string="Miss Ball 's faultless timing , rubber-faced expressions , wide-mouthed wails and extravagant pratfalls" type="NP">
          <tokens>
            <token id="16" string="Miss" />
            <token id="17" string="Ball" />
            <token id="18" string="'s" />
            <token id="19" string="faultless" />
            <token id="20" string="timing" />
            <token id="21" string="," />
            <token id="22" string="rubber-faced" />
            <token id="23" string="expressions" />
            <token id="24" string="," />
            <token id="25" string="wide-mouthed" />
            <token id="26" string="wails" />
            <token id="27" string="and" />
            <token id="28" string="extravagant" />
            <token id="29" string="pratfalls" />
          </tokens>
        </chunking>
        <chunking id="15" string="was distinguished by Miss Ball 's faultless timing , rubber-faced expressions , wide-mouthed wails and extravagant pratfalls" type="VP">
          <tokens>
            <token id="13" string="was" />
            <token id="14" string="distinguished" />
            <token id="15" string="by" />
            <token id="16" string="Miss" />
            <token id="17" string="Ball" />
            <token id="18" string="'s" />
            <token id="19" string="faultless" />
            <token id="20" string="timing" />
            <token id="21" string="," />
            <token id="22" string="rubber-faced" />
            <token id="23" string="expressions" />
            <token id="24" string="," />
            <token id="25" string="wide-mouthed" />
            <token id="26" string="wails" />
            <token id="27" string="and" />
            <token id="28" string="extravagant" />
            <token id="29" string="pratfalls" />
          </tokens>
        </chunking>
        <chunking id="16" string="wide-mouthed wails" type="NP">
          <tokens>
            <token id="25" string="wide-mouthed" />
            <token id="26" string="wails" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">show</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="14">distinguished</governor>
          <dependent id="2">show</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">show</governor>
          <dependent id="4">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">history</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">history</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">popular</governor>
          <dependent id="7">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">history</governor>
          <dependent id="8">popular</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">television</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">popular</governor>
          <dependent id="10">television</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">one</governor>
          <dependent id="11">history</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="14">distinguished</governor>
          <dependent id="13">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">distinguished</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">timing</governor>
          <dependent id="15">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Ball</governor>
          <dependent id="16">Miss</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="20">timing</governor>
          <dependent id="17">Ball</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Ball</governor>
          <dependent id="18">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">timing</governor>
          <dependent id="19">faultless</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">distinguished</governor>
          <dependent id="20">timing</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">expressions</governor>
          <dependent id="22">rubber-faced</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="20">timing</governor>
          <dependent id="23">expressions</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">wails</governor>
          <dependent id="25">wide-mouthed</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="23">expressions</governor>
          <dependent id="26">wails</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="23">expressions</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">pratfalls</governor>
          <dependent id="28">extravagant</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="23">expressions</governor>
          <dependent id="29">pratfalls</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Ball" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>``Working with Lucy was like receiving an M.A. or a Ph.D. in comedy,&amp;apost;&amp;apost; recalled Joan Rivers.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Working" lemma="work" stem="work" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="receiving" lemma="receive" stem="receiv" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="M.A." lemma="M.A." stem="m.a." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Ph.D." lemma="Ph.D." stem="ph.d." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="comedy" lemma="comedy" stem="comedi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="recalled" lemma="recall" stem="recal" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="Joan" lemma="Joan" stem="joan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="19" string="Rivers" lemma="Rivers" stem="river" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (S (VP (VBG Working) (PP (IN with) (NP (NNP Lucy))))) (VP (VBD was) (PP (IN like) (S (VP (VBG receiving) (NP (NP (DT an) (NNP M.A.)) (CC or) (NP (DT a) (NNP Ph.D.))) (PP (IN in) (NP (NN comedy)))))))) (, ,) ('' '') (VP (VBD recalled)) (NP (NNP Joan) (NNP Rivers)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Joan Rivers" type="NP">
          <tokens>
            <token id="18" string="Joan" />
            <token id="19" string="Rivers" />
          </tokens>
        </chunking>
        <chunking id="2" string="an M.A. or a Ph.D." type="NP">
          <tokens>
            <token id="8" string="an" />
            <token id="9" string="M.A." />
            <token id="10" string="or" />
            <token id="11" string="a" />
            <token id="12" string="Ph.D." />
          </tokens>
        </chunking>
        <chunking id="3" string="comedy" type="NP">
          <tokens>
            <token id="14" string="comedy" />
          </tokens>
        </chunking>
        <chunking id="4" string="an M.A." type="NP">
          <tokens>
            <token id="8" string="an" />
            <token id="9" string="M.A." />
          </tokens>
        </chunking>
        <chunking id="5" string="Lucy" type="NP">
          <tokens>
            <token id="4" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="6" string="was like receiving an M.A. or a Ph.D. in comedy" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="like" />
            <token id="7" string="receiving" />
            <token id="8" string="an" />
            <token id="9" string="M.A." />
            <token id="10" string="or" />
            <token id="11" string="a" />
            <token id="12" string="Ph.D." />
            <token id="13" string="in" />
            <token id="14" string="comedy" />
          </tokens>
        </chunking>
        <chunking id="7" string="recalled" type="VP">
          <tokens>
            <token id="17" string="recalled" />
          </tokens>
        </chunking>
        <chunking id="8" string="Working with Lucy" type="VP">
          <tokens>
            <token id="2" string="Working" />
            <token id="3" string="with" />
            <token id="4" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="9" string="receiving an M.A. or a Ph.D. in comedy" type="VP">
          <tokens>
            <token id="7" string="receiving" />
            <token id="8" string="an" />
            <token id="9" string="M.A." />
            <token id="10" string="or" />
            <token id="11" string="a" />
            <token id="12" string="Ph.D." />
            <token id="13" string="in" />
            <token id="14" string="comedy" />
          </tokens>
        </chunking>
        <chunking id="10" string="a Ph.D." type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="Ph.D." />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="csubj">
          <governor id="7">receiving</governor>
          <dependent id="2">Working</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Lucy</governor>
          <dependent id="3">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Working</governor>
          <dependent id="4">Lucy</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">receiving</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">receiving</governor>
          <dependent id="6">like</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">recalled</governor>
          <dependent id="7">receiving</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">M.A.</governor>
          <dependent id="8">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">receiving</governor>
          <dependent id="9">M.A.</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">M.A.</governor>
          <dependent id="10">or</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">Ph.D.</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">M.A.</governor>
          <dependent id="12">Ph.D.</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">comedy</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">receiving</governor>
          <dependent id="14">comedy</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">recalled</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Rivers</governor>
          <dependent id="18">Joan</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">recalled</governor>
          <dependent id="19">Rivers</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Joan Rivers" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Joan" />
            <token id="19" string="Rivers" />
          </tokens>
        </entity>
        <entity id="2" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Lucy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>``What she forgot about comic timing and delivery is more than most of us will ever learn in a lifetime.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="What" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="forgot" lemma="forget" stem="forgot" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="comic" lemma="comic" stem="comic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="timing" lemma="timing" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="delivery" lemma="delivery" stem="deliveri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="most" lemma="most" stem="most" pos="JJS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="us" lemma="we" stem="u" pos="PRP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="ever" lemma="ever" stem="ever" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="learn" lemma="learn" stem="learn" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="lifetime" lemma="lifetime" stem="lifetim" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (SBAR (WHNP (WP What)) (S (NP (PRP she)) (VP (VBD forgot) (PP (IN about) (NP (JJ comic) (NN timing) (CC and) (NN delivery))))))) (VP (VBZ is) (ADJP (JJR more)) (SBAR (IN than) (S (NP (NP (JJS most)) (PP (IN of) (NP (PRP us)))) (VP (MD will) (ADVP (RB ever)) (VP (VB learn) (PP (IN in) (NP (DT a) (NN lifetime)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="a lifetime" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="lifetime" />
          </tokens>
        </chunking>
        <chunking id="2" string="What she forgot about comic timing and delivery" type="NP">
          <tokens>
            <token id="2" string="What" />
            <token id="3" string="she" />
            <token id="4" string="forgot" />
            <token id="5" string="about" />
            <token id="6" string="comic" />
            <token id="7" string="timing" />
            <token id="8" string="and" />
            <token id="9" string="delivery" />
          </tokens>
        </chunking>
        <chunking id="3" string="more" type="ADJP">
          <tokens>
            <token id="11" string="more" />
          </tokens>
        </chunking>
        <chunking id="4" string="learn in a lifetime" type="VP">
          <tokens>
            <token id="18" string="learn" />
            <token id="19" string="in" />
            <token id="20" string="a" />
            <token id="21" string="lifetime" />
          </tokens>
        </chunking>
        <chunking id="5" string="is more than most of us will ever learn in a lifetime" type="VP">
          <tokens>
            <token id="10" string="is" />
            <token id="11" string="more" />
            <token id="12" string="than" />
            <token id="13" string="most" />
            <token id="14" string="of" />
            <token id="15" string="us" />
            <token id="16" string="will" />
            <token id="17" string="ever" />
            <token id="18" string="learn" />
            <token id="19" string="in" />
            <token id="20" string="a" />
            <token id="21" string="lifetime" />
          </tokens>
        </chunking>
        <chunking id="6" string="she" type="NP">
          <tokens>
            <token id="3" string="she" />
          </tokens>
        </chunking>
        <chunking id="7" string="forgot about comic timing and delivery" type="VP">
          <tokens>
            <token id="4" string="forgot" />
            <token id="5" string="about" />
            <token id="6" string="comic" />
            <token id="7" string="timing" />
            <token id="8" string="and" />
            <token id="9" string="delivery" />
          </tokens>
        </chunking>
        <chunking id="8" string="most" type="NP">
          <tokens>
            <token id="13" string="most" />
          </tokens>
        </chunking>
        <chunking id="9" string="most of us" type="NP">
          <tokens>
            <token id="13" string="most" />
            <token id="14" string="of" />
            <token id="15" string="us" />
          </tokens>
        </chunking>
        <chunking id="10" string="than most of us will ever learn in a lifetime" type="SBAR">
          <tokens>
            <token id="12" string="than" />
            <token id="13" string="most" />
            <token id="14" string="of" />
            <token id="15" string="us" />
            <token id="16" string="will" />
            <token id="17" string="ever" />
            <token id="18" string="learn" />
            <token id="19" string="in" />
            <token id="20" string="a" />
            <token id="21" string="lifetime" />
          </tokens>
        </chunking>
        <chunking id="11" string="us" type="NP">
          <tokens>
            <token id="15" string="us" />
          </tokens>
        </chunking>
        <chunking id="12" string="comic timing and delivery" type="NP">
          <tokens>
            <token id="6" string="comic" />
            <token id="7" string="timing" />
            <token id="8" string="and" />
            <token id="9" string="delivery" />
          </tokens>
        </chunking>
        <chunking id="13" string="will ever learn in a lifetime" type="VP">
          <tokens>
            <token id="16" string="will" />
            <token id="17" string="ever" />
            <token id="18" string="learn" />
            <token id="19" string="in" />
            <token id="20" string="a" />
            <token id="21" string="lifetime" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dobj">
          <governor id="4">forgot</governor>
          <dependent id="2">What</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">forgot</governor>
          <dependent id="3">she</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">more</governor>
          <dependent id="4">forgot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">timing</governor>
          <dependent id="5">about</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">timing</governor>
          <dependent id="6">comic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">forgot</governor>
          <dependent id="7">timing</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">timing</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">timing</governor>
          <dependent id="9">delivery</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">more</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">more</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">learn</governor>
          <dependent id="12">than</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">learn</governor>
          <dependent id="13">most</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">us</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">most</governor>
          <dependent id="15">us</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">learn</governor>
          <dependent id="16">will</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">learn</governor>
          <dependent id="17">ever</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">more</governor>
          <dependent id="18">learn</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">lifetime</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">lifetime</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">learn</governor>
          <dependent id="21">lifetime</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>Comedian Whoopi Goldberg said: ``Lucy was great because she represented every person.</content>
      <tokens>
        <token id="1" string="Comedian" lemma="comedian" stem="comedian" pos="NN" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="2" string="Whoopi" lemma="Whoopi" stem="whoopi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Goldberg" lemma="Goldberg" stem="goldberg" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="great" lemma="great" stem="great" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="represented" lemma="represent" stem="repres" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="person" lemma="person" stem="person" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN Comedian) (NNP Whoopi) (NNP Goldberg)) (VP (VBD said) (: :) (`` ``) (S (NP (NNP Lucy)) (VP (VBD was) (ADJP (JJ great)) (SBAR (IN because) (S (NP (PRP she)) (VP (VBD represented) (NP (DT every) (NN person)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="every person" type="NP">
          <tokens>
            <token id="13" string="every" />
            <token id="14" string="person" />
          </tokens>
        </chunking>
        <chunking id="2" string="was great because she represented every person" type="VP">
          <tokens>
            <token id="8" string="was" />
            <token id="9" string="great" />
            <token id="10" string="because" />
            <token id="11" string="she" />
            <token id="12" string="represented" />
            <token id="13" string="every" />
            <token id="14" string="person" />
          </tokens>
        </chunking>
        <chunking id="3" string="Comedian Whoopi Goldberg" type="NP">
          <tokens>
            <token id="1" string="Comedian" />
            <token id="2" string="Whoopi" />
            <token id="3" string="Goldberg" />
          </tokens>
        </chunking>
        <chunking id="4" string="represented every person" type="VP">
          <tokens>
            <token id="12" string="represented" />
            <token id="13" string="every" />
            <token id="14" string="person" />
          </tokens>
        </chunking>
        <chunking id="5" string="said : `` Lucy was great because she represented every person" type="VP">
          <tokens>
            <token id="4" string="said" />
            <token id="5" string=":" />
            <token id="6" string="``" />
            <token id="7" string="Lucy" />
            <token id="8" string="was" />
            <token id="9" string="great" />
            <token id="10" string="because" />
            <token id="11" string="she" />
            <token id="12" string="represented" />
            <token id="13" string="every" />
            <token id="14" string="person" />
          </tokens>
        </chunking>
        <chunking id="6" string="Lucy" type="NP">
          <tokens>
            <token id="7" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="7" string="great" type="ADJP">
          <tokens>
            <token id="9" string="great" />
          </tokens>
        </chunking>
        <chunking id="8" string="because she represented every person" type="SBAR">
          <tokens>
            <token id="10" string="because" />
            <token id="11" string="she" />
            <token id="12" string="represented" />
            <token id="13" string="every" />
            <token id="14" string="person" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="11" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Goldberg</governor>
          <dependent id="1">Comedian</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Goldberg</governor>
          <dependent id="2">Whoopi</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">said</governor>
          <dependent id="3">Goldberg</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">great</governor>
          <dependent id="7">Lucy</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">great</governor>
          <dependent id="8">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">said</governor>
          <dependent id="9">great</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">represented</governor>
          <dependent id="10">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">represented</governor>
          <dependent id="11">she</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">great</governor>
          <dependent id="12">represented</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">person</governor>
          <dependent id="13">every</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">represented</governor>
          <dependent id="14">person</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Whoopi Goldberg" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Whoopi" />
            <token id="3" string="Goldberg" />
          </tokens>
        </entity>
        <entity id="2" string="Comedian" type="TITLE" score="0.0">
          <tokens>
            <token id="1" string="Comedian" />
          </tokens>
        </entity>
        <entity id="3" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Lucy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>She showed us human foibles and gave us a chance to laugh at ourselves.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="showed" lemma="show" stem="show" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="us" lemma="we" stem="u" pos="PRP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="human" lemma="human" stem="human" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="foibles" lemma="foible" stem="foibl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="gave" lemma="give" stem="gave" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="us" lemma="we" stem="u" pos="PRP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="chance" lemma="chance" stem="chanc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="laugh" lemma="laugh" stem="laugh" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="ourselves" lemma="ourselves" stem="ourselv" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VP (VBD showed) (NP (PRP us)) (NP (JJ human) (NNS foibles))) (CC and) (VP (VBD gave) (NP (PRP us)) (NP (DT a) (NN chance) (S (VP (TO to) (VP (NN laugh) (PP (IN at) (NP (PRP ourselves))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="showed us human foibles" type="VP">
          <tokens>
            <token id="2" string="showed" />
            <token id="3" string="us" />
            <token id="4" string="human" />
            <token id="5" string="foibles" />
          </tokens>
        </chunking>
        <chunking id="2" string="human foibles" type="NP">
          <tokens>
            <token id="4" string="human" />
            <token id="5" string="foibles" />
          </tokens>
        </chunking>
        <chunking id="3" string="laugh at ourselves" type="VP">
          <tokens>
            <token id="12" string="laugh" />
            <token id="13" string="at" />
            <token id="14" string="ourselves" />
          </tokens>
        </chunking>
        <chunking id="4" string="showed us human foibles and gave us a chance to laugh at ourselves" type="VP">
          <tokens>
            <token id="2" string="showed" />
            <token id="3" string="us" />
            <token id="4" string="human" />
            <token id="5" string="foibles" />
            <token id="6" string="and" />
            <token id="7" string="gave" />
            <token id="8" string="us" />
            <token id="9" string="a" />
            <token id="10" string="chance" />
            <token id="11" string="to" />
            <token id="12" string="laugh" />
            <token id="13" string="at" />
            <token id="14" string="ourselves" />
          </tokens>
        </chunking>
        <chunking id="5" string="to laugh at ourselves" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="laugh" />
            <token id="13" string="at" />
            <token id="14" string="ourselves" />
          </tokens>
        </chunking>
        <chunking id="6" string="us" type="NP">
          <tokens>
            <token id="3" string="us" />
          </tokens>
        </chunking>
        <chunking id="7" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="8" string="gave us a chance to laugh at ourselves" type="VP">
          <tokens>
            <token id="7" string="gave" />
            <token id="8" string="us" />
            <token id="9" string="a" />
            <token id="10" string="chance" />
            <token id="11" string="to" />
            <token id="12" string="laugh" />
            <token id="13" string="at" />
            <token id="14" string="ourselves" />
          </tokens>
        </chunking>
        <chunking id="9" string="a chance to laugh at ourselves" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="chance" />
            <token id="11" string="to" />
            <token id="12" string="laugh" />
            <token id="13" string="at" />
            <token id="14" string="ourselves" />
          </tokens>
        </chunking>
        <chunking id="10" string="ourselves" type="NP">
          <tokens>
            <token id="14" string="ourselves" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">showed</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">showed</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="2">showed</governor>
          <dependent id="3">us</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">foibles</governor>
          <dependent id="4">human</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">showed</governor>
          <dependent id="5">foibles</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">showed</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">showed</governor>
          <dependent id="7">gave</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="7">gave</governor>
          <dependent id="8">us</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">chance</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">gave</governor>
          <dependent id="10">chance</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">laugh</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="10">chance</governor>
          <dependent id="12">laugh</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">ourselves</governor>
          <dependent id="13">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">laugh</governor>
          <dependent id="14">ourselves</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>Miss Goldberg said her favorite episode involved a visit by the ``I Love Lucy&amp;apost;&amp;apost; characters to Hollywood, where Lucy and Ethel spotted actor William Holden in a restaurant.</content>
      <tokens>
        <token id="1" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="Goldberg" lemma="Goldberg" stem="goldberg" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="5" string="favorite" lemma="favorite" stem="favorit" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="episode" lemma="episode" stem="episod" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="involved" lemma="involve" stem="involv" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="visit" lemma="visit" stem="visit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="Love" lemma="Love" stem="love" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="15" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="16" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="17" string="characters" lemma="character" stem="charact" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="Hollywood" lemma="Hollywood" stem="hollywood" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="Ethel" lemma="Ethel" stem="ethel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="25" string="spotted" lemma="spot" stem="spot" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="actor" lemma="actor" stem="actor" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="27" string="William" lemma="William" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="28" string="Holden" lemma="Holden" stem="holden" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="29" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="30" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="31" string="restaurant" lemma="restaurant" stem="restaur" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Miss) (NNP Goldberg)) (VP (VBD said) (SBAR (S (NP (PRP$ her) (JJ favorite) (NN episode)) (VP (VBD involved) (NP (DT a) (NN visit)) (PP (IN by) (NP (NP (DT the) (`` ``) (NX (NP (PRP I)) (PP (NP (NNP Love) (NNP Lucy) ('' '') (NNS characters)) (PP (TO to) (NP (NNP Hollywood)))))) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (NNP Lucy) (CC and) (NNP Ethel)) (VP (VBD spotted) (NP (NP (NN actor) (NNP William) (NNP Holden)) (PP (IN in) (NP (DT a) (NN restaurant))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="where Lucy and Ethel spotted actor William Holden in a restaurant" type="SBAR">
          <tokens>
            <token id="21" string="where" />
            <token id="22" string="Lucy" />
            <token id="23" string="and" />
            <token id="24" string="Ethel" />
            <token id="25" string="spotted" />
            <token id="26" string="actor" />
            <token id="27" string="William" />
            <token id="28" string="Holden" />
            <token id="29" string="in" />
            <token id="30" string="a" />
            <token id="31" string="restaurant" />
          </tokens>
        </chunking>
        <chunking id="2" string="actor William Holden in a restaurant" type="NP">
          <tokens>
            <token id="26" string="actor" />
            <token id="27" string="William" />
            <token id="28" string="Holden" />
            <token id="29" string="in" />
            <token id="30" string="a" />
            <token id="31" string="restaurant" />
          </tokens>
        </chunking>
        <chunking id="3" string="the `` I Love Lucy '' characters to Hollywood , where Lucy and Ethel spotted actor William Holden in a restaurant" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="``" />
            <token id="13" string="I" />
            <token id="14" string="Love" />
            <token id="15" string="Lucy" />
            <token id="16" string="''" />
            <token id="17" string="characters" />
            <token id="18" string="to" />
            <token id="19" string="Hollywood" />
            <token id="20" string="," />
            <token id="21" string="where" />
            <token id="22" string="Lucy" />
            <token id="23" string="and" />
            <token id="24" string="Ethel" />
            <token id="25" string="spotted" />
            <token id="26" string="actor" />
            <token id="27" string="William" />
            <token id="28" string="Holden" />
            <token id="29" string="in" />
            <token id="30" string="a" />
            <token id="31" string="restaurant" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="13" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="Love Lucy '' characters" type="NP">
          <tokens>
            <token id="14" string="Love" />
            <token id="15" string="Lucy" />
            <token id="16" string="''" />
            <token id="17" string="characters" />
          </tokens>
        </chunking>
        <chunking id="6" string="actor William Holden" type="NP">
          <tokens>
            <token id="26" string="actor" />
            <token id="27" string="William" />
            <token id="28" string="Holden" />
          </tokens>
        </chunking>
        <chunking id="7" string="a visit" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="visit" />
          </tokens>
        </chunking>
        <chunking id="8" string="Hollywood" type="NP">
          <tokens>
            <token id="19" string="Hollywood" />
          </tokens>
        </chunking>
        <chunking id="9" string="Miss Goldberg" type="NP">
          <tokens>
            <token id="1" string="Miss" />
            <token id="2" string="Goldberg" />
          </tokens>
        </chunking>
        <chunking id="10" string="involved a visit by the `` I Love Lucy '' characters to Hollywood , where Lucy and Ethel spotted actor William Holden in a restaurant" type="VP">
          <tokens>
            <token id="7" string="involved" />
            <token id="8" string="a" />
            <token id="9" string="visit" />
            <token id="10" string="by" />
            <token id="11" string="the" />
            <token id="12" string="``" />
            <token id="13" string="I" />
            <token id="14" string="Love" />
            <token id="15" string="Lucy" />
            <token id="16" string="''" />
            <token id="17" string="characters" />
            <token id="18" string="to" />
            <token id="19" string="Hollywood" />
            <token id="20" string="," />
            <token id="21" string="where" />
            <token id="22" string="Lucy" />
            <token id="23" string="and" />
            <token id="24" string="Ethel" />
            <token id="25" string="spotted" />
            <token id="26" string="actor" />
            <token id="27" string="William" />
            <token id="28" string="Holden" />
            <token id="29" string="in" />
            <token id="30" string="a" />
            <token id="31" string="restaurant" />
          </tokens>
        </chunking>
        <chunking id="11" string="spotted actor William Holden in a restaurant" type="VP">
          <tokens>
            <token id="25" string="spotted" />
            <token id="26" string="actor" />
            <token id="27" string="William" />
            <token id="28" string="Holden" />
            <token id="29" string="in" />
            <token id="30" string="a" />
            <token id="31" string="restaurant" />
          </tokens>
        </chunking>
        <chunking id="12" string="the `` I Love Lucy '' characters to Hollywood" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="``" />
            <token id="13" string="I" />
            <token id="14" string="Love" />
            <token id="15" string="Lucy" />
            <token id="16" string="''" />
            <token id="17" string="characters" />
            <token id="18" string="to" />
            <token id="19" string="Hollywood" />
          </tokens>
        </chunking>
        <chunking id="13" string="her favorite episode involved a visit by the `` I Love Lucy '' characters to Hollywood , where Lucy and Ethel spotted actor William Holden in a restaurant" type="SBAR">
          <tokens>
            <token id="4" string="her" />
            <token id="5" string="favorite" />
            <token id="6" string="episode" />
            <token id="7" string="involved" />
            <token id="8" string="a" />
            <token id="9" string="visit" />
            <token id="10" string="by" />
            <token id="11" string="the" />
            <token id="12" string="``" />
            <token id="13" string="I" />
            <token id="14" string="Love" />
            <token id="15" string="Lucy" />
            <token id="16" string="''" />
            <token id="17" string="characters" />
            <token id="18" string="to" />
            <token id="19" string="Hollywood" />
            <token id="20" string="," />
            <token id="21" string="where" />
            <token id="22" string="Lucy" />
            <token id="23" string="and" />
            <token id="24" string="Ethel" />
            <token id="25" string="spotted" />
            <token id="26" string="actor" />
            <token id="27" string="William" />
            <token id="28" string="Holden" />
            <token id="29" string="in" />
            <token id="30" string="a" />
            <token id="31" string="restaurant" />
          </tokens>
        </chunking>
        <chunking id="14" string="Lucy and Ethel" type="NP">
          <tokens>
            <token id="22" string="Lucy" />
            <token id="23" string="and" />
            <token id="24" string="Ethel" />
          </tokens>
        </chunking>
        <chunking id="15" string="where" type="WHADVP">
          <tokens>
            <token id="21" string="where" />
          </tokens>
        </chunking>
        <chunking id="16" string="a restaurant" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="restaurant" />
          </tokens>
        </chunking>
        <chunking id="17" string="her favorite episode" type="NP">
          <tokens>
            <token id="4" string="her" />
            <token id="5" string="favorite" />
            <token id="6" string="episode" />
          </tokens>
        </chunking>
        <chunking id="18" string="said her favorite episode involved a visit by the `` I Love Lucy '' characters to Hollywood , where Lucy and Ethel spotted actor William Holden in a restaurant" type="VP">
          <tokens>
            <token id="3" string="said" />
            <token id="4" string="her" />
            <token id="5" string="favorite" />
            <token id="6" string="episode" />
            <token id="7" string="involved" />
            <token id="8" string="a" />
            <token id="9" string="visit" />
            <token id="10" string="by" />
            <token id="11" string="the" />
            <token id="12" string="``" />
            <token id="13" string="I" />
            <token id="14" string="Love" />
            <token id="15" string="Lucy" />
            <token id="16" string="''" />
            <token id="17" string="characters" />
            <token id="18" string="to" />
            <token id="19" string="Hollywood" />
            <token id="20" string="," />
            <token id="21" string="where" />
            <token id="22" string="Lucy" />
            <token id="23" string="and" />
            <token id="24" string="Ethel" />
            <token id="25" string="spotted" />
            <token id="26" string="actor" />
            <token id="27" string="William" />
            <token id="28" string="Holden" />
            <token id="29" string="in" />
            <token id="30" string="a" />
            <token id="31" string="restaurant" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Goldberg</governor>
          <dependent id="1">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">said</governor>
          <dependent id="2">Goldberg</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">said</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">episode</governor>
          <dependent id="4">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">episode</governor>
          <dependent id="5">favorite</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">involved</governor>
          <dependent id="6">episode</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">said</governor>
          <dependent id="7">involved</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">visit</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">involved</governor>
          <dependent id="9">visit</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">I</governor>
          <dependent id="10">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">I</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">involved</governor>
          <dependent id="13">I</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">characters</governor>
          <dependent id="14">Love</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">characters</governor>
          <dependent id="15">Lucy</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">I</governor>
          <dependent id="17">characters</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Hollywood</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">characters</governor>
          <dependent id="19">Hollywood</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">spotted</governor>
          <dependent id="21">where</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">spotted</governor>
          <dependent id="22">Lucy</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">Lucy</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">Lucy</governor>
          <dependent id="24">Ethel</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">I</governor>
          <dependent id="25">spotted</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">Holden</governor>
          <dependent id="26">actor</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">Holden</governor>
          <dependent id="27">William</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">spotted</governor>
          <dependent id="28">Holden</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">restaurant</governor>
          <dependent id="29">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">restaurant</governor>
          <dependent id="30">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">Holden</governor>
          <dependent id="31">restaurant</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hollywood" type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="Hollywood" />
          </tokens>
        </entity>
        <entity id="2" string="Goldberg" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Goldberg" />
          </tokens>
        </entity>
        <entity id="3" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Lucy" />
          </tokens>
        </entity>
        <entity id="4" string="Ethel" type="PERSON" score="0.0">
          <tokens>
            <token id="24" string="Ethel" />
          </tokens>
        </entity>
        <entity id="5" string="William Holden" type="PERSON" score="0.0">
          <tokens>
            <token id="27" string="William" />
            <token id="28" string="Holden" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>``That was how we would all react to seeing a movie star in a restaurant,&amp;apost;&amp;apost; Miss Goldberg said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="all" lemma="all" stem="all" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="react" lemma="react" stem="react" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="seeing" lemma="see" stem="see" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="movie" lemma="movie" stem="movi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="star" lemma="star" stem="star" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="restaurant" lemma="restaurant" stem="restaur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="Goldberg" lemma="Goldberg" stem="goldberg" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="21" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (DT That)) (VP (VBD was) (SBAR (WHADVP (WRB how)) (S (NP (PRP we)) (VP (MD would) (RB all) (VP (VB react) (PP (TO to) (S (VP (VBG seeing) (NP (DT a) (NN movie) (NN star)) (PP (IN in) (NP (DT a) (NN restaurant)))))))))))) (, ,) ('' '') (NP (NNP Miss) (NNP Goldberg)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="That" type="NP">
          <tokens>
            <token id="2" string="That" />
          </tokens>
        </chunking>
        <chunking id="2" string="a movie star" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="movie" />
            <token id="13" string="star" />
          </tokens>
        </chunking>
        <chunking id="3" string="Miss Goldberg" type="NP">
          <tokens>
            <token id="19" string="Miss" />
            <token id="20" string="Goldberg" />
          </tokens>
        </chunking>
        <chunking id="4" string="would all react to seeing a movie star in a restaurant" type="VP">
          <tokens>
            <token id="6" string="would" />
            <token id="7" string="all" />
            <token id="8" string="react" />
            <token id="9" string="to" />
            <token id="10" string="seeing" />
            <token id="11" string="a" />
            <token id="12" string="movie" />
            <token id="13" string="star" />
            <token id="14" string="in" />
            <token id="15" string="a" />
            <token id="16" string="restaurant" />
          </tokens>
        </chunking>
        <chunking id="5" string="react to seeing a movie star in a restaurant" type="VP">
          <tokens>
            <token id="8" string="react" />
            <token id="9" string="to" />
            <token id="10" string="seeing" />
            <token id="11" string="a" />
            <token id="12" string="movie" />
            <token id="13" string="star" />
            <token id="14" string="in" />
            <token id="15" string="a" />
            <token id="16" string="restaurant" />
          </tokens>
        </chunking>
        <chunking id="6" string="was how we would all react to seeing a movie star in a restaurant" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="how" />
            <token id="5" string="we" />
            <token id="6" string="would" />
            <token id="7" string="all" />
            <token id="8" string="react" />
            <token id="9" string="to" />
            <token id="10" string="seeing" />
            <token id="11" string="a" />
            <token id="12" string="movie" />
            <token id="13" string="star" />
            <token id="14" string="in" />
            <token id="15" string="a" />
            <token id="16" string="restaurant" />
          </tokens>
        </chunking>
        <chunking id="7" string="how we would all react to seeing a movie star in a restaurant" type="SBAR">
          <tokens>
            <token id="4" string="how" />
            <token id="5" string="we" />
            <token id="6" string="would" />
            <token id="7" string="all" />
            <token id="8" string="react" />
            <token id="9" string="to" />
            <token id="10" string="seeing" />
            <token id="11" string="a" />
            <token id="12" string="movie" />
            <token id="13" string="star" />
            <token id="14" string="in" />
            <token id="15" string="a" />
            <token id="16" string="restaurant" />
          </tokens>
        </chunking>
        <chunking id="8" string="a restaurant" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="restaurant" />
          </tokens>
        </chunking>
        <chunking id="9" string="we" type="NP">
          <tokens>
            <token id="5" string="we" />
          </tokens>
        </chunking>
        <chunking id="10" string="seeing a movie star in a restaurant" type="VP">
          <tokens>
            <token id="10" string="seeing" />
            <token id="11" string="a" />
            <token id="12" string="movie" />
            <token id="13" string="star" />
            <token id="14" string="in" />
            <token id="15" string="a" />
            <token id="16" string="restaurant" />
          </tokens>
        </chunking>
        <chunking id="11" string="said" type="VP">
          <tokens>
            <token id="21" string="said" />
          </tokens>
        </chunking>
        <chunking id="12" string="how" type="WHADVP">
          <tokens>
            <token id="4" string="how" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">was</governor>
          <dependent id="2">That</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">said</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">react</governor>
          <dependent id="4">how</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">react</governor>
          <dependent id="5">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">react</governor>
          <dependent id="6">would</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">react</governor>
          <dependent id="7">all</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">was</governor>
          <dependent id="8">react</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">seeing</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">react</governor>
          <dependent id="10">seeing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">star</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">star</governor>
          <dependent id="12">movie</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">seeing</governor>
          <dependent id="13">star</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">restaurant</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">restaurant</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">seeing</governor>
          <dependent id="16">restaurant</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Goldberg</governor>
          <dependent id="19">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">said</governor>
          <dependent id="20">Goldberg</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Goldberg" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Goldberg" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>``She was looking at him in a compact mirror, and trying to look at him surreptitiously.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="looking" lemma="look" stem="look" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="compact" lemma="compact" stem="compact" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="mirror" lemma="mirror" stem="mirror" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="trying" lemma="try" stem="try" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="look" lemma="look" stem="look" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="surreptitiously" lemma="surreptitiously" stem="surreptiti" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP She)) (VP (VBD was) (VP (VP (VBG looking) (PP (IN at) (NP (PRP him))) (PP (IN in) (NP (DT a) (JJ compact) (NN mirror)))) (, ,) (CC and) (VP (VBG trying) (S (VP (TO to) (VP (VB look) (PP (IN at) (NP (PRP him))) (ADVP (RB surreptitiously)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="looking at him in a compact mirror" type="VP">
          <tokens>
            <token id="4" string="looking" />
            <token id="5" string="at" />
            <token id="6" string="him" />
            <token id="7" string="in" />
            <token id="8" string="a" />
            <token id="9" string="compact" />
            <token id="10" string="mirror" />
          </tokens>
        </chunking>
        <chunking id="2" string="to look at him surreptitiously" type="VP">
          <tokens>
            <token id="14" string="to" />
            <token id="15" string="look" />
            <token id="16" string="at" />
            <token id="17" string="him" />
            <token id="18" string="surreptitiously" />
          </tokens>
        </chunking>
        <chunking id="3" string="was looking at him in a compact mirror , and trying to look at him surreptitiously" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="looking" />
            <token id="5" string="at" />
            <token id="6" string="him" />
            <token id="7" string="in" />
            <token id="8" string="a" />
            <token id="9" string="compact" />
            <token id="10" string="mirror" />
            <token id="11" string="," />
            <token id="12" string="and" />
            <token id="13" string="trying" />
            <token id="14" string="to" />
            <token id="15" string="look" />
            <token id="16" string="at" />
            <token id="17" string="him" />
            <token id="18" string="surreptitiously" />
          </tokens>
        </chunking>
        <chunking id="4" string="trying to look at him surreptitiously" type="VP">
          <tokens>
            <token id="13" string="trying" />
            <token id="14" string="to" />
            <token id="15" string="look" />
            <token id="16" string="at" />
            <token id="17" string="him" />
            <token id="18" string="surreptitiously" />
          </tokens>
        </chunking>
        <chunking id="5" string="looking at him in a compact mirror , and trying to look at him surreptitiously" type="VP">
          <tokens>
            <token id="4" string="looking" />
            <token id="5" string="at" />
            <token id="6" string="him" />
            <token id="7" string="in" />
            <token id="8" string="a" />
            <token id="9" string="compact" />
            <token id="10" string="mirror" />
            <token id="11" string="," />
            <token id="12" string="and" />
            <token id="13" string="trying" />
            <token id="14" string="to" />
            <token id="15" string="look" />
            <token id="16" string="at" />
            <token id="17" string="him" />
            <token id="18" string="surreptitiously" />
          </tokens>
        </chunking>
        <chunking id="6" string="look at him surreptitiously" type="VP">
          <tokens>
            <token id="15" string="look" />
            <token id="16" string="at" />
            <token id="17" string="him" />
            <token id="18" string="surreptitiously" />
          </tokens>
        </chunking>
        <chunking id="7" string="him" type="NP">
          <tokens>
            <token id="6" string="him" />
          </tokens>
        </chunking>
        <chunking id="8" string="a compact mirror" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="compact" />
            <token id="10" string="mirror" />
          </tokens>
        </chunking>
        <chunking id="9" string="She" type="NP">
          <tokens>
            <token id="2" string="She" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">looking</governor>
          <dependent id="2">She</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">looking</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">looking</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">him</governor>
          <dependent id="5">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">looking</governor>
          <dependent id="6">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">mirror</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">mirror</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">mirror</governor>
          <dependent id="9">compact</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">looking</governor>
          <dependent id="10">mirror</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">looking</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">looking</governor>
          <dependent id="13">trying</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">look</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">trying</governor>
          <dependent id="15">look</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">him</governor>
          <dependent id="16">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">look</governor>
          <dependent id="17">him</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">look</governor>
          <dependent id="18">surreptitiously</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>And that&amp;apost;s just an example of how everyone can identify with Lucy.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="example" lemma="example" stem="exampl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="everyone" lemma="everyone" stem="everyon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="identify" lemma="identify" stem="identifi" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (DT that)) (VP (VBZ 's) (ADVP (RB just)) (NP (NP (DT an) (NN example)) (PP (IN of) (SBAR (WHADVP (WRB how)) (S (NP (NN everyone)) (VP (MD can) (VP (VB identify) (PP (IN with) (NP (NNP Lucy)))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="that" type="NP">
          <tokens>
            <token id="2" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="an example of how everyone can identify with Lucy" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="example" />
            <token id="7" string="of" />
            <token id="8" string="how" />
            <token id="9" string="everyone" />
            <token id="10" string="can" />
            <token id="11" string="identify" />
            <token id="12" string="with" />
            <token id="13" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="3" string="an example" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="example" />
          </tokens>
        </chunking>
        <chunking id="4" string="'s just an example of how everyone can identify with Lucy" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="just" />
            <token id="5" string="an" />
            <token id="6" string="example" />
            <token id="7" string="of" />
            <token id="8" string="how" />
            <token id="9" string="everyone" />
            <token id="10" string="can" />
            <token id="11" string="identify" />
            <token id="12" string="with" />
            <token id="13" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="5" string="how everyone can identify with Lucy" type="SBAR">
          <tokens>
            <token id="8" string="how" />
            <token id="9" string="everyone" />
            <token id="10" string="can" />
            <token id="11" string="identify" />
            <token id="12" string="with" />
            <token id="13" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="6" string="everyone" type="NP">
          <tokens>
            <token id="9" string="everyone" />
          </tokens>
        </chunking>
        <chunking id="7" string="identify with Lucy" type="VP">
          <tokens>
            <token id="11" string="identify" />
            <token id="12" string="with" />
            <token id="13" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="8" string="Lucy" type="NP">
          <tokens>
            <token id="13" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="9" string="can identify with Lucy" type="VP">
          <tokens>
            <token id="10" string="can" />
            <token id="11" string="identify" />
            <token id="12" string="with" />
            <token id="13" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="10" string="how" type="WHADVP">
          <tokens>
            <token id="8" string="how" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="6">example</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">example</governor>
          <dependent id="2">that</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">example</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">example</governor>
          <dependent id="4">just</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">example</governor>
          <dependent id="5">an</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">example</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">identify</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">identify</governor>
          <dependent id="8">how</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">identify</governor>
          <dependent id="9">everyone</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">identify</governor>
          <dependent id="10">can</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="6">example</governor>
          <dependent id="11">identify</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Lucy</governor>
          <dependent id="12">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">identify</governor>
          <dependent id="13">Lucy</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Lucy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>Bob Rosati, who lives down the street from the Beverly Hills home Miss Ball shared with husband Gary Morton, said he was watching a rerun of ``I Love Lucy&amp;apost;&amp;apost; on Wednesday morning when the screen went black and the words ``In Memory of Lucille Ball, 1911-1989&amp;apost;&amp;apost; appeared.</content>
      <tokens>
        <token id="1" string="Bob" lemma="Bob" stem="bob" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Rosati" lemma="Rosati" stem="rosati" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="lives" lemma="live" stem="live" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="down" lemma="down" stem="down" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="street" lemma="street" stem="street" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="Beverly" lemma="Beverly" stem="beverli" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="12" string="Hills" lemma="Hills" stem="hill" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="13" string="home" lemma="home" stem="home" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="true" />
        <token id="15" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="true" />
        <token id="16" string="shared" lemma="share" stem="share" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="husband" lemma="husband" stem="husband" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="Gary" lemma="Gary" stem="gari" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="20" string="Morton" lemma="Morton" stem="morton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="watching" lemma="watch" stem="watch" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="rerun" lemma="rerun" stem="rerun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="Love" lemma="Love" stem="love" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="32" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="33" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="Wednesday" lemma="Wednesday" stem="wednesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="36" string="morning" lemma="morning" stem="morn" pos="NN" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="37" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="39" string="screen" lemma="screen" stem="screen" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="40" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="words" lemma="word" stem="word" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="Memory" lemma="memory" stem="memori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="Lucille" lemma="Lucille" stem="lucil" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="50" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="51" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="52" string="1911-1989" lemma="1911-1989" stem="1911-1989" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="53" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="54" string="appeared" lemma="appear" stem="appear" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="55" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NNP Bob) (NNP Rosati)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBZ lives) (PRT (RP down)) (NP (DT the) (NN street)) (PP (IN from) (NP (NP (DT the) (ADJP (NNP Beverly) (NNP Hills)) (NN home)) (SBAR (S (NP (NNP Miss) (NNP Ball)) (VP (VBD shared) (PP (IN with) (NP (NN husband) (NNP Gary) (NNP Morton))))))))))) (, ,)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBD was) (VP (VBG watching) (NP (NP (DT a) (NN rerun)) (PP (IN of) (`` ``) (NP (NP (PRP I)) (NP (NNP Love) (NNP Lucy))) ('' '')) (PP (IN on) (NP (NNP Wednesday)))) (NP-TMP (NN morning)) (SBAR (WHADVP (WRB when)) (S (NP (DT the) (NN screen)) (VP (VBD went) (S (NP (ADJP (JJ black) (CC and) (DT the)) (NNS words)) (`` ``) (PP (IN In) (NP (NP (NN Memory)) (PP (IN of) (NP (NP (NNP Lucille) (NNP Ball)) (, ,) (NP (CD 1911-1989)))))))))))))))) ('' '') (VP (VBD appeared)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Miss Ball shared with husband Gary Morton" type="SBAR">
          <tokens>
            <token id="14" string="Miss" />
            <token id="15" string="Ball" />
            <token id="16" string="shared" />
            <token id="17" string="with" />
            <token id="18" string="husband" />
            <token id="19" string="Gary" />
            <token id="20" string="Morton" />
          </tokens>
        </chunking>
        <chunking id="2" string="the screen" type="NP">
          <tokens>
            <token id="38" string="the" />
            <token id="39" string="screen" />
          </tokens>
        </chunking>
        <chunking id="3" string="black and the words" type="NP">
          <tokens>
            <token id="41" string="black" />
            <token id="42" string="and" />
            <token id="43" string="the" />
            <token id="44" string="words" />
          </tokens>
        </chunking>
        <chunking id="4" string="when the screen went black and the words `` In Memory of Lucille Ball , 1911-1989" type="SBAR">
          <tokens>
            <token id="37" string="when" />
            <token id="38" string="the" />
            <token id="39" string="screen" />
            <token id="40" string="went" />
            <token id="41" string="black" />
            <token id="42" string="and" />
            <token id="43" string="the" />
            <token id="44" string="words" />
            <token id="45" string="``" />
            <token id="46" string="In" />
            <token id="47" string="Memory" />
            <token id="48" string="of" />
            <token id="49" string="Lucille" />
            <token id="50" string="Ball" />
            <token id="51" string="," />
            <token id="52" string="1911-1989" />
          </tokens>
        </chunking>
        <chunking id="5" string="I Love Lucy" type="NP">
          <tokens>
            <token id="30" string="I" />
            <token id="31" string="Love" />
            <token id="32" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="6" string="black and the" type="ADJP">
          <tokens>
            <token id="41" string="black" />
            <token id="42" string="and" />
            <token id="43" string="the" />
          </tokens>
        </chunking>
        <chunking id="7" string="Beverly Hills" type="ADJP">
          <tokens>
            <token id="11" string="Beverly" />
            <token id="12" string="Hills" />
          </tokens>
        </chunking>
        <chunking id="8" string="1911-1989" type="NP">
          <tokens>
            <token id="52" string="1911-1989" />
          </tokens>
        </chunking>
        <chunking id="9" string="Wednesday" type="NP">
          <tokens>
            <token id="35" string="Wednesday" />
          </tokens>
        </chunking>
        <chunking id="10" string="shared with husband Gary Morton" type="VP">
          <tokens>
            <token id="16" string="shared" />
            <token id="17" string="with" />
            <token id="18" string="husband" />
            <token id="19" string="Gary" />
            <token id="20" string="Morton" />
          </tokens>
        </chunking>
        <chunking id="11" string="was watching a rerun of `` I Love Lucy '' on Wednesday morning when the screen went black and the words `` In Memory of Lucille Ball , 1911-1989" type="VP">
          <tokens>
            <token id="24" string="was" />
            <token id="25" string="watching" />
            <token id="26" string="a" />
            <token id="27" string="rerun" />
            <token id="28" string="of" />
            <token id="29" string="``" />
            <token id="30" string="I" />
            <token id="31" string="Love" />
            <token id="32" string="Lucy" />
            <token id="33" string="''" />
            <token id="34" string="on" />
            <token id="35" string="Wednesday" />
            <token id="36" string="morning" />
            <token id="37" string="when" />
            <token id="38" string="the" />
            <token id="39" string="screen" />
            <token id="40" string="went" />
            <token id="41" string="black" />
            <token id="42" string="and" />
            <token id="43" string="the" />
            <token id="44" string="words" />
            <token id="45" string="``" />
            <token id="46" string="In" />
            <token id="47" string="Memory" />
            <token id="48" string="of" />
            <token id="49" string="Lucille" />
            <token id="50" string="Ball" />
            <token id="51" string="," />
            <token id="52" string="1911-1989" />
          </tokens>
        </chunking>
        <chunking id="12" string="a rerun" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="rerun" />
          </tokens>
        </chunking>
        <chunking id="13" string="husband Gary Morton" type="NP">
          <tokens>
            <token id="18" string="husband" />
            <token id="19" string="Gary" />
            <token id="20" string="Morton" />
          </tokens>
        </chunking>
        <chunking id="14" string="said he was watching a rerun of `` I Love Lucy '' on Wednesday morning when the screen went black and the words `` In Memory of Lucille Ball , 1911-1989" type="VP">
          <tokens>
            <token id="22" string="said" />
            <token id="23" string="he" />
            <token id="24" string="was" />
            <token id="25" string="watching" />
            <token id="26" string="a" />
            <token id="27" string="rerun" />
            <token id="28" string="of" />
            <token id="29" string="``" />
            <token id="30" string="I" />
            <token id="31" string="Love" />
            <token id="32" string="Lucy" />
            <token id="33" string="''" />
            <token id="34" string="on" />
            <token id="35" string="Wednesday" />
            <token id="36" string="morning" />
            <token id="37" string="when" />
            <token id="38" string="the" />
            <token id="39" string="screen" />
            <token id="40" string="went" />
            <token id="41" string="black" />
            <token id="42" string="and" />
            <token id="43" string="the" />
            <token id="44" string="words" />
            <token id="45" string="``" />
            <token id="46" string="In" />
            <token id="47" string="Memory" />
            <token id="48" string="of" />
            <token id="49" string="Lucille" />
            <token id="50" string="Ball" />
            <token id="51" string="," />
            <token id="52" string="1911-1989" />
          </tokens>
        </chunking>
        <chunking id="15" string="he" type="NP">
          <tokens>
            <token id="23" string="he" />
          </tokens>
        </chunking>
        <chunking id="16" string="he was watching a rerun of `` I Love Lucy '' on Wednesday morning when the screen went black and the words `` In Memory of Lucille Ball , 1911-1989" type="SBAR">
          <tokens>
            <token id="23" string="he" />
            <token id="24" string="was" />
            <token id="25" string="watching" />
            <token id="26" string="a" />
            <token id="27" string="rerun" />
            <token id="28" string="of" />
            <token id="29" string="``" />
            <token id="30" string="I" />
            <token id="31" string="Love" />
            <token id="32" string="Lucy" />
            <token id="33" string="''" />
            <token id="34" string="on" />
            <token id="35" string="Wednesday" />
            <token id="36" string="morning" />
            <token id="37" string="when" />
            <token id="38" string="the" />
            <token id="39" string="screen" />
            <token id="40" string="went" />
            <token id="41" string="black" />
            <token id="42" string="and" />
            <token id="43" string="the" />
            <token id="44" string="words" />
            <token id="45" string="``" />
            <token id="46" string="In" />
            <token id="47" string="Memory" />
            <token id="48" string="of" />
            <token id="49" string="Lucille" />
            <token id="50" string="Ball" />
            <token id="51" string="," />
            <token id="52" string="1911-1989" />
          </tokens>
        </chunking>
        <chunking id="17" string="Love Lucy" type="NP">
          <tokens>
            <token id="31" string="Love" />
            <token id="32" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="18" string="watching a rerun of `` I Love Lucy '' on Wednesday morning when the screen went black and the words `` In Memory of Lucille Ball , 1911-1989" type="VP">
          <tokens>
            <token id="25" string="watching" />
            <token id="26" string="a" />
            <token id="27" string="rerun" />
            <token id="28" string="of" />
            <token id="29" string="``" />
            <token id="30" string="I" />
            <token id="31" string="Love" />
            <token id="32" string="Lucy" />
            <token id="33" string="''" />
            <token id="34" string="on" />
            <token id="35" string="Wednesday" />
            <token id="36" string="morning" />
            <token id="37" string="when" />
            <token id="38" string="the" />
            <token id="39" string="screen" />
            <token id="40" string="went" />
            <token id="41" string="black" />
            <token id="42" string="and" />
            <token id="43" string="the" />
            <token id="44" string="words" />
            <token id="45" string="``" />
            <token id="46" string="In" />
            <token id="47" string="Memory" />
            <token id="48" string="of" />
            <token id="49" string="Lucille" />
            <token id="50" string="Ball" />
            <token id="51" string="," />
            <token id="52" string="1911-1989" />
          </tokens>
        </chunking>
        <chunking id="19" string="Memory" type="NP">
          <tokens>
            <token id="47" string="Memory" />
          </tokens>
        </chunking>
        <chunking id="20" string="who lives down the street from the Beverly Hills home Miss Ball shared with husband Gary Morton" type="SBAR">
          <tokens>
            <token id="4" string="who" />
            <token id="5" string="lives" />
            <token id="6" string="down" />
            <token id="7" string="the" />
            <token id="8" string="street" />
            <token id="9" string="from" />
            <token id="10" string="the" />
            <token id="11" string="Beverly" />
            <token id="12" string="Hills" />
            <token id="13" string="home" />
            <token id="14" string="Miss" />
            <token id="15" string="Ball" />
            <token id="16" string="shared" />
            <token id="17" string="with" />
            <token id="18" string="husband" />
            <token id="19" string="Gary" />
            <token id="20" string="Morton" />
          </tokens>
        </chunking>
        <chunking id="21" string="I" type="NP">
          <tokens>
            <token id="30" string="I" />
          </tokens>
        </chunking>
        <chunking id="22" string="Lucille Ball , 1911-1989" type="NP">
          <tokens>
            <token id="49" string="Lucille" />
            <token id="50" string="Ball" />
            <token id="51" string="," />
            <token id="52" string="1911-1989" />
          </tokens>
        </chunking>
        <chunking id="23" string="lives down the street from the Beverly Hills home Miss Ball shared with husband Gary Morton" type="VP">
          <tokens>
            <token id="5" string="lives" />
            <token id="6" string="down" />
            <token id="7" string="the" />
            <token id="8" string="street" />
            <token id="9" string="from" />
            <token id="10" string="the" />
            <token id="11" string="Beverly" />
            <token id="12" string="Hills" />
            <token id="13" string="home" />
            <token id="14" string="Miss" />
            <token id="15" string="Ball" />
            <token id="16" string="shared" />
            <token id="17" string="with" />
            <token id="18" string="husband" />
            <token id="19" string="Gary" />
            <token id="20" string="Morton" />
          </tokens>
        </chunking>
        <chunking id="24" string="the Beverly Hills home Miss Ball shared with husband Gary Morton" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="Beverly" />
            <token id="12" string="Hills" />
            <token id="13" string="home" />
            <token id="14" string="Miss" />
            <token id="15" string="Ball" />
            <token id="16" string="shared" />
            <token id="17" string="with" />
            <token id="18" string="husband" />
            <token id="19" string="Gary" />
            <token id="20" string="Morton" />
          </tokens>
        </chunking>
        <chunking id="25" string="when" type="WHADVP">
          <tokens>
            <token id="37" string="when" />
          </tokens>
        </chunking>
        <chunking id="26" string="went black and the words `` In Memory of Lucille Ball , 1911-1989" type="VP">
          <tokens>
            <token id="40" string="went" />
            <token id="41" string="black" />
            <token id="42" string="and" />
            <token id="43" string="the" />
            <token id="44" string="words" />
            <token id="45" string="``" />
            <token id="46" string="In" />
            <token id="47" string="Memory" />
            <token id="48" string="of" />
            <token id="49" string="Lucille" />
            <token id="50" string="Ball" />
            <token id="51" string="," />
            <token id="52" string="1911-1989" />
          </tokens>
        </chunking>
        <chunking id="27" string="Bob Rosati , who lives down the street from the Beverly Hills home Miss Ball shared with husband Gary Morton ," type="NP">
          <tokens>
            <token id="1" string="Bob" />
            <token id="2" string="Rosati" />
            <token id="3" string="," />
            <token id="4" string="who" />
            <token id="5" string="lives" />
            <token id="6" string="down" />
            <token id="7" string="the" />
            <token id="8" string="street" />
            <token id="9" string="from" />
            <token id="10" string="the" />
            <token id="11" string="Beverly" />
            <token id="12" string="Hills" />
            <token id="13" string="home" />
            <token id="14" string="Miss" />
            <token id="15" string="Ball" />
            <token id="16" string="shared" />
            <token id="17" string="with" />
            <token id="18" string="husband" />
            <token id="19" string="Gary" />
            <token id="20" string="Morton" />
            <token id="21" string="," />
          </tokens>
        </chunking>
        <chunking id="28" string="Memory of Lucille Ball , 1911-1989" type="NP">
          <tokens>
            <token id="47" string="Memory" />
            <token id="48" string="of" />
            <token id="49" string="Lucille" />
            <token id="50" string="Ball" />
            <token id="51" string="," />
            <token id="52" string="1911-1989" />
          </tokens>
        </chunking>
        <chunking id="29" string="appeared" type="VP">
          <tokens>
            <token id="54" string="appeared" />
          </tokens>
        </chunking>
        <chunking id="30" string="the street" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="street" />
          </tokens>
        </chunking>
        <chunking id="31" string="a rerun of `` I Love Lucy '' on Wednesday" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="rerun" />
            <token id="28" string="of" />
            <token id="29" string="``" />
            <token id="30" string="I" />
            <token id="31" string="Love" />
            <token id="32" string="Lucy" />
            <token id="33" string="''" />
            <token id="34" string="on" />
            <token id="35" string="Wednesday" />
          </tokens>
        </chunking>
        <chunking id="32" string="the Beverly Hills home" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="Beverly" />
            <token id="12" string="Hills" />
            <token id="13" string="home" />
          </tokens>
        </chunking>
        <chunking id="33" string="Lucille Ball" type="NP">
          <tokens>
            <token id="49" string="Lucille" />
            <token id="50" string="Ball" />
          </tokens>
        </chunking>
        <chunking id="34" string="Bob Rosati" type="NP">
          <tokens>
            <token id="1" string="Bob" />
            <token id="2" string="Rosati" />
          </tokens>
        </chunking>
        <chunking id="35" string="Miss Ball" type="NP">
          <tokens>
            <token id="14" string="Miss" />
            <token id="15" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Rosati</governor>
          <dependent id="1">Bob</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">said</governor>
          <dependent id="2">Rosati</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">lives</governor>
          <dependent id="4">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">Rosati</governor>
          <dependent id="5">lives</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="5">lives</governor>
          <dependent id="6">down</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">street</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">lives</governor>
          <dependent id="8">street</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">home</governor>
          <dependent id="9">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">home</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">Hills</governor>
          <dependent id="11">Beverly</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">home</governor>
          <dependent id="12">Hills</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">lives</governor>
          <dependent id="13">home</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Ball</governor>
          <dependent id="14">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">shared</governor>
          <dependent id="15">Ball</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">home</governor>
          <dependent id="16">shared</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Morton</governor>
          <dependent id="17">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Morton</governor>
          <dependent id="18">husband</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Morton</governor>
          <dependent id="19">Gary</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">shared</governor>
          <dependent id="20">Morton</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="54">appeared</governor>
          <dependent id="22">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">watching</governor>
          <dependent id="23">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="25">watching</governor>
          <dependent id="24">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">said</governor>
          <dependent id="25">watching</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">rerun</governor>
          <dependent id="26">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">watching</governor>
          <dependent id="27">rerun</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">I</governor>
          <dependent id="28">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">rerun</governor>
          <dependent id="30">I</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">Lucy</governor>
          <dependent id="31">Love</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="30">I</governor>
          <dependent id="32">Lucy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">Wednesday</governor>
          <dependent id="34">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">rerun</governor>
          <dependent id="35">Wednesday</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="25">watching</governor>
          <dependent id="36">morning</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="40">went</governor>
          <dependent id="37">when</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">screen</governor>
          <dependent id="38">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="40">went</governor>
          <dependent id="39">screen</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="25">watching</governor>
          <dependent id="40">went</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="44">words</governor>
          <dependent id="41">black</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="41">black</governor>
          <dependent id="42">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="41">black</governor>
          <dependent id="43">the</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="40">went</governor>
          <dependent id="44">words</dependent>
        </dependency>
        <dependency type="case">
          <governor id="47">Memory</governor>
          <dependent id="46">In</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="44">words</governor>
          <dependent id="47">Memory</dependent>
        </dependency>
        <dependency type="case">
          <governor id="50">Ball</governor>
          <dependent id="48">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="50">Ball</governor>
          <dependent id="49">Lucille</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="47">Memory</governor>
          <dependent id="50">Ball</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="50">Ball</governor>
          <dependent id="52">1911-1989</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="54">appeared</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Beverly Hills" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="Beverly" />
            <token id="12" string="Hills" />
          </tokens>
        </entity>
        <entity id="2" string="1911-1989" type="DURATION" score="0.0">
          <tokens>
            <token id="52" string="1911-1989" />
          </tokens>
        </entity>
        <entity id="3" string="Wednesday" type="DATE" score="0.0">
          <tokens>
            <token id="35" string="Wednesday" />
          </tokens>
        </entity>
        <entity id="4" string="Gary Morton" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Gary" />
            <token id="20" string="Morton" />
          </tokens>
        </entity>
        <entity id="5" string="morning" type="TIME" score="0.0">
          <tokens>
            <token id="36" string="morning" />
          </tokens>
        </entity>
        <entity id="6" string="Lucille Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="49" string="Lucille" />
            <token id="50" string="Ball" />
          </tokens>
        </entity>
        <entity id="7" string="Bob Rosati" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Bob" />
            <token id="2" string="Rosati" />
          </tokens>
        </entity>
        <entity id="8" string="Miss Ball" type="MISC" score="0.0">
          <tokens>
            <token id="14" string="Miss" />
            <token id="15" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>``I felt I had lost someone in my family.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="felt" lemma="feel" stem="felt" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="lost" lemma="lose" stem="lost" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="someone" lemma="someone" stem="someon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBD felt) (SBAR (S (NP (PRP I)) (VP (VBD had) (VP (VBN lost) (NP (NP (NN someone)) (PP (IN in) (NP (PRP$ my) (NN family))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="felt I had lost someone in my family" type="VP">
          <tokens>
            <token id="3" string="felt" />
            <token id="4" string="I" />
            <token id="5" string="had" />
            <token id="6" string="lost" />
            <token id="7" string="someone" />
            <token id="8" string="in" />
            <token id="9" string="my" />
            <token id="10" string="family" />
          </tokens>
        </chunking>
        <chunking id="2" string="someone in my family" type="NP">
          <tokens>
            <token id="7" string="someone" />
            <token id="8" string="in" />
            <token id="9" string="my" />
            <token id="10" string="family" />
          </tokens>
        </chunking>
        <chunking id="3" string="I had lost someone in my family" type="SBAR">
          <tokens>
            <token id="4" string="I" />
            <token id="5" string="had" />
            <token id="6" string="lost" />
            <token id="7" string="someone" />
            <token id="8" string="in" />
            <token id="9" string="my" />
            <token id="10" string="family" />
          </tokens>
        </chunking>
        <chunking id="4" string="my family" type="NP">
          <tokens>
            <token id="9" string="my" />
            <token id="10" string="family" />
          </tokens>
        </chunking>
        <chunking id="5" string="someone" type="NP">
          <tokens>
            <token id="7" string="someone" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="had lost someone in my family" type="VP">
          <tokens>
            <token id="5" string="had" />
            <token id="6" string="lost" />
            <token id="7" string="someone" />
            <token id="8" string="in" />
            <token id="9" string="my" />
            <token id="10" string="family" />
          </tokens>
        </chunking>
        <chunking id="8" string="lost someone in my family" type="VP">
          <tokens>
            <token id="6" string="lost" />
            <token id="7" string="someone" />
            <token id="8" string="in" />
            <token id="9" string="my" />
            <token id="10" string="family" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">felt</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">felt</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">lost</governor>
          <dependent id="4">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">lost</governor>
          <dependent id="5">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">felt</governor>
          <dependent id="6">lost</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">lost</governor>
          <dependent id="7">someone</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">family</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">family</governor>
          <dependent id="9">my</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">someone</governor>
          <dependent id="10">family</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>I couldn&amp;apost;t believe it,&amp;apost;&amp;apost; said Rosati, 40.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="believe" lemma="believe" stem="believ" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Rosati" lemma="Rosati" stem="rosati" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="40" lemma="40" stem="40" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (PRP I)) (VP (MD could) (RB n't) (VP (VB believe) (NP (PRP it))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Rosati)) (, ,) (NP (CD 40))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Rosati" type="NP">
          <tokens>
            <token id="9" string="Rosati" />
          </tokens>
        </chunking>
        <chunking id="2" string="could n't believe it" type="VP">
          <tokens>
            <token id="2" string="could" />
            <token id="3" string="n't" />
            <token id="4" string="believe" />
            <token id="5" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="believe it" type="VP">
          <tokens>
            <token id="4" string="believe" />
            <token id="5" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="5" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="40" type="NP">
          <tokens>
            <token id="11" string="40" />
          </tokens>
        </chunking>
        <chunking id="7" string="said" type="VP">
          <tokens>
            <token id="8" string="said" />
          </tokens>
        </chunking>
        <chunking id="8" string="Rosati , 40" type="NP">
          <tokens>
            <token id="9" string="Rosati" />
            <token id="10" string="," />
            <token id="11" string="40" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">believe</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">believe</governor>
          <dependent id="2">could</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">believe</governor>
          <dependent id="3">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">said</governor>
          <dependent id="4">believe</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">believe</governor>
          <dependent id="5">it</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">said</governor>
          <dependent id="9">Rosati</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">Rosati</governor>
          <dependent id="11">40</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Rosati" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Rosati" />
          </tokens>
        </entity>
        <entity id="2" string="40" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="40" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>``I was watching Lucy like I do every morning.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="watching" lemma="watch" stem="watch" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="6" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="10" string="morning" lemma="morning" stem="morn" pos="NN" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBD was) (VP (VBG watching) (NP (NNP Lucy)) (SBAR (IN like) (S (NP (PRP I)) (VP (VBP do) (NP-TMP (DT every) (NN morning))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was watching Lucy like I do every morning" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="watching" />
            <token id="5" string="Lucy" />
            <token id="6" string="like" />
            <token id="7" string="I" />
            <token id="8" string="do" />
            <token id="9" string="every" />
            <token id="10" string="morning" />
          </tokens>
        </chunking>
        <chunking id="2" string="watching Lucy like I do every morning" type="VP">
          <tokens>
            <token id="4" string="watching" />
            <token id="5" string="Lucy" />
            <token id="6" string="like" />
            <token id="7" string="I" />
            <token id="8" string="do" />
            <token id="9" string="every" />
            <token id="10" string="morning" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="Lucy" type="NP">
          <tokens>
            <token id="5" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="5" string="like I do every morning" type="SBAR">
          <tokens>
            <token id="6" string="like" />
            <token id="7" string="I" />
            <token id="8" string="do" />
            <token id="9" string="every" />
            <token id="10" string="morning" />
          </tokens>
        </chunking>
        <chunking id="6" string="do every morning" type="VP">
          <tokens>
            <token id="8" string="do" />
            <token id="9" string="every" />
            <token id="10" string="morning" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">watching</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">watching</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">watching</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">watching</governor>
          <dependent id="5">Lucy</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">do</governor>
          <dependent id="6">like</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">do</governor>
          <dependent id="7">I</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">watching</governor>
          <dependent id="8">do</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">morning</governor>
          <dependent id="9">every</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="8">do</governor>
          <dependent id="10">morning</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="every morning" type="SET" score="0.0">
          <tokens>
            <token id="9" string="every" />
            <token id="10" string="morning" />
          </tokens>
        </entity>
        <entity id="2" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Lucy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>She&amp;apost;s one of the most-admired ladies in this town.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="most-admired" lemma="most-admired" stem="most-admir" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="ladies" lemma="lady" stem="ladi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="town" lemma="town" stem="town" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VBZ 's) (NP (NP (CD one)) (PP (IN of) (NP (NP (DT the) (JJS most-admired) (NNS ladies)) (PP (IN in) (NP (DT this) (NN town))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the most-admired ladies" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="most-admired" />
            <token id="7" string="ladies" />
          </tokens>
        </chunking>
        <chunking id="2" string="this town" type="NP">
          <tokens>
            <token id="9" string="this" />
            <token id="10" string="town" />
          </tokens>
        </chunking>
        <chunking id="3" string="one" type="NP">
          <tokens>
            <token id="3" string="one" />
          </tokens>
        </chunking>
        <chunking id="4" string="'s one of the most-admired ladies in this town" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="one" />
            <token id="4" string="of" />
            <token id="5" string="the" />
            <token id="6" string="most-admired" />
            <token id="7" string="ladies" />
            <token id="8" string="in" />
            <token id="9" string="this" />
            <token id="10" string="town" />
          </tokens>
        </chunking>
        <chunking id="5" string="the most-admired ladies in this town" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="most-admired" />
            <token id="7" string="ladies" />
            <token id="8" string="in" />
            <token id="9" string="this" />
            <token id="10" string="town" />
          </tokens>
        </chunking>
        <chunking id="6" string="one of the most-admired ladies in this town" type="NP">
          <tokens>
            <token id="3" string="one" />
            <token id="4" string="of" />
            <token id="5" string="the" />
            <token id="6" string="most-admired" />
            <token id="7" string="ladies" />
            <token id="8" string="in" />
            <token id="9" string="this" />
            <token id="10" string="town" />
          </tokens>
        </chunking>
        <chunking id="7" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">one</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="3">one</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">ladies</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">ladies</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">ladies</governor>
          <dependent id="6">most-admired</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">one</governor>
          <dependent id="7">ladies</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">town</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">town</governor>
          <dependent id="9">this</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">ladies</governor>
          <dependent id="10">town</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>He was among a group of fans who stood reverently outside Miss Ball&amp;apost;s home on Roxbury Drive as florists delivered baskets of flowers to the house.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="group" lemma="group" stem="group" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="fans" lemma="fan" stem="fan" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="stood" lemma="stand" stem="stood" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="reverently" lemma="reverently" stem="rever" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="outside" lemma="outside" stem="outsid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="13" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="14" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="home" lemma="home" stem="home" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Roxbury" lemma="Roxbury" stem="roxburi" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="18" string="Drive" lemma="Drive" stem="drive" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="19" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="florists" lemma="florist" stem="florist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="delivered" lemma="deliver" stem="deliv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="baskets" lemma="basket" stem="basket" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="flowers" lemma="flower" stem="flower" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="house" lemma="house" stem="hous" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD was) (PP (IN among) (NP (NP (DT a) (NN group)) (PP (IN of) (NP (NP (NNS fans)) (SBAR (WHNP (WP who)) (S (VP (VBD stood) (ADVP (RB reverently)) (NP (NP (JJ outside) (NNP Miss) (NNP Ball) (POS 's)) (NN home)) (PP (IN on) (NP (NNP Roxbury) (NNP Drive))) (PP (IN as) (NP (NP (NNS florists)) (VP (VBN delivered) (NP (NP (NNS baskets)) (PP (IN of) (NP (NNS flowers)))) (PP (TO to) (NP (DT the) (NN house)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was among a group of fans who stood reverently outside Miss Ball 's home on Roxbury Drive as florists delivered baskets of flowers to the house" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="among" />
            <token id="4" string="a" />
            <token id="5" string="group" />
            <token id="6" string="of" />
            <token id="7" string="fans" />
            <token id="8" string="who" />
            <token id="9" string="stood" />
            <token id="10" string="reverently" />
            <token id="11" string="outside" />
            <token id="12" string="Miss" />
            <token id="13" string="Ball" />
            <token id="14" string="'s" />
            <token id="15" string="home" />
            <token id="16" string="on" />
            <token id="17" string="Roxbury" />
            <token id="18" string="Drive" />
            <token id="19" string="as" />
            <token id="20" string="florists" />
            <token id="21" string="delivered" />
            <token id="22" string="baskets" />
            <token id="23" string="of" />
            <token id="24" string="flowers" />
            <token id="25" string="to" />
            <token id="26" string="the" />
            <token id="27" string="house" />
          </tokens>
        </chunking>
        <chunking id="2" string="outside Miss Ball 's" type="NP">
          <tokens>
            <token id="11" string="outside" />
            <token id="12" string="Miss" />
            <token id="13" string="Ball" />
            <token id="14" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="Roxbury Drive" type="NP">
          <tokens>
            <token id="17" string="Roxbury" />
            <token id="18" string="Drive" />
          </tokens>
        </chunking>
        <chunking id="4" string="florists delivered baskets of flowers to the house" type="NP">
          <tokens>
            <token id="20" string="florists" />
            <token id="21" string="delivered" />
            <token id="22" string="baskets" />
            <token id="23" string="of" />
            <token id="24" string="flowers" />
            <token id="25" string="to" />
            <token id="26" string="the" />
            <token id="27" string="house" />
          </tokens>
        </chunking>
        <chunking id="5" string="baskets" type="NP">
          <tokens>
            <token id="22" string="baskets" />
          </tokens>
        </chunking>
        <chunking id="6" string="a group" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="group" />
          </tokens>
        </chunking>
        <chunking id="7" string="delivered baskets of flowers to the house" type="VP">
          <tokens>
            <token id="21" string="delivered" />
            <token id="22" string="baskets" />
            <token id="23" string="of" />
            <token id="24" string="flowers" />
            <token id="25" string="to" />
            <token id="26" string="the" />
            <token id="27" string="house" />
          </tokens>
        </chunking>
        <chunking id="8" string="a group of fans who stood reverently outside Miss Ball 's home on Roxbury Drive as florists delivered baskets of flowers to the house" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="group" />
            <token id="6" string="of" />
            <token id="7" string="fans" />
            <token id="8" string="who" />
            <token id="9" string="stood" />
            <token id="10" string="reverently" />
            <token id="11" string="outside" />
            <token id="12" string="Miss" />
            <token id="13" string="Ball" />
            <token id="14" string="'s" />
            <token id="15" string="home" />
            <token id="16" string="on" />
            <token id="17" string="Roxbury" />
            <token id="18" string="Drive" />
            <token id="19" string="as" />
            <token id="20" string="florists" />
            <token id="21" string="delivered" />
            <token id="22" string="baskets" />
            <token id="23" string="of" />
            <token id="24" string="flowers" />
            <token id="25" string="to" />
            <token id="26" string="the" />
            <token id="27" string="house" />
          </tokens>
        </chunking>
        <chunking id="9" string="the house" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="house" />
          </tokens>
        </chunking>
        <chunking id="10" string="florists" type="NP">
          <tokens>
            <token id="20" string="florists" />
          </tokens>
        </chunking>
        <chunking id="11" string="stood reverently outside Miss Ball 's home on Roxbury Drive as florists delivered baskets of flowers to the house" type="VP">
          <tokens>
            <token id="9" string="stood" />
            <token id="10" string="reverently" />
            <token id="11" string="outside" />
            <token id="12" string="Miss" />
            <token id="13" string="Ball" />
            <token id="14" string="'s" />
            <token id="15" string="home" />
            <token id="16" string="on" />
            <token id="17" string="Roxbury" />
            <token id="18" string="Drive" />
            <token id="19" string="as" />
            <token id="20" string="florists" />
            <token id="21" string="delivered" />
            <token id="22" string="baskets" />
            <token id="23" string="of" />
            <token id="24" string="flowers" />
            <token id="25" string="to" />
            <token id="26" string="the" />
            <token id="27" string="house" />
          </tokens>
        </chunking>
        <chunking id="12" string="who stood reverently outside Miss Ball 's home on Roxbury Drive as florists delivered baskets of flowers to the house" type="SBAR">
          <tokens>
            <token id="8" string="who" />
            <token id="9" string="stood" />
            <token id="10" string="reverently" />
            <token id="11" string="outside" />
            <token id="12" string="Miss" />
            <token id="13" string="Ball" />
            <token id="14" string="'s" />
            <token id="15" string="home" />
            <token id="16" string="on" />
            <token id="17" string="Roxbury" />
            <token id="18" string="Drive" />
            <token id="19" string="as" />
            <token id="20" string="florists" />
            <token id="21" string="delivered" />
            <token id="22" string="baskets" />
            <token id="23" string="of" />
            <token id="24" string="flowers" />
            <token id="25" string="to" />
            <token id="26" string="the" />
            <token id="27" string="house" />
          </tokens>
        </chunking>
        <chunking id="13" string="flowers" type="NP">
          <tokens>
            <token id="24" string="flowers" />
          </tokens>
        </chunking>
        <chunking id="14" string="outside Miss Ball 's home" type="NP">
          <tokens>
            <token id="11" string="outside" />
            <token id="12" string="Miss" />
            <token id="13" string="Ball" />
            <token id="14" string="'s" />
            <token id="15" string="home" />
          </tokens>
        </chunking>
        <chunking id="15" string="fans" type="NP">
          <tokens>
            <token id="7" string="fans" />
          </tokens>
        </chunking>
        <chunking id="16" string="baskets of flowers" type="NP">
          <tokens>
            <token id="22" string="baskets" />
            <token id="23" string="of" />
            <token id="24" string="flowers" />
          </tokens>
        </chunking>
        <chunking id="17" string="fans who stood reverently outside Miss Ball 's home on Roxbury Drive as florists delivered baskets of flowers to the house" type="NP">
          <tokens>
            <token id="7" string="fans" />
            <token id="8" string="who" />
            <token id="9" string="stood" />
            <token id="10" string="reverently" />
            <token id="11" string="outside" />
            <token id="12" string="Miss" />
            <token id="13" string="Ball" />
            <token id="14" string="'s" />
            <token id="15" string="home" />
            <token id="16" string="on" />
            <token id="17" string="Roxbury" />
            <token id="18" string="Drive" />
            <token id="19" string="as" />
            <token id="20" string="florists" />
            <token id="21" string="delivered" />
            <token id="22" string="baskets" />
            <token id="23" string="of" />
            <token id="24" string="flowers" />
            <token id="25" string="to" />
            <token id="26" string="the" />
            <token id="27" string="house" />
          </tokens>
        </chunking>
        <chunking id="18" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">group</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">group</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">group</governor>
          <dependent id="3">among</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">group</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">group</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">fans</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">group</governor>
          <dependent id="7">fans</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">stood</governor>
          <dependent id="8">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">fans</governor>
          <dependent id="9">stood</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">stood</governor>
          <dependent id="10">reverently</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">Ball</governor>
          <dependent id="11">outside</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Ball</governor>
          <dependent id="12">Miss</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">home</governor>
          <dependent id="13">Ball</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Ball</governor>
          <dependent id="14">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">stood</governor>
          <dependent id="15">home</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Drive</governor>
          <dependent id="16">on</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Drive</governor>
          <dependent id="17">Roxbury</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">stood</governor>
          <dependent id="18">Drive</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">florists</governor>
          <dependent id="19">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">stood</governor>
          <dependent id="20">florists</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="20">florists</governor>
          <dependent id="21">delivered</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">delivered</governor>
          <dependent id="22">baskets</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">flowers</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">baskets</governor>
          <dependent id="24">flowers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">house</governor>
          <dependent id="25">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">house</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">delivered</governor>
          <dependent id="27">house</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Roxbury Drive" type="LOCATION" score="0.0">
          <tokens>
            <token id="17" string="Roxbury" />
            <token id="18" string="Drive" />
          </tokens>
        </entity>
        <entity id="2" string="Miss Ball" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="Miss" />
            <token id="13" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="false">
      <content>Tour vans passed by in a non-stop procession.</content>
      <tokens>
        <token id="1" string="Tour" lemma="tour" stem="tour" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="vans" lemma="van" stem="van" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="passed" lemma="pass" stem="pass" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="non-stop" lemma="non-stop" stem="non-stop" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="procession" lemma="procession" stem="process" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN Tour) (NNS vans)) (VP (VBN passed) (PP (IN by) (PP (IN in) (NP (DT a) (JJ non-stop) (NN procession))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Tour vans" type="NP">
          <tokens>
            <token id="1" string="Tour" />
            <token id="2" string="vans" />
          </tokens>
        </chunking>
        <chunking id="2" string="a non-stop procession" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="non-stop" />
            <token id="8" string="procession" />
          </tokens>
        </chunking>
        <chunking id="3" string="passed by in a non-stop procession" type="VP">
          <tokens>
            <token id="3" string="passed" />
            <token id="4" string="by" />
            <token id="5" string="in" />
            <token id="6" string="a" />
            <token id="7" string="non-stop" />
            <token id="8" string="procession" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">vans</governor>
          <dependent id="1">Tour</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">passed</governor>
          <dependent id="2">vans</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">passed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">procession</governor>
          <dependent id="4">by</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">procession</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">procession</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">procession</governor>
          <dependent id="7">non-stop</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">passed</governor>
          <dependent id="8">procession</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>On Hollywood Boulevard&amp;apost;s Walk of Fame, flower arrangements were placed on Miss Ball&amp;apost;s two stars _ one for her film work, one for television.</content>
      <tokens>
        <token id="1" string="On" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Hollywood" lemma="Hollywood" stem="hollywood" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="3" string="Boulevard" lemma="Boulevard" stem="boulevard" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Walk" lemma="walk" stem="walk" pos="VB" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="7" string="Fame" lemma="Fame" stem="fame" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="flower" lemma="flower" stem="flower" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="arrangements" lemma="arrangement" stem="arrang" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="placed" lemma="place" stem="place" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="15" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="16" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="18" string="stars" lemma="star" stem="star" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="_" lemma="_" stem="_" pos="VBP" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="21" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="film" lemma="film" stem="film" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="work" lemma="work" stem="work" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="27" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (PP (IN On) (NP (NP (NNP Hollywood) (NNP Boulevard) (POS 's)) (NP (NP (VB Walk)) (PP (IN of) (NP (NNP Fame)))))) (, ,) (NP (NN flower) (NNS arrangements)) (VP (VBD were) (VP (VBN placed) (PP (IN on) (NP (NP (NNP Miss) (NNP Ball) (POS 's)) (CD two) (NNS stars)))))) (VP (VBP _) (NP (CD one)) (PP (IN for) (NP (PRP$ her) (NN film)))) (NP (NP (NN work)) (, ,) (NP (NP (CD one)) (PP (IN for) (NP (NN television))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Walk" type="NP">
          <tokens>
            <token id="5" string="Walk" />
          </tokens>
        </chunking>
        <chunking id="2" string="work , one for television" type="NP">
          <tokens>
            <token id="24" string="work" />
            <token id="25" string="," />
            <token id="26" string="one" />
            <token id="27" string="for" />
            <token id="28" string="television" />
          </tokens>
        </chunking>
        <chunking id="3" string="flower arrangements" type="NP">
          <tokens>
            <token id="9" string="flower" />
            <token id="10" string="arrangements" />
          </tokens>
        </chunking>
        <chunking id="4" string="one" type="NP">
          <tokens>
            <token id="20" string="one" />
          </tokens>
        </chunking>
        <chunking id="5" string="her film" type="NP">
          <tokens>
            <token id="22" string="her" />
            <token id="23" string="film" />
          </tokens>
        </chunking>
        <chunking id="6" string="_ one for her film" type="VP">
          <tokens>
            <token id="19" string="_" />
            <token id="20" string="one" />
            <token id="21" string="for" />
            <token id="22" string="her" />
            <token id="23" string="film" />
          </tokens>
        </chunking>
        <chunking id="7" string="television" type="NP">
          <tokens>
            <token id="28" string="television" />
          </tokens>
        </chunking>
        <chunking id="8" string="work" type="NP">
          <tokens>
            <token id="24" string="work" />
          </tokens>
        </chunking>
        <chunking id="9" string="Hollywood Boulevard 's Walk of Fame" type="NP">
          <tokens>
            <token id="2" string="Hollywood" />
            <token id="3" string="Boulevard" />
            <token id="4" string="'s" />
            <token id="5" string="Walk" />
            <token id="6" string="of" />
            <token id="7" string="Fame" />
          </tokens>
        </chunking>
        <chunking id="10" string="Miss Ball 's" type="NP">
          <tokens>
            <token id="14" string="Miss" />
            <token id="15" string="Ball" />
            <token id="16" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="Walk of Fame" type="NP">
          <tokens>
            <token id="5" string="Walk" />
            <token id="6" string="of" />
            <token id="7" string="Fame" />
          </tokens>
        </chunking>
        <chunking id="12" string="were placed on Miss Ball 's two stars" type="VP">
          <tokens>
            <token id="11" string="were" />
            <token id="12" string="placed" />
            <token id="13" string="on" />
            <token id="14" string="Miss" />
            <token id="15" string="Ball" />
            <token id="16" string="'s" />
            <token id="17" string="two" />
            <token id="18" string="stars" />
          </tokens>
        </chunking>
        <chunking id="13" string="one for television" type="NP">
          <tokens>
            <token id="26" string="one" />
            <token id="27" string="for" />
            <token id="28" string="television" />
          </tokens>
        </chunking>
        <chunking id="14" string="Miss Ball 's two stars" type="NP">
          <tokens>
            <token id="14" string="Miss" />
            <token id="15" string="Ball" />
            <token id="16" string="'s" />
            <token id="17" string="two" />
            <token id="18" string="stars" />
          </tokens>
        </chunking>
        <chunking id="15" string="Hollywood Boulevard 's" type="NP">
          <tokens>
            <token id="2" string="Hollywood" />
            <token id="3" string="Boulevard" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="16" string="Fame" type="NP">
          <tokens>
            <token id="7" string="Fame" />
          </tokens>
        </chunking>
        <chunking id="17" string="placed on Miss Ball 's two stars" type="VP">
          <tokens>
            <token id="12" string="placed" />
            <token id="13" string="on" />
            <token id="14" string="Miss" />
            <token id="15" string="Ball" />
            <token id="16" string="'s" />
            <token id="17" string="two" />
            <token id="18" string="stars" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">Boulevard</governor>
          <dependent id="1">On</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Boulevard</governor>
          <dependent id="2">Hollywood</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">placed</governor>
          <dependent id="3">Boulevard</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">Boulevard</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">Boulevard</governor>
          <dependent id="5">Walk</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Fame</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">Walk</governor>
          <dependent id="7">Fame</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">arrangements</governor>
          <dependent id="9">flower</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">placed</governor>
          <dependent id="10">arrangements</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">placed</governor>
          <dependent id="11">were</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="19">_</governor>
          <dependent id="12">placed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">stars</governor>
          <dependent id="13">on</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Ball</governor>
          <dependent id="14">Miss</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">stars</governor>
          <dependent id="15">Ball</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Ball</governor>
          <dependent id="16">'s</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="18">stars</governor>
          <dependent id="17">two</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">placed</governor>
          <dependent id="18">stars</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">_</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">_</governor>
          <dependent id="20">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">film</governor>
          <dependent id="21">for</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">film</governor>
          <dependent id="22">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">_</governor>
          <dependent id="23">film</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">_</governor>
          <dependent id="24">work</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="24">work</governor>
          <dependent id="26">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">television</governor>
          <dependent id="27">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">one</governor>
          <dependent id="28">television</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="20" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="Hollywood Boulevard" type="LOCATION" score="0.0">
          <tokens>
            <token id="2" string="Hollywood" />
            <token id="3" string="Boulevard" />
          </tokens>
        </entity>
        <entity id="3" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="17" string="two" />
          </tokens>
        </entity>
        <entity id="4" string="Walk of Fame" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="5" string="Walk" />
            <token id="6" string="of" />
            <token id="7" string="Fame" />
          </tokens>
        </entity>
        <entity id="5" string="Miss Ball" type="MISC" score="0.0">
          <tokens>
            <token id="14" string="Miss" />
            <token id="15" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>Budd Friedman, owner of the Improvisation comedy clubs, said, ``The world of comedy has lost its first lady.</content>
      <tokens>
        <token id="1" string="Budd" lemma="Budd" stem="budd" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Friedman" lemma="Friedman" stem="friedman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="owner" lemma="owner" stem="owner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Improvisation" lemma="improvisation" stem="improvis" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="8" string="comedy" lemma="comedy" stem="comedi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="clubs" lemma="club" stem="club" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="comedy" lemma="comedy" stem="comedi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="lost" lemma="lose" stem="lost" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="22" string="lady" lemma="lady" stem="ladi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Budd) (NNP Friedman)) (, ,) (NP (NP (NN owner)) (PP (IN of) (NP (DT the) (NN Improvisation) (NN comedy) (NNS clubs)))) (, ,)) (VP (VBD said) (, ,) (`` ``) (S (NP (NP (DT The) (NN world)) (PP (IN of) (NP (NN comedy)))) (VP (VBZ has) (VP (VBN lost) (NP (PRP$ its) (JJ first) (NN lady)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="owner" type="NP">
          <tokens>
            <token id="4" string="owner" />
          </tokens>
        </chunking>
        <chunking id="2" string="The world" type="NP">
          <tokens>
            <token id="14" string="The" />
            <token id="15" string="world" />
          </tokens>
        </chunking>
        <chunking id="3" string="lost its first lady" type="VP">
          <tokens>
            <token id="19" string="lost" />
            <token id="20" string="its" />
            <token id="21" string="first" />
            <token id="22" string="lady" />
          </tokens>
        </chunking>
        <chunking id="4" string="Budd Friedman , owner of the Improvisation comedy clubs ," type="NP">
          <tokens>
            <token id="1" string="Budd" />
            <token id="2" string="Friedman" />
            <token id="3" string="," />
            <token id="4" string="owner" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="Improvisation" />
            <token id="8" string="comedy" />
            <token id="9" string="clubs" />
            <token id="10" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="has lost its first lady" type="VP">
          <tokens>
            <token id="18" string="has" />
            <token id="19" string="lost" />
            <token id="20" string="its" />
            <token id="21" string="first" />
            <token id="22" string="lady" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Improvisation comedy clubs" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="Improvisation" />
            <token id="8" string="comedy" />
            <token id="9" string="clubs" />
          </tokens>
        </chunking>
        <chunking id="7" string="said , `` The world of comedy has lost its first lady" type="VP">
          <tokens>
            <token id="11" string="said" />
            <token id="12" string="," />
            <token id="13" string="``" />
            <token id="14" string="The" />
            <token id="15" string="world" />
            <token id="16" string="of" />
            <token id="17" string="comedy" />
            <token id="18" string="has" />
            <token id="19" string="lost" />
            <token id="20" string="its" />
            <token id="21" string="first" />
            <token id="22" string="lady" />
          </tokens>
        </chunking>
        <chunking id="8" string="comedy" type="NP">
          <tokens>
            <token id="17" string="comedy" />
          </tokens>
        </chunking>
        <chunking id="9" string="its first lady" type="NP">
          <tokens>
            <token id="20" string="its" />
            <token id="21" string="first" />
            <token id="22" string="lady" />
          </tokens>
        </chunking>
        <chunking id="10" string="owner of the Improvisation comedy clubs" type="NP">
          <tokens>
            <token id="4" string="owner" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="Improvisation" />
            <token id="8" string="comedy" />
            <token id="9" string="clubs" />
          </tokens>
        </chunking>
        <chunking id="11" string="Budd Friedman" type="NP">
          <tokens>
            <token id="1" string="Budd" />
            <token id="2" string="Friedman" />
          </tokens>
        </chunking>
        <chunking id="12" string="The world of comedy" type="NP">
          <tokens>
            <token id="14" string="The" />
            <token id="15" string="world" />
            <token id="16" string="of" />
            <token id="17" string="comedy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Friedman</governor>
          <dependent id="1">Budd</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">said</governor>
          <dependent id="2">Friedman</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Friedman</governor>
          <dependent id="4">owner</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">clubs</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">clubs</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">clubs</governor>
          <dependent id="7">Improvisation</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">clubs</governor>
          <dependent id="8">comedy</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">owner</governor>
          <dependent id="9">clubs</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">world</governor>
          <dependent id="14">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">lost</governor>
          <dependent id="15">world</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">comedy</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">world</governor>
          <dependent id="17">comedy</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">lost</governor>
          <dependent id="18">has</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">said</governor>
          <dependent id="19">lost</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">lady</governor>
          <dependent id="20">its</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">lady</governor>
          <dependent id="21">first</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">lost</governor>
          <dependent id="22">lady</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="21" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="Budd Friedman" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Budd" />
            <token id="2" string="Friedman" />
          </tokens>
        </entity>
        <entity id="3" string="Improvisation" type="MISC" score="0.0">
          <tokens>
            <token id="7" string="Improvisation" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>Her death is an irreparable loss ... to our industry.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="Her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="death" lemma="death" stem="death" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="irreparable" lemma="irreparable" stem="irrepar" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="loss" lemma="loss" stem="loss" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="..." lemma="..." stem="..." pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="industry" lemma="industry" stem="industri" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP$ Her) (NN death)) (VP (VBZ is) (NP (NP (DT an) (JJ irreparable) (NN loss)) (: ...) (PP (TO to) (NP (PRP$ our) (NN industry))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="our industry" type="NP">
          <tokens>
            <token id="9" string="our" />
            <token id="10" string="industry" />
          </tokens>
        </chunking>
        <chunking id="2" string="an irreparable loss" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="irreparable" />
            <token id="6" string="loss" />
          </tokens>
        </chunking>
        <chunking id="3" string="is an irreparable loss ... to our industry" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="an" />
            <token id="5" string="irreparable" />
            <token id="6" string="loss" />
            <token id="7" string="..." />
            <token id="8" string="to" />
            <token id="9" string="our" />
            <token id="10" string="industry" />
          </tokens>
        </chunking>
        <chunking id="4" string="Her death" type="NP">
          <tokens>
            <token id="1" string="Her" />
            <token id="2" string="death" />
          </tokens>
        </chunking>
        <chunking id="5" string="an irreparable loss ... to our industry" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="irreparable" />
            <token id="6" string="loss" />
            <token id="7" string="..." />
            <token id="8" string="to" />
            <token id="9" string="our" />
            <token id="10" string="industry" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">death</governor>
          <dependent id="1">Her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">loss</governor>
          <dependent id="2">death</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">loss</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">loss</governor>
          <dependent id="4">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">loss</governor>
          <dependent id="5">irreparable</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">loss</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">industry</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">industry</governor>
          <dependent id="9">our</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">loss</governor>
          <dependent id="10">industry</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>Actor Danny DeVito recalled getting a personal congratulation from Miss Ball in 1981 when he won an Emmy for the TV series ``Taxi.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="Actor" lemma="actor" stem="actor" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="Danny" lemma="Danny" stem="danni" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="DeVito" lemma="DeVito" stem="devito" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="recalled" lemma="recall" stem="recal" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="getting" lemma="get" stem="get" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="personal" lemma="personal" stem="person" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="congratulation" lemma="congratulation" stem="congratul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="1981" lemma="1981" stem="1981" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="14" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Emmy" lemma="Emmy" stem="emmy" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="19" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="TV" lemma="tv" stem="tv" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="series" lemma="series" stem="seri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Taxi" lemma="taxi" stem="taxi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN Actor) (NNP Danny) (NNP DeVito)) (VP (VBD recalled) (S (VP (VBG getting) (NP (DT a) (JJ personal) (NN congratulation)) (PP (IN from) (NP (NP (NNP Miss) (NNP Ball)) (PP (IN in) (NP (CD 1981))))))) (SBAR (WHADVP (WRB when)) (S (NP (PRP he)) (VP (VBD won) (NP (DT an) (NNP Emmy)) (PP (IN for) (NP (NP (DT the) (NN TV) (NN series)) (`` ``) (NP (NN Taxi)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="when he won an Emmy for the TV series `` Taxi" type="SBAR">
          <tokens>
            <token id="14" string="when" />
            <token id="15" string="he" />
            <token id="16" string="won" />
            <token id="17" string="an" />
            <token id="18" string="Emmy" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="TV" />
            <token id="22" string="series" />
            <token id="23" string="``" />
            <token id="24" string="Taxi" />
          </tokens>
        </chunking>
        <chunking id="2" string="recalled getting a personal congratulation from Miss Ball in 1981 when he won an Emmy for the TV series `` Taxi" type="VP">
          <tokens>
            <token id="4" string="recalled" />
            <token id="5" string="getting" />
            <token id="6" string="a" />
            <token id="7" string="personal" />
            <token id="8" string="congratulation" />
            <token id="9" string="from" />
            <token id="10" string="Miss" />
            <token id="11" string="Ball" />
            <token id="12" string="in" />
            <token id="13" string="1981" />
            <token id="14" string="when" />
            <token id="15" string="he" />
            <token id="16" string="won" />
            <token id="17" string="an" />
            <token id="18" string="Emmy" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="TV" />
            <token id="22" string="series" />
            <token id="23" string="``" />
            <token id="24" string="Taxi" />
          </tokens>
        </chunking>
        <chunking id="3" string="a personal congratulation" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="personal" />
            <token id="8" string="congratulation" />
          </tokens>
        </chunking>
        <chunking id="4" string="Miss Ball in 1981" type="NP">
          <tokens>
            <token id="10" string="Miss" />
            <token id="11" string="Ball" />
            <token id="12" string="in" />
            <token id="13" string="1981" />
          </tokens>
        </chunking>
        <chunking id="5" string="when" type="WHADVP">
          <tokens>
            <token id="14" string="when" />
          </tokens>
        </chunking>
        <chunking id="6" string="the TV series" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="TV" />
            <token id="22" string="series" />
          </tokens>
        </chunking>
        <chunking id="7" string="getting a personal congratulation from Miss Ball in 1981" type="VP">
          <tokens>
            <token id="5" string="getting" />
            <token id="6" string="a" />
            <token id="7" string="personal" />
            <token id="8" string="congratulation" />
            <token id="9" string="from" />
            <token id="10" string="Miss" />
            <token id="11" string="Ball" />
            <token id="12" string="in" />
            <token id="13" string="1981" />
          </tokens>
        </chunking>
        <chunking id="8" string="an Emmy" type="NP">
          <tokens>
            <token id="17" string="an" />
            <token id="18" string="Emmy" />
          </tokens>
        </chunking>
        <chunking id="9" string="1981" type="NP">
          <tokens>
            <token id="13" string="1981" />
          </tokens>
        </chunking>
        <chunking id="10" string="the TV series `` Taxi" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="TV" />
            <token id="22" string="series" />
            <token id="23" string="``" />
            <token id="24" string="Taxi" />
          </tokens>
        </chunking>
        <chunking id="11" string="Taxi" type="NP">
          <tokens>
            <token id="24" string="Taxi" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="15" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="Actor Danny DeVito" type="NP">
          <tokens>
            <token id="1" string="Actor" />
            <token id="2" string="Danny" />
            <token id="3" string="DeVito" />
          </tokens>
        </chunking>
        <chunking id="14" string="Miss Ball" type="NP">
          <tokens>
            <token id="10" string="Miss" />
            <token id="11" string="Ball" />
          </tokens>
        </chunking>
        <chunking id="15" string="won an Emmy for the TV series `` Taxi" type="VP">
          <tokens>
            <token id="16" string="won" />
            <token id="17" string="an" />
            <token id="18" string="Emmy" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="TV" />
            <token id="22" string="series" />
            <token id="23" string="``" />
            <token id="24" string="Taxi" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">DeVito</governor>
          <dependent id="1">Actor</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">DeVito</governor>
          <dependent id="2">Danny</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">recalled</governor>
          <dependent id="3">DeVito</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">recalled</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">recalled</governor>
          <dependent id="5">getting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">congratulation</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">congratulation</governor>
          <dependent id="7">personal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">getting</governor>
          <dependent id="8">congratulation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Ball</governor>
          <dependent id="9">from</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Ball</governor>
          <dependent id="10">Miss</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">getting</governor>
          <dependent id="11">Ball</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">1981</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">Ball</governor>
          <dependent id="13">1981</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">won</governor>
          <dependent id="14">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">won</governor>
          <dependent id="15">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">recalled</governor>
          <dependent id="16">won</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">Emmy</governor>
          <dependent id="17">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">won</governor>
          <dependent id="18">Emmy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">series</governor>
          <dependent id="19">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">series</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">series</governor>
          <dependent id="21">TV</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">won</governor>
          <dependent id="22">series</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="22">series</governor>
          <dependent id="24">Taxi</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Emmy" type="MISC" score="0.0">
          <tokens>
            <token id="18" string="Emmy" />
          </tokens>
        </entity>
        <entity id="2" string="Danny DeVito" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Danny" />
            <token id="3" string="DeVito" />
          </tokens>
        </entity>
        <entity id="3" string="1981" type="DATE" score="0.0">
          <tokens>
            <token id="13" string="1981" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>``It made it like it had been blessed,&amp;apost;&amp;apost; he recalled.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="blessed" lemma="bless" stem="bless" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="recalled" lemma="recall" stem="recal" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP It)) (VP (VBD made) (NP (PRP it)) (SBAR (IN like) (S (NP (PRP it)) (VP (VBD had) (VP (VBN been) (VP (VBN blessed)))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD recalled)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="been blessed" type="VP">
          <tokens>
            <token id="8" string="been" />
            <token id="9" string="blessed" />
          </tokens>
        </chunking>
        <chunking id="2" string="had been blessed" type="VP">
          <tokens>
            <token id="7" string="had" />
            <token id="8" string="been" />
            <token id="9" string="blessed" />
          </tokens>
        </chunking>
        <chunking id="3" string="like it had been blessed" type="SBAR">
          <tokens>
            <token id="5" string="like" />
            <token id="6" string="it" />
            <token id="7" string="had" />
            <token id="8" string="been" />
            <token id="9" string="blessed" />
          </tokens>
        </chunking>
        <chunking id="4" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="4" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="blessed" type="VP">
          <tokens>
            <token id="9" string="blessed" />
          </tokens>
        </chunking>
        <chunking id="7" string="made it like it had been blessed" type="VP">
          <tokens>
            <token id="3" string="made" />
            <token id="4" string="it" />
            <token id="5" string="like" />
            <token id="6" string="it" />
            <token id="7" string="had" />
            <token id="8" string="been" />
            <token id="9" string="blessed" />
          </tokens>
        </chunking>
        <chunking id="8" string="recalled" type="VP">
          <tokens>
            <token id="13" string="recalled" />
          </tokens>
        </chunking>
        <chunking id="9" string="he" type="NP">
          <tokens>
            <token id="12" string="he" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">made</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">recalled</governor>
          <dependent id="3">made</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">made</governor>
          <dependent id="4">it</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">blessed</governor>
          <dependent id="5">like</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">blessed</governor>
          <dependent id="6">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">blessed</governor>
          <dependent id="7">had</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">blessed</governor>
          <dependent id="8">been</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">made</governor>
          <dependent id="9">blessed</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">recalled</governor>
          <dependent id="12">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">recalled</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>Admirers included President Bush, in Southern California at the time of Miss Ball&amp;apost;s passing, and former President Reagan.</content>
      <tokens>
        <token id="1" string="Admirers" lemma="admirer" stem="admirer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="included" lemma="include" stem="includ" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="President" lemma="President" stem="presid" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="4" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Southern" lemma="Southern" stem="southern" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="8" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="9" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="passing" lemma="passing" stem="pass" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="President" lemma="President" stem="presid" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="21" string="Reagan" lemma="Reagan" stem="reagan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Admirers)) (VP (VBD included) (NP (NNP President) (NNP Bush)) (, ,) (PP (IN in) (NP (NNP Southern) (NNP California))) (PP (IN at) (NP (NP (NP (DT the) (NN time)) (PP (IN of) (NP (NP (NNP Miss) (NNP Ball) (POS 's)) (NN passing)))) (, ,) (CC and) (NP (JJ former) (NNP President) (NNP Reagan))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="former President Reagan" type="NP">
          <tokens>
            <token id="19" string="former" />
            <token id="20" string="President" />
            <token id="21" string="Reagan" />
          </tokens>
        </chunking>
        <chunking id="2" string="the time of Miss Ball 's passing" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="time" />
            <token id="12" string="of" />
            <token id="13" string="Miss" />
            <token id="14" string="Ball" />
            <token id="15" string="'s" />
            <token id="16" string="passing" />
          </tokens>
        </chunking>
        <chunking id="3" string="Miss Ball 's passing" type="NP">
          <tokens>
            <token id="13" string="Miss" />
            <token id="14" string="Ball" />
            <token id="15" string="'s" />
            <token id="16" string="passing" />
          </tokens>
        </chunking>
        <chunking id="4" string="Southern California" type="NP">
          <tokens>
            <token id="7" string="Southern" />
            <token id="8" string="California" />
          </tokens>
        </chunking>
        <chunking id="5" string="the time" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="time" />
          </tokens>
        </chunking>
        <chunking id="6" string="President Bush" type="NP">
          <tokens>
            <token id="3" string="President" />
            <token id="4" string="Bush" />
          </tokens>
        </chunking>
        <chunking id="7" string="Admirers" type="NP">
          <tokens>
            <token id="1" string="Admirers" />
          </tokens>
        </chunking>
        <chunking id="8" string="Miss Ball 's" type="NP">
          <tokens>
            <token id="13" string="Miss" />
            <token id="14" string="Ball" />
            <token id="15" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="the time of Miss Ball 's passing , and former President Reagan" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="time" />
            <token id="12" string="of" />
            <token id="13" string="Miss" />
            <token id="14" string="Ball" />
            <token id="15" string="'s" />
            <token id="16" string="passing" />
            <token id="17" string="," />
            <token id="18" string="and" />
            <token id="19" string="former" />
            <token id="20" string="President" />
            <token id="21" string="Reagan" />
          </tokens>
        </chunking>
        <chunking id="10" string="included President Bush , in Southern California at the time of Miss Ball 's passing , and former President Reagan" type="VP">
          <tokens>
            <token id="2" string="included" />
            <token id="3" string="President" />
            <token id="4" string="Bush" />
            <token id="5" string="," />
            <token id="6" string="in" />
            <token id="7" string="Southern" />
            <token id="8" string="California" />
            <token id="9" string="at" />
            <token id="10" string="the" />
            <token id="11" string="time" />
            <token id="12" string="of" />
            <token id="13" string="Miss" />
            <token id="14" string="Ball" />
            <token id="15" string="'s" />
            <token id="16" string="passing" />
            <token id="17" string="," />
            <token id="18" string="and" />
            <token id="19" string="former" />
            <token id="20" string="President" />
            <token id="21" string="Reagan" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">included</governor>
          <dependent id="1">Admirers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">included</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Bush</governor>
          <dependent id="3">President</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">included</governor>
          <dependent id="4">Bush</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">California</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">California</governor>
          <dependent id="7">Southern</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">included</governor>
          <dependent id="8">California</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">time</governor>
          <dependent id="9">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">time</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">included</governor>
          <dependent id="11">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">passing</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Ball</governor>
          <dependent id="13">Miss</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">passing</governor>
          <dependent id="14">Ball</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Ball</governor>
          <dependent id="15">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">time</governor>
          <dependent id="16">passing</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">time</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">Reagan</governor>
          <dependent id="19">former</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Reagan</governor>
          <dependent id="20">President</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">time</governor>
          <dependent id="21">Reagan</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Ball" />
          </tokens>
        </entity>
        <entity id="2" string="Southern California" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="Southern" />
            <token id="8" string="California" />
          </tokens>
        </entity>
        <entity id="3" string="Bush" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Bush" />
          </tokens>
        </entity>
        <entity id="4" string="time" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="time" />
          </tokens>
        </entity>
        <entity id="5" string="President" type="TITLE" score="0.0">
          <tokens>
            <token id="3" string="President" />
          </tokens>
        </entity>
        <entity id="6" string="Reagan" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Reagan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>``Her red hair, her antics on the screen, her timing and her zest for life made her an American institution,&amp;apost;&amp;apost; the former president and Nancy Reagan said in a statement.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="red" lemma="red" stem="red" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="hair" lemma="hair" stem="hair" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="antics" lemma="antic" stem="antic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="screen" lemma="screen" stem="screen" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="timing" lemma="timing" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="zest" lemma="zest" stem="zest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="American" lemma="american" stem="american" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="23" string="institution" lemma="institution" stem="institut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="president" lemma="president" stem="presid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="Nancy" lemma="Nancy" stem="nanci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="31" string="Reagan" lemma="Reagan" stem="reagan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="32" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="statement" lemma="statement" stem="statement" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (NP (PRP$ Her) (JJ red) (NN hair)) (, ,) (NP (NP (PRP$ her) (NNS antics)) (PP (IN on) (NP (NP (DT the) (NN screen)) (, ,) (NP (PRP$ her) (NN timing)) (CC and) (NP (PRP$ her) (NN zest)))) (PP (IN for) (NP (NN life))))) (VP (VBD made) (NP (PRP$ her)) (NP (DT an) (JJ American) (NN institution)))) (, ,) ('' '') (NP (NP (DT the) (JJ former) (NN president)) (CC and) (NP (NNP Nancy) (NNP Reagan))) (VP (VBD said) (PP (IN in) (NP (DT a) (NN statement)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="said in a statement" type="VP">
          <tokens>
            <token id="32" string="said" />
            <token id="33" string="in" />
            <token id="34" string="a" />
            <token id="35" string="statement" />
          </tokens>
        </chunking>
        <chunking id="2" string="the screen" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="screen" />
          </tokens>
        </chunking>
        <chunking id="3" string="her zest" type="NP">
          <tokens>
            <token id="15" string="her" />
            <token id="16" string="zest" />
          </tokens>
        </chunking>
        <chunking id="4" string="a statement" type="NP">
          <tokens>
            <token id="34" string="a" />
            <token id="35" string="statement" />
          </tokens>
        </chunking>
        <chunking id="5" string="her timing" type="NP">
          <tokens>
            <token id="12" string="her" />
            <token id="13" string="timing" />
          </tokens>
        </chunking>
        <chunking id="6" string="made her an American institution" type="VP">
          <tokens>
            <token id="19" string="made" />
            <token id="20" string="her" />
            <token id="21" string="an" />
            <token id="22" string="American" />
            <token id="23" string="institution" />
          </tokens>
        </chunking>
        <chunking id="7" string="the former president and Nancy Reagan" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="former" />
            <token id="28" string="president" />
            <token id="29" string="and" />
            <token id="30" string="Nancy" />
            <token id="31" string="Reagan" />
          </tokens>
        </chunking>
        <chunking id="8" string="life" type="NP">
          <tokens>
            <token id="18" string="life" />
          </tokens>
        </chunking>
        <chunking id="9" string="her antics" type="NP">
          <tokens>
            <token id="6" string="her" />
            <token id="7" string="antics" />
          </tokens>
        </chunking>
        <chunking id="10" string="the screen , her timing and her zest" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="screen" />
            <token id="11" string="," />
            <token id="12" string="her" />
            <token id="13" string="timing" />
            <token id="14" string="and" />
            <token id="15" string="her" />
            <token id="16" string="zest" />
          </tokens>
        </chunking>
        <chunking id="11" string="an American institution" type="NP">
          <tokens>
            <token id="21" string="an" />
            <token id="22" string="American" />
            <token id="23" string="institution" />
          </tokens>
        </chunking>
        <chunking id="12" string="Her red hair , her antics on the screen , her timing and her zest for life" type="NP">
          <tokens>
            <token id="2" string="Her" />
            <token id="3" string="red" />
            <token id="4" string="hair" />
            <token id="5" string="," />
            <token id="6" string="her" />
            <token id="7" string="antics" />
            <token id="8" string="on" />
            <token id="9" string="the" />
            <token id="10" string="screen" />
            <token id="11" string="," />
            <token id="12" string="her" />
            <token id="13" string="timing" />
            <token id="14" string="and" />
            <token id="15" string="her" />
            <token id="16" string="zest" />
            <token id="17" string="for" />
            <token id="18" string="life" />
          </tokens>
        </chunking>
        <chunking id="13" string="her" type="NP">
          <tokens>
            <token id="20" string="her" />
          </tokens>
        </chunking>
        <chunking id="14" string="Nancy Reagan" type="NP">
          <tokens>
            <token id="30" string="Nancy" />
            <token id="31" string="Reagan" />
          </tokens>
        </chunking>
        <chunking id="15" string="Her red hair" type="NP">
          <tokens>
            <token id="2" string="Her" />
            <token id="3" string="red" />
            <token id="4" string="hair" />
          </tokens>
        </chunking>
        <chunking id="16" string="her antics on the screen , her timing and her zest for life" type="NP">
          <tokens>
            <token id="6" string="her" />
            <token id="7" string="antics" />
            <token id="8" string="on" />
            <token id="9" string="the" />
            <token id="10" string="screen" />
            <token id="11" string="," />
            <token id="12" string="her" />
            <token id="13" string="timing" />
            <token id="14" string="and" />
            <token id="15" string="her" />
            <token id="16" string="zest" />
            <token id="17" string="for" />
            <token id="18" string="life" />
          </tokens>
        </chunking>
        <chunking id="17" string="the former president" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="former" />
            <token id="28" string="president" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="4">hair</governor>
          <dependent id="2">Her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">hair</governor>
          <dependent id="3">red</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">made</governor>
          <dependent id="4">hair</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">antics</governor>
          <dependent id="6">her</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="4">hair</governor>
          <dependent id="7">antics</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">screen</governor>
          <dependent id="8">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">screen</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">antics</governor>
          <dependent id="10">screen</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">timing</governor>
          <dependent id="12">her</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">screen</governor>
          <dependent id="13">timing</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">screen</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">zest</governor>
          <dependent id="15">her</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">screen</governor>
          <dependent id="16">zest</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">life</governor>
          <dependent id="17">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">antics</governor>
          <dependent id="18">life</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="32">said</governor>
          <dependent id="19">made</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="19">made</governor>
          <dependent id="20">her</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">institution</governor>
          <dependent id="21">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">institution</governor>
          <dependent id="22">American</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">made</governor>
          <dependent id="23">institution</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">president</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">president</governor>
          <dependent id="27">former</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">said</governor>
          <dependent id="28">president</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="28">president</governor>
          <dependent id="29">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Reagan</governor>
          <dependent id="30">Nancy</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="28">president</governor>
          <dependent id="31">Reagan</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="32">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">statement</governor>
          <dependent id="33">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">statement</governor>
          <dependent id="34">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">said</governor>
          <dependent id="35">statement</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Nancy Reagan" type="PERSON" score="0.0">
          <tokens>
            <token id="30" string="Nancy" />
            <token id="31" string="Reagan" />
          </tokens>
        </entity>
        <entity id="2" string="American" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="22" string="American" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>``Just the mention of her name brings a smile.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="mention" lemma="mention" stem="mention" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="name" lemma="name" stem="name" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="brings" lemma="bring" stem="bring" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="smile" lemma="smile" stem="smile" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NP (RB Just) (DT the) (NN mention)) (PP (IN of) (NP (PRP$ her) (NN name)))) (VP (VBZ brings) (NP (DT a) (NN smile))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Just the mention of her name" type="NP">
          <tokens>
            <token id="2" string="Just" />
            <token id="3" string="the" />
            <token id="4" string="mention" />
            <token id="5" string="of" />
            <token id="6" string="her" />
            <token id="7" string="name" />
          </tokens>
        </chunking>
        <chunking id="2" string="a smile" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="smile" />
          </tokens>
        </chunking>
        <chunking id="3" string="brings a smile" type="VP">
          <tokens>
            <token id="8" string="brings" />
            <token id="9" string="a" />
            <token id="10" string="smile" />
          </tokens>
        </chunking>
        <chunking id="4" string="her name" type="NP">
          <tokens>
            <token id="6" string="her" />
            <token id="7" string="name" />
          </tokens>
        </chunking>
        <chunking id="5" string="Just the mention" type="NP">
          <tokens>
            <token id="2" string="Just" />
            <token id="3" string="the" />
            <token id="4" string="mention" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">mention</governor>
          <dependent id="2">Just</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">mention</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">brings</governor>
          <dependent id="4">mention</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">name</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">name</governor>
          <dependent id="6">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">mention</governor>
          <dependent id="7">name</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">brings</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">smile</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">brings</governor>
          <dependent id="10">smile</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>... We love Lucy and will miss her deeply.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="..." lemma="..." stem="..." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="love" lemma="love" stem="love" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="miss" lemma="miss" stem="miss" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="deeply" lemma="deeply" stem="deepli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ...) (NP (PRP We)) (VP (VP (VBP love) (NP (NNP Lucy))) (CC and) (VP (MD will) (VP (VB miss) (NP (PRP$ her)) (ADVP (RB deeply))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="love Lucy and will miss her deeply" type="VP">
          <tokens>
            <token id="3" string="love" />
            <token id="4" string="Lucy" />
            <token id="5" string="and" />
            <token id="6" string="will" />
            <token id="7" string="miss" />
            <token id="8" string="her" />
            <token id="9" string="deeply" />
          </tokens>
        </chunking>
        <chunking id="2" string="her" type="NP">
          <tokens>
            <token id="8" string="her" />
          </tokens>
        </chunking>
        <chunking id="3" string="Lucy" type="NP">
          <tokens>
            <token id="4" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="4" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="5" string="love Lucy" type="VP">
          <tokens>
            <token id="3" string="love" />
            <token id="4" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="6" string="miss her deeply" type="VP">
          <tokens>
            <token id="7" string="miss" />
            <token id="8" string="her" />
            <token id="9" string="deeply" />
          </tokens>
        </chunking>
        <chunking id="7" string="will miss her deeply" type="VP">
          <tokens>
            <token id="6" string="will" />
            <token id="7" string="miss" />
            <token id="8" string="her" />
            <token id="9" string="deeply" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">love</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">love</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">love</governor>
          <dependent id="4">Lucy</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">love</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">miss</governor>
          <dependent id="6">will</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">love</governor>
          <dependent id="7">miss</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">miss</governor>
          <dependent id="8">her</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">miss</governor>
          <dependent id="9">deeply</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Lucy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="false">
      <content>``Lucille Ball possessed the gift of laughter,&amp;apost;&amp;apost; Bush said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Lucille" lemma="Lucille" stem="lucil" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="possessed" lemma="possess" stem="possess" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="gift" lemma="gift" stem="gift" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="laughter" lemma="laughter" stem="laughter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (NNP Lucille) (NNP Ball)) (VP (VBD possessed) (NP (NP (DT the) (NN gift)) (PP (IN of) (NP (NN laughter)))))) (, ,) ('' '') (NP (NNP Bush)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="laughter" type="NP">
          <tokens>
            <token id="8" string="laughter" />
          </tokens>
        </chunking>
        <chunking id="2" string="possessed the gift of laughter" type="VP">
          <tokens>
            <token id="4" string="possessed" />
            <token id="5" string="the" />
            <token id="6" string="gift" />
            <token id="7" string="of" />
            <token id="8" string="laughter" />
          </tokens>
        </chunking>
        <chunking id="3" string="the gift" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="gift" />
          </tokens>
        </chunking>
        <chunking id="4" string="the gift of laughter" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="gift" />
            <token id="7" string="of" />
            <token id="8" string="laughter" />
          </tokens>
        </chunking>
        <chunking id="5" string="Bush" type="NP">
          <tokens>
            <token id="11" string="Bush" />
          </tokens>
        </chunking>
        <chunking id="6" string="said" type="VP">
          <tokens>
            <token id="12" string="said" />
          </tokens>
        </chunking>
        <chunking id="7" string="Lucille Ball" type="NP">
          <tokens>
            <token id="2" string="Lucille" />
            <token id="3" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Ball</governor>
          <dependent id="2">Lucille</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">possessed</governor>
          <dependent id="3">Ball</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">said</governor>
          <dependent id="4">possessed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">gift</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">possessed</governor>
          <dependent id="6">gift</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">laughter</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">gift</governor>
          <dependent id="8">laughter</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">said</governor>
          <dependent id="11">Bush</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Bush" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Bush" />
          </tokens>
        </entity>
        <entity id="2" string="Lucille Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Lucille" />
            <token id="3" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="45" has_coreference="true">
      <content>``But she also embodied an even greater treasure _ the gift of love.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="embodied" lemma="embody" stem="embodi" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="greater" lemma="greater" stem="greater" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="treasure" lemma="treasure" stem="treasur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="_" lemma="_" stem="_" pos="IN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="gift" lemma="gift" stem="gift" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="love" lemma="love" stem="love" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (CC But) (NP (PRP she)) (ADVP (RB also)) (VP (VBD embodied) (NP (DT an) (ADJP (RB even) (JJR greater)) (NN treasure)) (PP (IN _) (NP (NP (DT the) (NN gift)) (PP (IN of) (NP (NN love)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the gift" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="gift" />
          </tokens>
        </chunking>
        <chunking id="2" string="love" type="NP">
          <tokens>
            <token id="14" string="love" />
          </tokens>
        </chunking>
        <chunking id="3" string="an even greater treasure" type="NP">
          <tokens>
            <token id="6" string="an" />
            <token id="7" string="even" />
            <token id="8" string="greater" />
            <token id="9" string="treasure" />
          </tokens>
        </chunking>
        <chunking id="4" string="embodied an even greater treasure _ the gift of love" type="VP">
          <tokens>
            <token id="5" string="embodied" />
            <token id="6" string="an" />
            <token id="7" string="even" />
            <token id="8" string="greater" />
            <token id="9" string="treasure" />
            <token id="10" string="_" />
            <token id="11" string="the" />
            <token id="12" string="gift" />
            <token id="13" string="of" />
            <token id="14" string="love" />
          </tokens>
        </chunking>
        <chunking id="5" string="even greater" type="ADJP">
          <tokens>
            <token id="7" string="even" />
            <token id="8" string="greater" />
          </tokens>
        </chunking>
        <chunking id="6" string="she" type="NP">
          <tokens>
            <token id="3" string="she" />
          </tokens>
        </chunking>
        <chunking id="7" string="the gift of love" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="gift" />
            <token id="13" string="of" />
            <token id="14" string="love" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="5">embodied</governor>
          <dependent id="2">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">embodied</governor>
          <dependent id="3">she</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">embodied</governor>
          <dependent id="4">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">embodied</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">treasure</governor>
          <dependent id="6">an</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">greater</governor>
          <dependent id="7">even</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">treasure</governor>
          <dependent id="8">greater</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">embodied</governor>
          <dependent id="9">treasure</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">gift</governor>
          <dependent id="10">_</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">gift</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">embodied</governor>
          <dependent id="12">gift</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">love</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">gift</governor>
          <dependent id="14">love</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="46" has_coreference="true">
      <content>She appealed to the gentler impulses of the human spirit.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="appealed" lemma="appeal" stem="appeal" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="gentler" lemma="gentler" stem="gentler" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="impulses" lemma="impulse" stem="impuls" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="human" lemma="human" stem="human" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="spirit" lemma="spirit" stem="spirit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VBD appealed) (PP (TO to) (NP (NP (DT the) (JJR gentler) (NNS impulses)) (PP (IN of) (NP (DT the) (JJ human) (NN spirit)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the gentler impulses" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="gentler" />
            <token id="6" string="impulses" />
          </tokens>
        </chunking>
        <chunking id="2" string="the human spirit" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="human" />
            <token id="10" string="spirit" />
          </tokens>
        </chunking>
        <chunking id="3" string="the gentler impulses of the human spirit" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="gentler" />
            <token id="6" string="impulses" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="human" />
            <token id="10" string="spirit" />
          </tokens>
        </chunking>
        <chunking id="4" string="appealed to the gentler impulses of the human spirit" type="VP">
          <tokens>
            <token id="2" string="appealed" />
            <token id="3" string="to" />
            <token id="4" string="the" />
            <token id="5" string="gentler" />
            <token id="6" string="impulses" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="human" />
            <token id="10" string="spirit" />
          </tokens>
        </chunking>
        <chunking id="5" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">appealed</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">appealed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">impulses</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">impulses</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">impulses</governor>
          <dependent id="5">gentler</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">appealed</governor>
          <dependent id="6">impulses</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">spirit</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">spirit</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">spirit</governor>
          <dependent id="9">human</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">impulses</governor>
          <dependent id="10">spirit</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="47" has_coreference="true">
      <content>She was not merely an actress or comedienne.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="merely" lemma="merely" stem="mere" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="actress" lemma="actress" stem="actress" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="comedienne" lemma="comedienne" stem="comedienn" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VBD was) (RB not) (ADVP (RB merely)) (NP (DT an) (NN actress) (CC or) (NN comedienne))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was not merely an actress or comedienne" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="not" />
            <token id="4" string="merely" />
            <token id="5" string="an" />
            <token id="6" string="actress" />
            <token id="7" string="or" />
            <token id="8" string="comedienne" />
          </tokens>
        </chunking>
        <chunking id="2" string="an actress or comedienne" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="actress" />
            <token id="7" string="or" />
            <token id="8" string="comedienne" />
          </tokens>
        </chunking>
        <chunking id="3" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">actress</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">actress</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">actress</governor>
          <dependent id="3">not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">actress</governor>
          <dependent id="4">merely</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">actress</governor>
          <dependent id="5">an</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">actress</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">actress</governor>
          <dependent id="7">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">actress</governor>
          <dependent id="8">comedienne</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="48" has_coreference="true">
      <content>She was Lucy and she was loved.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="loved" lemma="love" stem="love" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP She)) (VP (VBD was) (NP (NNP Lucy)))) (CC and) (S (NP (PRP she)) (VP (VBD was) (VP (VBN loved)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="was loved" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="loved" />
          </tokens>
        </chunking>
        <chunking id="2" string="loved" type="VP">
          <tokens>
            <token id="7" string="loved" />
          </tokens>
        </chunking>
        <chunking id="3" string="was Lucy" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="4" string="Lucy" type="NP">
          <tokens>
            <token id="3" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="5" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="6" string="she" type="NP">
          <tokens>
            <token id="5" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">Lucy</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="3">Lucy</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">Lucy</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">Lucy</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">loved</governor>
          <dependent id="5">she</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">loved</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">Lucy</governor>
          <dependent id="7">loved</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Lucy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="49" has_coreference="true">
      <content>``To baby boomers, a happy chunk of our childhood is missing,&amp;apost;&amp;apost; said ``Saturday Night Live&amp;apost;&amp;apost; comedian Victoria Jackson, who was born two years after ``I Love Lucy&amp;apost;&amp;apost; went off the air as a regular series.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="To" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="baby" lemma="baby" stem="babi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="boomers" lemma="boomer" stem="boomer" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="happy" lemma="happy" stem="happi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="chunk" lemma="chunk" stem="chunk" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="childhood" lemma="childhood" stem="childhood" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="missing" lemma="miss" stem="miss" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Saturday" lemma="Saturday" stem="saturdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="19" string="Night" lemma="Night" stem="night" pos="NNP" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="20" string="Live" lemma="Live" stem="live" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="comedian" lemma="comedian" stem="comedian" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="Victoria" lemma="Victoria" stem="victoria" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="24" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="born" lemma="bear" stem="born" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="30" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="31" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="32" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="34" string="Love" lemma="Love" stem="love" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="35" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="36" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="37" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="38" string="off" lemma="off" stem="off" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="39" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="40" string="air" lemma="air" stem="air" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="41" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="42" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="43" string="regular" lemma="regular" stem="regular" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="44" string="series" lemma="series" stem="seri" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="45" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (PP (TO To) (NP (NN baby) (NNS boomers))) (, ,) (NP (NP (DT a) (JJ happy) (NN chunk)) (PP (IN of) (NP (PRP$ our) (NN childhood)))) (VP (VBZ is) (ADJP (VBG missing)))) (, ,) ('' '') (VP (VBD said) (`` ``) (NP (NNP Saturday) (NNP Night) (NNP Live)) ('' '')) (NP (NP (NN comedian) (NNP Victoria) (NNP Jackson)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD was) (VP (VBN born) (SBAR (NP (CD two) (NNS years)) (IN after) (S (`` ``) (NP (NP (PRP I)) (NP (NNP Love) (NNP Lucy))) ('' '') (VP (VBD went) (PP (IN off) (NP (DT the) (NN air))) (PP (IN as) (NP (DT a) (JJ regular) (NN series))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="our childhood" type="NP">
          <tokens>
            <token id="10" string="our" />
            <token id="11" string="childhood" />
          </tokens>
        </chunking>
        <chunking id="2" string="Saturday Night Live" type="NP">
          <tokens>
            <token id="18" string="Saturday" />
            <token id="19" string="Night" />
            <token id="20" string="Live" />
          </tokens>
        </chunking>
        <chunking id="3" string="who was born two years after `` I Love Lucy '' went off the air as a regular series" type="SBAR">
          <tokens>
            <token id="26" string="who" />
            <token id="27" string="was" />
            <token id="28" string="born" />
            <token id="29" string="two" />
            <token id="30" string="years" />
            <token id="31" string="after" />
            <token id="32" string="``" />
            <token id="33" string="I" />
            <token id="34" string="Love" />
            <token id="35" string="Lucy" />
            <token id="36" string="''" />
            <token id="37" string="went" />
            <token id="38" string="off" />
            <token id="39" string="the" />
            <token id="40" string="air" />
            <token id="41" string="as" />
            <token id="42" string="a" />
            <token id="43" string="regular" />
            <token id="44" string="series" />
          </tokens>
        </chunking>
        <chunking id="4" string="comedian Victoria Jackson , who was born two years after `` I Love Lucy '' went off the air as a regular series" type="NP">
          <tokens>
            <token id="22" string="comedian" />
            <token id="23" string="Victoria" />
            <token id="24" string="Jackson" />
            <token id="25" string="," />
            <token id="26" string="who" />
            <token id="27" string="was" />
            <token id="28" string="born" />
            <token id="29" string="two" />
            <token id="30" string="years" />
            <token id="31" string="after" />
            <token id="32" string="``" />
            <token id="33" string="I" />
            <token id="34" string="Love" />
            <token id="35" string="Lucy" />
            <token id="36" string="''" />
            <token id="37" string="went" />
            <token id="38" string="off" />
            <token id="39" string="the" />
            <token id="40" string="air" />
            <token id="41" string="as" />
            <token id="42" string="a" />
            <token id="43" string="regular" />
            <token id="44" string="series" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="33" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="I Love Lucy" type="NP">
          <tokens>
            <token id="33" string="I" />
            <token id="34" string="Love" />
            <token id="35" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="7" string="is missing" type="VP">
          <tokens>
            <token id="12" string="is" />
            <token id="13" string="missing" />
          </tokens>
        </chunking>
        <chunking id="8" string="baby boomers" type="NP">
          <tokens>
            <token id="3" string="baby" />
            <token id="4" string="boomers" />
          </tokens>
        </chunking>
        <chunking id="9" string="the air" type="NP">
          <tokens>
            <token id="39" string="the" />
            <token id="40" string="air" />
          </tokens>
        </chunking>
        <chunking id="10" string="a happy chunk" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="happy" />
            <token id="8" string="chunk" />
          </tokens>
        </chunking>
        <chunking id="11" string="born two years after `` I Love Lucy '' went off the air as a regular series" type="VP">
          <tokens>
            <token id="28" string="born" />
            <token id="29" string="two" />
            <token id="30" string="years" />
            <token id="31" string="after" />
            <token id="32" string="``" />
            <token id="33" string="I" />
            <token id="34" string="Love" />
            <token id="35" string="Lucy" />
            <token id="36" string="''" />
            <token id="37" string="went" />
            <token id="38" string="off" />
            <token id="39" string="the" />
            <token id="40" string="air" />
            <token id="41" string="as" />
            <token id="42" string="a" />
            <token id="43" string="regular" />
            <token id="44" string="series" />
          </tokens>
        </chunking>
        <chunking id="12" string="was born two years after `` I Love Lucy '' went off the air as a regular series" type="VP">
          <tokens>
            <token id="27" string="was" />
            <token id="28" string="born" />
            <token id="29" string="two" />
            <token id="30" string="years" />
            <token id="31" string="after" />
            <token id="32" string="``" />
            <token id="33" string="I" />
            <token id="34" string="Love" />
            <token id="35" string="Lucy" />
            <token id="36" string="''" />
            <token id="37" string="went" />
            <token id="38" string="off" />
            <token id="39" string="the" />
            <token id="40" string="air" />
            <token id="41" string="as" />
            <token id="42" string="a" />
            <token id="43" string="regular" />
            <token id="44" string="series" />
          </tokens>
        </chunking>
        <chunking id="13" string="two years" type="NP">
          <tokens>
            <token id="29" string="two" />
            <token id="30" string="years" />
          </tokens>
        </chunking>
        <chunking id="14" string="comedian Victoria Jackson" type="NP">
          <tokens>
            <token id="22" string="comedian" />
            <token id="23" string="Victoria" />
            <token id="24" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="15" string="went off the air as a regular series" type="VP">
          <tokens>
            <token id="37" string="went" />
            <token id="38" string="off" />
            <token id="39" string="the" />
            <token id="40" string="air" />
            <token id="41" string="as" />
            <token id="42" string="a" />
            <token id="43" string="regular" />
            <token id="44" string="series" />
          </tokens>
        </chunking>
        <chunking id="16" string="said `` Saturday Night Live ''" type="VP">
          <tokens>
            <token id="16" string="said" />
            <token id="17" string="``" />
            <token id="18" string="Saturday" />
            <token id="19" string="Night" />
            <token id="20" string="Live" />
            <token id="21" string="''" />
          </tokens>
        </chunking>
        <chunking id="17" string="a regular series" type="NP">
          <tokens>
            <token id="42" string="a" />
            <token id="43" string="regular" />
            <token id="44" string="series" />
          </tokens>
        </chunking>
        <chunking id="18" string="a happy chunk of our childhood" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="happy" />
            <token id="8" string="chunk" />
            <token id="9" string="of" />
            <token id="10" string="our" />
            <token id="11" string="childhood" />
          </tokens>
        </chunking>
        <chunking id="19" string="missing" type="ADJP">
          <tokens>
            <token id="13" string="missing" />
          </tokens>
        </chunking>
        <chunking id="20" string="two years after `` I Love Lucy '' went off the air as a regular series" type="SBAR">
          <tokens>
            <token id="29" string="two" />
            <token id="30" string="years" />
            <token id="31" string="after" />
            <token id="32" string="``" />
            <token id="33" string="I" />
            <token id="34" string="Love" />
            <token id="35" string="Lucy" />
            <token id="36" string="''" />
            <token id="37" string="went" />
            <token id="38" string="off" />
            <token id="39" string="the" />
            <token id="40" string="air" />
            <token id="41" string="as" />
            <token id="42" string="a" />
            <token id="43" string="regular" />
            <token id="44" string="series" />
          </tokens>
        </chunking>
        <chunking id="21" string="Love Lucy" type="NP">
          <tokens>
            <token id="34" string="Love" />
            <token id="35" string="Lucy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">boomers</governor>
          <dependent id="2">To</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">boomers</governor>
          <dependent id="3">baby</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">missing</governor>
          <dependent id="4">boomers</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">chunk</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">chunk</governor>
          <dependent id="7">happy</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">missing</governor>
          <dependent id="8">chunk</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">childhood</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">childhood</governor>
          <dependent id="10">our</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">chunk</governor>
          <dependent id="11">childhood</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">missing</governor>
          <dependent id="12">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">said</governor>
          <dependent id="13">missing</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Live</governor>
          <dependent id="18">Saturday</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Live</governor>
          <dependent id="19">Night</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">said</governor>
          <dependent id="20">Live</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Jackson</governor>
          <dependent id="22">comedian</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Jackson</governor>
          <dependent id="23">Victoria</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">said</governor>
          <dependent id="24">Jackson</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="28">born</governor>
          <dependent id="26">who</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="28">born</governor>
          <dependent id="27">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="24">Jackson</governor>
          <dependent id="28">born</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="30">years</governor>
          <dependent id="29">two</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="37">went</governor>
          <dependent id="30">years</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="37">went</governor>
          <dependent id="31">after</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="37">went</governor>
          <dependent id="33">I</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Lucy</governor>
          <dependent id="34">Love</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="33">I</governor>
          <dependent id="35">Lucy</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="28">born</governor>
          <dependent id="37">went</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">air</governor>
          <dependent id="38">off</dependent>
        </dependency>
        <dependency type="det">
          <governor id="40">air</governor>
          <dependent id="39">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="37">went</governor>
          <dependent id="40">air</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">series</governor>
          <dependent id="41">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="44">series</governor>
          <dependent id="42">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="44">series</governor>
          <dependent id="43">regular</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="37">went</governor>
          <dependent id="44">series</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="two years" type="DURATION" score="0.0">
          <tokens>
            <token id="29" string="two" />
            <token id="30" string="years" />
          </tokens>
        </entity>
        <entity id="2" string="Night" type="TIME" score="0.0">
          <tokens>
            <token id="19" string="Night" />
          </tokens>
        </entity>
        <entity id="3" string="Victoria Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Victoria" />
            <token id="24" string="Jackson" />
          </tokens>
        </entity>
        <entity id="4" string="Saturday" type="DATE" score="0.0">
          <tokens>
            <token id="18" string="Saturday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="50" has_coreference="true">
      <content>``She didn&amp;apost;t make me laugh out loud, I remember, she just made me happy about life.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="laugh" lemma="laugh" stem="laugh" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="out" lemma="out" stem="out" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="loud" lemma="loud" stem="loud" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="remember" lemma="remember" stem="rememb" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="happy" lemma="happy" stem="happi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP She)) (VP (VBD did) (RB n't) (VP (VB make) (S (NP (PRP me)) (VP (NN laugh) (ADVP (RB out) (RB loud))))))) (PRN (, ,) (S (NP (PRP I)) (VP (VBP remember))) (, ,)) (S (NP (PRP she)) (ADVP (RB just)) (VP (VBD made) (S (NP (PRP me)) (ADJP (JJ happy) (PP (IN about) (NP (NN life))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="laugh out loud" type="VP">
          <tokens>
            <token id="7" string="laugh" />
            <token id="8" string="out" />
            <token id="9" string="loud" />
          </tokens>
        </chunking>
        <chunking id="2" string="remember" type="VP">
          <tokens>
            <token id="12" string="remember" />
          </tokens>
        </chunking>
        <chunking id="3" string="make me laugh out loud" type="VP">
          <tokens>
            <token id="5" string="make" />
            <token id="6" string="me" />
            <token id="7" string="laugh" />
            <token id="8" string="out" />
            <token id="9" string="loud" />
          </tokens>
        </chunking>
        <chunking id="4" string="me" type="NP">
          <tokens>
            <token id="6" string="me" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="11" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="made me happy about life" type="VP">
          <tokens>
            <token id="16" string="made" />
            <token id="17" string="me" />
            <token id="18" string="happy" />
            <token id="19" string="about" />
            <token id="20" string="life" />
          </tokens>
        </chunking>
        <chunking id="7" string="happy about life" type="ADJP">
          <tokens>
            <token id="18" string="happy" />
            <token id="19" string="about" />
            <token id="20" string="life" />
          </tokens>
        </chunking>
        <chunking id="8" string="life" type="NP">
          <tokens>
            <token id="20" string="life" />
          </tokens>
        </chunking>
        <chunking id="9" string="did n't make me laugh out loud" type="VP">
          <tokens>
            <token id="3" string="did" />
            <token id="4" string="n't" />
            <token id="5" string="make" />
            <token id="6" string="me" />
            <token id="7" string="laugh" />
            <token id="8" string="out" />
            <token id="9" string="loud" />
          </tokens>
        </chunking>
        <chunking id="10" string="She" type="NP">
          <tokens>
            <token id="2" string="She" />
          </tokens>
        </chunking>
        <chunking id="11" string="she" type="NP">
          <tokens>
            <token id="14" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">make</governor>
          <dependent id="2">She</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">make</governor>
          <dependent id="3">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">make</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">make</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">laugh</governor>
          <dependent id="6">me</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">make</governor>
          <dependent id="7">laugh</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">loud</governor>
          <dependent id="8">out</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">laugh</governor>
          <dependent id="9">loud</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">remember</governor>
          <dependent id="11">I</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">make</governor>
          <dependent id="12">remember</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">made</governor>
          <dependent id="14">she</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">made</governor>
          <dependent id="15">just</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="5">make</governor>
          <dependent id="16">made</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">happy</governor>
          <dependent id="17">me</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">made</governor>
          <dependent id="18">happy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">life</governor>
          <dependent id="19">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">happy</governor>
          <dependent id="20">life</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="51" has_coreference="true">
      <content>Said comic Tim Conway: ``We&amp;apost;re going to miss this lady, but not really, because she&amp;apost;s still here.</content>
      <tokens>
        <token id="1" string="Said" lemma="Said" stem="said" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="comic" lemma="comic" stem="comic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Tim" lemma="Tim" stem="tim" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="Conway" lemma="Conway" stem="conwai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="5" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="miss" lemma="miss" stem="miss" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="lady" lemma="lady" stem="ladi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="here" lemma="here" stem="here" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NP (NNP Said)) (NP (JJ comic) (NNP Tim) (NNP Conway))) (: :) (S (`` ``) (NP (PRP We)) (VP (VBP 're) (VP (VBG going) (S (VP (TO to) (VP (VB miss) (NP (NP (DT this) (NN lady)) (, ,) (CONJP (CC but) (RB not)) (NP (ADVP (RB really)) (, ,) (SBAR (IN because) (S (NP (PRP she)) (VP (VBZ 's) (ADVP (RB still)) (ADVP (RB here))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="comic Tim Conway" type="NP">
          <tokens>
            <token id="2" string="comic" />
            <token id="3" string="Tim" />
            <token id="4" string="Conway" />
          </tokens>
        </chunking>
        <chunking id="2" string="really , because she 's still here" type="NP">
          <tokens>
            <token id="17" string="really" />
            <token id="18" string="," />
            <token id="19" string="because" />
            <token id="20" string="she" />
            <token id="21" string="'s" />
            <token id="22" string="still" />
            <token id="23" string="here" />
          </tokens>
        </chunking>
        <chunking id="3" string="to miss this lady , but not really , because she 's still here" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="miss" />
            <token id="12" string="this" />
            <token id="13" string="lady" />
            <token id="14" string="," />
            <token id="15" string="but" />
            <token id="16" string="not" />
            <token id="17" string="really" />
            <token id="18" string="," />
            <token id="19" string="because" />
            <token id="20" string="she" />
            <token id="21" string="'s" />
            <token id="22" string="still" />
            <token id="23" string="here" />
          </tokens>
        </chunking>
        <chunking id="4" string="because she 's still here" type="SBAR">
          <tokens>
            <token id="19" string="because" />
            <token id="20" string="she" />
            <token id="21" string="'s" />
            <token id="22" string="still" />
            <token id="23" string="here" />
          </tokens>
        </chunking>
        <chunking id="5" string="Said comic Tim Conway : `` We 're going to miss this lady , but not really , because she 's still here ." type="NP">
          <tokens>
            <token id="1" string="Said" />
            <token id="2" string="comic" />
            <token id="3" string="Tim" />
            <token id="4" string="Conway" />
            <token id="5" string=":" />
            <token id="6" string="``" />
            <token id="7" string="We" />
            <token id="8" string="'re" />
            <token id="9" string="going" />
            <token id="10" string="to" />
            <token id="11" string="miss" />
            <token id="12" string="this" />
            <token id="13" string="lady" />
            <token id="14" string="," />
            <token id="15" string="but" />
            <token id="16" string="not" />
            <token id="17" string="really" />
            <token id="18" string="," />
            <token id="19" string="because" />
            <token id="20" string="she" />
            <token id="21" string="'s" />
            <token id="22" string="still" />
            <token id="23" string="here" />
            <token id="24" string="." />
          </tokens>
        </chunking>
        <chunking id="6" string="this lady , but not really , because she 's still here" type="NP">
          <tokens>
            <token id="12" string="this" />
            <token id="13" string="lady" />
            <token id="14" string="," />
            <token id="15" string="but" />
            <token id="16" string="not" />
            <token id="17" string="really" />
            <token id="18" string="," />
            <token id="19" string="because" />
            <token id="20" string="she" />
            <token id="21" string="'s" />
            <token id="22" string="still" />
            <token id="23" string="here" />
          </tokens>
        </chunking>
        <chunking id="7" string="Said comic Tim Conway" type="NP">
          <tokens>
            <token id="1" string="Said" />
            <token id="2" string="comic" />
            <token id="3" string="Tim" />
            <token id="4" string="Conway" />
          </tokens>
        </chunking>
        <chunking id="8" string="We" type="NP">
          <tokens>
            <token id="7" string="We" />
          </tokens>
        </chunking>
        <chunking id="9" string="'re going to miss this lady , but not really , because she 's still here" type="VP">
          <tokens>
            <token id="8" string="'re" />
            <token id="9" string="going" />
            <token id="10" string="to" />
            <token id="11" string="miss" />
            <token id="12" string="this" />
            <token id="13" string="lady" />
            <token id="14" string="," />
            <token id="15" string="but" />
            <token id="16" string="not" />
            <token id="17" string="really" />
            <token id="18" string="," />
            <token id="19" string="because" />
            <token id="20" string="she" />
            <token id="21" string="'s" />
            <token id="22" string="still" />
            <token id="23" string="here" />
          </tokens>
        </chunking>
        <chunking id="10" string="she" type="NP">
          <tokens>
            <token id="20" string="she" />
          </tokens>
        </chunking>
        <chunking id="11" string="'s still here" type="VP">
          <tokens>
            <token id="21" string="'s" />
            <token id="22" string="still" />
            <token id="23" string="here" />
          </tokens>
        </chunking>
        <chunking id="12" string="Said" type="NP">
          <tokens>
            <token id="1" string="Said" />
          </tokens>
        </chunking>
        <chunking id="13" string="miss this lady , but not really , because she 's still here" type="VP">
          <tokens>
            <token id="11" string="miss" />
            <token id="12" string="this" />
            <token id="13" string="lady" />
            <token id="14" string="," />
            <token id="15" string="but" />
            <token id="16" string="not" />
            <token id="17" string="really" />
            <token id="18" string="," />
            <token id="19" string="because" />
            <token id="20" string="she" />
            <token id="21" string="'s" />
            <token id="22" string="still" />
            <token id="23" string="here" />
          </tokens>
        </chunking>
        <chunking id="14" string="this lady" type="NP">
          <tokens>
            <token id="12" string="this" />
            <token id="13" string="lady" />
          </tokens>
        </chunking>
        <chunking id="15" string="going to miss this lady , but not really , because she 's still here" type="VP">
          <tokens>
            <token id="9" string="going" />
            <token id="10" string="to" />
            <token id="11" string="miss" />
            <token id="12" string="this" />
            <token id="13" string="lady" />
            <token id="14" string="," />
            <token id="15" string="but" />
            <token id="16" string="not" />
            <token id="17" string="really" />
            <token id="18" string="," />
            <token id="19" string="because" />
            <token id="20" string="she" />
            <token id="21" string="'s" />
            <token id="22" string="still" />
            <token id="23" string="here" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">Said</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">Conway</governor>
          <dependent id="2">comic</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Conway</governor>
          <dependent id="3">Tim</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">Said</governor>
          <dependent id="4">Conway</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">going</governor>
          <dependent id="7">We</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">going</governor>
          <dependent id="8">'re</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="1">Said</governor>
          <dependent id="9">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">miss</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">going</governor>
          <dependent id="11">miss</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">lady</governor>
          <dependent id="12">this</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">miss</governor>
          <dependent id="13">lady</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">not</governor>
          <dependent id="15">but</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">lady</governor>
          <dependent id="16">not</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">lady</governor>
          <dependent id="17">really</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">'s</governor>
          <dependent id="19">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">'s</governor>
          <dependent id="20">she</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">really</governor>
          <dependent id="21">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">'s</governor>
          <dependent id="22">still</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">'s</governor>
          <dependent id="23">here</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Tim Conway" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Tim" />
            <token id="4" string="Conway" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="52" has_coreference="true">
      <content>All those wonderful things they did together ... those wonderful TV shows ... are still available.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="All" lemma="all" stem="all" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="wonderful" lemma="wonderful" stem="wonder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="things" lemma="thing" stem="thing" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="together" lemma="together" stem="togeth" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="..." lemma="..." stem="..." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="wonderful" lemma="wonderful" stem="wonder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="TV" lemma="tv" stem="tv" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="shows" lemma="show" stem="show" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="..." lemma="..." stem="..." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="available" lemma="available" stem="avail" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (PDT All) (DT those) (JJ wonderful) (NNS things)) (NP (PRP they))) (VP (VBD did) (ADVP (RB together)))) (: ...) (S (NP (NP (DT those) (JJ wonderful) (NN TV)) (NP (NNS shows))) (: ...) (VP (VBP are) (ADVP (RB still)) (ADJP (JJ available)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="shows" type="NP">
          <tokens>
            <token id="12" string="shows" />
          </tokens>
        </chunking>
        <chunking id="2" string="they" type="NP">
          <tokens>
            <token id="5" string="they" />
          </tokens>
        </chunking>
        <chunking id="3" string="those wonderful TV shows" type="NP">
          <tokens>
            <token id="9" string="those" />
            <token id="10" string="wonderful" />
            <token id="11" string="TV" />
            <token id="12" string="shows" />
          </tokens>
        </chunking>
        <chunking id="4" string="those wonderful TV" type="NP">
          <tokens>
            <token id="9" string="those" />
            <token id="10" string="wonderful" />
            <token id="11" string="TV" />
          </tokens>
        </chunking>
        <chunking id="5" string="are still available" type="VP">
          <tokens>
            <token id="14" string="are" />
            <token id="15" string="still" />
            <token id="16" string="available" />
          </tokens>
        </chunking>
        <chunking id="6" string="All those wonderful things they" type="NP">
          <tokens>
            <token id="1" string="All" />
            <token id="2" string="those" />
            <token id="3" string="wonderful" />
            <token id="4" string="things" />
            <token id="5" string="they" />
          </tokens>
        </chunking>
        <chunking id="7" string="All those wonderful things" type="NP">
          <tokens>
            <token id="1" string="All" />
            <token id="2" string="those" />
            <token id="3" string="wonderful" />
            <token id="4" string="things" />
          </tokens>
        </chunking>
        <chunking id="8" string="available" type="ADJP">
          <tokens>
            <token id="16" string="available" />
          </tokens>
        </chunking>
        <chunking id="9" string="did together" type="VP">
          <tokens>
            <token id="6" string="did" />
            <token id="7" string="together" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det:predet">
          <governor id="4">things</governor>
          <dependent id="1">All</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">things</governor>
          <dependent id="2">those</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">things</governor>
          <dependent id="3">wonderful</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">did</governor>
          <dependent id="4">things</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">things</governor>
          <dependent id="5">they</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">did</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">did</governor>
          <dependent id="7">together</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">TV</governor>
          <dependent id="9">those</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">TV</governor>
          <dependent id="10">wonderful</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">available</governor>
          <dependent id="11">TV</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">TV</governor>
          <dependent id="12">shows</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">available</governor>
          <dependent id="14">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">available</governor>
          <dependent id="15">still</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="6">did</governor>
          <dependent id="16">available</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="53" has_coreference="true">
      <content>Although Miss Ball hadn&amp;apost;t visited her hometown of Jamestown, N.Y, since 1956 and had no family there, she had stayed in touch with friends.</content>
      <tokens>
        <token id="1" string="Although" lemma="although" stem="although" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="visited" lemma="visit" stem="visit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="hometown" lemma="hometown" stem="hometown" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Jamestown" lemma="Jamestown" stem="jamestown" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="N.Y" lemma="N.Y" stem="n.y" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="1956" lemma="1956" stem="1956" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="there" lemma="there" stem="there" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="stayed" lemma="stay" stem="stai" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="touch" lemma="touch" stem="touch" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="friends" lemma="friend" stem="friend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Although) (S (NP (NNP Miss) (NNP Ball)) (VP (VP (VBD had) (RB n't) (VP (VBN visited) (NP (NP (PRP$ her) (NN hometown)) (PP (IN of) (NP (NNP Jamestown) (, ,) (NNP N.Y) (, ,)))) (PP (IN since) (NP (CD 1956))))) (CC and) (VP (VBD had) (NP (DT no) (NN family)) (ADVP (RB there)))))) (, ,) (NP (PRP she)) (VP (VBD had) (VP (VBN stayed) (PP (IN in) (NP (NN touch))) (PP (IN with) (NP (NNS friends))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="her hometown" type="NP">
          <tokens>
            <token id="7" string="her" />
            <token id="8" string="hometown" />
          </tokens>
        </chunking>
        <chunking id="2" string="stayed in touch with friends" type="VP">
          <tokens>
            <token id="24" string="stayed" />
            <token id="25" string="in" />
            <token id="26" string="touch" />
            <token id="27" string="with" />
            <token id="28" string="friends" />
          </tokens>
        </chunking>
        <chunking id="3" string="visited her hometown of Jamestown , N.Y , since 1956" type="VP">
          <tokens>
            <token id="6" string="visited" />
            <token id="7" string="her" />
            <token id="8" string="hometown" />
            <token id="9" string="of" />
            <token id="10" string="Jamestown" />
            <token id="11" string="," />
            <token id="12" string="N.Y" />
            <token id="13" string="," />
            <token id="14" string="since" />
            <token id="15" string="1956" />
          </tokens>
        </chunking>
        <chunking id="4" string="had stayed in touch with friends" type="VP">
          <tokens>
            <token id="23" string="had" />
            <token id="24" string="stayed" />
            <token id="25" string="in" />
            <token id="26" string="touch" />
            <token id="27" string="with" />
            <token id="28" string="friends" />
          </tokens>
        </chunking>
        <chunking id="5" string="touch" type="NP">
          <tokens>
            <token id="26" string="touch" />
          </tokens>
        </chunking>
        <chunking id="6" string="Jamestown , N.Y ," type="NP">
          <tokens>
            <token id="10" string="Jamestown" />
            <token id="11" string="," />
            <token id="12" string="N.Y" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="no family" type="NP">
          <tokens>
            <token id="18" string="no" />
            <token id="19" string="family" />
          </tokens>
        </chunking>
        <chunking id="8" string="she" type="NP">
          <tokens>
            <token id="22" string="she" />
          </tokens>
        </chunking>
        <chunking id="9" string="friends" type="NP">
          <tokens>
            <token id="28" string="friends" />
          </tokens>
        </chunking>
        <chunking id="10" string="had n't visited her hometown of Jamestown , N.Y , since 1956" type="VP">
          <tokens>
            <token id="4" string="had" />
            <token id="5" string="n't" />
            <token id="6" string="visited" />
            <token id="7" string="her" />
            <token id="8" string="hometown" />
            <token id="9" string="of" />
            <token id="10" string="Jamestown" />
            <token id="11" string="," />
            <token id="12" string="N.Y" />
            <token id="13" string="," />
            <token id="14" string="since" />
            <token id="15" string="1956" />
          </tokens>
        </chunking>
        <chunking id="11" string="her hometown of Jamestown , N.Y ," type="NP">
          <tokens>
            <token id="7" string="her" />
            <token id="8" string="hometown" />
            <token id="9" string="of" />
            <token id="10" string="Jamestown" />
            <token id="11" string="," />
            <token id="12" string="N.Y" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="12" string="had n't visited her hometown of Jamestown , N.Y , since 1956 and had no family there" type="VP">
          <tokens>
            <token id="4" string="had" />
            <token id="5" string="n't" />
            <token id="6" string="visited" />
            <token id="7" string="her" />
            <token id="8" string="hometown" />
            <token id="9" string="of" />
            <token id="10" string="Jamestown" />
            <token id="11" string="," />
            <token id="12" string="N.Y" />
            <token id="13" string="," />
            <token id="14" string="since" />
            <token id="15" string="1956" />
            <token id="16" string="and" />
            <token id="17" string="had" />
            <token id="18" string="no" />
            <token id="19" string="family" />
            <token id="20" string="there" />
          </tokens>
        </chunking>
        <chunking id="13" string="had no family there" type="VP">
          <tokens>
            <token id="17" string="had" />
            <token id="18" string="no" />
            <token id="19" string="family" />
            <token id="20" string="there" />
          </tokens>
        </chunking>
        <chunking id="14" string="Although Miss Ball had n't visited her hometown of Jamestown , N.Y , since 1956 and had no family there" type="SBAR">
          <tokens>
            <token id="1" string="Although" />
            <token id="2" string="Miss" />
            <token id="3" string="Ball" />
            <token id="4" string="had" />
            <token id="5" string="n't" />
            <token id="6" string="visited" />
            <token id="7" string="her" />
            <token id="8" string="hometown" />
            <token id="9" string="of" />
            <token id="10" string="Jamestown" />
            <token id="11" string="," />
            <token id="12" string="N.Y" />
            <token id="13" string="," />
            <token id="14" string="since" />
            <token id="15" string="1956" />
            <token id="16" string="and" />
            <token id="17" string="had" />
            <token id="18" string="no" />
            <token id="19" string="family" />
            <token id="20" string="there" />
          </tokens>
        </chunking>
        <chunking id="15" string="Miss Ball" type="NP">
          <tokens>
            <token id="2" string="Miss" />
            <token id="3" string="Ball" />
          </tokens>
        </chunking>
        <chunking id="16" string="1956" type="NP">
          <tokens>
            <token id="15" string="1956" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="6">visited</governor>
          <dependent id="1">Although</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Ball</governor>
          <dependent id="2">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">visited</governor>
          <dependent id="3">Ball</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">visited</governor>
          <dependent id="4">had</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">visited</governor>
          <dependent id="5">n't</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="24">stayed</governor>
          <dependent id="6">visited</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">hometown</governor>
          <dependent id="7">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">visited</governor>
          <dependent id="8">hometown</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">N.Y</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">N.Y</governor>
          <dependent id="10">Jamestown</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">hometown</governor>
          <dependent id="12">N.Y</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">1956</governor>
          <dependent id="14">since</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">visited</governor>
          <dependent id="15">1956</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">visited</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">visited</governor>
          <dependent id="17">had</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="19">family</governor>
          <dependent id="18">no</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">had</governor>
          <dependent id="19">family</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">had</governor>
          <dependent id="20">there</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">stayed</governor>
          <dependent id="22">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">stayed</governor>
          <dependent id="23">had</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="24">stayed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">touch</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">stayed</governor>
          <dependent id="26">touch</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">friends</governor>
          <dependent id="27">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">stayed</governor>
          <dependent id="28">friends</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jamestown" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="Jamestown" />
          </tokens>
        </entity>
        <entity id="2" string="Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Ball" />
          </tokens>
        </entity>
        <entity id="3" string="N.Y" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="N.Y" />
          </tokens>
        </entity>
        <entity id="4" string="1956" type="DATE" score="0.0">
          <tokens>
            <token id="15" string="1956" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="54" has_coreference="true">
      <content>Irene Rosseti, who now lives in Celoron, N.Y., said Miss Ball recently had sent her and her husband a letter on their 50th wedding anniversary.</content>
      <tokens>
        <token id="1" string="Irene" lemma="Irene" stem="irene" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Rosseti" lemma="Rosseti" stem="rosseti" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="lives" lemma="live" stem="live" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Celoron" lemma="Celoron" stem="celoron" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="N.Y." lemma="N.Y." stem="n.y." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="recently" lemma="recently" stem="recent" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="sent" lemma="send" stem="sent" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="husband" lemma="husband" stem="husband" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="letter" lemma="letter" stem="letter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="50th" lemma="50th" stem="50th" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="27" string="wedding" lemma="wedding" stem="wed" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="anniversary" lemma="anniversary" stem="anniversari" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Irene) (NNP Rosseti)) (, ,) (SBAR (WHNP (WP who)) (S (ADVP (RB now)) (VP (VBZ lives) (PP (IN in) (NP (NNP Celoron) (, ,) (NNP N.Y.)))))) (, ,)) (VP (VBD said) (SBAR (S (NP (NNP Miss) (NNP Ball)) (ADVP (RB recently)) (VP (VBD had) (VP (VBN sent) (NP (ADJP (PRP$ her) (CC and) (PRP$ her)) (NN husband)) (NP (NP (DT a) (NN letter)) (PP (IN on) (NP (PRP$ their) (JJ 50th) (NN wedding) (NN anniversary))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Celoron , N.Y." type="NP">
          <tokens>
            <token id="8" string="Celoron" />
            <token id="9" string="," />
            <token id="10" string="N.Y." />
          </tokens>
        </chunking>
        <chunking id="2" string="her and her" type="ADJP">
          <tokens>
            <token id="18" string="her" />
            <token id="19" string="and" />
            <token id="20" string="her" />
          </tokens>
        </chunking>
        <chunking id="3" string="Miss Ball recently had sent her and her husband a letter on their 50th wedding anniversary" type="SBAR">
          <tokens>
            <token id="13" string="Miss" />
            <token id="14" string="Ball" />
            <token id="15" string="recently" />
            <token id="16" string="had" />
            <token id="17" string="sent" />
            <token id="18" string="her" />
            <token id="19" string="and" />
            <token id="20" string="her" />
            <token id="21" string="husband" />
            <token id="22" string="a" />
            <token id="23" string="letter" />
            <token id="24" string="on" />
            <token id="25" string="their" />
            <token id="26" string="50th" />
            <token id="27" string="wedding" />
            <token id="28" string="anniversary" />
          </tokens>
        </chunking>
        <chunking id="4" string="a letter on their 50th wedding anniversary" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="letter" />
            <token id="24" string="on" />
            <token id="25" string="their" />
            <token id="26" string="50th" />
            <token id="27" string="wedding" />
            <token id="28" string="anniversary" />
          </tokens>
        </chunking>
        <chunking id="5" string="sent her and her husband a letter on their 50th wedding anniversary" type="VP">
          <tokens>
            <token id="17" string="sent" />
            <token id="18" string="her" />
            <token id="19" string="and" />
            <token id="20" string="her" />
            <token id="21" string="husband" />
            <token id="22" string="a" />
            <token id="23" string="letter" />
            <token id="24" string="on" />
            <token id="25" string="their" />
            <token id="26" string="50th" />
            <token id="27" string="wedding" />
            <token id="28" string="anniversary" />
          </tokens>
        </chunking>
        <chunking id="6" string="a letter" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="letter" />
          </tokens>
        </chunking>
        <chunking id="7" string="who now lives in Celoron , N.Y." type="SBAR">
          <tokens>
            <token id="4" string="who" />
            <token id="5" string="now" />
            <token id="6" string="lives" />
            <token id="7" string="in" />
            <token id="8" string="Celoron" />
            <token id="9" string="," />
            <token id="10" string="N.Y." />
          </tokens>
        </chunking>
        <chunking id="8" string="had sent her and her husband a letter on their 50th wedding anniversary" type="VP">
          <tokens>
            <token id="16" string="had" />
            <token id="17" string="sent" />
            <token id="18" string="her" />
            <token id="19" string="and" />
            <token id="20" string="her" />
            <token id="21" string="husband" />
            <token id="22" string="a" />
            <token id="23" string="letter" />
            <token id="24" string="on" />
            <token id="25" string="their" />
            <token id="26" string="50th" />
            <token id="27" string="wedding" />
            <token id="28" string="anniversary" />
          </tokens>
        </chunking>
        <chunking id="9" string="Irene Rosseti" type="NP">
          <tokens>
            <token id="1" string="Irene" />
            <token id="2" string="Rosseti" />
          </tokens>
        </chunking>
        <chunking id="10" string="lives in Celoron , N.Y." type="VP">
          <tokens>
            <token id="6" string="lives" />
            <token id="7" string="in" />
            <token id="8" string="Celoron" />
            <token id="9" string="," />
            <token id="10" string="N.Y." />
          </tokens>
        </chunking>
        <chunking id="11" string="their 50th wedding anniversary" type="NP">
          <tokens>
            <token id="25" string="their" />
            <token id="26" string="50th" />
            <token id="27" string="wedding" />
            <token id="28" string="anniversary" />
          </tokens>
        </chunking>
        <chunking id="12" string="her and her husband" type="NP">
          <tokens>
            <token id="18" string="her" />
            <token id="19" string="and" />
            <token id="20" string="her" />
            <token id="21" string="husband" />
          </tokens>
        </chunking>
        <chunking id="13" string="said Miss Ball recently had sent her and her husband a letter on their 50th wedding anniversary" type="VP">
          <tokens>
            <token id="12" string="said" />
            <token id="13" string="Miss" />
            <token id="14" string="Ball" />
            <token id="15" string="recently" />
            <token id="16" string="had" />
            <token id="17" string="sent" />
            <token id="18" string="her" />
            <token id="19" string="and" />
            <token id="20" string="her" />
            <token id="21" string="husband" />
            <token id="22" string="a" />
            <token id="23" string="letter" />
            <token id="24" string="on" />
            <token id="25" string="their" />
            <token id="26" string="50th" />
            <token id="27" string="wedding" />
            <token id="28" string="anniversary" />
          </tokens>
        </chunking>
        <chunking id="14" string="Irene Rosseti , who now lives in Celoron , N.Y. ," type="NP">
          <tokens>
            <token id="1" string="Irene" />
            <token id="2" string="Rosseti" />
            <token id="3" string="," />
            <token id="4" string="who" />
            <token id="5" string="now" />
            <token id="6" string="lives" />
            <token id="7" string="in" />
            <token id="8" string="Celoron" />
            <token id="9" string="," />
            <token id="10" string="N.Y." />
            <token id="11" string="," />
          </tokens>
        </chunking>
        <chunking id="15" string="Miss Ball" type="NP">
          <tokens>
            <token id="13" string="Miss" />
            <token id="14" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Rosseti</governor>
          <dependent id="1">Irene</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">said</governor>
          <dependent id="2">Rosseti</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">lives</governor>
          <dependent id="4">who</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">lives</governor>
          <dependent id="5">now</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">Rosseti</governor>
          <dependent id="6">lives</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">N.Y.</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">N.Y.</governor>
          <dependent id="8">Celoron</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">lives</governor>
          <dependent id="10">N.Y.</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Ball</governor>
          <dependent id="13">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">sent</governor>
          <dependent id="14">Ball</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">sent</governor>
          <dependent id="15">recently</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">sent</governor>
          <dependent id="16">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">said</governor>
          <dependent id="17">sent</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">husband</governor>
          <dependent id="18">her</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">her</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">her</governor>
          <dependent id="20">her</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="17">sent</governor>
          <dependent id="21">husband</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">letter</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">sent</governor>
          <dependent id="23">letter</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">anniversary</governor>
          <dependent id="24">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="28">anniversary</governor>
          <dependent id="25">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">anniversary</governor>
          <dependent id="26">50th</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">anniversary</governor>
          <dependent id="27">wedding</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">letter</governor>
          <dependent id="28">anniversary</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="N.Y." type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="N.Y." />
          </tokens>
        </entity>
        <entity id="2" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="now" />
          </tokens>
        </entity>
        <entity id="3" string="Irene Rosseti" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Irene" />
            <token id="2" string="Rosseti" />
          </tokens>
        </entity>
        <entity id="4" string="50th" type="ORDINAL" score="0.0">
          <tokens>
            <token id="26" string="50th" />
          </tokens>
        </entity>
        <entity id="5" string="recently" type="DATE" score="0.0">
          <tokens>
            <token id="15" string="recently" />
          </tokens>
        </entity>
        <entity id="6" string="Celoron" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="Celoron" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="55" has_coreference="true">
      <content>``Even though she was a big star, she was still just Lucy to us,&amp;apost;&amp;apost; she recalled.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="though" lemma="though" stem="though" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="big" lemma="big" stem="big" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="star" lemma="star" stem="star" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="us" lemma="we" stem="u" pos="PRP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="recalled" lemma="recall" stem="recal" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (SBAR (RB Even) (IN though) (S (NP (PRP she)) (VP (VBD was) (NP (DT a) (JJ big) (NN star))))) (, ,) (NP (PRP she)) (VP (VBD was) (ADVP (RB still)) (ADVP (RB just)) (NP (NP (NNP Lucy)) (PP (TO to) (NP (PRP us)))))) (, ,) ('' '') (NP (PRP she)) (VP (VBD recalled)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Even though she was a big star" type="SBAR">
          <tokens>
            <token id="2" string="Even" />
            <token id="3" string="though" />
            <token id="4" string="she" />
            <token id="5" string="was" />
            <token id="6" string="a" />
            <token id="7" string="big" />
            <token id="8" string="star" />
          </tokens>
        </chunking>
        <chunking id="2" string="was a big star" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="a" />
            <token id="7" string="big" />
            <token id="8" string="star" />
          </tokens>
        </chunking>
        <chunking id="3" string="was still just Lucy to us" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="still" />
            <token id="13" string="just" />
            <token id="14" string="Lucy" />
            <token id="15" string="to" />
            <token id="16" string="us" />
          </tokens>
        </chunking>
        <chunking id="4" string="Lucy to us" type="NP">
          <tokens>
            <token id="14" string="Lucy" />
            <token id="15" string="to" />
            <token id="16" string="us" />
          </tokens>
        </chunking>
        <chunking id="5" string="Lucy" type="NP">
          <tokens>
            <token id="14" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="6" string="recalled" type="VP">
          <tokens>
            <token id="20" string="recalled" />
          </tokens>
        </chunking>
        <chunking id="7" string="us" type="NP">
          <tokens>
            <token id="16" string="us" />
          </tokens>
        </chunking>
        <chunking id="8" string="she" type="NP">
          <tokens>
            <token id="4" string="she" />
          </tokens>
        </chunking>
        <chunking id="9" string="a big star" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="big" />
            <token id="8" string="star" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="8">star</governor>
          <dependent id="2">Even</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">star</governor>
          <dependent id="3">though</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">star</governor>
          <dependent id="4">she</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">star</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">star</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">star</governor>
          <dependent id="7">big</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">Lucy</governor>
          <dependent id="8">star</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">Lucy</governor>
          <dependent id="10">she</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">Lucy</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">Lucy</governor>
          <dependent id="12">still</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">Lucy</governor>
          <dependent id="13">just</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">recalled</governor>
          <dependent id="14">Lucy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">us</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">Lucy</governor>
          <dependent id="16">us</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">recalled</governor>
          <dependent id="19">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">recalled</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Lucy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="56" has_coreference="true">
      <content>Hospital spokesman Wise said that the family has asked that donations be sent to the Lucille Ball Foundation, in care of Irella-Manella, 1800 Ave. of the Stars, Suite 900, Los Angeles, Ca. 90067.</content>
      <tokens>
        <token id="1" string="Hospital" lemma="Hospital" stem="hospit" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="spokesman" lemma="spokesman" stem="spokesman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="Wise" lemma="Wise" stem="wise" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="asked" lemma="ask" stem="ask" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="donations" lemma="donation" stem="donat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="sent" lemma="send" stem="sent" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Lucille" lemma="Lucille" stem="lucil" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="17" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="18" string="Foundation" lemma="Foundation" stem="foundat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="care" lemma="care" stem="care" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Irella-Manella" lemma="Irella-Manella" stem="irella-manella" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="1800" lemma="1800" stem="1800" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="26" string="Ave." lemma="Ave." stem="ave." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="Stars" lemma="Stars" stem="star" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="Suite" lemma="Suite" stem="suit" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="900" lemma="900" stem="900" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="33" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="35" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="36" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="Ca." lemma="Ca." stem="ca." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="38" string="90067" lemma="90067" stem="90067" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Hospital) (NN spokesman) (NNP Wise)) (VP (VBD said) (SBAR (IN that) (S (NP (DT the) (NN family)) (VP (VBZ has) (VP (VBN asked) (SBAR (IN that) (S (NP (NNS donations)) (VP (VB be) (VP (VBN sent) (PP (TO to) (NP (DT the) (NNP Lucille) (NNP Ball) (NNP Foundation))) (, ,) (PP (IN in) (NP (NP (NN care)) (PP (IN of) (NP (NP (NNP Irella-Manella)) (, ,) (NP (CD 1800) (NNP Ave.) (IN of) (DT the) (NNP Stars)) (, ,) (NP (NNP Suite) (CD 900)) (, ,) (NP (NNP Los) (NNP Angeles)) (, ,) (NP (NNP Ca.) (CD 90067))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="be sent to the Lucille Ball Foundation , in care of Irella-Manella , 1800 Ave. of the Stars , Suite 900 , Los Angeles , Ca. 90067" type="VP">
          <tokens>
            <token id="12" string="be" />
            <token id="13" string="sent" />
            <token id="14" string="to" />
            <token id="15" string="the" />
            <token id="16" string="Lucille" />
            <token id="17" string="Ball" />
            <token id="18" string="Foundation" />
            <token id="19" string="," />
            <token id="20" string="in" />
            <token id="21" string="care" />
            <token id="22" string="of" />
            <token id="23" string="Irella-Manella" />
            <token id="24" string="," />
            <token id="25" string="1800" />
            <token id="26" string="Ave." />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="Stars" />
            <token id="30" string="," />
            <token id="31" string="Suite" />
            <token id="32" string="900" />
            <token id="33" string="," />
            <token id="34" string="Los" />
            <token id="35" string="Angeles" />
            <token id="36" string="," />
            <token id="37" string="Ca." />
            <token id="38" string="90067" />
          </tokens>
        </chunking>
        <chunking id="2" string="asked that donations be sent to the Lucille Ball Foundation , in care of Irella-Manella , 1800 Ave. of the Stars , Suite 900 , Los Angeles , Ca. 90067" type="VP">
          <tokens>
            <token id="9" string="asked" />
            <token id="10" string="that" />
            <token id="11" string="donations" />
            <token id="12" string="be" />
            <token id="13" string="sent" />
            <token id="14" string="to" />
            <token id="15" string="the" />
            <token id="16" string="Lucille" />
            <token id="17" string="Ball" />
            <token id="18" string="Foundation" />
            <token id="19" string="," />
            <token id="20" string="in" />
            <token id="21" string="care" />
            <token id="22" string="of" />
            <token id="23" string="Irella-Manella" />
            <token id="24" string="," />
            <token id="25" string="1800" />
            <token id="26" string="Ave." />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="Stars" />
            <token id="30" string="," />
            <token id="31" string="Suite" />
            <token id="32" string="900" />
            <token id="33" string="," />
            <token id="34" string="Los" />
            <token id="35" string="Angeles" />
            <token id="36" string="," />
            <token id="37" string="Ca." />
            <token id="38" string="90067" />
          </tokens>
        </chunking>
        <chunking id="3" string="donations" type="NP">
          <tokens>
            <token id="11" string="donations" />
          </tokens>
        </chunking>
        <chunking id="4" string="care of Irella-Manella , 1800 Ave. of the Stars , Suite 900 , Los Angeles , Ca. 90067" type="NP">
          <tokens>
            <token id="21" string="care" />
            <token id="22" string="of" />
            <token id="23" string="Irella-Manella" />
            <token id="24" string="," />
            <token id="25" string="1800" />
            <token id="26" string="Ave." />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="Stars" />
            <token id="30" string="," />
            <token id="31" string="Suite" />
            <token id="32" string="900" />
            <token id="33" string="," />
            <token id="34" string="Los" />
            <token id="35" string="Angeles" />
            <token id="36" string="," />
            <token id="37" string="Ca." />
            <token id="38" string="90067" />
          </tokens>
        </chunking>
        <chunking id="5" string="Irella-Manella" type="NP">
          <tokens>
            <token id="23" string="Irella-Manella" />
          </tokens>
        </chunking>
        <chunking id="6" string="that donations be sent to the Lucille Ball Foundation , in care of Irella-Manella , 1800 Ave. of the Stars , Suite 900 , Los Angeles , Ca. 90067" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="donations" />
            <token id="12" string="be" />
            <token id="13" string="sent" />
            <token id="14" string="to" />
            <token id="15" string="the" />
            <token id="16" string="Lucille" />
            <token id="17" string="Ball" />
            <token id="18" string="Foundation" />
            <token id="19" string="," />
            <token id="20" string="in" />
            <token id="21" string="care" />
            <token id="22" string="of" />
            <token id="23" string="Irella-Manella" />
            <token id="24" string="," />
            <token id="25" string="1800" />
            <token id="26" string="Ave." />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="Stars" />
            <token id="30" string="," />
            <token id="31" string="Suite" />
            <token id="32" string="900" />
            <token id="33" string="," />
            <token id="34" string="Los" />
            <token id="35" string="Angeles" />
            <token id="36" string="," />
            <token id="37" string="Ca." />
            <token id="38" string="90067" />
          </tokens>
        </chunking>
        <chunking id="7" string="Ca. 90067" type="NP">
          <tokens>
            <token id="37" string="Ca." />
            <token id="38" string="90067" />
          </tokens>
        </chunking>
        <chunking id="8" string="Suite 900" type="NP">
          <tokens>
            <token id="31" string="Suite" />
            <token id="32" string="900" />
          </tokens>
        </chunking>
        <chunking id="9" string="Irella-Manella , 1800 Ave. of the Stars , Suite 900 , Los Angeles , Ca. 90067" type="NP">
          <tokens>
            <token id="23" string="Irella-Manella" />
            <token id="24" string="," />
            <token id="25" string="1800" />
            <token id="26" string="Ave." />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="Stars" />
            <token id="30" string="," />
            <token id="31" string="Suite" />
            <token id="32" string="900" />
            <token id="33" string="," />
            <token id="34" string="Los" />
            <token id="35" string="Angeles" />
            <token id="36" string="," />
            <token id="37" string="Ca." />
            <token id="38" string="90067" />
          </tokens>
        </chunking>
        <chunking id="10" string="has asked that donations be sent to the Lucille Ball Foundation , in care of Irella-Manella , 1800 Ave. of the Stars , Suite 900 , Los Angeles , Ca. 90067" type="VP">
          <tokens>
            <token id="8" string="has" />
            <token id="9" string="asked" />
            <token id="10" string="that" />
            <token id="11" string="donations" />
            <token id="12" string="be" />
            <token id="13" string="sent" />
            <token id="14" string="to" />
            <token id="15" string="the" />
            <token id="16" string="Lucille" />
            <token id="17" string="Ball" />
            <token id="18" string="Foundation" />
            <token id="19" string="," />
            <token id="20" string="in" />
            <token id="21" string="care" />
            <token id="22" string="of" />
            <token id="23" string="Irella-Manella" />
            <token id="24" string="," />
            <token id="25" string="1800" />
            <token id="26" string="Ave." />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="Stars" />
            <token id="30" string="," />
            <token id="31" string="Suite" />
            <token id="32" string="900" />
            <token id="33" string="," />
            <token id="34" string="Los" />
            <token id="35" string="Angeles" />
            <token id="36" string="," />
            <token id="37" string="Ca." />
            <token id="38" string="90067" />
          </tokens>
        </chunking>
        <chunking id="11" string="that the family has asked that donations be sent to the Lucille Ball Foundation , in care of Irella-Manella , 1800 Ave. of the Stars , Suite 900 , Los Angeles , Ca. 90067" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="the" />
            <token id="7" string="family" />
            <token id="8" string="has" />
            <token id="9" string="asked" />
            <token id="10" string="that" />
            <token id="11" string="donations" />
            <token id="12" string="be" />
            <token id="13" string="sent" />
            <token id="14" string="to" />
            <token id="15" string="the" />
            <token id="16" string="Lucille" />
            <token id="17" string="Ball" />
            <token id="18" string="Foundation" />
            <token id="19" string="," />
            <token id="20" string="in" />
            <token id="21" string="care" />
            <token id="22" string="of" />
            <token id="23" string="Irella-Manella" />
            <token id="24" string="," />
            <token id="25" string="1800" />
            <token id="26" string="Ave." />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="Stars" />
            <token id="30" string="," />
            <token id="31" string="Suite" />
            <token id="32" string="900" />
            <token id="33" string="," />
            <token id="34" string="Los" />
            <token id="35" string="Angeles" />
            <token id="36" string="," />
            <token id="37" string="Ca." />
            <token id="38" string="90067" />
          </tokens>
        </chunking>
        <chunking id="12" string="1800 Ave. of the Stars" type="NP">
          <tokens>
            <token id="25" string="1800" />
            <token id="26" string="Ave." />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="Stars" />
          </tokens>
        </chunking>
        <chunking id="13" string="the family" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="family" />
          </tokens>
        </chunking>
        <chunking id="14" string="said that the family has asked that donations be sent to the Lucille Ball Foundation , in care of Irella-Manella , 1800 Ave. of the Stars , Suite 900 , Los Angeles , Ca. 90067" type="VP">
          <tokens>
            <token id="4" string="said" />
            <token id="5" string="that" />
            <token id="6" string="the" />
            <token id="7" string="family" />
            <token id="8" string="has" />
            <token id="9" string="asked" />
            <token id="10" string="that" />
            <token id="11" string="donations" />
            <token id="12" string="be" />
            <token id="13" string="sent" />
            <token id="14" string="to" />
            <token id="15" string="the" />
            <token id="16" string="Lucille" />
            <token id="17" string="Ball" />
            <token id="18" string="Foundation" />
            <token id="19" string="," />
            <token id="20" string="in" />
            <token id="21" string="care" />
            <token id="22" string="of" />
            <token id="23" string="Irella-Manella" />
            <token id="24" string="," />
            <token id="25" string="1800" />
            <token id="26" string="Ave." />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="Stars" />
            <token id="30" string="," />
            <token id="31" string="Suite" />
            <token id="32" string="900" />
            <token id="33" string="," />
            <token id="34" string="Los" />
            <token id="35" string="Angeles" />
            <token id="36" string="," />
            <token id="37" string="Ca." />
            <token id="38" string="90067" />
          </tokens>
        </chunking>
        <chunking id="15" string="Los Angeles" type="NP">
          <tokens>
            <token id="34" string="Los" />
            <token id="35" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="16" string="Hospital spokesman Wise" type="NP">
          <tokens>
            <token id="1" string="Hospital" />
            <token id="2" string="spokesman" />
            <token id="3" string="Wise" />
          </tokens>
        </chunking>
        <chunking id="17" string="sent to the Lucille Ball Foundation , in care of Irella-Manella , 1800 Ave. of the Stars , Suite 900 , Los Angeles , Ca. 90067" type="VP">
          <tokens>
            <token id="13" string="sent" />
            <token id="14" string="to" />
            <token id="15" string="the" />
            <token id="16" string="Lucille" />
            <token id="17" string="Ball" />
            <token id="18" string="Foundation" />
            <token id="19" string="," />
            <token id="20" string="in" />
            <token id="21" string="care" />
            <token id="22" string="of" />
            <token id="23" string="Irella-Manella" />
            <token id="24" string="," />
            <token id="25" string="1800" />
            <token id="26" string="Ave." />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="Stars" />
            <token id="30" string="," />
            <token id="31" string="Suite" />
            <token id="32" string="900" />
            <token id="33" string="," />
            <token id="34" string="Los" />
            <token id="35" string="Angeles" />
            <token id="36" string="," />
            <token id="37" string="Ca." />
            <token id="38" string="90067" />
          </tokens>
        </chunking>
        <chunking id="18" string="care" type="NP">
          <tokens>
            <token id="21" string="care" />
          </tokens>
        </chunking>
        <chunking id="19" string="the Lucille Ball Foundation" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="Lucille" />
            <token id="17" string="Ball" />
            <token id="18" string="Foundation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Wise</governor>
          <dependent id="1">Hospital</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Wise</governor>
          <dependent id="2">spokesman</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">said</governor>
          <dependent id="3">Wise</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">asked</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">family</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">asked</governor>
          <dependent id="7">family</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">asked</governor>
          <dependent id="8">has</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">said</governor>
          <dependent id="9">asked</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">sent</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">sent</governor>
          <dependent id="11">donations</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">sent</governor>
          <dependent id="12">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">asked</governor>
          <dependent id="13">sent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Foundation</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">Foundation</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Foundation</governor>
          <dependent id="16">Lucille</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Foundation</governor>
          <dependent id="17">Ball</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">sent</governor>
          <dependent id="18">Foundation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">care</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">sent</governor>
          <dependent id="21">care</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Irella-Manella</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">care</governor>
          <dependent id="23">Irella-Manella</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="29">Stars</governor>
          <dependent id="25">1800</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Stars</governor>
          <dependent id="26">Ave.</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">Stars</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">Stars</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="23">Irella-Manella</governor>
          <dependent id="29">Stars</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="23">Irella-Manella</governor>
          <dependent id="31">Suite</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="31">Suite</governor>
          <dependent id="32">900</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Angeles</governor>
          <dependent id="34">Los</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="23">Irella-Manella</governor>
          <dependent id="35">Angeles</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="23">Irella-Manella</governor>
          <dependent id="37">Ca.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="37">Ca.</governor>
          <dependent id="38">90067</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="90067" type="NUMBER" score="0.0">
          <tokens>
            <token id="38" string="90067" />
          </tokens>
        </entity>
        <entity id="2" string="1800" type="DATE" score="0.0">
          <tokens>
            <token id="25" string="1800" />
          </tokens>
        </entity>
        <entity id="3" string="Irella-Manella" type="LOCATION" score="0.0">
          <tokens>
            <token id="23" string="Irella-Manella" />
          </tokens>
        </entity>
        <entity id="4" string="900" type="NUMBER" score="0.0">
          <tokens>
            <token id="32" string="900" />
          </tokens>
        </entity>
        <entity id="5" string="Lucille Ball Foundation" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="16" string="Lucille" />
            <token id="17" string="Ball" />
            <token id="18" string="Foundation" />
          </tokens>
        </entity>
        <entity id="6" string="Wise" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Wise" />
          </tokens>
        </entity>
        <entity id="7" string="Los Angeles" type="LOCATION" score="0.0">
          <tokens>
            <token id="34" string="Los" />
            <token id="35" string="Angeles" />
          </tokens>
        </entity>
        <entity id="8" string="Ca." type="LOCATION" score="0.0">
          <tokens>
            <token id="37" string="Ca." />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="14-15" string="Lucille Ball" id_sentence="1" />
      <mentions>
        <mention ids_tokens="10" string="her" id_sentence="2" />
        <mention ids_tokens="15-17" string="Miss Ball's" id_sentence="4" />
        <mention ids_tokens="4" string="her" id_sentence="5" />
        <mention ids_tokens="16" string="her" id_sentence="5" />
        <mention ids_tokens="13-15" string="Miss Ball's" id_sentence="6" />
        <mention ids_tokens="1-3" string="Miss Ball's" id_sentence="7" />
        <mention ids_tokens="1-2" string="Miss Ball" id_sentence="8" />
        <mention ids_tokens="4" string="her" id_sentence="8" />
        <mention ids_tokens="10" string="she" id_sentence="8" />
        <mention ids_tokens="2" string="her" id_sentence="9" />
        <mention ids_tokens="7" string="her" id_sentence="9" />
        <mention ids_tokens="11" string="her" id_sentence="9" />
        <mention ids_tokens="28" string="I" id_sentence="9" />
        <mention ids_tokens="33" string="my" id_sentence="9" />
        <mention ids_tokens="1-2" string="Miss Ball" id_sentence="10" />
        <mention ids_tokens="13" string="her" id_sentence="10" />
        <mention ids_tokens="2" string="She" id_sentence="11" />
        <mention ids_tokens="1" string="Her" id_sentence="12" />
        <mention ids_tokens="1-2" string="Miss Ball" id_sentence="15" />
        <mention ids_tokens="2" string="Ball" id_sentence="15" />
        <mention ids_tokens="4" string="her" id_sentence="15" />
        <mention ids_tokens="15-17" string="I Love Lucy" id_sentence="15" />
        <mention ids_tokens="16-18" string="Miss Ball's" id_sentence="19" />
        <mention ids_tokens="14-15" string="Miss Ball" id_sentence="28" />
        <mention ids_tokens="30-32" string="I Love Lucy" id_sentence="28" />
        <mention ids_tokens="49-52" string="Lucille Ball , 1911-1989" id_sentence="28" />
        <mention ids_tokens="14-16" string="Miss Ball's" id_sentence="35" />
        <mention ids_tokens="22" string="her" id_sentence="35" />
        <mention ids_tokens="13-15" string="Miss Ball's" id_sentence="40" />
        <mention ids_tokens="2" string="Her" id_sentence="41" />
        <mention ids_tokens="6" string="her" id_sentence="41" />
        <mention ids_tokens="12" string="her" id_sentence="41" />
        <mention ids_tokens="15" string="her" id_sentence="41" />
        <mention ids_tokens="20" string="her" id_sentence="41" />
        <mention ids_tokens="6" string="her" id_sentence="42" />
        <mention ids_tokens="3" string="she" id_sentence="45" />
        <mention ids_tokens="1" string="She" id_sentence="46" />
        <mention ids_tokens="1" string="She" id_sentence="47" />
        <mention ids_tokens="1" string="She" id_sentence="48" />
        <mention ids_tokens="5" string="she" id_sentence="48" />
        <mention ids_tokens="33-35" string="I Love Lucy" id_sentence="49" />
        <mention ids_tokens="2" string="She" id_sentence="50" />
        <mention ids_tokens="14" string="she" id_sentence="50" />
        <mention ids_tokens="2-3" string="Miss Ball" id_sentence="53" />
        <mention ids_tokens="7" string="her" id_sentence="53" />
        <mention ids_tokens="22" string="she" id_sentence="53" />
        <mention ids_tokens="13-14" string="Miss Ball" id_sentence="54" />
        <mention ids_tokens="18" string="her" id_sentence="54" />
        <mention ids_tokens="20" string="her" id_sentence="54" />
      </mentions>
    </coreference>
    <coreference id="2" type="NOMINAL">
      <referenced ids_tokens="8-9" string="childhood neighbors" id_sentence="1" />
      <mentions>
        <mention ids_tokens="20-21" string="their neighbors" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="3" type="NOMINAL">
      <referenced ids_tokens="13-14-15-16" string="Miss Ball 's death" id_sentence="6" />
      <mentions>
        <mention ids_tokens="11-15" string="the death of Lucille Ball" id_sentence="1" />
      </mentions>
    </coreference>
    <coreference id="5" type="NOMINAL">
      <referenced ids_tokens="10-11-12" string="her television family" id_sentence="2" />
      <mentions>
        <mention ids_tokens="1" string="She" id_sentence="3" />
        <mention ids_tokens="1-2" string="Her family" id_sentence="12" />
        <mention ids_tokens="5" string="her" id_sentence="12" />
        <mention ids_tokens="2" string="She" id_sentence="13" />
        <mention ids_tokens="3" string="she" id_sentence="14" />
        <mention ids_tokens="14" string="her" id_sentence="14" />
        <mention ids_tokens="9-10" string="my family" id_sentence="29" />
        <mention ids_tokens="18-19" string="no family" id_sentence="53" />
        <mention ids_tokens="6-7" string="the family" id_sentence="56" />
      </mentions>
    </coreference>
    <coreference id="6" type="LIST">
      <referenced ids_tokens="13-14-15-16" string="crazy and delighted viewers" id_sentence="2" />
      <mentions>
        <mention ids_tokens="13" string="we" id_sentence="5" />
        <mention ids_tokens="21" string="you" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="9-10-11" string="emergency heart surgery" id_sentence="3" />
      <mentions>
        <mention ids_tokens="8-10" string="the heart surgery" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="8" type="PROPER">
      <referenced ids_tokens="18-19-20" string="spokesman Ron Wise" id_sentence="6" />
      <mentions>
        <mention ids_tokens="8" string="Wise" id_sentence="12" />
        <mention ids_tokens="1" string="He" id_sentence="14" />
        <mention ids_tokens="1-3" string="Hospital spokesman Wise" id_sentence="56" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="11-12" string="her daughter" id_sentence="9" />
      <mentions>
        <mention ids_tokens="7" string="her" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="13" type="NOMINAL">
      <referenced ids_tokens="4-5-6-7-8-9-10" string="an irreparable loss ... to our industry" id_sentence="37" />
      <mentions>
        <mention ids_tokens="13-14" string="her death" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="14" type="PROPER">
      <referenced ids_tokens="6-7" string="early Wednesday" id_sentence="14" />
      <mentions>
        <mention ids_tokens="35" string="Wednesday" id_sentence="28" />
      </mentions>
    </coreference>
    <coreference id="15" type="NOMINAL">
      <referenced ids_tokens="4-5-6-7" string="her late former husband" id_sentence="15" />
      <mentions>
        <mention ids_tokens="18-21" string="her and her husband" id_sentence="54" />
        <mention ids_tokens="25" string="their" id_sentence="54" />
        <mention ids_tokens="16" string="us" id_sentence="55" />
      </mentions>
    </coreference>
    <coreference id="16" type="PROPER">
      <referenced ids_tokens="4" string="Lucy" id_sentence="20" />
      <mentions>
        <mention ids_tokens="16-17" string="Love Lucy" id_sentence="15" />
        <mention ids_tokens="11-31" string="the `` I Love Lucy'' characters to Hollywood , where Lucy and Ethel spotted actor William Holden in a restaurant" id_sentence="24" />
        <mention ids_tokens="11-19" string="the `` I Love Lucy'' characters to Hollywood" id_sentence="24" />
        <mention ids_tokens="2" string="She" id_sentence="26" />
        <mention ids_tokens="31-32" string="Love Lucy" id_sentence="28" />
        <mention ids_tokens="1" string="She" id_sentence="32" />
        <mention ids_tokens="8" string="her" id_sentence="43" />
        <mention ids_tokens="34-35" string="Love Lucy" id_sentence="49" />
        <mention ids_tokens="10" string="she" id_sentence="55" />
        <mention ids_tokens="14-16" string="Lucy to us" id_sentence="55" />
      </mentions>
    </coreference>
    <coreference id="17" type="PROPER">
      <referenced ids_tokens="14-15" string="Vivian Vance" id_sentence="16" />
      <mentions>
        <mention ids_tokens="7" string="she" id_sentence="17" />
        <mention ids_tokens="12" string="her" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="18" type="PROPER">
      <referenced ids_tokens="25-26" string="Ethel Mertz" id_sentence="16" />
      <mentions>
        <mention ids_tokens="24" string="Ethel" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="19" type="NOMINAL">
      <referenced ids_tokens="2-3-4" string="the ground-breaking show" id_sentence="16" />
      <mentions>
        <mention ids_tokens="1-2" string="The show" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="21" type="PROPER">
      <referenced ids_tokens="18-19-20" string="actress-comedian Jane Curtin" id_sentence="17" />
      <mentions>
        <mention ids_tokens="10" string="I" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="22" type="NOMINAL">
      <referenced ids_tokens="12-13" string="her shows" id_sentence="18" />
      <mentions>
        <mention ids_tokens="12" string="shows" id_sentence="52" />
      </mentions>
    </coreference>
    <coreference id="23" type="NOMINAL">
      <referenced ids_tokens="16-17-18-19-20" string="Miss Ball 's faultless timing" id_sentence="19" />
      <mentions>
        <mention ids_tokens="12-13" string="her timing" id_sentence="41" />
      </mentions>
    </coreference>
    <coreference id="24" type="NOMINAL">
      <referenced ids_tokens="28-29" string="extravagant pratfalls" id_sentence="19" />
      <mentions>
        <mention ids_tokens="15" string="us" id_sentence="21" />
        <mention ids_tokens="3" string="us" id_sentence="23" />
        <mention ids_tokens="8" string="us" id_sentence="23" />
        <mention ids_tokens="14" string="ourselves" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="25" type="PROPER">
      <referenced ids_tokens="8-9" string="an M.A." id_sentence="20" />
      <mentions>
        <mention ids_tokens="3" string="she" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="26" type="PROPER">
      <referenced ids_tokens="1-2-3" string="Comedian Whoopi Goldberg" id_sentence="22" />
      <mentions>
        <mention ids_tokens="1" string="She" id_sentence="23" />
        <mention ids_tokens="1-2" string="Miss Goldberg" id_sentence="24" />
        <mention ids_tokens="4" string="her" id_sentence="24" />
        <mention ids_tokens="19-20" string="Miss Goldberg" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="27" type="NOMINAL">
      <referenced ids_tokens="4-5-6" string="her favorite episode" id_sentence="24" />
      <mentions>
        <mention ids_tokens="2" string="That" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="28" type="NOMINAL">
      <referenced ids_tokens="14-15-16-17" string="Love Lucy '' characters" id_sentence="24" />
      <mentions>
        <mention ids_tokens="5" string="we" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="29" type="PROPER">
      <referenced ids_tokens="26-27-28-29-30-31" string="actor William Holden in a restaurant" id_sentence="24" />
      <mentions>
        <mention ids_tokens="6" string="him" id_sentence="26" />
        <mention ids_tokens="17" string="him" id_sentence="26" />
      </mentions>
    </coreference>
    <coreference id="31" type="NOMINAL">
      <referenced ids_tokens="8-9-10" string="a compact mirror" id_sentence="26" />
      <mentions>
        <mention ids_tokens="2" string="that" id_sentence="27" />
        <mention ids_tokens="5-13" string="an example of how everyone can identify with Lucy" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="33" type="NOMINAL">
      <referenced ids_tokens="10-11-12-13-14-15-16-17-18-19-20" string="the Beverly Hills home Miss Ball shared with husband Gary Morton" id_sentence="28" />
      <mentions>
        <mention ids_tokens="5" string="it" id_sentence="30" />
      </mentions>
    </coreference>
    <coreference id="35" type="PROPER">
      <referenced ids_tokens="9-10-11" string="Rosati , 40" id_sentence="30" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="29" />
        <mention ids_tokens="4" string="I" id_sentence="29" />
        <mention ids_tokens="9" string="my" id_sentence="29" />
        <mention ids_tokens="2" string="I" id_sentence="31" />
        <mention ids_tokens="7" string="I" id_sentence="31" />
        <mention ids_tokens="1" string="He" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="38" type="NOMINAL">
      <referenced ids_tokens="20-21-22" string="its first lady" id_sentence="36" />
      <mentions>
        <mention ids_tokens="1" string="Her" id_sentence="37" />
        <mention ids_tokens="12-13" string="this lady" id_sentence="51" />
        <mention ids_tokens="17-23" string="really , because she's still here" id_sentence="51" />
        <mention ids_tokens="20" string="she" id_sentence="51" />
      </mentions>
    </coreference>
    <coreference id="39" type="PROPER">
      <referenced ids_tokens="1-2-3" string="Actor Danny DeVito" id_sentence="38" />
      <mentions>
        <mention ids_tokens="12" string="he" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="40" type="PROPER">
      <referenced ids_tokens="10-11-12-13" string="Miss Ball in 1981" id_sentence="38" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="39" />
        <mention ids_tokens="4" string="it" id_sentence="39" />
        <mention ids_tokens="6" string="it" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="43" type="LIST">
      <referenced ids_tokens="26-27-28-29-30-31" string="the former president and Nancy Reagan" id_sentence="41" />
      <mentions>
        <mention ids_tokens="2" string="We" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="44" type="LIST">
      <referenced ids_tokens="5-6-7-8" string="an actress or comedienne" id_sentence="47" />
      <mentions>
        <mention ids_tokens="10" string="our" id_sentence="49" />
        <mention ids_tokens="5" string="they" id_sentence="52" />
      </mentions>
    </coreference>
    <coreference id="45" type="NOMINAL">
      <referenced ids_tokens="3-4" string="baby boomers" id_sentence="49" />
      <mentions>
        <mention ids_tokens="7" string="We" id_sentence="51" />
      </mentions>
    </coreference>
    <coreference id="46" type="PROPER">
      <referenced ids_tokens="22-23-24-25-26-27-28-29-30-31-32-33-34-35-36-37-38-39-40-41-42-43-44" string="comedian Victoria Jackson , who was born two years after `` I Love Lucy '' went off the air as a regular series" id_sentence="49" />
      <mentions>
        <mention ids_tokens="6" string="me" id_sentence="50" />
        <mention ids_tokens="11" string="I" id_sentence="50" />
        <mention ids_tokens="17" string="me" id_sentence="50" />
      </mentions>
    </coreference>
    <coreference id="47" type="PROPER">
      <referenced ids_tokens="12" string="N.Y" id_sentence="53" />
      <mentions>
        <mention ids_tokens="10" string="N.Y." id_sentence="54" />
      </mentions>
    </coreference>
    <coreference id="48" type="PROPER">
      <referenced ids_tokens="1-2" string="Irene Rosseti" id_sentence="54" />
      <mentions>
        <mention ids_tokens="4" string="she" id_sentence="55" />
        <mention ids_tokens="19" string="she" id_sentence="55" />
      </mentions>
    </coreference>
  </coreferences>
</document>
